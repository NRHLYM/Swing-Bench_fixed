{"problem_statement": "Can not set stylesheet path from `c` via the `c-api`\n### Context\r\nMost of the important `usvg` options written in `rust` are available in the `c` api. Some of the accessible options are setting the language, resource directory, rendering modes, and so on. However, the stylesheet option, which is available in the `rust` api, is *not* available in the `c` api.\r\n\r\nhttps://github.com/linebender/resvg/blob/bda7db0d0b2eb32c5f63f90279cec19613945a9d/crates/usvg/src/main.rs#L28-L29\r\n------\r\n### Question\r\n- Are there plans to add this option to the `c-api`? Something like this perhaps?\r\n```h\r\n/**\r\n *\r\n * @brief Sets a path that will be used when resolving CSS attributes.\r\n *\r\n */\r\nvoid resvg_options_set_stylesheet(resvg_options *opt, const char *path);\r\n```\r\n\r\n**P.S.**: Great work on the library!\n", "patch": "diff --git a/crates/c-api/examples/cairo/example.c b/crates/c-api/examples/cairo/example.c\nindex 29e25903..b72384c0 100644\n--- a/crates/c-api/examples/cairo/example.c\n+++ b/crates/c-api/examples/cairo/example.c\n@@ -15,12 +15,17 @@ int main(int argc, char **argv)\n         abort();\n     }\n \n+    // Initialize resvg's library logging system\n     resvg_init_log();\n \n     resvg_options *opt = resvg_options_create();\n     resvg_options_load_system_fonts(opt);\n \n+    // Optionally, you can add some CSS to control the SVG rendering.\n+    resvg_options_set_stylesheet(opt, \"svg { fill: black; }\");\n+\n     resvg_render_tree *tree;\n+    // Construct a tree from the svg file and pass in some options\n     int err = resvg_parse_tree_from_file(argv[1], opt, &tree);\n     resvg_options_destroy(opt);\n     if (err != RESVG_OK)\n@@ -33,6 +38,7 @@ int main(int argc, char **argv)\n     int width = (int)size.width;\n     int height = (int)size.height;\n \n+    // Using the dimension info, allocate enough pixels to account for the entire image\n     cairo_surface_t *surface = cairo_image_surface_create(CAIRO_FORMAT_ARGB32, width, height);\n \n     /* resvg doesn't support stride, so cairo_surface_t should have no padding */\n@@ -50,9 +56,11 @@ int main(int argc, char **argv)\n         surface_data[i + 2] = r;\n     }\n \n+    // Save image\n     cairo_surface_write_to_png(surface, argv[2]);\n-    cairo_surface_destroy(surface);\n \n+    // De-initialize the allocated memory\n+    cairo_surface_destroy(surface);\n     resvg_tree_destroy(tree);\n \n     return 0;\ndiff --git a/crates/c-api/lib.rs b/crates/c-api/lib.rs\nindex c7ff2843..1ddeb6f8 100644\n--- a/crates/c-api/lib.rs\n+++ b/crates/c-api/lib.rs\n@@ -158,6 +158,20 @@ pub extern \"C\" fn resvg_options_set_dpi(opt: *mut resvg_options, dpi: f32) {\n     cast_opt(opt).dpi = dpi as f32;\n }\n \n+/// @brief Provides the content of a stylesheet that will be used when resolving CSS attributes.\n+///\n+/// Must be UTF-8. Can be set to NULL.\n+///\n+/// Default: NULL\n+#[no_mangle]\n+pub extern \"C\" fn resvg_options_set_stylesheet(opt: *mut resvg_options, content: *const c_char) {\n+    if content.is_null() {\n+        cast_opt(opt).style_sheet = None;\n+    } else {\n+        cast_opt(opt).style_sheet = Some(cstr_to_str(content).unwrap().into());\n+    }\n+}\n+\n /// @brief Sets the default font family.\n ///\n /// Will be used when no `font-family` attribute is set in the SVG.\ndiff --git a/crates/c-api/resvg.h b/crates/c-api/resvg.h\nindex 271b7fe8..e3d4917f 100644\n--- a/crates/c-api/resvg.h\n+++ b/crates/c-api/resvg.h\n@@ -173,6 +173,15 @@ void resvg_options_set_resources_dir(resvg_options *opt, const char *path);\n  */\n void resvg_options_set_dpi(resvg_options *opt, float dpi);\n \n+/**\n+ * @brief Provides the content of a stylesheet that will be used when resolving CSS attributes.\n+ *\n+ * Must be UTF-8. Can be set to NULL.\n+ *\n+ * Default: NULL\n+ */\n+void resvg_options_set_stylesheet(resvg_options *opt, const char *content);\n+\n /**\n  * @brief Sets the default font family.\n  *\n", "instance_id": "linebender__resvg-873", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: the stylesheet option available in the Rust API of the `usvg` library is not exposed in the C API. The goal is to add this functionality to the C API, and a suggested function signature is provided, which helps in understanding the expected outcome. The context provided also references specific lines in the codebase, which adds to the clarity. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define how the stylesheet content should be handled (e.g., whether it\u2019s a file path or raw CSS content, though the code changes suggest the latter). Additionally, there are no mentions of potential constraints, edge cases, or specific requirements for error handling. While the intent is clear, these missing details prevent it from being fully comprehensive.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to several factors. First, the scope of the code changes is relatively small and localized, involving modifications to a few files (`resvg.h` for the C API header, `lib.rs` for the implementation, and an example file for demonstration). The changes primarily consist of adding a new function to set the stylesheet content in the C API, mirroring existing functionality in the Rust API, which reduces the need for deep architectural understanding or complex logic design. Second, the technical concepts required are straightforward: basic C and Rust interoperability (using `extern \"C\"` and handling C strings), understanding of the `usvg` library\u2019s options structure, and minimal memory management. Third, the code changes do not indicate significant handling of edge cases beyond checking for a null pointer, and no complex error handling or performance considerations are apparent. Overall, this task requires understanding some code logic and making simple modifications to extend an existing API, fitting well within the easy category. The score of 0.3 reflects that while it\u2019s not trivial (due to the need for C-Rust interoperability), it\u2019s still a relatively simple feature addition for someone familiar with the languages and the library."}
{"problem_statement": "Switch to zune-jpeg\nApparently `jpeg-decoder` is somewhat deprecated.\r\n\r\nAdditionally:\r\n\r\n- [x] try to decode JPEG directly to `tiny_skia::Pixmap` to avoid needless allocations\r\n- [ ] ~~try to use JPEG-native resizing when possible #781~~\n", "patch": "diff --git a/Cargo.lock b/Cargo.lock\nindex da7bf245f..989aa3619 100644\n--- a/Cargo.lock\n+++ b/Cargo.lock\n@@ -135,12 +135,6 @@ version = \"0.12.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"029d73f573d8e8d63e6d5020011d3255b28c3ba85d6cf870a07184ed23de9284\"\n \n-[[package]]\n-name = \"jpeg-decoder\"\n-version = \"0.3.1\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"f5d4a7da358eff58addd2877a45865158f0d78c911d43a5784ceb7bbf52833b0\"\n-\n [[package]]\n name = \"kurbo\"\n version = \"0.11.0\"\n@@ -212,7 +206,6 @@ name = \"resvg\"\n version = \"0.42.0\"\n dependencies = [\n  \"gif\",\n- \"jpeg-decoder\",\n  \"log\",\n  \"once_cell\",\n  \"pico-args\",\n@@ -221,6 +214,7 @@ dependencies = [\n  \"svgtypes\",\n  \"tiny-skia\",\n  \"usvg\",\n+ \"zune-jpeg\",\n ]\n \n [[package]]\n@@ -449,3 +443,18 @@ name = \"xmlwriter\"\n version = \"0.1.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n checksum = \"ec7a2a501ed189703dba8b08142f057e887dfc4b2cc4db2d343ac6376ba3e0b9\"\n+\n+[[package]]\n+name = \"zune-core\"\n+version = \"0.4.12\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"3f423a2c17029964870cfaabb1f13dfab7d092a62a29a89264f4d36990ca414a\"\n+\n+[[package]]\n+name = \"zune-jpeg\"\n+version = \"0.4.11\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"ec866b44a2a1fd6133d363f073ca1b179f438f99e7e5bfb1e33f7181facfe448\"\n+dependencies = [\n+ \"zune-core\",\n+]\ndiff --git a/crates/resvg/Cargo.toml b/crates/resvg/Cargo.toml\nindex d4a6d0327..85ec077da 100644\n--- a/crates/resvg/Cargo.toml\n+++ b/crates/resvg/Cargo.toml\n@@ -16,13 +16,13 @@ required-features = [\"text\", \"system-fonts\", \"memmap-fonts\"]\n \n [dependencies]\n gif = { version = \"0.13\", optional = true }\n-jpeg-decoder = { version = \"0.3\", default-features = false, features = [\"platform_independent\"], optional = true }\n log = \"0.4\"\n pico-args = { version = \"0.5\", features = [\"eq-separator\"] }\n rgb = \"0.8\"\n svgtypes = \"0.15.1\"\n tiny-skia = \"0.11.4\"\n usvg = { path = \"../usvg\", version = \"0.42.0\", default-features = false }\n+zune-jpeg = { version = \"0.4\", optional = true }\n \n [dev-dependencies]\n once_cell = \"1.5\"\n@@ -40,4 +40,4 @@ memmap-fonts = [\"usvg/memmap-fonts\"]\n # Enables decoding and rendering of raster images.\n # When disabled, `image` elements with SVG data will still be rendered.\n # Adds around 200KiB to your binary.\n-raster-images = [\"gif\", \"jpeg-decoder\"]\n+raster-images = [\"gif\", \"dep:zune-jpeg\"]\ndiff --git a/crates/resvg/src/image.rs b/crates/resvg/src/image.rs\nindex 68ac72ce6..e63e0a079 100644\n--- a/crates/resvg/src/image.rs\n+++ b/crates/resvg/src/image.rs\n@@ -78,31 +78,16 @@ mod raster_images {\n     }\n \n     fn decode_jpeg(data: &[u8]) -> Option<tiny_skia::Pixmap> {\n-        let mut decoder = jpeg_decoder::Decoder::new(data);\n+        use zune_jpeg::zune_core::colorspace::ColorSpace;\n+        use zune_jpeg::zune_core::options::DecoderOptions;\n+\n+        let options = DecoderOptions::default().jpeg_set_out_colorspace(ColorSpace::RGBA);\n+        let mut decoder = zune_jpeg::JpegDecoder::new_with_options(data, options);\n         let img_data = decoder.decode().ok()?;\n         let info = decoder.info()?;\n \n         let size = tiny_skia::IntSize::from_wh(info.width as u32, info.height as u32)?;\n-\n-        let data = match info.pixel_format {\n-            jpeg_decoder::PixelFormat::RGB24 => img_data,\n-            jpeg_decoder::PixelFormat::L8 => {\n-                let mut rgb_data: Vec<u8> = Vec::with_capacity(img_data.len() * 3);\n-                for gray in img_data {\n-                    rgb_data.push(gray);\n-                    rgb_data.push(gray);\n-                    rgb_data.push(gray);\n-                }\n-\n-                rgb_data\n-            }\n-            _ => return None,\n-        };\n-\n-        let (w, h) = size.dimensions();\n-        let mut pixmap = tiny_skia::Pixmap::new(w, h)?;\n-        rgb_to_pixmap(&data, &mut pixmap);\n-        Some(pixmap)\n+        tiny_skia::Pixmap::from_vec(img_data, size)\n     }\n \n     fn decode_gif(data: &[u8]) -> Option<tiny_skia::Pixmap> {\n@@ -122,21 +107,6 @@ mod raster_images {\n         Some(pixmap)\n     }\n \n-    fn rgb_to_pixmap(data: &[u8], pixmap: &mut tiny_skia::Pixmap) {\n-        use rgb::FromSlice;\n-\n-        let mut i = 0;\n-        let dst = pixmap.data_mut();\n-        for p in data.as_rgb() {\n-            dst[i + 0] = p.r;\n-            dst[i + 1] = p.g;\n-            dst[i + 2] = p.b;\n-            dst[i + 3] = 255;\n-\n-            i += tiny_skia::BYTES_PER_PIXEL;\n-        }\n-    }\n-\n     fn rgba_to_pixmap(data: &[u8], pixmap: &mut tiny_skia::Pixmap) {\n         use rgb::FromSlice;\n \n", "instance_id": "linebender__resvg-789", "clarity": 1, "difficulty": 0.35, "clarity_explanation": "The problem statement is quite brief and lacks critical details, leading to significant ambiguities. The goal of switching from `jpeg-decoder` to `zune-jpeg` is mentioned, along with a note about decoding JPEG directly to `tiny_skia::Pixmap` to avoid allocations. However, there is no detailed explanation of why `jpeg-decoder` is deprecated, what specific issues or limitations it has, or what benefits `zune-jpeg` offers. Additionally, there are no explicit input/output formats, constraints, or requirements for compatibility with the existing codebase. The crossed-out task about JPEG-native resizing adds further confusion as it is unclear whether it is relevant to the current scope. Overall, the statement provides a high-level intent but misses crucial context and specifics needed for a clear understanding of the task.", "difficulty_explanation": "The difficulty of this task falls in the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The changes are relatively localized, primarily affecting dependency management (`Cargo.toml` and `Cargo.lock`) and a specific module (`image.rs`) for JPEG decoding. The modifications involve replacing one library with another and updating the decoding logic. The codebase impact is minimal, with no apparent architectural changes or cross-module dependencies beyond the image decoding logic. The amount of code change is small, with a few lines added or removed.\n\n2. **Technical Concepts Involved**: The task requires basic familiarity with Rust dependency management (Cargo), understanding of image decoding libraries (`jpeg-decoder` vs. `zune-jpeg`), and integration with `tiny_skia::Pixmap` for rendering. The concepts are not particularly complex for someone with moderate Rust experience. The removal of manual RGB conversion logic in favor of `zune-jpeg`'s direct RGBA output simplifies the implementation.\n\n3. **Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases or specific error conditions to handle. The code changes show a straightforward replacement of the decoding logic, with error handling already present via `Option` returns in the `decode_jpeg` function. No additional complexity in error handling is introduced, though potential differences in how `zune-jpeg` handles malformed input or unsupported formats might need consideration (not evident from the diff).\n\n4. **Overall Complexity**: While the task requires understanding the purpose of the library switch and ensuring compatibility with the existing `tiny_skia` integration, it does not involve deep architectural changes or advanced concepts. The primary challenge lies in verifying that `zune-jpeg` behaves correctly with the existing codebase, which is a relatively straightforward validation task.\n\nGiven these points, a score of 0.35 reflects an \"Easy\" task that requires some understanding of the code logic and library integration but does not pose significant technical challenges or require extensive modifications."}
{"problem_statement": "Bug: Last elements in `basic_charset` initialization are discarded\n### Describe the bug\r\n\r\nWhen initializing a `basic_charset` with character arrays such as those returned by `digits()` and others, the last element of the array is incorrectly discarded. \r\n\r\nhttps://github.com/ashvardanian/StringZilla/blob/152ed046701aceae2c3d4c995b0b661a9aa06d95/include/stringzilla/stringzilla.hpp#L192-L195\r\n\r\nThis is due to the use of `count_characters - 1` in the loop that populates the `basic_charset` bitset. \r\nhttps://github.com/ashvardanian/StringZilla/blob/152ed046701aceae2c3d4c995b0b661a9aa06d95/include/stringzilla/stringzilla.hpp#L283-L289\r\n\r\nWhile this prevents including a null terminator for string literals like `sz::char_set(\"x\")`, it causes incorrect behavior when handling character arrays that do not have a null terminator, resulting in the exclusion of the final character.\r\n\r\nI believe this local block is the full extent of the affected code.\r\n\r\nhttps://github.com/ashvardanian/StringZilla/blob/152ed046701aceae2c3d4c995b0b661a9aa06d95/include/stringzilla/stringzilla.hpp#L330-L341\r\n\r\n### Steps to reproduce\r\n\r\n```cpp\r\n#include \"stringzilla/stringzilla.hpp\"\r\n\r\nnamespace sz = ashvardanian::stringzilla;\r\n\r\nint main() {\r\n        sz::string haystack = \"239\";\r\n\r\n        // Test with null-terminated string\r\n        assert(haystack.contains_only(sz::char_set(\"0123456789\")));\r\n        // Passes: null terminator is correctly discarded\r\n\r\n        // Test with initializer list\r\n        static std::initializer_list all = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'};\r\n        assert (haystack.contains_only(sz::char_set {all}));\r\n        // Passes: constructor for initializer list is called\r\n\r\n        // Test with carray\r\n        sz::carray<10> all_digits = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'};\r\n        assert(haystack.contains_only(sz::char_set {all_digits}));\r\n        assert(haystack.is_digit());\r\n        // Fails: '9' is incorrectly discarded\r\n}\r\n```\r\n\r\n### Expected behavior\r\n\r\nNo asserts\r\n\r\n### StringZilla version\r\n\r\nv3.11.0\r\n\r\n### Operating System\r\n\r\nUbuntu 22.04.5\r\n\r\n### Hardware architecture\r\n\r\nx86\r\n\r\n### Which interface are you using?\r\n\r\nC++ bindings\r\n\r\n### Contact Details\r\n\r\n_No response_\r\n\r\n### Are you open to being tagged as a contributor?\r\n\r\n- [X] I am open to being mentioned in the project `.git` history as a contributor\r\n\r\n### Is there an existing issue for this?\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's Code of Conduct\n", "patch": "diff --git a/include/stringzilla/stringzilla.hpp b/include/stringzilla/stringzilla.hpp\nindex a80da804..43869f08 100644\n--- a/include/stringzilla/stringzilla.hpp\n+++ b/include/stringzilla/stringzilla.hpp\n@@ -283,7 +283,7 @@ class basic_charset {\n     template <std::size_t count_characters>\n     explicit basic_charset(char_type const (&chars)[count_characters]) noexcept : basic_charset() {\n         static_assert(count_characters > 0, \"Character array cannot be empty\");\n-        for (std::size_t i = 0; i < count_characters - 1; ++i) { // count_characters - 1 to exclude the null terminator\n+        for (std::size_t i = 0; i != count_characters; ++i) {\n             char_type c = chars[i];\n             bitset_._u64s[sz_bitcast(sz_u8_t, c) >> 6] |= (1ull << (sz_bitcast(sz_u8_t, c) & 63u));\n         }\n@@ -292,7 +292,7 @@ class basic_charset {\n     template <std::size_t count_characters>\n     explicit basic_charset(std::array<char_type, count_characters> const &chars) noexcept : basic_charset() {\n         static_assert(count_characters > 0, \"Character array cannot be empty\");\n-        for (std::size_t i = 0; i < count_characters - 1; ++i) { // count_characters - 1 to exclude the null terminator\n+        for (std::size_t i = 0; i != count_characters; ++i) {\n             char_type c = chars[i];\n             bitset_._u64s[sz_bitcast(sz_u8_t, c) >> 6] |= (1ull << (sz_bitcast(sz_u8_t, c) & 63u));\n         }\n", "instance_id": "ashvardanian__StringZilla-202", "clarity": 3, "difficulty": 0.15, "clarity_explanation": "The problem statement is comprehensive and well-structured. It clearly describes the bug in the `basic_charset` initialization where the last element of a character array is discarded due to the use of `count_characters - 1` in the loop. The statement includes specific references to the affected code lines in the GitHub repository, provides detailed steps to reproduce the issue with a clear code example, and specifies the expected behavior. Additionally, it includes relevant context about the environment (OS, hardware, library version, and interface) and confirms that the issue has been searched for in existing issues. The only minor omission is a lack of explicit discussion on potential edge cases beyond the provided examples, but the provided test cases and code references make the problem's scope and impact very clear. Hence, it merits a score of 3 for clarity.", "difficulty_explanation": "The difficulty of this problem is very low, falling in the 0.0-0.2 range. The issue is a straightforward bug fix involving a small, localized change in the codebase. The code changes provided in the diff show that the fix requires modifying just two lines in a single file (`stringzilla.hpp`), specifically adjusting the loop condition from `i < count_characters - 1` to `i != count_characters` in two constructor overloads of the `basic_charset` class. This does not require deep understanding of the broader codebase or complex interactions between modules, nor does it impact the system's architecture. The technical concepts involved are basic\u2014understanding loop conditions and array indexing in C++. There are no significant edge cases or error handling requirements beyond the specific issue of including all characters in the array, which is already addressed by the fix. The problem is isolated, and the solution is a simple adjustment, making it a very easy task for any developer with basic C++ knowledge."}
{"problem_statement": "Support more values for imageRendering\nAs a standard SVG attribute, only `optimizeSpeed` and `optimizeQuality` are supported (see https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/image-rendering), however, as mentioned in the note there, it can also be used as a CSS property with the following possible values:\r\n\r\n[smooth](https://developer.mozilla.org/en-US/docs/Web/CSS/image-rendering#smooth)\r\n\r\n    The image should be scaled with an algorithm that maximizes the appearance of the image. In particular, scaling algorithms that \"smooth\" colors are acceptable, such as bilinear interpolation. This is intended for images such as photos.\r\n[high-quality](https://developer.mozilla.org/en-US/docs/Web/CSS/image-rendering#high-quality)\r\n\r\n    Identical to smooth, but with a preference for higher-quality scaling. If system resources are constrained, images with high-quality should be prioritized over those with any other value, when considering which images to degrade the quality of and to what degree.\r\n[crisp-edges](https://developer.mozilla.org/en-US/docs/Web/CSS/image-rendering#crisp-edges)\r\n\r\n    The image is scaled with an algorithm such as \"nearest neighbor\" that preserves contrast and edges in the image. Generally intended for images such as pixel art or line drawings, no blurring or color smoothing occurs.\r\n[pixelated](https://developer.mozilla.org/en-US/docs/Web/CSS/image-rendering#pixelated)\r\n\r\n    The image is scaled with the \"nearest neighbor\" or similar algorithm to the nearest integer multiple of the original image size, then uses smooth interpolation to bring the image to the final desired size. This is intended to preserve a \"pixelated\" look without introducing scaling artifacts when the upscaled resolution isn't an integer multiple of the original.\r\n\r\nHere is an example SVG that uses `pixelated`:\r\n![test](https://github.com/user-attachments/assets/6dad07a1-0381-4147-be00-874c2d83c181)\r\n\n", "patch": "diff --git a/crates/resvg/src/image.rs b/crates/resvg/src/image.rs\nindex 3f4f34958..bcb315841 100644\n--- a/crates/resvg/src/image.rs\n+++ b/crates/resvg/src/image.rs\n@@ -57,6 +57,7 @@ fn render_vector(\n #[cfg(feature = \"raster-images\")]\n mod raster_images {\n     use crate::OptionLog;\n+    use usvg::ImageRendering;\n \n     fn decode_raster(image: &usvg::ImageKind) -> Option<tiny_skia::Pixmap> {\n         match image {\n@@ -169,10 +170,14 @@ mod raster_images {\n         let rect = tiny_skia::Size::from_wh(raster.width() as f32, raster.height() as f32)?\n             .to_rect(0.0, 0.0)?;\n \n-        let mut quality = tiny_skia::FilterQuality::Bicubic;\n-        if rendering_mode == usvg::ImageRendering::OptimizeSpeed {\n-            quality = tiny_skia::FilterQuality::Nearest;\n-        }\n+        let quality = match rendering_mode {\n+            ImageRendering::OptimizeQuality => tiny_skia::FilterQuality::Bicubic,\n+            ImageRendering::OptimizeSpeed => tiny_skia::FilterQuality::Nearest,\n+            ImageRendering::Smooth => tiny_skia::FilterQuality::Bilinear,\n+            ImageRendering::HighQuality => tiny_skia::FilterQuality::Bicubic,\n+            ImageRendering::CrispEdges => tiny_skia::FilterQuality::Nearest,\n+            ImageRendering::Pixelated => tiny_skia::FilterQuality::Nearest,\n+        };\n \n         let pattern = tiny_skia::Pattern::new(\n             raster.as_ref(),\ndiff --git a/crates/resvg/src/main.rs b/crates/resvg/src/main.rs\nindex 45ced6017..b30252354 100644\n--- a/crates/resvg/src/main.rs\n+++ b/crates/resvg/src/main.rs\n@@ -162,7 +162,7 @@ OPTIONS:\n                                 geometricPrecision]\n   --image-rendering HINT        Selects the default image rendering method\n                                 [default: optimizeQuality]\n-                                [possible values: optimizeQuality, optimizeSpeed]\n+                                [possible values: optimizeQuality, optimizeSpeed, smooth, high-quality, crisp-edges, pixelated]\n   --resources-dir DIR           Sets a directory that will be used during\n                                 relative paths resolving.\n                                 Expected to be the same as the directory that\ndiff --git a/crates/usvg/src/main.rs b/crates/usvg/src/main.rs\nindex 56a53b146..1ecc02c62 100644\n--- a/crates/usvg/src/main.rs\n+++ b/crates/usvg/src/main.rs\n@@ -43,7 +43,7 @@ OPTIONS:\n                                     geometricPrecision]\n   --image-rendering HINT            Selects the default image rendering method\n                                     [default: optimizeQuality]\n-                                    [possible values: optimizeQuality, optimizeSpeed]\n+                                    [possible values: optimizeQuality, optimizeSpeed, smooth, high-quality, crisp-edges, pixelated]\n   --resources-dir DIR               Sets a directory that will be used during\n                                     relative paths resolving.\n                                     Expected to be the same as the directory that\ndiff --git a/crates/usvg/src/parser/svgtree/mod.rs b/crates/usvg/src/parser/svgtree/mod.rs\nindex 540a8b45e..edb36f191 100644\n--- a/crates/usvg/src/parser/svgtree/mod.rs\n+++ b/crates/usvg/src/parser/svgtree/mod.rs\n@@ -1020,6 +1020,10 @@ impl<'a, 'input: 'a> FromValue<'a, 'input> for ImageRendering {\n         match value {\n             \"auto\" | \"optimizeQuality\" => Some(ImageRendering::OptimizeQuality),\n             \"optimizeSpeed\" => Some(ImageRendering::OptimizeSpeed),\n+            \"smooth\" => Some(ImageRendering::Smooth),\n+            \"high-quality\" => Some(ImageRendering::HighQuality),\n+            \"crisp-edges\" => Some(ImageRendering::CrispEdges),\n+            \"pixelated\" => Some(ImageRendering::Pixelated),\n             _ => None,\n         }\n     }\ndiff --git a/crates/usvg/src/parser/svgtree/parse.rs b/crates/usvg/src/parser/svgtree/parse.rs\nindex dfb04fb7b..0c2328ba2 100644\n--- a/crates/usvg/src/parser/svgtree/parse.rs\n+++ b/crates/usvg/src/parser/svgtree/parse.rs\n@@ -242,6 +242,13 @@ pub(crate) fn parse_svg_element<'input>(\n         // For some reason those properties are allowed only inside a `style` attribute and CSS.\n         if matches!(aid, AId::MixBlendMode | AId::Isolation | AId::FontKerning) {\n             continue;\n+        } else if aid == AId::ImageRendering\n+            && matches!(\n+                attr.value(),\n+                \"smooth\" | \"high-quality\" | \"crisp-edges\" | \"pixelated\"\n+            )\n+        {\n+            continue;\n         }\n \n         append_attribute(parent_id, tag_name, aid, attr.value_storage().clone(), doc);\ndiff --git a/crates/usvg/src/tree/mod.rs b/crates/usvg/src/tree/mod.rs\nindex a964c11cd..481cda9ce 100644\n--- a/crates/usvg/src/tree/mod.rs\n+++ b/crates/usvg/src/tree/mod.rs\n@@ -170,6 +170,11 @@ impl std::str::FromStr for TextRendering {\n pub enum ImageRendering {\n     OptimizeQuality,\n     OptimizeSpeed,\n+    // The following can only appear as presentation attributes.\n+    Smooth,\n+    HighQuality,\n+    CrispEdges,\n+    Pixelated,\n }\n \n impl Default for ImageRendering {\n@@ -185,6 +190,10 @@ impl std::str::FromStr for ImageRendering {\n         match s {\n             \"optimizeQuality\" => Ok(ImageRendering::OptimizeQuality),\n             \"optimizeSpeed\" => Ok(ImageRendering::OptimizeSpeed),\n+            \"smooth\" => Ok(ImageRendering::Smooth),\n+            \"high-quality\" => Ok(ImageRendering::HighQuality),\n+            \"crisp-edges\" => Ok(ImageRendering::CrispEdges),\n+            \"pixelated\" => Ok(ImageRendering::Pixelated),\n             _ => Err(\"invalid\"),\n         }\n     }\ndiff --git a/crates/usvg/src/writer.rs b/crates/usvg/src/writer.rs\nindex c36045fd8..9b0e74467 100644\n--- a/crates/usvg/src/writer.rs\n+++ b/crates/usvg/src/writer.rs\n@@ -647,6 +647,18 @@ fn write_element(node: &Node, is_clip_path: bool, opt: &WriteOptions, xml: &mut\n                 ImageRendering::OptimizeSpeed => {\n                     xml.write_svg_attribute(AId::ImageRendering, \"optimizeSpeed\");\n                 }\n+                ImageRendering::Smooth => {\n+                    xml.write_attribute(AId::Style.to_str(), \"image-rendering:smooth\");\n+                }\n+                ImageRendering::HighQuality => {\n+                    xml.write_attribute(AId::Style.to_str(), \"image-rendering:high-quality\");\n+                }\n+                ImageRendering::CrispEdges => {\n+                    xml.write_attribute(AId::Style.to_str(), \"image-rendering:crisp-edges\");\n+                }\n+                ImageRendering::Pixelated => {\n+                    xml.write_attribute(AId::Style.to_str(), \"image-rendering:pixelated\");\n+                }\n             }\n \n             xml.write_image_data(&img.kind);\ndiff --git a/docs/svg2-changelog.md b/docs/svg2-changelog.md\nindex c6c2638c1..0ed6ba4e3 100644\n--- a/docs/svg2-changelog.md\n+++ b/docs/svg2-changelog.md\n@@ -196,7 +196,7 @@ Basically everything from [CSS Text Module Level 3](https://www.w3.org/TR/css-te\n - [x] An [`isolation`](https://www.w3.org/TR/compositing-1/#isolation) property.\n - [ ] `left`, `center` and `right` variants to `refX` and `refY` properties of the [`marker`](https://www.w3.org/TR/SVG2/painting.html#MarkerElement) element.\n - [x] An `auto-start-reverse` variant to [`orient`](https://www.w3.org/TR/SVG2/painting.html#OrientAttribute) property of the [`marker`](https://www.w3.org/TR/SVG2/painting.html#MarkerElement) element\n-\n+- [x] The `image-rendering` can appear as a presentation attribute with additional possible values. Currently, there is only best-effort support for \"pixelated\".\n ### Changed\n \n - [x] Markers can be set on all shapes and not only on `path`.\n", "instance_id": "linebender__resvg-833", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "The problem statement is mostly clear in describing the goal of extending support for additional `image-rendering` values as a CSS property in SVG processing, beyond the initially supported `optimizeSpeed` and `optimizeQuality`. It provides detailed descriptions of the new values (`smooth`, `high-quality`, `crisp-edges`, `pixelated`) with references to their intended use cases and includes an example SVG image for context. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly address how these new values should interact with existing rendering logic or specify any constraints or edge cases (e.g., fallback behavior if a rendering mode is unsupported by the underlying library). Additionally, while the note about \"best-effort support for pixelated\" is mentioned in the changelog, it is unclear what limitations or specific behaviors are expected for this mode. Overall, the statement is valid and clear but lacks some critical details for a fully comprehensive understanding.", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the scope of code changes spans multiple files across different crates (`resvg`, `usvg`), affecting parsing, rendering logic, command-line options, and documentation. This requires a moderate understanding of the codebase structure and interactions between modules. Second, the technical concepts involved include familiarity with SVG standards, CSS properties, image rendering algorithms (e.g., mapping rendering modes to filter qualities like `Bicubic`, `Bilinear`, `Nearest`), and Rust-specific enum handling and parsing logic. While these concepts are not overly complex for an experienced developer, they do require a solid grasp of domain-specific knowledge (SVG/CSS) and library-specific mappings (`tiny_skia::FilterQuality`). Third, the changes are mostly additive and straightforward\u2014extending enums, updating parsing logic, and adjusting rendering quality mappings\u2014without significant architectural impact or complex refactoring. However, there is a minor challenge in ensuring consistency across different parts of the codebase (e.g., CLI options, XML writing logic). Lastly, edge cases and error handling are not extensively addressed in the problem or code changes, though some implicit considerations (like unsupported values being skipped in parsing) are handled. Overall, this task requires moderate effort and understanding, fitting within the 0.4-0.6 range, with a score of 0.45 reflecting a slightly below-average complexity for a medium-difficulty problem due to the relatively straightforward nature of the modifications."}
{"problem_statement": "Bug: `sz_dispatch_table` didn't initialize in rust binding on Windows\n### Describe the bug\r\n\r\nWhen debugging test suite in rust binding, I found `sz_dispatch_table` didn't initialize.\r\n![image](https://github.com/user-attachments/assets/7955896c-3a75-4f24-89cf-386142f9fc06)\r\n\r\nBuild output: \r\n```sh\r\n[stringzilla 3.10.1] TARGET = Some(\"x86_64-pc-windows-msvc\")\r\n[stringzilla 3.10.1] OPT_LEVEL = Some(\"3\")\r\n[stringzilla 3.10.1] HOST = Some(\"x86_64-pc-windows-msvc\")\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CC_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CC_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CC\r\n[stringzilla 3.10.1] HOST_CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC\r\n[stringzilla 3.10.1] CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CRATE_CC_NO_DEFAULTS\r\n[stringzilla 3.10.1] CRATE_CC_NO_DEFAULTS = None\r\n[stringzilla 3.10.1] CARGO_CFG_TARGET_FEATURE = Some(\"cmpxchg16b,fxsr,lahfsahf,sse,sse2,sse3\")\r\n[stringzilla 3.10.1] DEBUG = Some(\"false\")\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CFLAGS\r\n[stringzilla 3.10.1] HOST_CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS\r\n[stringzilla 3.10.1] CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CC_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CC_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CC\r\n[stringzilla 3.10.1] HOST_CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC\r\n[stringzilla 3.10.1] CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CRATE_CC_NO_DEFAULTS\r\n[stringzilla 3.10.1] CRATE_CC_NO_DEFAULTS = None\r\n[stringzilla 3.10.1] CARGO_CFG_TARGET_FEATURE = Some(\"cmpxchg16b,fxsr,lahfsahf,sse,sse2,sse3\")\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CFLAGS\r\n[stringzilla 3.10.1] HOST_CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS\r\n[stringzilla 3.10.1] CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CC_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CC_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CC\r\n[stringzilla 3.10.1] HOST_CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC\r\n[stringzilla 3.10.1] CC = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CRATE_CC_NO_DEFAULTS\r\n[stringzilla 3.10.1] CRATE_CC_NO_DEFAULTS = None\r\n[stringzilla 3.10.1] CARGO_CFG_TARGET_FEATURE = Some(\"cmpxchg16b,fxsr,lahfsahf,sse,sse2,sse3\")\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] CFLAGS_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_CFLAGS\r\n[stringzilla 3.10.1] HOST_CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CFLAGS\r\n[stringzilla 3.10.1] CFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=CC_ENABLE_DEBUG_OUTPUT\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=AR_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] AR_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=AR_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] AR_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_AR\r\n[stringzilla 3.10.1] HOST_AR = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=AR\r\n[stringzilla 3.10.1] AR = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=ARFLAGS_x86_64-pc-windows-msvc\r\n[stringzilla 3.10.1] ARFLAGS_x86_64-pc-windows-msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=ARFLAGS_x86_64_pc_windows_msvc\r\n[stringzilla 3.10.1] ARFLAGS_x86_64_pc_windows_msvc = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=HOST_ARFLAGS\r\n[stringzilla 3.10.1] HOST_ARFLAGS = None\r\n[stringzilla 3.10.1] cargo:rerun-if-env-changed=ARFLAGS\r\n[stringzilla 3.10.1] ARFLAGS = None\r\n[stringzilla 3.10.1] cargo:rustc-link-search=native=D:\\VisualStudio\\VisualStudio\\VC\\Tools\\MSVC\\14.37.32822\\atlmfc\\lib\\x64\r\n[stringzilla 3.10.1] cargo:rustc-link-lib=static=stringzilla\r\n[stringzilla 3.10.1] cargo:rustc-link-search=native=D:\\Rust\\StringZilla\\target\\release\\build\\stringzilla-dd6b387b3407d0f8\\out\r\n[stringzilla 3.10.1] cargo:rerun-if-changed=c/lib.c\r\n[stringzilla 3.10.1] cargo:rerun-if-changed=rust/lib.rs\r\n[stringzilla 3.10.1] cargo:rerun-if-changed=include/stringzilla/stringzilla.h\r\n```\r\n\r\n### StringZilla version\r\n\r\nhttps://github.com/ashvardanian/StringZilla/commit/f195c5027ce618ac0fb625de04602c0aaed5f6d9\r\n\r\n### Operating System\r\n\r\nWindows 11\r\n\r\n### Hardware architecture\r\n\r\nx86\r\n\r\n### Which interface are you using?\r\n\r\nRust binding\r\n\r\n### Contact Details\r\n\r\n_No response_\r\n\r\n### Are you open to being tagged as a contributor?\r\n\r\n- [ ] I am open to being mentioned in the project `.git` history as a contributor\r\n\r\n### Is there an existing issue for this?\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's Code of Conduct\n", "patch": "diff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 68bbd2a4..df55dcca 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -327,6 +327,16 @@ if(${STRINGZILLA_BUILD_SHARED})\n         \"SZ_USE_ARM_NEON=1\"\n         \"SZ_USE_ARM_SVE=1\")\n     endif()\n+\n+    if (MSVC)\n+      # Add dependencies for necessary runtime libraries in case of static linking\n+      # This ensures that basic runtime functions are available:\n+      # msvcrt.lib: Microsoft Visual C Runtime, required for basic C runtime functions on Windows.\n+      # vcruntime.lib: Microsoft Visual C++ Runtime library for basic runtime functions.\n+      # ucrt.lib: Universal C Runtime, necessary for linking basic C functions like I/O.\n+      target_link_libraries(${target} PRIVATE msvcrt.lib vcruntime.lib ucrt.lib)\n+    endif()\n+\n   endfunction()\n \n   define_shared(stringzilla_shared)\n@@ -344,4 +354,6 @@ if(${STRINGZILLA_BUILD_SHARED})\n     \"$<$<CXX_COMPILER_ID:MSVC>:/Oi-;/GS->\")\n   target_link_options(stringzillite PRIVATE \"$<$<CXX_COMPILER_ID:GNU,Clang>:-nostdlib>\")\n   target_link_options(stringzillite PRIVATE \"$<$<CXX_COMPILER_ID:MSVC>:/NODEFAULTLIB>\")\n+\n+\n endif()\ndiff --git a/README.md b/README.md\nindex 821be609..dbfd3f9b 100644\n--- a/README.md\n+++ b/README.md\n@@ -171,7 +171,7 @@ __Who is this for?__\n       <span style=\"color:#ABABAB;\">arm:</span> <b>9.4</b> MB/s\n     </td>\n     <td align=\"center\">\n-      <code>uniform_int_distribution</code><br/>\n+      <code>std::uniform_int_distribution</code><br/>\n       <span style=\"color:#ABABAB;\">x86:</span> <b>47.2</b> &centerdot;\n       <span style=\"color:#ABABAB;\">arm:</span> <b>20.4</b> MB/s\n     </td>\n@@ -193,7 +193,7 @@ __Who is this for?__\n   <tr>\n     <td align=\"center\">\u26aa</td>\n     <td align=\"center\">\n-      <code>transform</code><br/>\n+      <code>std::transform</code><br/>\n       <span style=\"color:#ABABAB;\">x86:</span> <b>3.81</b> &centerdot;\n       <span style=\"color:#ABABAB;\">arm:</span> <b>2.65</b> GB/s\n     </td>\ndiff --git a/c/lib.c b/c/lib.c\nindex e523e377..073514a6 100644\n--- a/c/lib.c\n+++ b/c/lib.c\n@@ -232,21 +232,20 @@ static void sz_dispatch_table_init(void) {\n }\n \n #if defined(_MSC_VER)\n+#pragma section(\".CRT$XCU\", read)\n+__declspec(allocate(\".CRT$XCU\")) void (*_sz_dispatch_table_init)() = sz_dispatch_table_init;\n+\n BOOL WINAPI DllMain(HINSTANCE hints, DWORD forward_reason, LPVOID lp) {\n     switch (forward_reason) {\n-    case DLL_PROCESS_ATTACH: sz_dispatch_table_init(); return TRUE;\n+    case DLL_PROCESS_ATTACH:\n+        sz_dispatch_table_init(); // Ensure initialization\n+        return TRUE;\n     case DLL_THREAD_ATTACH: return TRUE;\n     case DLL_THREAD_DETACH: return TRUE;\n     case DLL_PROCESS_DETACH: return TRUE;\n     }\n-}\n-\n-#if SZ_AVOID_LIBC\n-BOOL WINAPI _DllMainCRTStartup(HINSTANCE hints, DWORD forward_reason, LPVOID lp) {\n-    DllMain(hints, forward_reason, lp);\n     return TRUE;\n }\n-#endif\n \n #else\n __attribute__((constructor)) static void sz_dispatch_table_init_on_gcc_or_clang(void) { sz_dispatch_table_init(); }\ndiff --git a/include/stringzilla/stringzilla.h b/include/stringzilla/stringzilla.h\nindex fbfbf28b..8176ee13 100644\n--- a/include/stringzilla/stringzilla.h\n+++ b/include/stringzilla/stringzilla.h\n@@ -5323,8 +5323,16 @@ SZ_PUBLIC void sz_look_up_transform_avx512(sz_cptr_t source, sz_size_t length, s\n     // operate on 4 registers, it might be cleaner to use 2x separate `_mm512_permutexvar_epi8` calls.\n     // Combining the results with 2x `_mm512_test_epi8_mask` and 3x blends afterwards.\n     //\n-    //  - `_mm512_mask_blend_epi8` - 1 cycle latency, and generally 2x can run in parallel.\n-    //  - `_mm512_test_epi8_mask` - 3 cycles latency, same as most comparison functions in AVX-512.\n+    //  - 4x `_mm512_permutexvar_epi8` maps to \"VPERMB (ZMM, ZMM, ZMM)\":\n+    //      - On Ice Lake: 3 cycles latency, ports: 1*p5\n+    //      - On Genoa: 6 cycles latency, ports: 1*FP12\n+    //  - 3x `_mm512_mask_blend_epi8` maps to \"VPBLENDMB_Z (ZMM, K, ZMM, ZMM)\":\n+    //      - On Ice Lake: 3 cycles latency, ports: 1*p05\n+    //      - On Genoa: 1 cycle latency, ports: 1*FP0123\n+    //  - 2x `_mm512_test_epi8_mask` maps to \"VPTESTMB (K, ZMM, ZMM)\":\n+    //      - On Ice Lake: 3 cycles latency, ports: 1*p5\n+    //      - On Genoa: 4 cycles latency, ports: 1*FP01\n+    //\n     sz_u512_vec_t lut_0_to_63_vec, lut_64_to_127_vec, lut_128_to_191_vec, lut_192_to_255_vec;\n     lut_0_to_63_vec.zmm = _mm512_loadu_si512((lut));\n     lut_64_to_127_vec.zmm = _mm512_loadu_si512((lut + 64));\ndiff --git a/python/lib.c b/python/lib.c\nindex 966d5862..11302712 100644\n--- a/python/lib.c\n+++ b/python/lib.c\n@@ -96,8 +96,8 @@ typedef struct {\n typedef struct {\n     PyObject ob_base;\n \n-    PyObject *text_object;      //< For reference counting\n-    PyObject *separator_object; //< For reference counting\n+    PyObject *text_obj;      //< For reference counting\n+    PyObject *separator_obj; //< For reference counting\n \n     sz_string_view_t text;\n     sz_string_view_t separator;\n@@ -596,35 +596,14 @@ static int Str_init(Str *self, PyObject *args, PyObject *kwargs) {\n \n     // Parse keyword arguments, if provided, and ensure no duplicates\n     if (kwargs) {\n-        PyObject *key, *value;\n         Py_ssize_t pos = 0;\n-        while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"parent\") == 0) {\n-                if (parent_obj) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received `parent` both as positional and keyword argument\");\n-                    return -1;\n-                }\n-                parent_obj = value;\n-            }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"from\") == 0) {\n-                if (from_obj) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received `from` both as positional and keyword argument\");\n-                    return -1;\n-                }\n-                from_obj = value;\n-            }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"to\") == 0) {\n-                if (to_obj) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received `to` both as positional and keyword argument\");\n-                    return -1;\n-                }\n-                to_obj = value;\n-            }\n-            else {\n-                PyErr_SetString(PyExc_TypeError, \"Invalid keyword argument\");\n+        PyObject *key, *value;\n+        while (PyDict_Next(kwargs, &pos, &key, &value))\n+            if (PyUnicode_CompareWithASCIIString(key, \"parent\") == 0 && !parent_obj) { parent_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"from\") == 0 && !from_obj) { from_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"to\") == 0 && !to_obj) { to_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n                 return -1;\n-            }\n-        }\n     }\n \n     // Now, type-check and cast each argument\n@@ -726,11 +705,11 @@ static PyObject *Str_like_hash(PyObject *self, PyObject *args, PyObject *kwargs)\n         return NULL;\n     }\n \n-    PyObject *text_object = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *text_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n     sz_string_view_t text;\n \n     // Validate and convert `text`\n-    if (!export_string_like(text_object, &text.start, &text.length)) {\n+    if (!export_string_like(text_obj, &text.start, &text.length)) {\n         wrap_current_exception(\"The text argument must be string-like\");\n         return NULL;\n     }\n@@ -739,6 +718,43 @@ static PyObject *Str_like_hash(PyObject *self, PyObject *args, PyObject *kwargs)\n     return PyLong_FromSize_t((size_t)result);\n }\n \n+static char const doc_like_equal[] = //\n+    \"Compute the equals value of the string.\\n\\n\"\n+    \"This function can be called as a method on a Str object or as a standalone function.\\n\\n\"\n+    \"Args:\\n\"\n+    \"  self (Str or str or bytes): The string object (if called as a method).\\n\"\n+    \"  text (str): The string to equals (if called as a function).\\n\\n\"\n+    \"Returns:\\n\"\n+    \"  int: The equals value of the string.\\n\\n\"\n+    \"Raises:\\n\"\n+    \"  TypeError: If the argument is not string-like or incorrect number of arguments is provided.\";\n+\n+static PyObject *Str_like_equal(PyObject *self, PyObject *args, PyObject *kwargs) {\n+    // Check minimum arguments\n+    int is_member = self != NULL && PyObject_TypeCheck(self, &StrType);\n+    Py_ssize_t nargs = PyTuple_Size(args);\n+    if (nargs < !is_member || nargs > !is_member + 1 || kwargs) {\n+        PyErr_SetString(PyExc_TypeError, \"equals() expects exactly two positional arguments\");\n+        return NULL;\n+    }\n+\n+    PyObject *text_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *other_obj = PyTuple_GET_ITEM(args, is_member);\n+    sz_string_view_t text, other;\n+\n+    // Validate and convert tje texts\n+    if (!export_string_like(text_obj, &text.start, &text.length) || //\n+        !export_string_like(other_obj, &other.start, &other.length)) {\n+        wrap_current_exception(\"The arguments must be string-like\");\n+        return NULL;\n+    }\n+\n+    if (text.length != other.length) { Py_RETURN_FALSE; }\n+    sz_bool_t result = sz_equal(text.start, other.start, text.length);\n+    if (result != sz_true_k) { Py_RETURN_FALSE; }\n+    Py_RETURN_TRUE;\n+}\n+\n static PyObject *Str_get_address(Str *self, void *closure) { return PyLong_FromSize_t((sz_size_t)self->memory.start); }\n static PyObject *Str_get_nbytes(Str *self, void *closure) { return PyLong_FromSize_t(self->memory.length); }\n \n@@ -1275,8 +1291,8 @@ static PyObject *Str_decode(PyObject *self, PyObject *args, PyObject *kwargs) {\n         Py_ssize_t pos = 0;\n         PyObject *key, *value;\n         while (PyDict_Next(kwargs, &pos, &key, &value))\n-            if (PyUnicode_CompareWithASCIIString(key, \"encoding\") == 0) { encoding_obj = value; }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"errors\") == 0) { errors_obj = value; }\n+            if (PyUnicode_CompareWithASCIIString(key, \"encoding\") == 0 && !encoding_obj) { encoding_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"errors\") == 0 && !errors_obj) { errors_obj = value; }\n             else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n                 return NULL;\n     }\n@@ -1318,7 +1334,7 @@ static PyObject *Str_write_to(PyObject *self, PyObject *args, PyObject *kwargs)\n         return NULL;\n     }\n \n-    PyObject *text_object = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *text_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n     PyObject *path_obj = PyTuple_GET_ITEM(args, !is_member + 0);\n \n     // Parse keyword arguments\n@@ -1331,7 +1347,7 @@ static PyObject *Str_write_to(PyObject *self, PyObject *args, PyObject *kwargs)\n     sz_string_view_t path;\n \n     // Validate and convert `text` and `path`\n-    if (!export_string_like(text_object, &text.start, &text.length) ||\n+    if (!export_string_like(text_obj, &text.start, &text.length) ||\n         !export_string_like(path_obj, &path.start, &path.length)) {\n         wrap_current_exception(\"Text and path must be string-like\");\n         return NULL;\n@@ -1397,7 +1413,7 @@ static PyObject *Str_offset_within(PyObject *self, PyObject *args, PyObject *kwa\n     }\n \n     PyObject *slice_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n-    PyObject *text_object = PyTuple_GET_ITEM(args, !is_member + 0);\n+    PyObject *text_obj = PyTuple_GET_ITEM(args, !is_member + 0);\n \n     // Parse keyword arguments\n     if (kwargs) {\n@@ -1409,7 +1425,7 @@ static PyObject *Str_offset_within(PyObject *self, PyObject *args, PyObject *kwa\n     sz_string_view_t slice;\n \n     // Validate and convert `text` and `slice`\n-    if (!export_string_like(text_object, &text.start, &text.length) ||\n+    if (!export_string_like(text_obj, &text.start, &text.length) ||\n         !export_string_like(slice_obj, &slice.start, &slice.length)) {\n         wrap_current_exception(\"Text and slice must be string-like\");\n         return NULL;\n@@ -1447,14 +1463,11 @@ static int _Str_find_implementation_( //\n     if (kwargs) {\n         Py_ssize_t pos = 0;\n         PyObject *key, *value;\n-        while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"start\") == 0) { start_obj = value; }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"end\") == 0) { end_obj = value; }\n-            else {\n-                PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key);\n+        while (PyDict_Next(kwargs, &pos, &key, &value))\n+            if (PyUnicode_CompareWithASCIIString(key, \"start\") == 0 && !start_obj) { start_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"end\") == 0 && !end_obj) { end_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n                 return 0;\n-            }\n-        }\n     }\n \n     sz_string_view_t haystack;\n@@ -1793,16 +1806,12 @@ static PyObject *_Str_edit_distance(PyObject *self, PyObject *args, PyObject *kw\n     PyObject *bound_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n \n     if (kwargs) {\n-        PyObject *key, *value;\n         Py_ssize_t pos = 0;\n+        PyObject *key, *value;\n         while (PyDict_Next(kwargs, &pos, &key, &value))\n-            if (PyUnicode_CompareWithASCIIString(key, \"bound\") == 0) {\n-                if (bound_obj) {\n-                    PyErr_Format(PyExc_TypeError, \"Received bound both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                bound_obj = value;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"bound\") == 0 && !bound_obj) { bound_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n+                return NULL;\n     }\n \n     Py_ssize_t bound = 0; // Default value for bound\n@@ -1876,16 +1885,12 @@ static PyObject *_Str_hamming_distance(PyObject *self, PyObject *args, PyObject\n     PyObject *bound_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n \n     if (kwargs) {\n-        PyObject *key, *value;\n         Py_ssize_t pos = 0;\n+        PyObject *key, *value;\n         while (PyDict_Next(kwargs, &pos, &key, &value))\n-            if (PyUnicode_CompareWithASCIIString(key, \"bound\") == 0) {\n-                if (bound_obj) {\n-                    PyErr_Format(PyExc_TypeError, \"Received bound both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                bound_obj = value;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"bound\") == 0 && !bound_obj) { bound_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n+                return NULL;\n     }\n \n     Py_ssize_t bound = 0; // Default value for bound\n@@ -1959,49 +1964,40 @@ static PyObject *Str_alignment_score(PyObject *self, PyObject *args, PyObject *k\n \n     PyObject *str1_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n     PyObject *str2_obj = PyTuple_GET_ITEM(args, !is_member + 0);\n-    PyObject *substitutions_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n-    PyObject *gap_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n+    PyObject *substitution_matrix_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n+    PyObject *gap_score_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n \n     if (kwargs) {\n-        PyObject *key, *value;\n         Py_ssize_t pos = 0;\n+        PyObject *key, *value;\n         while (PyDict_Next(kwargs, &pos, &key, &value))\n-            if (PyUnicode_CompareWithASCIIString(key, \"gap_score\") == 0) {\n-                if (gap_obj) {\n-                    PyErr_Format(PyExc_TypeError, \"Received the `gap_score` both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                gap_obj = value;\n-            }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"substitution_matrix\") == 0) {\n-                if (substitutions_obj) {\n-                    PyErr_Format(PyExc_TypeError,\n-                                 \"Received the `substitution_matrix` both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                substitutions_obj = value;\n+            if (PyUnicode_CompareWithASCIIString(key, \"gap_score\") == 0 && !gap_score_obj) { gap_score_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"substitution_matrix\") == 0 && !substitution_matrix_obj) {\n+                substitution_matrix_obj = value;\n             }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n+                return NULL;\n     }\n \n     Py_ssize_t gap = 1; // Default value for gap costs\n-    if (gap_obj && (gap = PyLong_AsSsize_t(gap_obj)) && (gap >= 128 || gap <= -128)) {\n+    if (gap_score_obj && (gap = PyLong_AsSsize_t(gap_score_obj)) && (gap >= 128 || gap <= -128)) {\n         PyErr_Format(PyExc_ValueError, \"The `gap_score` must fit into an 8-bit signed integer\");\n         return NULL;\n     }\n \n-    // Now extract the substitution matrix from the `substitutions_obj`.\n+    // Now extract the substitution matrix from the `substitution_matrix_obj`.\n     // It must conform to the buffer protocol, and contain a continuous 256x256 matrix of 8-bit signed integers.\n     sz_error_cost_t const *substitutions;\n \n     // Ensure the substitution matrix object is provided\n-    if (!substitutions_obj) {\n+    if (!substitution_matrix_obj) {\n         PyErr_Format(PyExc_TypeError, \"No substitution matrix provided\");\n         return NULL;\n     }\n \n     // Request a buffer view\n     Py_buffer substitutions_view;\n-    if (PyObject_GetBuffer(substitutions_obj, &substitutions_view, PyBUF_FULL)) {\n+    if (PyObject_GetBuffer(substitution_matrix_obj, &substitutions_view, PyBUF_FULL)) {\n         PyErr_Format(PyExc_TypeError, \"Failed to get buffer from substitution matrix\");\n         return NULL;\n     }\n@@ -2156,9 +2152,9 @@ static char const doc_translate[] = //\n     \"Args:\\n\"\n     \"  self (Str or str or bytes): The string object.\\n\"\n     \"  table (str or dict): A 256-character string or a dictionary mapping bytes to bytes.\\n\"\n+    \"  inplace (bool, optional): If True, the string is modified in place (default is False).\\n\\n\"\n     \"  start (int, optional): The starting index for translation (default is 0).\\n\"\n     \"  end (int, optional): The ending index for translation (default is the string length).\\n\\n\"\n-    \"  inplace (bool, optional): If True, the string is modified in place (default is False).\\n\\n\"\n     \"Returns:\\n\"\n     \"  Union[None, str, bytes]: If inplace is False, a new string is returned, otherwise None.\\n\\n\"\n     \"Raises:\\n\"\n@@ -2175,9 +2171,21 @@ static PyObject *Str_translate(PyObject *self, PyObject *args, PyObject *kwargs)\n \n     PyObject *str_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n     PyObject *look_up_table_obj = PyTuple_GET_ITEM(args, !is_member);\n-    PyObject *start_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n-    PyObject *end_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n-    PyObject *inplace_obj = nargs > !is_member + 3 ? PyTuple_GET_ITEM(args, !is_member + 3) : NULL;\n+    PyObject *inplace_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n+    PyObject *start_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n+    PyObject *end_obj = nargs > !is_member + 3 ? PyTuple_GET_ITEM(args, !is_member + 3) : NULL;\n+\n+    // Optional keyword arguments\n+    if (kwargs) {\n+        Py_ssize_t pos = 0;\n+        PyObject *key, *value;\n+        while (PyDict_Next(kwargs, &pos, &key, &value))\n+            if (PyUnicode_CompareWithASCIIString(key, \"inplace\") == 0 && !inplace_obj) { inplace_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"start\") == 0 && !start_obj) { start_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"end\") == 0 && !end_obj) { end_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n+                return NULL;\n+    }\n \n     // Optional start and end arguments\n     Py_ssize_t start = 0, end = PY_SSIZE_T_MAX;\n@@ -2362,7 +2370,7 @@ static PyObject *Str_find_last_not_of(PyObject *self, PyObject *args, PyObject *\n /**\n  *  @brief  Given parsed split settings, constructs an iterator that would produce that split.\n  */\n-static SplitIterator *Str_split_iter_(PyObject *text_object, PyObject *separator_object,             //\n+static SplitIterator *Str_split_iter_(PyObject *text_obj, PyObject *separator_obj,                   //\n                                       sz_string_view_t const text, sz_string_view_t const separator, //\n                                       int keepseparator, Py_ssize_t maxsplit, sz_find_t finder, sz_size_t match_length,\n                                       sz_bool_t is_reverse) {\n@@ -2372,8 +2380,8 @@ static SplitIterator *Str_split_iter_(PyObject *text_object, PyObject *separator\n     if (result_obj == NULL && PyErr_NoMemory()) return NULL;\n \n     // Set its properties based on the slice\n-    result_obj->text_object = text_object;\n-    result_obj->separator_object = separator_object;\n+    result_obj->text_obj = text_obj;\n+    result_obj->separator_obj = separator_obj;\n     result_obj->text = text;\n     result_obj->separator = separator;\n     result_obj->finder = finder;\n@@ -2385,8 +2393,8 @@ static SplitIterator *Str_split_iter_(PyObject *text_object, PyObject *separator\n     result_obj->reached_tail = 0;\n \n     // Increment the reference count of the parent\n-    Py_INCREF(result_obj->text_object);\n-    Py_XINCREF(result_obj->separator_object);\n+    Py_INCREF(result_obj->text_obj);\n+    Py_XINCREF(result_obj->separator_obj);\n     return result_obj;\n }\n \n@@ -2572,8 +2580,8 @@ static PyObject *Str_split_with_known_callback(PyObject *self, PyObject *args, P\n         return NULL;\n     }\n \n-    PyObject *text_object = is_member ? self : PyTuple_GET_ITEM(args, 0);\n-    PyObject *separator_object = nargs > !is_member + 0 ? PyTuple_GET_ITEM(args, !is_member + 0) : NULL;\n+    PyObject *text_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *separator_obj = nargs > !is_member + 0 ? PyTuple_GET_ITEM(args, !is_member + 0) : NULL;\n     PyObject *maxsplit_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n     PyObject *keepseparator_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n \n@@ -2581,9 +2589,11 @@ static PyObject *Str_split_with_known_callback(PyObject *self, PyObject *args, P\n         PyObject *key, *value;\n         Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"separator\") == 0) { separator_object = value; }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"maxsplit\") == 0) { maxsplit_obj = value; }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"keepseparator\") == 0) { keepseparator_obj = value; }\n+            if (PyUnicode_CompareWithASCIIString(key, \"separator\") == 0 && !separator_obj) { separator_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"maxsplit\") == 0 && !maxsplit_obj) { maxsplit_obj = value; }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"keepseparator\") == 0 && !keepseparator_obj) {\n+                keepseparator_obj = value;\n+            }\n             else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key))\n                 return NULL;\n         }\n@@ -2595,14 +2605,14 @@ static PyObject *Str_split_with_known_callback(PyObject *self, PyObject *args, P\n     Py_ssize_t maxsplit;\n \n     // Validate and convert `text`\n-    if (!export_string_like(text_object, &text.start, &text.length)) {\n+    if (!export_string_like(text_obj, &text.start, &text.length)) {\n         wrap_current_exception(\"The text argument must be string-like\");\n         return NULL;\n     }\n \n     // Validate and convert `separator`\n-    if (separator_object) {\n-        if (!export_string_like(separator_object, &separator.start, &separator.length)) {\n+    if (separator_obj) {\n+        if (!export_string_like(separator_obj, &separator.start, &separator.length)) {\n             wrap_current_exception(\"The separator argument must be string-like\");\n             return NULL;\n         }\n@@ -2640,11 +2650,11 @@ static PyObject *Str_split_with_known_callback(PyObject *self, PyObject *args, P\n \n     // Dispatch the right backend\n     if (is_lazy_iterator)\n-        return Str_split_iter_(text_object, separator_object, text, separator, //\n+        return Str_split_iter_(text_obj, separator_obj, text, separator, //\n                                keepseparator, maxsplit, finder, match_length, is_reverse);\n     else\n-        return !is_reverse ? Str_split_(text_object, text, separator, keepseparator, maxsplit, finder, match_length)\n-                           : Str_rsplit_(text_object, text, separator, keepseparator, maxsplit, finder, match_length);\n+        return !is_reverse ? Str_split_(text_obj, text, separator, keepseparator, maxsplit, finder, match_length)\n+                           : Str_rsplit_(text_obj, text, separator, keepseparator, maxsplit, finder, match_length);\n }\n \n static char const doc_split[] = //\n@@ -2781,7 +2791,7 @@ static PyObject *Str_splitlines(PyObject *self, PyObject *args, PyObject *kwargs\n         return NULL;\n     }\n \n-    PyObject *text_object = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *text_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n     PyObject *keeplinebreaks_obj = nargs > !is_member ? PyTuple_GET_ITEM(args, !is_member) : NULL;\n     PyObject *maxsplit_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n \n@@ -2789,8 +2799,10 @@ static PyObject *Str_splitlines(PyObject *self, PyObject *args, PyObject *kwargs\n         PyObject *key, *value;\n         Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"keeplinebreaks\") == 0) { keeplinebreaks_obj = value; }\n-            else if (PyUnicode_CompareWithASCIIString(key, \"maxsplit\") == 0) { maxsplit_obj = value; }\n+            if (PyUnicode_CompareWithASCIIString(key, \"keeplinebreaks\") == 0 && !keeplinebreaks_obj) {\n+                keeplinebreaks_obj = value;\n+            }\n+            else if (PyUnicode_CompareWithASCIIString(key, \"maxsplit\") == 0 && !maxsplit_obj) { maxsplit_obj = value; }\n             else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key)) { return NULL; }\n         }\n     }\n@@ -2800,7 +2812,7 @@ static PyObject *Str_splitlines(PyObject *self, PyObject *args, PyObject *kwargs\n     Py_ssize_t maxsplit = PY_SSIZE_T_MAX; // Default value for maxsplit\n \n     // Validate and convert `text`\n-    if (!export_string_like(text_object, &text.start, &text.length)) {\n+    if (!export_string_like(text_obj, &text.start, &text.length)) {\n         wrap_current_exception(\"The text argument must be string-like\");\n         return NULL;\n     }\n@@ -2847,7 +2859,7 @@ static PyObject *Str_splitlines(PyObject *self, PyObject *args, PyObject *kwargs\n     sz_string_view_t separator;\n     separator.start = \"\\x0A\\x0B\\x0C\\x0D\\x85\\x1C\\x1D\\x1E\";\n     separator.length = 8;\n-    return Str_split_(text_object, text, separator, keeplinebreaks, maxsplit, &sz_find_char_from, 1);\n+    return Str_split_(text_obj, text, separator, keeplinebreaks, maxsplit, &sz_find_char_from, 1);\n }\n \n static PyObject *Str_concat(PyObject *self, PyObject *other) {\n@@ -3026,16 +3038,16 @@ static PyObject *SplitIteratorType_next(SplitIterator *self) {\n \n     // Set its properties based on the slice\n     result_obj->memory = result_memory;\n-    result_obj->parent = self->text_object;\n+    result_obj->parent = self->text_obj;\n \n     // Increment the reference count of the parent\n-    Py_INCREF(self->text_object);\n+    Py_INCREF(self->text_obj);\n     return (PyObject *)result_obj;\n }\n \n static void SplitIteratorType_dealloc(SplitIterator *self) {\n-    Py_XDECREF(self->text_object);\n-    Py_XDECREF(self->separator_object);\n+    Py_XDECREF(self->text_obj);\n+    Py_XDECREF(self->separator_obj);\n     Py_TYPE(self)->tp_free((PyObject *)self);\n }\n \n@@ -3060,43 +3072,22 @@ static PyTypeObject SplitIteratorType = {\n #pragma region Strs\n \n static PyObject *Strs_shuffle(Strs *self, PyObject *args, PyObject *kwargs) {\n-    unsigned int seed = time(NULL); // Default seed\n \n     // Check for positional arguments\n     Py_ssize_t nargs = PyTuple_Size(args);\n+    PyObject *seed_obj = nargs == 1 ? PyTuple_GET_ITEM(args, 0) : NULL;\n     if (nargs > 1) {\n         PyErr_SetString(PyExc_TypeError, \"shuffle() takes at most 1 positional argument\");\n         return NULL;\n     }\n-    else if (nargs == 1) {\n-        PyObject *seed_obj = PyTuple_GET_ITEM(args, 0);\n-        if (!PyLong_Check(seed_obj)) {\n-            PyErr_SetString(PyExc_TypeError, \"The seed must be an integer\");\n-            return NULL;\n-        }\n-        seed = PyLong_AsUnsignedLong(seed_obj);\n-    }\n \n     // Check for keyword arguments\n     if (kwargs) {\n         PyObject *key, *value;\n         Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"seed\") == 0) {\n-                if (nargs == 1) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received seed both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                if (!PyLong_Check(value)) {\n-                    PyErr_SetString(PyExc_TypeError, \"The seed must be an integer\");\n-                    return NULL;\n-                }\n-                seed = PyLong_AsUnsignedLong(value);\n-            }\n-            else {\n-                PyErr_Format(PyExc_TypeError, \"Received an unexpected keyword argument '%U'\", key);\n-                return NULL;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"seed\") == 0 && !seed_obj) { seed_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key)) { return NULL; }\n         }\n     }\n \n@@ -3112,6 +3103,7 @@ static PyObject *Strs_shuffle(Strs *self, PyObject *args, PyObject *kwargs) {\n     size_t count = reordered->count;\n \n     // Fisher-Yates Shuffle Algorithm\n+    unsigned int seed = seed_obj ? PyLong_AsUnsignedLong(seed_obj) : time(NULL);\n     srand(seed);\n     for (size_t i = count - 1; i > 0; --i) {\n         size_t j = rand() % (i + 1);\n@@ -3182,17 +3174,8 @@ static PyObject *Strs_sort(Strs *self, PyObject *args, PyObject *kwargs) {\n         PyObject *key, *value;\n         Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"reverse\") == 0) {\n-                if (reverse_obj) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received reverse both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                reverse_obj = value;\n-            }\n-            else {\n-                PyErr_Format(PyExc_TypeError, \"Received an unexpected keyword argument '%U'\", key);\n-                return NULL;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"reverse\") == 0 && !reverse_obj) { reverse_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key)) { return NULL; }\n         }\n     }\n \n@@ -3235,17 +3218,8 @@ static PyObject *Strs_order(Strs *self, PyObject *args, PyObject *kwargs) {\n         PyObject *key, *value;\n         Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"reverse\") == 0) {\n-                if (reverse_obj) {\n-                    PyErr_SetString(PyExc_TypeError, \"Received reverse both as positional and keyword argument\");\n-                    return NULL;\n-                }\n-                reverse_obj = value;\n-            }\n-            else {\n-                PyErr_Format(PyExc_TypeError, \"Received an unexpected keyword argument '%U'\", key);\n-                return NULL;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"reverse\") == 0 && !reverse_obj) { reverse_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key)) { return NULL; }\n         }\n     }\n \n@@ -3299,8 +3273,8 @@ static PyObject *Strs_order(Strs *self, PyObject *args, PyObject *kwargs) {\n }\n \n static PyObject *Strs_sample(Strs *self, PyObject *args, PyObject *kwargs) {\n-    PyObject *seed_obj = NULL;\n     PyObject *sample_size_obj = NULL;\n+    PyObject *seed_obj = NULL;\n \n     // Check for positional arguments\n     Py_ssize_t nargs = PyTuple_Size(args);\n@@ -3312,14 +3286,11 @@ static PyObject *Strs_sample(Strs *self, PyObject *args, PyObject *kwargs) {\n \n     // Parse keyword arguments\n     if (kwargs) {\n-        Py_ssize_t pos = 0;\n         PyObject *key, *value;\n+        Py_ssize_t pos = 0;\n         while (PyDict_Next(kwargs, &pos, &key, &value)) {\n-            if (PyUnicode_CompareWithASCIIString(key, \"seed\") == 0) { seed_obj = value; }\n-            else {\n-                PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key);\n-                return 0;\n-            }\n+            if (PyUnicode_CompareWithASCIIString(key, \"seed\") == 0 && !seed_obj) { seed_obj = value; }\n+            else if (PyErr_Format(PyExc_TypeError, \"Got an unexpected keyword argument '%U'\", key)) { return NULL; }\n         }\n     }\n \n@@ -3647,6 +3618,7 @@ static PyMethodDef stringzilla_methods[] = {\n \n     // Global unary extensions\n     {\"hash\", Str_like_hash, SZ_METHOD_FLAGS, doc_like_hash},\n+    {\"equal\", Str_like_equal, SZ_METHOD_FLAGS, doc_like_equal},\n \n     {NULL, NULL, 0, NULL}};\n \ndiff --git a/scripts/bench_memory.cpp b/scripts/bench_memory.cpp\nindex eb72fc96..d8131102 100644\n--- a/scripts/bench_memory.cpp\n+++ b/scripts/bench_memory.cpp\n@@ -232,11 +232,11 @@ void bench_memory(std::vector<std::string_view> const &slices, sz_cptr_t dataset\n     bench_memory(slices, copy_functions<true>(dataset_start_ptr, output_buffer_ptr));\n     bench_memory(slices, copy_functions<false>(dataset_start_ptr, output_buffer_ptr));\n     bench_memory(slices, fill_functions(dataset_start_ptr, output_buffer_ptr));\n-    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 1));\n-    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 8));\n-    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, SZ_CACHE_LINE_WIDTH));\n-    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, max_shift_length));\n-    // bench_memory(slices, transform_functions());\n+    bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 1));\n+    bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 8));\n+    bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, SZ_CACHE_LINE_WIDTH));\n+    bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, max_shift_length));\n+    bench_memory(slices, transform_functions());\n }\n \n int main(int argc, char const **argv) {\n", "instance_id": "ashvardanian__StringZilla-181", "clarity": 1, "difficulty": 0.65, "clarity_explanation": "The problem statement is valid but lacks critical details, leading to significant ambiguities. The issue described is that `sz_dispatch_table` does not initialize in the Rust binding on Windows, and a screenshot is provided as evidence. However, there are no specifics about the expected behavior of `sz_dispatch_table`, the conditions under which it fails to initialize, or the desired outcome after the fix. The build output log is extensive but does not clearly point to the root cause of the issue. Additionally, there are no examples of input/output or test cases to validate the fix, and the problem statement does not mention any specific constraints or edge cases. While the code changes provide some context, the lack of a detailed explanation in the problem description about why `sz_dispatch_table` fails to initialize or what the initialization should achieve makes it difficult to fully understand the goal without diving deep into the codebase or making assumptions.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes spans multiple files (`CMakeLists.txt`, `c/lib.c`, etc.) and involves modifications to both build configurations and runtime initialization logic, indicating a need to understand interactions between different parts of the codebase (e.g., Rust bindings, C library, and Windows-specific behavior). The changes in `CMakeLists.txt` to link against MSVC runtime libraries and the modifications in `c/lib.c` to ensure initialization via `DllMain` suggest a deep understanding of Windows-specific DLL initialization and static linking challenges. \n\nSecond, the technical concepts involved are moderately complex, including knowledge of Windows DLL lifecycle management (`DllMain`), C runtime initialization, and cross-language bindings (Rust to C). Additionally, familiarity with build systems like CMake and how they interact with MSVC on Windows is required. \n\nThird, while the problem statement does not explicitly mention edge cases, the nature of the fix (ensuring initialization in a Windows environment) implies potential issues with different Windows versions, build configurations (static vs. dynamic linking), and Rust binding interactions, which would require careful error handling and testing. The code changes also impact a critical part of the system (initialization logic), which could have broader implications on the library's behavior if not handled correctly.\n\nOverall, solving this problem requires a solid grasp of system-level programming on Windows, cross-language integration, and build system intricacies, placing it in the 0.6-0.8 range. I\u2019ve assigned a score of 0.65 as it leans toward the lower end of \"Hard\" due to the relatively focused nature of the changes, despite the need for specialized knowledge."}
{"problem_statement": "Bug: sz_find incorrectly finds the substring with length=5\n### Describe the bug\n\nStringZilla incorrectly finds this case `\"Hello, world!\".find(\"world\", 0, 11)` which must return -1.\r\n\r\nFunction `sz_equal_serial` doesn't handle correctly the suffix of substring `\"world\"` (`suffix == \"d\"`). It goes exactly to last statement `return (sz_bool)(a_end == a);` where `a_end == \"!\"` and `a == \"!\"` which is very strange because at the first line of the function there is an assignment `sz_ptr_t const a_end = a + length;` where `length == 1` in debugger.\r\n\r\nIt looks like a while loop before `return` statement is written incorrectly for this case. `b++` (b was empty `\"\\0\"` string before entering the loop) remains empty randomly because subsequent memory is also clean (zeroes).\r\n\r\nI'm aware about #72 though it is just a wish for optimization.\n\n### Steps to reproduce\n\nSimple to test it in Python:\r\n```sh\r\npip install stringzilla\r\n```\r\nand\r\n```python\r\n>>> print(\"Hello, world!\".find(\"world\", 0, 11)) # original CPython algorithm\r\n-1\r\n>>> from stringzilla import Str\r\n>>> print(Str(\"Hello, world!\").find(\"world\", 0, 11)) # StringZilla algorithm\r\n7\r\n```\n\n### Expected behavior\n\n```python\r\n>>> print(\"Hello, world!\".find(\"world\", 0, 11)) # original CPython algorithm\r\n-1\r\n```\n\n### StringZilla version\n\n3.8.4\n\n### Operating System\n\nUbuntu 22.04 and Windows 10/11 64-bit\n\n### Hardware architecture\n\nx86\n\n### Which interface are you using?\n\nPython bindings\n\n### Contact Details\n\n_No response_\n\n### Are you open to being tagged as a contributor?\n\n- [X] I am open to being mentioned in the project `.git` history as a contributor\n\n### Is there an existing issue for this?\n\n- [X] I have searched the existing issues\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct\n", "patch": "diff --git a/.github/workflows/prerelease.yml b/.github/workflows/prerelease.yml\nindex a7d0e259..6efbdef6 100644\n--- a/.github/workflows/prerelease.yml\n+++ b/.github/workflows/prerelease.yml\n@@ -18,6 +18,32 @@ permissions:\n   contents: read\n \n jobs:\n+  versioning:\n+    name: Update Version\n+    runs-on: ubuntu-latest\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          fetch-depth: 0\n+          persist-credentials: false\n+      - name: Run TinySemVer\n+        uses: ashvardanian/tinysemver@v2.0.1\n+        with:\n+          verbose: \"true\"\n+          version-file: \"VERSION\"\n+          update-version-in: |\n+            Cargo.toml:^version = \"(\\d+\\.\\d+\\.\\d+)\"\n+            package.json:\"version\": \"(\\d+\\.\\d+\\.\\d+)\"\n+            CMakeLists.txt:VERSION (\\d+\\.\\d+\\.\\d+)\n+          update-major-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_MAJOR (\\d+)\n+          update-minor-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_MINOR (\\d+)\n+          update-patch-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_PATCH (\\d+)\n+          dry-run: \"true\"\n+\n   test_ubuntu_gcc:\n     name: Ubuntu (GCC 12)\n     runs-on: ubuntu-22.04\n@@ -230,7 +256,7 @@ jobs:\n           wget https://apt.llvm.org/llvm.sh\n           chmod +x llvm.sh\n           sudo ./llvm.sh 16\n-        \n+\n       - name: Build C/C++\n         run: |\n           cmake -B build_artifacts \\\ndiff --git a/.github/workflows/release.yml b/.github/workflows/release.yml\nindex 1f34d98e..a7b42e9e 100644\n--- a/.github/workflows/release.yml\n+++ b/.github/workflows/release.yml\n@@ -18,22 +18,38 @@ permissions:\n \n jobs:\n   versioning:\n-    name: Semantic Release\n-    runs-on: ubuntu-22.04\n+    name: Update Version\n+    runs-on: ubuntu-latest\n     steps:\n-      - uses: actions/checkout@v4\n+      - name: Checkout\n+        uses: actions/checkout@v4\n         with:\n+          fetch-depth: 0\n           persist-credentials: false\n-      - name: Set up Node.js\n-        uses: actions/setup-node@v4\n-        with:\n-          node-version: 20\n       - name: Set up Cargo\n         uses: actions-rs/toolchain@v1\n         with:\n           toolchain: stable\n           override: true\n-      - run: npm install --ignore-scripts --save-dev --prefix ./package-ci @semantic-release/exec @semantic-release/git conventional-changelog-eslint semantic-release && npx --prefix ./package-ci semantic-release\n+      - name: Run TinySemVer\n+        uses: ashvardanian/tinysemver@v2.0.1\n+        with:\n+          verbose: \"true\"\n+          version-file: \"VERSION\"\n+          update-version-in: |\n+            Cargo.toml:^version = \"(\\d+\\.\\d+\\.\\d+)\"\n+            package.json:\"version\": \"(\\d+\\.\\d+\\.\\d+)\"\n+            CMakeLists.txt:VERSION (\\d+\\.\\d+\\.\\d+)\n+          update-major-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_MAJOR (\\d+)\n+          update-minor-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_MINOR (\\d+)\n+          update-patch-version-in: |\n+            include/stringzilla/stringzilla.h:^#define STRINGZILLA_VERSION_PATCH (\\d+)\n+          dry-run: \"false\"\n+          push: \"true\"\n+          create-release: \"true\"\n+          github-token: ${{ secrets.SEMANTIC_RELEASE_TOKEN }}\n \n   rebase:\n     name: Rebase Dev. Branch\ndiff --git a/.github/workflows/update_version.sh b/.github/workflows/update_version.sh\ndeleted file mode 100644\nindex fc70eda3..00000000\n--- a/.github/workflows/update_version.sh\n+++ /dev/null\n@@ -1,13 +0,0 @@\n-#!/bin/sh\n-\n-echo $1 > VERSION && \n-    sed -i \"s/^\\(#define STRINGZILLA_VERSION_MAJOR \\).*/\\1$(echo \"$1\" | cut -d. -f1)/\" ./include/stringzilla/stringzilla.h &&\n-    sed -i \"s/^\\(#define STRINGZILLA_VERSION_MINOR \\).*/\\1$(echo \"$1\" | cut -d. -f2)/\" ./include/stringzilla/stringzilla.h &&\n-    sed -i \"s/^\\(#define STRINGZILLA_VERSION_PATCH \\).*/\\1$(echo \"$1\" | cut -d. -f3)/\" ./include/stringzilla/stringzilla.h &&\n-    sed -i \"s/^version = \\\".*\\\"/version = \\\"$1\\\"/\" Cargo.toml &&\n-    sed -i \"s/\\\"version\\\": \\\".*\\\"/\\\"version\\\": \\\"$1\\\"/\" package.json &&\n-    sed -i \"s/VERSION [0-9]\\+\\.[0-9]\\+\\.[0-9]\\+/VERSION $1/\" CMakeLists.txt\n-\n-# Update the version in the Cargo.lock file, but don't report an error if it fails...\n-# as `cargo` may not be available in the current environment.\n-cargo update || true\ndiff --git a/CONTRIBUTING.md b/CONTRIBUTING.md\nindex dd76bd41..c9d6a950 100644\n--- a/CONTRIBUTING.md\n+++ b/CONTRIBUTING.md\n@@ -56,6 +56,10 @@ unzip enwik9.zip && rm enwik9.zip && mv enwik9 enwik9.txt\n # 4.7 GB (1.7 GB compressed), 1'004'598 lines of UTF8, 268'435'456 tokens of mean length 8\n wget --no-clobber -O xlsum.csv.gz https://github.com/ashvardanian/xl-sum/releases/download/v1.0.0/xlsum.csv.gz\n gzip -d xlsum.csv.gz\n+\n+# Human chromosome generator dataset generated by https://github.com/rghilduta/human-chromosome-data-generator/blob/main/generate_chromosome_data.sh\n+# 1200 rows, each 800 characters long (939K)\n+wget --no-clobber -O human_protein_1200row_800len.txt https://media.githubusercontent.com/media/rghilduta/human-chromosome-data-generator/main/examples/human_protein_1200row_800len.txt\n ```\n \n ## IDE Integrations\ndiff --git a/cli/wc.py b/cli/wc.py\nindex e73bd3a5..d1533ab0 100755\n--- a/cli/wc.py\n+++ b/cli/wc.py\n@@ -1,6 +1,6 @@\n #!/usr/bin/env python3\n \n-import sys\n+import sys, os\n import argparse\n import stringzilla\n from stringzilla import File, Str\n@@ -30,6 +30,13 @@ def parse_arguments():\n     parser.add_argument(\n         \"-w\", \"--words\", action=\"store_true\", help=\"print the word counts\"\n     )\n+    parser.add_argument(\n+        \"--files0-from\",\n+        metavar=\"filename\",\n+        help=\"Read input from the files specified by NUL-terminated names in file F;\"\n+        \" If F is - then read names from standard input\",\n+    )\n+\n     parser.add_argument(\"--version\", action=\"version\", version=stringzilla.__version__)\n     return parser.parse_args()\n \n@@ -45,27 +52,28 @@ def wc(file_path, args):\n         except RuntimeError:  # File gives a RuntimeError if the file does not exist\n             return f\"No such file: {file_path}\", False\n \n-    line_count = mapped_bytes.count(\"\\n\")\n-    word_count = mapped_bytes.count(\" \") + 1\n-    char_count = mapped_bytes.__len__()\n-    counts = {\n-        \"line_count\": line_count,\n-        \"word_count\": word_count,\n-        \"char_count\": char_count,\n-    }\n+    counts = {}\n+    if args.lines:\n+        counts[\"line_count\"] = mapped_bytes.count(\"\\n\")\n+    if args.words:\n+        counts[\"word_count\"] = mapped_bytes.count(\" \") + 1\n+    if args.chars:\n+        counts[\"char_count\"] = mapped_bytes.__len__()\n \n     if args.max_line_length:\n-        max_line_length = max(len(line) for line in str(mapped_bytes).split(\"\\n\"))\n+        max_line_length = max(len(line) for line in mapped_bytes.split(\"\\n\"))\n         counts[\"max_line_length\"] = max_line_length\n \n-    if args.bytes or args.chars:\n-        byte_count = char_count  # assume 1 char = 1 byte\n-        counts[\"byte_count\"] = byte_count\n+    if args.bytes:\n+        if args.chars:\n+            counts[\"byte_count\"] = counts[\"char_count\"]\n+        else:\n+            counts[\"byte_count\"] = mapped_bytes.__len__()\n \n     return counts, True\n \n \n-def format_output(counts, args):\n+def format_output(counts, args, just):\n     selected_counts = []\n     if args.lines:\n         selected_counts.append(counts[\"line_count\"])\n@@ -74,18 +82,18 @@ def format_output(counts, args):\n     if args.chars:\n         selected_counts.append(counts[\"char_count\"])\n     if args.bytes:\n-        selected_counts.append(counts.get(\"byte_count\", counts[\"char_count\"]))\n+        selected_counts.append(counts[\"byte_count\"])\n     if args.max_line_length:\n         selected_counts.append(counts.get(\"max_line_length\", 0))\n \n-    if not any([args.lines, args.words, args.chars, args.bytes, args.max_line_length]):\n-        selected_counts = [\n-            counts[\"line_count\"],\n-            counts[\"word_count\"],\n-            counts[\"char_count\"],\n-        ]\n+    return \" \".join(str(count).rjust(just) for count in selected_counts)\n+\n \n-    return \" \".join(str(count) for count in selected_counts)\n+def get_files_from(fn):\n+    f = open(fn, \"r\")\n+    s = f.read()\n+    f.close()\n+    return [x for x in s.split(\"\\0\") if os.path.isfile(x)]\n \n \n def main():\n@@ -97,19 +105,33 @@ def main():\n         \"max_line_length\": 0,\n         \"byte_count\": 0,\n     }\n+    if not any([args.lines, args.words, args.chars, args.bytes, args.max_line_length]):\n+        args.lines = 1\n+        args.words = 1\n+        args.bytes = 1\n+\n+    # wc uses the file size to determine column width when printing\n+    if args.files0_from:\n+        if args.files[0] == \"-\":\n+            args.files = get_files_from(args.files0_from)\n+            if len(args.files) == 0:\n+                # print(\"  No filenames found in \", args.files0_from)\n+                exit(0)\n+\n+    just = max(len(str(os.stat(fn).st_size)) for fn in args.files)\n \n     for file_path in args.files:\n         counts, success = wc(file_path, args)\n         if success:\n             for key in total_counts.keys():\n                 total_counts[key] += counts.get(key, 0)\n-            output = format_output(counts, args) + f\" {file_path}\"\n+            output = format_output(counts, args, just) + f\" {file_path}\"\n             print(output)\n         else:\n             print(counts)\n \n     if len(args.files) > 1:\n-        total_output = format_output(total_counts, args) + \" total\"\n+        total_output = format_output(total_counts, args, just) + \" total\"\n         print(total_output)\n \n \ndiff --git a/include/stringzilla/stringzilla.h b/include/stringzilla/stringzilla.h\nindex 5c8d64c5..36b98cc7 100644\n--- a/include/stringzilla/stringzilla.h\n+++ b/include/stringzilla/stringzilla.h\n@@ -2194,7 +2194,7 @@ SZ_INTERNAL sz_cptr_t _sz_find_with_prefix(sz_cptr_t h, sz_size_t h_length, sz_c\n \n         // Verify the remaining part of the needle\n         sz_size_t remaining = h_length - (found - h);\n-        if (remaining < suffix_length) return SZ_NULL_CHAR;\n+        if (remaining < n_length) return SZ_NULL_CHAR;\n         if (sz_equal(found + prefix_length, n + prefix_length, suffix_length)) return found;\n \n         // Adjust the position.\n@@ -2246,7 +2246,6 @@ SZ_INTERNAL sz_cptr_t _sz_rfind_horspool_over_256bytes_serial(sz_cptr_t h, sz_si\n }\n \n SZ_PUBLIC sz_cptr_t sz_find_serial(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n, sz_size_t n_length) {\n-\n     // This almost never fires, but it's better to be safe than sorry.\n     if (h_length < n_length || !n_length) return SZ_NULL_CHAR;\n \n@@ -2620,11 +2619,9 @@ SZ_PUBLIC sz_size_t sz_edit_distance_serial(     //\n     // Skip the matching prefixes and suffixes, they won't affect the distance.\n     for (sz_cptr_t a_end = longer + longer_length, b_end = shorter + shorter_length;\n          longer != a_end && shorter != b_end && *longer == *shorter;\n-         ++longer, ++shorter, --longer_length, --shorter_length)\n-        ;\n+         ++longer, ++shorter, --longer_length, --shorter_length);\n     for (; longer_length && shorter_length && longer[longer_length - 1] == shorter[shorter_length - 1];\n-         --longer_length, --shorter_length)\n-        ;\n+         --longer_length, --shorter_length);\n \n     // Bounded computations may exit early.\n     if (bound) {\ndiff --git a/include/stringzilla/stringzilla.hpp b/include/stringzilla/stringzilla.hpp\nindex 98e1c2ec..499d4f29 100644\n--- a/include/stringzilla/stringzilla.hpp\n+++ b/include/stringzilla/stringzilla.hpp\n@@ -1348,9 +1348,7 @@ class basic_string_slice {\n      *  @brief  Compares two strings lexicographically. If prefix matches, lengths are compared.\n      *  @return 0 if equal, negative if `*this` is less than `other`, positive if `*this` is greater than `other`.\n      */\n-    int compare(string_view other) const noexcept {\n-        return (int)sz_order(start_, length_, other.start_, other.length_);\n-    }\n+    int compare(string_view other) const noexcept { return (int)sz_order(data(), size(), other.data(), other.size()); }\n \n     /**\n      *  @brief  Compares two strings lexicographically. If prefix matches, lengths are compared.\n@@ -1443,7 +1441,7 @@ class basic_string_slice {\n \n     /**  @brief  Checks if the string starts with the other string. */\n     bool starts_with(string_view other) const noexcept {\n-        return length_ >= other.length_ && sz_equal(start_, other.start_, other.length_) == sz_true_k;\n+        return length_ >= other.size() && sz_equal(start_, other.data(), other.size()) == sz_true_k;\n     }\n \n     /**  @brief  Checks if the string starts with the other string. */\n@@ -1457,8 +1455,8 @@ class basic_string_slice {\n \n     /**  @brief  Checks if the string ends with the other string. */\n     bool ends_with(string_view other) const noexcept {\n-        return length_ >= other.length_ &&\n-               sz_equal(start_ + length_ - other.length_, other.start_, other.length_) == sz_true_k;\n+        return length_ >= other.size() &&\n+               sz_equal(start_ + length_ - other.size(), other.data(), other.size()) == sz_true_k;\n     }\n \n     /**  @brief  Checks if the string ends with the other string. */\n@@ -1472,12 +1470,12 @@ class basic_string_slice {\n \n     /**  @brief  Python-like convenience function, dropping the matching prefix. */\n     string_slice remove_prefix(string_view other) const noexcept {\n-        return starts_with(other) ? string_slice {start_ + other.length_, length_ - other.length_} : *this;\n+        return starts_with(other) ? string_slice {start_ + other.size(), length_ - other.size()} : *this;\n     }\n \n     /**  @brief  Python-like convenience function, dropping the matching suffix. */\n     string_slice remove_suffix(string_view other) const noexcept {\n-        return ends_with(other) ? string_slice {start_, length_ - other.length_} : *this;\n+        return ends_with(other) ? string_slice {start_, length_ - other.size()} : *this;\n     }\n \n #pragma endregion\n@@ -1497,7 +1495,7 @@ class basic_string_slice {\n      *  @return The offset of the first character of the match, or `npos` if not found.\n      */\n     size_type find(string_view other, size_type skip = 0) const noexcept {\n-        auto ptr = sz_find(start_ + skip, length_ - skip, other.start_, other.length_);\n+        auto ptr = sz_find(start_ + skip, length_ - skip, other.data(), other.size());\n         return ptr ? ptr - start_ : npos;\n     }\n \n@@ -1525,7 +1523,7 @@ class basic_string_slice {\n      *  @return The offset of the first character of the match, or `npos` if not found.\n      */\n     size_type rfind(string_view other) const noexcept {\n-        auto ptr = sz_rfind(start_, length_, other.start_, other.length_);\n+        auto ptr = sz_rfind(start_, length_, other.data(), other.size());\n         return ptr ? ptr - start_ : npos;\n     }\n \n@@ -1731,7 +1729,7 @@ class basic_string_slice {\n      */\n     string_slice lstrip(char_set set) const noexcept {\n         set = set.inverted();\n-        auto new_start = sz_find_charset(start_, length_, &set.raw());\n+        auto new_start = (pointer)sz_find_charset(start_, length_, &set.raw());\n         return new_start ? string_slice {new_start, length_ - static_cast<size_type>(new_start - start_)}\n                          : string_slice();\n     }\n@@ -1742,7 +1740,7 @@ class basic_string_slice {\n      */\n     string_slice rstrip(char_set set) const noexcept {\n         set = set.inverted();\n-        auto new_end = sz_rfind_charset(start_, length_, &set.raw());\n+        auto new_end = (pointer)sz_rfind_charset(start_, length_, &set.raw());\n         return new_end ? string_slice {start_, static_cast<size_type>(new_end - start_ + 1)} : string_slice();\n     }\n \n@@ -1752,7 +1750,7 @@ class basic_string_slice {\n      */\n     string_slice strip(char_set set) const noexcept {\n         set = set.inverted();\n-        auto new_start = sz_find_charset(start_, length_, &set.raw());\n+        auto new_start = (pointer)sz_find_charset(start_, length_, &set.raw());\n         return new_start ? string_slice {new_start,\n                                          static_cast<size_type>(\n                                              sz_rfind_charset(new_start, length_ - (new_start - start_), &set.raw()) -\n@@ -1811,7 +1809,7 @@ class basic_string_slice {\n     rsplit_chars_type rsplit(char_set set = whitespaces_set()) const noexcept { return {*this, {set}}; }\n \n     /**  @brief  Split around the occurrences of all newline characters. */\n-    split_chars_type splitlines() const noexcept { return split(newlines_set); }\n+    split_chars_type splitlines() const noexcept { return split(newlines_set()); }\n \n #pragma endregion\n \n@@ -1826,9 +1824,9 @@ class basic_string_slice {\n     }\n \n   private:\n-    sz_constexpr_if_cpp20 string_view &assign(string_view const &other) noexcept {\n-        start_ = other.start_;\n-        length_ = other.length_;\n+    sz_constexpr_if_cpp20 string_slice &assign(string_view const &other) noexcept {\n+        start_ = (pointer)other.data();\n+        length_ = other.size();\n         return *this;\n     }\n \n@@ -1841,17 +1839,17 @@ class basic_string_slice {\n     template <typename pattern_>\n     partition_type partition_(pattern_ &&pattern, std::size_t pattern_length) const noexcept {\n         size_type pos = find(pattern);\n-        if (pos == npos) return {*this, string_view(), string_view()};\n-        return {string_view(start_, pos), string_view(start_ + pos, pattern_length),\n-                string_view(start_ + pos + pattern_length, length_ - pos - pattern_length)};\n+        if (pos == npos) return {string_slice(*this), string_slice(), string_slice()};\n+        return {string_slice(start_, pos), string_slice(start_ + pos, pattern_length),\n+                string_slice(start_ + pos + pattern_length, length_ - pos - pattern_length)};\n     }\n \n     template <typename pattern_>\n     partition_type rpartition_(pattern_ &&pattern, std::size_t pattern_length) const noexcept {\n         size_type pos = rfind(pattern);\n-        if (pos == npos) return {*this, string_view(), string_view()};\n-        return {string_view(start_, pos), string_view(start_ + pos, pattern_length),\n-                string_view(start_ + pos + pattern_length, length_ - pos - pattern_length)};\n+        if (pos == npos) return {string_slice(*this), string_slice(), string_slice()};\n+        return {string_slice(start_, pos), string_slice(start_ + pos, pattern_length),\n+                string_slice(start_ + pos + pattern_length, length_ - pos - pattern_length)};\n     }\n };\n \n@@ -3191,7 +3189,7 @@ class basic_string {\n         return basic_string {concatenation<string_view, string_view> {view(), other}};\n     }\n     basic_string operator+(std::initializer_list<char_type> other) const noexcept(false) {\n-        return basic_string {concatenation<string_view, string_view> {view(), other}};\n+        return basic_string {concatenation<string_view, string_view> {view(), string_view(other)}};\n     }\n \n #pragma endregion\ndiff --git a/package-ci.json b/package-ci.json\ndeleted file mode 100644\nindex 6288162c..00000000\n--- a/package-ci.json\n+++ /dev/null\n@@ -1,10 +0,0 @@\n-{\n-    \"name\": \"stringzilla-ci\",\n-    \"version\": \"1.0.0\",\n-    \"devDependencies\": {\n-        \"@semantic-release/exec\": \"^6.0.3\",\n-        \"@semantic-release/git\": \"^10.0.1\",\n-        \"conventional-changelog-eslint\": \"^3.0.9\",\n-        \"semantic-release\": \"^21.1.2\"\n-    }\n-}\n\\ No newline at end of file\ndiff --git a/rust/lib.rs b/rust/lib.rs\nindex 652bba5a..30150efb 100644\n--- a/rust/lib.rs\n+++ b/rust/lib.rs\n@@ -696,6 +696,265 @@ pub mod sz {\n     }\n }\n \n+pub trait Matcher<'a> {\n+    fn find(&self, haystack: &'a [u8]) -> Option<usize>;\n+    fn needle_length(&self) -> usize;\n+    fn skip_length(&self, include_overlaps: bool, is_reverse: bool) -> usize;\n+}\n+\n+pub enum MatcherType<'a> {\n+    Find(&'a [u8]),\n+    RFind(&'a [u8]),\n+    FindFirstOf(&'a [u8]),\n+    FindLastOf(&'a [u8]),\n+    FindFirstNotOf(&'a [u8]),\n+    FindLastNotOf(&'a [u8]),\n+}\n+\n+impl<'a> Matcher<'a> for MatcherType<'a> {\n+    fn find(&self, haystack: &'a [u8]) -> Option<usize> {\n+        match self {\n+            MatcherType::Find(needle) => sz::find(haystack, needle),\n+            MatcherType::RFind(needle) => sz::rfind(haystack, needle),\n+            MatcherType::FindFirstOf(needles) => sz::find_char_from(haystack, needles),\n+            MatcherType::FindLastOf(needles) => sz::rfind_char_from(haystack, needles),\n+            MatcherType::FindFirstNotOf(needles) => sz::find_char_not_from(haystack, needles),\n+            MatcherType::FindLastNotOf(needles) => sz::rfind_char_not_from(haystack, needles),\n+        }\n+    }\n+\n+    fn needle_length(&self) -> usize {\n+        match self {\n+            MatcherType::Find(needle) | MatcherType::RFind(needle) => needle.len(),\n+            _ => 1,\n+        }\n+    }\n+\n+    fn skip_length(&self, include_overlaps: bool, is_reverse: bool) -> usize {\n+        match (include_overlaps, is_reverse) {\n+            (true, true) => self.needle_length().saturating_sub(1),\n+            (true, false) => 1,\n+            (false, true) => 0,\n+            (false, false) => self.needle_length(),\n+        }\n+    }\n+}\n+\n+/// An iterator over non-overlapping matches of a pattern in a string slice.\n+/// This iterator yields the matched substrings in the order they are found.\n+///\n+/// # Examples\n+///\n+/// ```\n+/// use stringzilla::{sz, MatcherType, RangeMatches};\n+///\n+/// let haystack = b\"abababa\";\n+/// let matcher = MatcherType::Find(b\"aba\");\n+/// let matches: Vec<&[u8]> = RangeMatches::new(haystack, matcher, false).collect();\n+/// assert_eq!(matches, vec![b\"aba\", b\"aba\"]);\n+/// ```\n+pub struct RangeMatches<'a> {\n+    haystack: &'a [u8],\n+    matcher: MatcherType<'a>,\n+    position: usize,\n+    include_overlaps: bool,\n+}\n+\n+impl<'a> RangeMatches<'a> {\n+    pub fn new(haystack: &'a [u8], matcher: MatcherType<'a>, include_overlaps: bool) -> Self {\n+        Self {\n+            haystack,\n+            matcher,\n+            position: 0,\n+            include_overlaps,\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator for RangeMatches<'a> {\n+    type Item = &'a [u8];\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        if self.position >= self.haystack.len() {\n+            return None;\n+        }\n+\n+        if let Some(index) = self.matcher.find(&self.haystack[self.position..]) {\n+            let start = self.position + index;\n+            let end = start + self.matcher.needle_length();\n+            self.position = start + self.matcher.skip_length(self.include_overlaps, false);\n+            Some(&self.haystack[start..end])\n+        } else {\n+            self.position = self.haystack.len();\n+            None\n+        }\n+    }\n+}\n+\n+/// An iterator over non-overlapping splits of a string slice by a pattern.\n+/// This iterator yields the substrings between the matches of the pattern.\n+///\n+/// # Examples\n+///\n+/// ```\n+/// use stringzilla::{sz, MatcherType, RangeSplits};\n+///\n+/// let haystack = b\"a,b,c,d\";\n+/// let matcher = MatcherType::Find(b\",\");\n+/// let splits: Vec<&[u8]> = RangeSplits::new(haystack, matcher).collect();\n+/// assert_eq!(splits, vec![b\"a\", b\"b\", b\"c\", b\"d\"]);\n+/// ```\n+pub struct RangeSplits<'a> {\n+    haystack: &'a [u8],\n+    matcher: MatcherType<'a>,\n+    position: usize,\n+    last_match: Option<usize>,\n+}\n+\n+impl<'a> RangeSplits<'a> {\n+    pub fn new(haystack: &'a [u8], matcher: MatcherType<'a>) -> Self {\n+        Self {\n+            haystack,\n+            matcher,\n+            position: 0,\n+            last_match: None,\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator for RangeSplits<'a> {\n+    type Item = &'a [u8];\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        if self.position > self.haystack.len() {\n+            return None;\n+        }\n+\n+        if let Some(index) = self.matcher.find(&self.haystack[self.position..]) {\n+            let start = self.position;\n+            let end = self.position + index;\n+            self.position = end + self.matcher.needle_length();\n+            self.last_match = Some(end);\n+            Some(&self.haystack[start..end])\n+        } else if self.position < self.haystack.len() || self.last_match.is_some() {\n+            let start = self.position;\n+            self.position = self.haystack.len() + 1;\n+            Some(&self.haystack[start..])\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+/// An iterator over non-overlapping matches of a pattern in a string slice, searching from the end.\n+/// This iterator yields the matched substrings in reverse order.\n+///\n+/// # Examples\n+///\n+/// ```\n+/// use stringzilla::{sz, MatcherType, RangeRMatches};\n+///\n+/// let haystack = b\"abababa\";\n+/// let matcher = MatcherType::RFind(b\"aba\");\n+/// let matches: Vec<&[u8]> = RangeRMatches::new(haystack, matcher, false).collect();\n+/// assert_eq!(matches, vec![b\"aba\", b\"aba\"]);\n+/// ```\n+pub struct RangeRMatches<'a> {\n+    haystack: &'a [u8],\n+    matcher: MatcherType<'a>,\n+    position: usize,\n+    include_overlaps: bool,\n+}\n+\n+impl<'a> RangeRMatches<'a> {\n+    pub fn new(haystack: &'a [u8], matcher: MatcherType<'a>, include_overlaps: bool) -> Self {\n+        Self {\n+            haystack,\n+            matcher,\n+            position: haystack.len(),\n+            include_overlaps,\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator for RangeRMatches<'a> {\n+    type Item = &'a [u8];\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        if self.position == 0 {\n+            return None;\n+        }\n+\n+        let search_area = &self.haystack[..self.position];\n+        if let Some(index) = self.matcher.find(search_area) {\n+            let start = index;\n+            let end = start + self.matcher.needle_length();\n+            let result = Some(&self.haystack[start..end]);\n+\n+            let skip = self.matcher.skip_length(self.include_overlaps, true);\n+            self.position = start + skip;\n+\n+            result\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+/// An iterator over non-overlapping splits of a string slice by a pattern, searching from the end.\n+/// This iterator yields the substrings between the matches of the pattern in reverse order.\n+///\n+/// # Examples\n+///\n+/// ```\n+/// use stringzilla::{sz, MatcherType, RangeRSplits};\n+///\n+/// let haystack = b\"a,b,c,d\";\n+/// let matcher = MatcherType::RFind(b\",\");\n+/// let splits: Vec<&[u8]> = RangeRSplits::new(haystack, matcher).collect();\n+/// assert_eq!(splits, vec![b\"d\", b\"c\", b\"b\", b\"a\"]);\n+/// ```\n+pub struct RangeRSplits<'a> {\n+    haystack: &'a [u8],\n+    matcher: MatcherType<'a>,\n+    position: usize,\n+}\n+\n+impl<'a> RangeRSplits<'a> {\n+    pub fn new(haystack: &'a [u8], matcher: MatcherType<'a>) -> Self {\n+        Self {\n+            haystack,\n+            matcher,\n+            position: haystack.len(),\n+        }\n+    }\n+}\n+\n+impl<'a> Iterator for RangeRSplits<'a> {\n+    type Item = &'a [u8];\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        if self.position == 0 {\n+            return None;\n+        }\n+\n+        let search_area = &self.haystack[..self.position];\n+        if let Some(index) = self.matcher.find(search_area) {\n+            let end = self.position;\n+            let start = index + self.matcher.needle_length();\n+            let result = Some(&self.haystack[start..end]);\n+\n+            self.position = index;\n+\n+            result\n+        } else {\n+            let result = Some(&self.haystack[..self.position]);\n+            self.position = 0;\n+            result\n+        }\n+    }\n+}\n+\n /// Provides extensions for string searching and manipulation functionalities\n /// on types that can reference byte slices ([u8]). This trait extends the capability\n /// of any type implementing `AsRef<[u8]>`, allowing easy integration of SIMD-accelerated\n@@ -724,9 +983,9 @@ pub mod sz {\n ///\n /// assert_eq!(haystack.sz_find(needle.as_bytes()), Some(2));\n /// ```\n-pub trait StringZilla<N>\n+pub trait StringZilla<'a, N>\n where\n-    N: AsRef<[u8]>,\n+    N: AsRef<[u8]> + 'a,\n {\n     /// Searches for the first occurrence of `needle` in `self`.\n     ///\n@@ -828,12 +1087,157 @@ where\n     /// assert_eq!(first.sz_alignment_score(second.as_bytes(), matrix, gap_penalty), -3);\n     /// ```\n     fn sz_alignment_score(&self, other: N, matrix: [[i8; 256]; 256], gap: i8) -> isize;\n+\n+    /// Returns an iterator over all non-overlapping matches of the given `needle` in `self`.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needle`: The byte slice to search for within `self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"abababa\";\n+    /// let needle = b\"aba\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_matches(needle).collect();\n+    /// assert_eq!(matches, vec![b\"aba\", b\"aba\", b\"aba\"]);\n+    /// ```\n+    fn sz_matches(&'a self, needle: &'a N) -> RangeMatches<'a>;\n+\n+    /// Returns an iterator over all non-overlapping matches of the given `needle` in `self`, searching from the end.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needle`: The byte slice to search for within `self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"abababa\";\n+    /// let needle = b\"aba\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_rmatches(needle).collect();\n+    /// assert_eq!(matches, vec![b\"aba\", b\"aba\", b\"aba\"]);\n+    /// ```\n+    fn sz_rmatches(&'a self, needle: &'a N) -> RangeRMatches<'a>;\n+\n+    /// Returns an iterator over the substrings of `self` that are separated by the given `needle`.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needle`: The byte slice to split `self` by.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"a,b,c,d\";\n+    /// let needle = b\",\";\n+    /// let splits: Vec<&[u8]> = haystack.sz_splits(needle).collect();\n+    /// assert_eq!(splits, vec![b\"a\", b\"b\", b\"c\", b\"d\"]);\n+    /// ```\n+    fn sz_splits(&'a self, needle: &'a N) -> RangeSplits<'a>;\n+\n+    /// Returns an iterator over the substrings of `self` that are separated by the given `needle`, searching from the end.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needle`: The byte slice to split `self` by.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"a,b,c,d\";\n+    /// let needle = b\",\";\n+    /// let splits: Vec<&[u8]> = haystack.sz_rsplits(needle).collect();\n+    /// assert_eq!(splits, vec![b\"d\", b\"c\", b\"b\", b\"a\"]);\n+    /// ```\n+    fn sz_rsplits(&'a self, needle: &'a N) -> RangeRSplits<'a>;\n+\n+    /// Returns an iterator over all non-overlapping matches of any of the bytes in `needles` within `self`.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needles`: The set of bytes to search for within `self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"Hello, world!\";\n+    /// let needles = b\"aeiou\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_find_first_of(needles).collect();\n+    /// assert_eq!(matches, vec![b\"e\", b\"o\", b\"o\"]);\n+    /// ```\n+    fn sz_find_first_of(&'a self, needles: &'a N) -> RangeMatches<'a>;\n+\n+    /// Returns an iterator over all non-overlapping matches of any of the bytes in `needles` within `self`, searching from the end.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needles`: The set of bytes to search for within `self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"Hello, world!\";\n+    /// let needles = b\"aeiou\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_find_last_of(needles).collect();\n+    /// assert_eq!(matches, vec![b\"o\", b\"o\", b\"e\"]);\n+    /// ```\n+    fn sz_find_last_of(&'a self, needles: &'a N) -> RangeRMatches<'a>;\n+\n+    /// Returns an iterator over all non-overlapping matches of any byte not in `needles` within `self`.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needles`: The set of bytes that should not be matched within `self`.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"Hello, world!\";\n+    /// let needles = b\"aeiou\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_find_first_not_of(needles).collect();\n+    /// assert_eq!(matches, vec![b\"H\", b\"l\", b\"l\", b\",\", b\" \", b\"w\", b\"r\", b\"l\", b\"d\", b\"!\"]);\n+    /// ```\n+    fn sz_find_first_not_of(&'a self, needles: &'a N) -> RangeMatches<'a>;\n+\n+    /// Returns an iterator over all non-overlapping matches of any byte not in `needles` within `self`, searching from the end.\n+    ///\n+    /// # Arguments\n+    ///\n+    /// * `needles`: The set of bytes that should not be matched within `self`.\n+    ///q\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// use stringzilla::StringZilla;\n+    ///\n+    /// let haystack = b\"Hello, world!\";\n+    /// let needles = b\"aeiou\";\n+    /// let matches: Vec<&[u8]> = haystack.sz_find_last_not_of(needles).collect();\n+    /// assert_eq!(matches, vec![b\"!\", b\"d\", b\"l\", b\"r\", b\"w\", b\" \", b\",\", b\"l\", b\"l\", b\"H\"]);\n+    /// ```\n+    fn sz_find_last_not_of(&'a self, needles: &'a N) -> RangeRMatches<'a>;\n+\n }\n \n-impl<T, N> StringZilla<N> for T\n+impl<'a, T, N> StringZilla<'a, N> for T\n where\n-    T: AsRef<[u8]>,\n-    N: AsRef<[u8]>,\n+    T: AsRef<[u8]> + ?Sized,\n+    N: AsRef<[u8]> + 'a,\n {\n     fn sz_find(&self, needle: N) -> Option<usize> {\n         sz::find(self, needle)\n@@ -866,6 +1270,54 @@ where\n     fn sz_alignment_score(&self, other: N, matrix: [[i8; 256]; 256], gap: i8) -> isize {\n         sz::alignment_score(self, other, matrix, gap)\n     }\n+\n+    fn sz_matches(&'a self, needle: &'a N) -> RangeMatches<'a> {\n+        RangeMatches::new(self.as_ref(), MatcherType::Find(needle.as_ref()), true)\n+    }\n+\n+    fn sz_rmatches(&'a self, needle: &'a N) -> RangeRMatches<'a> {\n+        RangeRMatches::new(self.as_ref(), MatcherType::RFind(needle.as_ref()), true)\n+    }\n+\n+    fn sz_splits(&'a self, needle: &'a N) -> RangeSplits<'a> {\n+        RangeSplits::new(self.as_ref(), MatcherType::Find(needle.as_ref()))\n+    }\n+\n+    fn sz_rsplits(&'a self, needle: &'a N) -> RangeRSplits<'a> {\n+        RangeRSplits::new(self.as_ref(), MatcherType::RFind(needle.as_ref()))\n+    }\n+\n+    fn sz_find_first_of(&'a self, needles: &'a N) -> RangeMatches<'a> {\n+        RangeMatches::new(\n+            self.as_ref(),\n+            MatcherType::FindFirstOf(needles.as_ref()),\n+            true,\n+        )\n+    }\n+\n+    fn sz_find_last_of(&'a self, needles: &'a N) -> RangeRMatches<'a> {\n+        RangeRMatches::new(\n+            self.as_ref(),\n+            MatcherType::FindLastOf(needles.as_ref()),\n+            true,\n+        )\n+    }\n+\n+    fn sz_find_first_not_of(&'a self, needles: &'a N) -> RangeMatches<'a> {\n+        RangeMatches::new(\n+            self.as_ref(),\n+            MatcherType::FindFirstNotOf(needles.as_ref()),\n+            true,\n+        )\n+    }\n+\n+    fn sz_find_last_not_of(&'a self, needles: &'a N) -> RangeRMatches<'a> {\n+        RangeRMatches::new(\n+            self.as_ref(),\n+            MatcherType::FindLastNotOf(needles.as_ref()),\n+            true,\n+        )\n+    }\n }\n \n /// Provides a tool for mutating a byte slice by filling it with random data from a specified alphabet.\n@@ -1016,4 +1468,164 @@ mod tests {\n             .iter()\n             .all(|&b| b == b'd' || b == b'c' || b == b'b' || b == b'a'));\n     }\n+\n+    mod search_split_iterators {\n+        use super::*;\n+        use crate::{MatcherType, RangeMatches, RangeRMatches};\n+\n+        #[test]\n+        fn test_matches() {\n+            let haystack = b\"hello world hello universe\";\n+            let needle = b\"hello\";\n+            let matches: Vec<_> = haystack.sz_matches(needle).collect();\n+            assert_eq!(matches, vec![b\"hello\", b\"hello\"]);\n+        }\n+\n+        #[test]\n+        fn test_rmatches() {\n+            let haystack = b\"hello world hello universe\";\n+            let needle = b\"hello\";\n+            let matches: Vec<_> = haystack.sz_rmatches(needle).collect();\n+            assert_eq!(matches, vec![b\"hello\", b\"hello\"]);\n+        }\n+\n+        #[test]\n+        fn test_splits() {\n+            let haystack = b\"alpha,beta;gamma\";\n+            let needle = b\",\";\n+            let splits: Vec<_> = haystack.sz_splits(needle).collect();\n+            assert_eq!(splits, vec![&b\"alpha\"[..], &b\"beta;gamma\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_rsplits() {\n+            let haystack = b\"alpha,beta;gamma\";\n+            let needle = b\";\";\n+            let splits: Vec<_> = haystack.sz_rsplits(needle).collect();\n+            assert_eq!(splits, vec![&b\"gamma\"[..], &b\"alpha,beta\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_splits_with_empty_parts() {\n+            let haystack = b\"a,,b,\";\n+            let needle = b\",\";\n+            let splits: Vec<_> = haystack.sz_splits(needle).collect();\n+            assert_eq!(splits, vec![b\"a\", &b\"\"[..], b\"b\", &b\"\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_matches_with_overlaps() {\n+            let haystack = b\"aaaa\";\n+            let needle = b\"aa\";\n+            let matches: Vec<_> = haystack.sz_matches(needle).collect();\n+            assert_eq!(matches, vec![b\"aa\", b\"aa\", b\"aa\"]);\n+        }\n+\n+        #[test]\n+        fn test_splits_with_utf8() {\n+            let haystack = \"\u3053\u3093\u306b\u3061\u306f,\u4e16\u754c\".as_bytes();\n+            let needle = b\",\";\n+            let splits: Vec<_> = haystack.sz_splits(needle).collect();\n+            assert_eq!(splits, vec![\"\u3053\u3093\u306b\u3061\u306f\".as_bytes(), \"\u4e16\u754c\".as_bytes()]);\n+        }\n+\n+        #[test]\n+        fn test_find_first_of() {\n+            let haystack = b\"hello world\";\n+            let needles = b\"or\";\n+            let matches: Vec<_> = haystack.sz_find_first_of(needles).collect();\n+            assert_eq!(matches, vec![b\"o\", b\"o\", b\"r\"]);\n+        }\n+\n+        #[test]\n+        fn test_find_last_of() {\n+            let haystack = b\"hello world\";\n+            let needles = b\"or\";\n+            let matches: Vec<_> = haystack.sz_find_last_of(needles).collect();\n+            assert_eq!(matches, vec![b\"r\", b\"o\", b\"o\"]);\n+        }\n+\n+        #[test]\n+        fn test_find_first_not_of() {\n+            let haystack = b\"aabbbcccd\";\n+            let needles = b\"ab\";\n+            let matches: Vec<_> = haystack.sz_find_first_not_of(needles).collect();\n+            assert_eq!(matches, vec![b\"c\", b\"c\", b\"c\", b\"d\"]);\n+        }\n+\n+        #[test]\n+        fn test_find_last_not_of() {\n+            let haystack = b\"aabbbcccd\";\n+            let needles = b\"cd\";\n+            let matches: Vec<_> = haystack.sz_find_last_not_of(needles).collect();\n+            assert_eq!(matches, vec![b\"b\", b\"b\", b\"b\", b\"a\", b\"a\"]);\n+        }\n+\n+        #[test]\n+        fn test_find_first_of_empty_needles() {\n+            let haystack = b\"hello world\";\n+            let needles = b\"\";\n+            let matches: Vec<_> = haystack.sz_find_first_of(needles).collect();\n+            assert_eq!(matches, Vec::<&[u8]>::new());\n+        }\n+\n+        #[test]\n+        fn test_find_last_of_empty_haystack() {\n+            let haystack = b\"\";\n+            let needles = b\"abc\";\n+            let matches: Vec<_> = haystack.sz_find_last_of(needles).collect();\n+            assert_eq!(matches, Vec::<&[u8]>::new());\n+        }\n+\n+        #[test]\n+        fn test_find_first_not_of_all_matching() {\n+            let haystack = b\"aaabbbccc\";\n+            let needles = b\"abc\";\n+            let matches: Vec<_> = haystack.sz_find_first_not_of(needles).collect();\n+            assert_eq!(matches, Vec::<&[u8]>::new());\n+        }\n+\n+        #[test]\n+        fn test_find_last_not_of_all_not_matching() {\n+            let haystack = b\"hello world\";\n+            let needles = b\"xyz\";\n+            let matches: Vec<_> = haystack.sz_find_last_not_of(needles).collect();\n+            assert_eq!(\n+                matches,\n+                vec![b\"d\", b\"l\", b\"r\", b\"o\", b\"w\", b\" \", b\"o\", b\"l\", b\"l\", b\"e\", b\"h\"]\n+            );\n+        }\n+\n+        #[test]\n+        fn test_range_matches_overlapping() {\n+            let haystack = b\"aaaa\";\n+            let matcher = MatcherType::Find(b\"aa\");\n+            let matches: Vec<_> = RangeMatches::new(haystack, matcher, true).collect();\n+            assert_eq!(matches, vec![&b\"aa\"[..], &b\"aa\"[..], &b\"aa\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_range_matches_non_overlapping() {\n+            let haystack = b\"aaaa\";\n+            let matcher = MatcherType::Find(b\"aa\");\n+            let matches: Vec<_> = RangeMatches::new(haystack, matcher, false).collect();\n+            assert_eq!(matches, vec![&b\"aa\"[..], &b\"aa\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_range_rmatches_overlapping() {\n+            let haystack = b\"aaaa\";\n+            let matcher = MatcherType::RFind(b\"aa\");\n+            let matches: Vec<_> = RangeRMatches::new(haystack, matcher, true).collect();\n+            assert_eq!(matches, vec![&b\"aa\"[..], &b\"aa\"[..], &b\"aa\"[..]]);\n+        }\n+\n+        #[test]\n+        fn test_range_rmatches_non_overlapping() {\n+            let haystack = b\"aaaa\";\n+            let matcher = MatcherType::RFind(b\"aa\");\n+            let matches: Vec<_> = RangeRMatches::new(haystack, matcher, false).collect();\n+            assert_eq!(matches, vec![&b\"aa\"[..], &b\"aa\"[..]]);\n+        }\n+    }\n }\n", "instance_id": "ashvardanian__StringZilla-156", "clarity": 2, "difficulty": 0.55, "clarity_explanation": "The problem statement is mostly clear in describing the bug in the `sz_find` function of the StringZilla library, specifically with the `find` method returning incorrect results for a substring search with specified start and end indices. It provides a reproducible example using Python bindings, showing the expected behavior versus the actual behavior, which is very helpful. The issue is pinpointed to a potential flaw in the `sz_equal_serial` function's handling of suffixes and a problematic while loop. However, there are minor ambiguities: the problem statement does not fully clarify the expected behavior for all edge cases (e.g., empty strings, invalid indices), and the description of the loop issue is somewhat vague, relying on debugger observations rather than a precise explanation of the logical error. Additionally, while the bug is described, the constraints or broader context of the `find` method's behavior (e.g., performance expectations or compatibility with CPython) are not fully detailed. Overall, it is clear enough to understand the issue and start working on a fix, but some minor details are missing.", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the clarity of the problem statement helps narrow down the issue to the `sz_find` function and its suffix handling, but identifying the exact logical error in the loop or comparison logic requires a moderate understanding of string matching algorithms (likely Horspool or similar, as hinted by the code). The code changes provided show modifications in multiple areas, including the core library logic in `stringzilla.h` (fixing the `find` function's length check), Rust bindings (adding new iterator-based search and split functionalities), and even CI workflows (versioning updates). This indicates that solving the core bug and integrating the fix requires understanding interactions across C/C++ core logic, Rust interfaces, and potentially Python bindings, which adds to the complexity. The technical concepts involved include string matching algorithms, memory handling in C, and iterator design in Rust, which are moderately complex but not overly advanced. Edge cases, such as empty strings, invalid indices, or overlapping matches, are partially addressed in the new Rust iterators but not fully specified in the problem statement, requiring the developer to infer and handle them. The changes impact a core functionality (`find`), which could have downstream effects on performance or behavior in other parts of the system, necessitating careful testing. However, the problem does not seem to require deep architectural refactoring or advanced domain-specific knowledge beyond string processing, keeping it from being classified as hard or very hard. A score of 0.55 reflects the need for a solid grasp of multiple concepts, careful debugging, and moderate cross-module changes, but it remains within the reach of an intermediate developer with experience in systems programming."}
{"problem_statement": "Deduplicate fontdb types\n`resvg` optionally depends on `fontdb`. Meanwhile,\r\n\r\n- `usvg::FontStyle` is identical to `fontdb::Style`\r\n- `usvg::FontStretch` is identical to `fontdb::Stretch`\r\n\r\nWorse, there isn't even a conversion method between the two. This is a pain when implementing a `usvg::FontResolver`.\n", "patch": "diff --git a/crates/usvg/src/tree/text.rs b/crates/usvg/src/tree/text.rs\nindex 64903fa6..f488ec79 100644\n--- a/crates/usvg/src/tree/text.rs\n+++ b/crates/usvg/src/tree/text.rs\n@@ -33,6 +33,40 @@ impl Default for FontStretch {\n     }\n }\n \n+#[cfg(feature = \"text\")]\n+impl From<fontdb::Stretch> for FontStretch {\n+    fn from(stretch: fontdb::Stretch) -> Self {\n+        match stretch {\n+            fontdb::Stretch::UltraCondensed => FontStretch::UltraCondensed,\n+            fontdb::Stretch::ExtraCondensed => FontStretch::ExtraCondensed,\n+            fontdb::Stretch::Condensed => FontStretch::Condensed,\n+            fontdb::Stretch::SemiCondensed => FontStretch::SemiCondensed,\n+            fontdb::Stretch::Normal => FontStretch::Normal,\n+            fontdb::Stretch::SemiExpanded => FontStretch::SemiExpanded,\n+            fontdb::Stretch::Expanded => FontStretch::Expanded,\n+            fontdb::Stretch::ExtraExpanded => FontStretch::ExtraExpanded,\n+            fontdb::Stretch::UltraExpanded => FontStretch::UltraExpanded,\n+        }\n+    }\n+}\n+\n+#[cfg(feature = \"text\")]\n+impl From<FontStretch> for fontdb::Stretch {\n+    fn from(stretch: FontStretch) -> Self {\n+        match stretch {\n+            FontStretch::UltraCondensed => fontdb::Stretch::UltraCondensed,\n+            FontStretch::ExtraCondensed => fontdb::Stretch::ExtraCondensed,\n+            FontStretch::Condensed => fontdb::Stretch::Condensed,\n+            FontStretch::SemiCondensed => fontdb::Stretch::SemiCondensed,\n+            FontStretch::Normal => fontdb::Stretch::Normal,\n+            FontStretch::SemiExpanded => fontdb::Stretch::SemiExpanded,\n+            FontStretch::Expanded => fontdb::Stretch::Expanded,\n+            FontStretch::ExtraExpanded => fontdb::Stretch::ExtraExpanded,\n+            FontStretch::UltraExpanded => fontdb::Stretch::UltraExpanded,\n+        }\n+    }\n+}\n+\n /// A font style property.\n #[derive(Clone, Copy, PartialEq, Eq, Debug, Hash)]\n pub enum FontStyle {\n@@ -51,6 +85,28 @@ impl Default for FontStyle {\n     }\n }\n \n+#[cfg(feature = \"text\")]\n+impl From<fontdb::Style> for FontStyle {\n+    fn from(style: fontdb::Style) -> Self {\n+        match style {\n+            fontdb::Style::Normal => FontStyle::Normal,\n+            fontdb::Style::Italic => FontStyle::Italic,\n+            fontdb::Style::Oblique => FontStyle::Oblique,\n+        }\n+    }\n+}\n+\n+#[cfg(feature = \"text\")]\n+impl From<FontStyle> for fontdb::Style {\n+    fn from(style: FontStyle) -> Self {\n+        match style {\n+            FontStyle::Normal => fontdb::Style::Normal,\n+            FontStyle::Italic => fontdb::Style::Italic,\n+            FontStyle::Oblique => fontdb::Style::Oblique,\n+        }\n+    }\n+}\n+\n /// Text font properties.\n #[derive(Clone, Eq, PartialEq, Hash, Debug)]\n pub struct Font {\n", "instance_id": "linebender__resvg-813", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: there is a duplication of types between `usvg` and `fontdb` (specifically `FontStyle` and `FontStretch`), and there is no conversion mechanism between them, which creates friction when implementing a `usvg::FontResolver`. The goal of deduplicating or providing conversion is implied, and the code changes align with this interpretation by adding conversion implementations. However, the statement lacks explicit detail on the expected solution (e.g., whether to fully deduplicate by removing one set of types or just add conversions) and does not mention any constraints, edge cases, or broader implications of the change. Additionally, there are no examples or specific use cases provided to illustrate the pain point. Thus, while the problem is valid and mostly clear, minor details are missing, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls in the easy range (0.2-0.4) due to several factors. First, the scope of the code changes is limited to a single file (`crates/usvg/src/tree/text.rs`) and involves straightforward additions of conversion implementations using the `From` trait in Rust. The changes do not impact the broader architecture of the codebase or require understanding complex interactions between modules. Second, the technical concepts involved are basic: familiarity with Rust's trait system and enum matching, which are fundamental language features, is sufficient. No advanced algorithms, design patterns, or domain-specific knowledge (beyond basic text rendering concepts) are required. Third, the problem statement and code changes do not indicate any specific edge cases or error handling requirements, and the conversions are direct mappings without apparent complexity. The overall amount of code change is small, consisting of repetitive but simple match expressions. Therefore, a difficulty score of 0.25 is appropriate, reflecting an easy task that requires minimal effort and understanding of basic code logic to implement the conversions."}
{"problem_statement": "Bug:  compilation error on `partition` with single char argument\n### Describe the bug\r\n\r\nI met compilation error on following code in README.md\r\n\r\n```cpp\r\nauto parts = haystack.partition(':'); // Matching a character\r\n```\r\n\r\nIt seem to be caused by the lack of overload function definition following:\r\n```\r\npartition_type partition(char pattern) const noexcept { return partition_(char_set{pattern}, 1); }\r\n```\r\n\r\n\r\n### Steps to reproduce\r\n\r\n```cpp\r\n#include \"stringzilla/stringzilla.hpp\"\r\n\r\nint main() {\r\n  auto haystack = ashvardanian::stringzilla::string_view{\"a:b:c\"};\r\n  auto [before, match, after] = haystack.partition(':');\r\n}\r\n```\r\n\r\nOS: Fedora Linux 40\r\n\r\n\r\n### Expected behavior\r\n\r\nSame as `haystack.partition(ashvardanian::stringzilla::char_set(\";\"))`\r\n\r\n\r\n### StringZilla version\r\n\r\n3.9.6\r\n\r\n### Operating System\r\n\r\nFedora Linux 40\r\n\r\n### Hardware architecture\r\n\r\nx86\r\n\r\n### Which interface are you using?\r\n\r\nC++ bindings\r\n\r\n### Contact Details\r\n\r\n_No response_\r\n\r\n### Are you open to being tagged as a contributor?\r\n\r\n- [X] I am open to being mentioned in the project `.git` history as a contributor\r\n\r\n### Is there an existing issue for this?\r\n\r\n- [X] I have searched the existing issues\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow this project's Code of Conduct\n", "patch": "diff --git a/.github/workflows/build_tools.sh b/.github/workflows/build_tools.sh\ndeleted file mode 100755\nindex f6a9dc63..00000000\n--- a/.github/workflows/build_tools.sh\n+++ /dev/null\n@@ -1,44 +0,0 @@\n-#!/bin/bash\n-\n-# Assign arguments to variables\n-BUILD_TYPE=$1    # Debug or Release\n-COMPILER=$2      # GCC, LLVM, or MSVC\n-\n-# Set common flags\n-COMMON_FLAGS=\"-DSTRINGZILLA_BUILD_TEST=1 -DSTRINGZILLA_BUILD_BENCHMARK=1 -DSTRINGZILLA_BUILD_SHARED=0\"\n-\n-# Compiler specific settings\n-case \"$COMPILER\" in\n-    \"GCC\")\n-        COMPILER_FLAGS=\"-DCMAKE_CXX_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++\"\n-        ;;\n-    \"LLVM\")\n-        COMPILER_FLAGS=\"-DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++\"\n-        ;;\n-    \"MSVC\")\n-        COMPILER_FLAGS=\"\" \n-        ;;\n-    *)\n-        echo \"Unknown compiler: $COMPILER\"\n-        exit 1\n-        ;;\n-esac\n-\n-# Set build type\n-case \"$BUILD_TYPE\" in\n-    \"Debug\")\n-        BUILD_DIR=\"build_debug\"\n-        BUILD_FLAGS=\"-DCMAKE_BUILD_TYPE=Debug\"\n-        ;;\n-    \"Release\")\n-        BUILD_DIR=\"build_release\"\n-        BUILD_FLAGS=\"-DCMAKE_BUILD_TYPE=RelWithDebInfo\"\n-        ;;\n-    *)\n-        echo \"Unknown build type: $BUILD_TYPE\"\n-        exit 1\n-        ;;\n-esac\n-\n-# Execute commands\n-cmake $COMMON_FLAGS $COMPILER_FLAGS $BUILD_FLAGS -B $BUILD_DIR && cmake --build $BUILD_DIR --config $BUILD_TYPE\ndiff --git a/.github/workflows/prerelease.yml b/.github/workflows/prerelease.yml\nindex 94d6928c..3fbe9b44 100644\n--- a/.github/workflows/prerelease.yml\n+++ b/.github/workflows/prerelease.yml\n@@ -20,7 +20,7 @@ permissions:\n jobs:\n   versioning:\n     name: Update Version\n-    runs-on: ubuntu-latest\n+    runs-on: ubuntu-24\n     steps:\n       - name: Checkout\n         uses: actions/checkout@v4\n@@ -100,7 +100,7 @@ jobs:\n \n         # Python\n       - name: Set up Python ${{ env.PYTHON_VERSION }}\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: ${{ env.PYTHON_VERSION }}\n       - name: Build Python\n@@ -184,7 +184,7 @@ jobs:\n \n         # Python\n       - name: Set up Python ${{ env.PYTHON_VERSION }}\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: ${{ env.PYTHON_VERSION }}\n       - name: Build Python\n@@ -281,7 +281,7 @@ jobs:\n \n   test_macos:\n     name: MacOS\n-    runs-on: macos-latest\n+    runs-on: macos-13\n \n     steps:\n       - uses: actions/checkout@v4\n@@ -316,7 +316,7 @@ jobs:\n \n         # Python\n       - name: Set up Python ${{ env.PYTHON_VERSION }}\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: ${{ env.PYTHON_VERSION }}\n       - name: Build Python\n@@ -324,6 +324,8 @@ jobs:\n           python -m pip install --upgrade pip\n           pip install pytest pytest-repeat numpy pyarrow\n           python -m pip install .\n+        env:\n+          MACOSX_DEPLOYMENT_TARGET: \"11.0\"\n       - name: Test Python\n         run: pytest scripts/test.py -s -x\n \n@@ -346,7 +348,7 @@ jobs:\n \n   test_windows:\n     name: Windows\n-    runs-on: windows-latest\n+    runs-on: windows-2022\n     steps:\n       - uses: actions/checkout@v4\n       - uses: ilammy/msvc-dev-cmd@v1\n@@ -387,7 +389,7 @@ jobs:\n \n         # Python\n       - name: Set up Python ${{ env.PYTHON_VERSION }}\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: ${{ env.PYTHON_VERSION }}\n       - name: Build Python\n@@ -400,7 +402,7 @@ jobs:\n \n   test_alpine:\n     name: Alpine Linux\n-    runs-on: ubuntu-latest\n+    runs-on: ubuntu-24\n     container:\n       image: alpine:latest\n       options: --privileged # If needed for certain Docker operations\n@@ -449,18 +451,18 @@ jobs:\n       ]\n     strategy:\n       matrix:\n-        os: [ubuntu-latest, macos-latest, windows-latest]\n+        os: [ubuntu-24, macos-13, windows-2022]\n         python-version: [\"36\", \"37\", \"38\", \"39\", \"310\", \"311\", \"312\"]\n     steps:\n       - uses: actions/checkout@v4\n       - name: Set up Python\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: 3.x\n \n         # We only need QEMU for Linux builds\n       - name: Setup QEMU\n-        if: matrix.os == 'ubuntu-latest'\n+        if: matrix.os == 'ubuntu-24'\n         uses: docker/setup-qemu-action@v3\n       - name: Install cibuildwheel\n         run: python -m pip install cibuildwheel\ndiff --git a/.github/workflows/release.yml b/.github/workflows/release.yml\nindex a6767394..144ae8b0 100644\n--- a/.github/workflows/release.yml\n+++ b/.github/workflows/release.yml\n@@ -19,7 +19,7 @@ permissions:\n jobs:\n   versioning:\n     name: Update Version\n-    runs-on: ubuntu-latest\n+    runs-on: ubuntu-24\n     steps:\n       - name: Checkout\n         uses: actions/checkout@v4\n@@ -49,7 +49,7 @@ jobs:\n \n   rebase:\n     name: Rebase Dev. Branch\n-    runs-on: ubuntu-latest\n+    runs-on: ubuntu-24\n     if: github.ref == 'refs/heads/main'\n     needs: versioning\n     steps:\n@@ -78,7 +78,7 @@ jobs:\n     needs: versioning\n     strategy:\n       matrix:\n-        os: [ubuntu-latest, macos-latest, windows-latest]\n+        os: [ubuntu-24, macos-13, windows-2022]\n         python-version: [\"36\", \"37\", \"38\", \"39\", \"310\", \"311\", \"312\"]\n     steps:\n       - uses: actions/checkout@v4\n@@ -86,11 +86,11 @@ jobs:\n           ref: \"main\"\n \n       - name: Set up Python\n-        uses: actions/setup-python@v5\n+        uses: actions/setup-python@v5.2.0\n         with:\n           python-version: 3.x\n       - name: Setup QEMU\n-        if: matrix.os == 'ubuntu-latest' # We only need QEMU for Linux builds\n+        if: matrix.os == 'ubuntu-24' # We only need QEMU for Linux builds\n         uses: docker/setup-qemu-action@v3\n       - name: Install cibuildwheel\n         run: python -m pip install cibuildwheel\n@@ -98,6 +98,7 @@ jobs:\n         run: cibuildwheel --output-dir wheelhouse\n         env:\n           CIBW_BUILD: cp${{ matrix.python-version }}-*\n+          MACOSX_DEPLOYMENT_TARGET: \"11.0\"\n       - name: Upload wheels\n         uses: actions/upload-artifact@v4\n         with:\n@@ -152,7 +153,7 @@ jobs:\n   # publish_javascript:\n   #   name: Publish JavaScript\n   #   needs: versioning\n-  #   runs-on: ubuntu-latest\n+  #   runs-on: ubuntu-24\n   #   steps:\n   #     - uses: actions/checkout@v4\n   #       with:\n@@ -297,7 +298,7 @@ jobs:\n \n   create_macos_library:\n     name: Create Library for MacOS ${{ matrix.arch }}\n-    runs-on: macos-latest\n+    runs-on: macos-13\n     needs: versioning\n     strategy:\n       fail-fast: false\ndiff --git a/.gitignore b/.gitignore\nindex 6fd5cd1b..58e1c789 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -34,3 +34,7 @@ node_modules/\n leipzig1M.txt\n enwik9.txt\n xlsum.csv\n+human_protein_1200row_800len.txt\n+\n+# StringZilla-specific log files\n+/failed_sz_*\n\\ No newline at end of file\ndiff --git a/.vscode/launch.json b/.vscode/launch.json\nindex d899d3fe..71d59186 100644\n--- a/.vscode/launch.json\n+++ b/.vscode/launch.json\n@@ -8,6 +8,7 @@\n       \"name\": \"Debug C++ Unit Tests\",\n       \"type\": \"cppdbg\",\n       \"request\": \"launch\",\n+      \"preLaunchTask\": \"Build Test: Debug\",\n       \"program\": \"${workspaceFolder}/build_debug/stringzilla_test_cpp20\",\n       \"cwd\": \"${workspaceFolder}\",\n       \"environment\": [\n@@ -18,16 +19,13 @@\n       ],\n       \"stopAtEntry\": false,\n       \"linux\": {\n-        \"preLaunchTask\": \"Build with GCC: Debug\",\n         \"MIMode\": \"gdb\"\n       },\n       \"osx\": {\n-        \"preLaunchTask\": \"Build with LLVM: Debug\",\n         \"MIMode\": \"lldb\"\n       },\n       \"windows\": {\n         \"program\": \"${workspaceFolder}\\\\build_debug\\\\stringzilla_test_cpp20.exe\",\n-        \"preLaunchTask\": \"Build with MSVC: Debug\",\n         \"MIMode\": \"gdb\",\n         \"miDebuggerPath\": \"C:\\\\MinGw\\\\bin\\\\gdb.exe\"\n       }\n@@ -48,17 +46,15 @@\n         }\n       ],\n       \"stopAtEntry\": false,\n+      \"preLaunchTask\": \"Build Benchmarks: Debug\",\n       \"linux\": {\n-        \"preLaunchTask\": \"Build with GCC: Debug\",\n         \"MIMode\": \"gdb\"\n       },\n       \"osx\": {\n-        \"preLaunchTask\": \"Build with LLVM: Debug\",\n         \"MIMode\": \"lldb\"\n       },\n       \"windows\": {\n         \"program\": \"${workspaceFolder}\\\\build_debug\\\\stringzilla_${fileBasenameNoExtension}.exe\",\n-        \"preLaunchTask\": \"Build with MSVC: Debug\",\n         \"MIMode\": \"gdb\",\n         \"miDebuggerPath\": \"C:\\\\MinGw\\\\bin\\\\gdb.exe\"\n       }\ndiff --git a/.vscode/settings.json b/.vscode/settings.json\nindex c3c54adc..ee77189d 100644\n--- a/.vscode/settings.json\n+++ b/.vscode/settings.json\n@@ -257,7 +257,8 @@\n     \"xtr1common\": \"cpp\",\n     \"xtree\": \"cpp\",\n     \"xutility\": \"cpp\",\n-    \"errno.h\": \"c\"\n+    \"errno.h\": \"c\",\n+    \"text_encoding\": \"cpp\"\n   },\n   \"python.pythonPath\": \"~/miniconda3/bin/python\"\n }\n\\ No newline at end of file\ndiff --git a/.vscode/tasks.json b/.vscode/tasks.json\nindex dfb3e46d..1ffc6a28 100644\n--- a/.vscode/tasks.json\n+++ b/.vscode/tasks.json\n@@ -2,40 +2,58 @@\n     \"version\": \"2.0.0\",\n     \"tasks\": [\n         {\n-            \"label\": \"Build with GCC: Debug\",\n-            \"command\": \"./.github/workflows/build_tools.sh Debug GCC\",\n+            \"label\": \"Build Test: Debug\",\n+            \"command\": \"cmake -D CMAKE_BUILD_TYPE=Debug -D STRINGZILLA_BUILD_TEST=1 -B build_debug && cmake --build build_debug --config Debug --target stringzilla_test_cpp20\",\n+            \"args\": [],\n             \"type\": \"shell\",\n-            \"problemMatcher\": [\n-                \"$gcc\"\n-            ]\n+            \"osx\": {\n+                \"environment\": [\n+                    {\n+                        \"name\": \"CXX\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang++\"\n+                    },\n+                    {\n+                        \"name\": \"CC\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang\"\n+                    }\n+                ]\n+            }\n         },\n         {\n-            \"label\": \"Build with GCC: Release\",\n-            \"command\": \"./.github/workflows/build_tools.sh Release GCC\",\n+            \"label\": \"Build Benchmarks: Debug\",\n+            \"command\": \"cmake -D CMAKE_BUILD_TYPE=Debug -D STRINGZILLA_BUILD_TEST=0 -D STRINGZILLA_BUILD_BENCHMARK=1 -B build_debug && cmake --build build_debug --config Debug\",\n+            \"args\": [],\n             \"type\": \"shell\",\n-            \"problemMatcher\": [\n-                \"$gcc\"\n-            ]\n+            \"osx\": {\n+                \"environment\": [\n+                    {\n+                        \"name\": \"CXX\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang++\"\n+                    },\n+                    {\n+                        \"name\": \"CC\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang\"\n+                    }\n+                ]\n+            }\n         },\n         {\n-            \"label\": \"Build with LLVM: Debug\",\n-            \"command\": \"./.github/workflows/build_tools.sh Debug LLVM\",\n-            \"type\": \"shell\"\n-        },\n-        {\n-            \"label\": \"Build with LLVM: Release\",\n-            \"command\": \"./.github/workflows/build_tools.sh Release LLVM\",\n-            \"type\": \"shell\"\n-        },\n-        {\n-            \"label\": \"Build with MSVC: Debug\",\n-            \"command\": \"./.github/workflows/build_tools.sh Debug MSVC\",\n-            \"type\": \"shell\"\n+            \"label\": \"Build Benchmarks: Release\",\n+            \"command\": \"cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_TEST=0 -D STRINGZILLA_BUILD_BENCHMARK=1 -B build_release && cmake --build build_release --config Release\",\n+            \"args\": [],\n+            \"type\": \"shell\",\n+            \"osx\": {\n+                \"environment\": [\n+                    {\n+                        \"name\": \"CXX\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang++\"\n+                    },\n+                    {\n+                        \"name\": \"CC\",\n+                        \"value\": \"$(brew --prefix llvm)/bin/clang\"\n+                    }\n+                ]\n+            }\n         },\n-        {\n-            \"label\": \"Build with MSVC: Release\",\n-            \"command\": \"./.github/workflows/build_tools.sh Release MSVC\",\n-            \"type\": \"shell\"\n-        }\n     ]\n }\n\\ No newline at end of file\ndiff --git a/CMakeLists.txt b/CMakeLists.txt\nindex 8549ee32..be6d9dcd 100644\n--- a/CMakeLists.txt\n+++ b/CMakeLists.txt\n@@ -264,6 +264,7 @@ if(${STRINGZILLA_BUILD_BENCHMARK})\n   define_launcher(stringzilla_bench_sort scripts/bench_sort.cpp 17 \"${STRINGZILLA_TARGET_ARCH}\")\n   define_launcher(stringzilla_bench_token scripts/bench_token.cpp 17 \"${STRINGZILLA_TARGET_ARCH}\")\n   define_launcher(stringzilla_bench_container scripts/bench_container.cpp 17 \"${STRINGZILLA_TARGET_ARCH}\")\n+  define_launcher(stringzilla_bench_memory scripts/bench_memory.cpp 17 \"${STRINGZILLA_TARGET_ARCH}\")\n endif()\n \n if(${STRINGZILLA_BUILD_TEST})\ndiff --git a/CONTRIBUTING.md b/CONTRIBUTING.md\nindex bd903210..da369582 100644\n--- a/CONTRIBUTING.md\n+++ b/CONTRIBUTING.md\n@@ -45,7 +45,7 @@ You can download them using the following commands:\n ```sh\n # English Leipzig Corpora Collection\n # 124 MB, 1'000'000 lines of ASCII, 8'388'608 tokens of mean length 5\n-wget --no-clobber -O leipzig1M.txt https://introcs.cs.princeton.edu/python/42sort/leipzig1m.txt \n+wget --no-clobber -O leipzig1M.txt https://introcs.cs.princeton.edu/python/42sort/leipzig1m.txt\n \n # Hutter Prize \"enwik9\" dataset for compression\n # 1 GB (0.3 GB compressed), 13'147'025 lines of ASCII, 67'108'864 tokens of mean length 6\n@@ -55,7 +55,7 @@ unzip enwik9.zip && rm enwik9.zip && mv enwik9 enwik9.txt\n # XL Sum dataset for multilingual extractive summarization\n # 4.7 GB (1.7 GB compressed), 1'004'598 lines of UTF8, 268'435'456 tokens of mean length 8\n wget --no-clobber -O xlsum.csv.gz https://github.com/ashvardanian/xl-sum/releases/download/v1.0.0/xlsum.csv.gz\n-gzip -d xlsum.csv.gz\n+gzip -d  xlsum.csv.gz\n \n # Human chromosome generator dataset generated by:\n # 1200 rows, each 800 characters long (939K)\n@@ -105,11 +105,22 @@ For Python code:\n The primary C implementation and the C++ wrapper are built with CMake.\n Assuming the extensive use of new SIMD intrinsics and recent C++ language features, using a recent compiler is recommended.\n We prefer GCC 12, which is available from default Ubuntu repositories with Ubuntu 22.04 LTS onwards.\n-If this is your first experience with CMake, use the following commands to get started:\n+If this is your first experience with CMake, use the following commands to get started on Ubuntu:\n \n ```bash\n-sudo apt-get update && sudo apt-get install cmake build-essential libjemalloc-dev g++-12 gcc-12 # Ubuntu\n-brew install libomp llvm # MacOS\n+sudo apt-get update && sudo apt-get install cmake build-essential libjemalloc-dev g++-12 gcc-12\n+```\n+\n+On MacOS it's recommended to use Homebrew and install Clang, as opposed to \"Apple Clang\".\n+Replacing the default compiler is not recommended, as it may break the system, but you can pass it as an environment variable:\n+\n+```bash\n+brew install llvm\n+cmake -D CMAKE_BUILD_TYPE=Release -D SIMSIMD_BUILD_TESTS=1 \\\n+    -D CMAKE_C_COMPILER=\"$(brew --prefix llvm)/bin/clang\" \\\n+    -D CMAKE_CXX_COMPILER=\"$(brew --prefix llvm)/bin/clang++\" \\\n+    -B build_release\n+cmake --build build_release --config Release\n ```\n \n ### Testing\n@@ -117,7 +128,7 @@ brew install libomp llvm # MacOS\n Using modern syntax, this is how you build and run the test suite:\n \n ```bash\n-cmake -DSTRINGZILLA_BUILD_TEST=1 -DCMAKE_BUILD_TYPE=Debug -B build_debug\n+cmake -D STRINGZILLA_BUILD_TEST=1 -D CMAKE_BUILD_TYPE=Debug -B build_debug\n cmake --build build_debug --config Debug          # Which will produce the following targets:\n build_debug/stringzilla_test_cpp20                # Unit test for the entire library compiled for current hardware\n build_debug/stringzilla_test_cpp20_x86_serial     # x86 variant compiled for IvyBridge - last arch. before AVX2\n@@ -131,10 +142,10 @@ Overall, CppCheck and Clang-Tidy are extremely noisy and not suitable for CI, bu\n sudo apt install cppcheck clang-tidy-11\n \n cmake -B build_artifacts \\\n-  -DCMAKE_BUILD_TYPE=RelWithDebInfo \\\n-  -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n-  -DSTRINGZILLA_BUILD_BENCHMARK=1 \\\n-  -DSTRINGZILLA_BUILD_TEST=1\n+  -D CMAKE_BUILD_TYPE=RelWithDebInfo \\\n+  -D CMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n+  -D STRINGZILLA_BUILD_BENCHMARK=1 \\\n+  -D STRINGZILLA_BUILD_TEST=1\n \n cppcheck --project=build_artifacts/compile_commands.json --enable=all\n \n@@ -145,20 +156,22 @@ I'd recommend putting the following breakpoints:\n \n - `__asan::ReportGenericError` - to detect illegal memory accesses.\n - `__GI_exit` - to stop at exit points - the end of running any executable.\n-- `__builtin_unreachable` - to catch all the places where the code is expected to be unreachable.\n+- `__builtin_unreachable` - to catch unexpected code paths.\n+- `_sz_assert_failure` - to catch StringZilla logic assertions.\n \n ### Benchmarking\n \n For benchmarks, you can use the following commands:\n \n ```bash\n-cmake -DSTRINGZILLA_BUILD_BENCHMARK=1 -B build_release\n-cmake --build build_release --config Release      # Which will produce the following targets:\n-build_release/stringzilla_bench_search <path>     # for substring search\n-build_release/stringzilla_bench_token <path>      # for hashing, equality comparisons, etc.\n-build_release/stringzilla_bench_similarity <path> # for edit distances and alignment scores\n-build_release/stringzilla_bench_sort <path>       # for sorting arrays of strings\n-build_release/stringzilla_bench_container <path>  # for STL containers with string keys\n+cmake -D STRINGZILLA_BUILD_BENCHMARK=1 -B build_release\n+cmake --build build_release --config Release      # Produces the following targets:\n+build_release/stringzilla_bench_memory <path>     # - for string copies and fills\n+build_release/stringzilla_bench_search <path>     # - for substring search\n+build_release/stringzilla_bench_token <path>      # - for hashing, equality comparisons, etc.\n+build_release/stringzilla_bench_similarity <path> # - for edit distances and alignment scores\n+build_release/stringzilla_bench_sort <path>       # - for sorting arrays of strings\n+build_release/stringzilla_bench_container <path>  # - for STL containers with string keys\n ```\n \n ### Benchmarking Hardware-Specific Optimizations\n@@ -168,14 +181,14 @@ The assumption would be that newer ISA extensions would provide better performan\n On x86_64, you can use the following commands to compile for Sandy Bridge, Haswell, and Sapphire Rapids:\n \n ```bash\n-cmake -DCMAKE_BUILD_TYPE=Release -DSTRINGZILLA_BUILD_BENCHMARK=1 \\\n-    -DSTRINGZILLA_TARGET_ARCH=\"ivybridge\" -B build_release/ivybridge && \\\n+cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_BENCHMARK=1 \\\n+    -D STRINGZILLA_TARGET_ARCH=\"ivybridge\" -B build_release/ivybridge && \\\n     cmake --build build_release/ivybridge --config Release\n-cmake -DCMAKE_BUILD_TYPE=Release -DSTRINGZILLA_BUILD_BENCHMARK=1 \\\n-    -DSTRINGZILLA_TARGET_ARCH=\"haswell\" -B build_release/haswell && \\\n+cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_BENCHMARK=1 \\\n+    -D STRINGZILLA_TARGET_ARCH=\"haswell\" -B build_release/haswell && \\\n     cmake --build build_release/haswell --config Release\n-cmake -DCMAKE_BUILD_TYPE=Release -DSTRINGZILLA_BUILD_BENCHMARK=1 \\\n-    -DSTRINGZILLA_TARGET_ARCH=\"sapphirerapids\" -B build_release/sapphirerapids && \\\n+cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_BENCHMARK=1 \\\n+    -D STRINGZILLA_TARGET_ARCH=\"sapphirerapids\" -B build_release/sapphirerapids && \\\n     cmake --build build_release/sapphirerapids --config Release\n ```\n \n@@ -185,11 +198,11 @@ Alternatively, you may want to compare the performance of the code compiled with\n On x86_64, you may want to compare GCC, Clang, and ICX.\n \n ```bash\n-cmake -DCMAKE_BUILD_TYPE=Release -DSTRINGZILLA_BUILD_BENCHMARK=1 -DSTRINGZILLA_BUILD_SHARED=1 \\\n-    -DCMAKE_CXX_COMPILER=g++-12 -DCMAKE_C_COMPILER=gcc-12 \\\n+cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_BENCHMARK=1 -D STRINGZILLA_BUILD_SHARED=1 \\\n+    -D CMAKE_CXX_COMPILER=g++-12 -D CMAKE_C_COMPILER=gcc-12 \\\n     -B build_release/gcc && cmake --build build_release/gcc --config Release\n-cmake -DCMAKE_BUILD_TYPE=Release -DSTRINGZILLA_BUILD_BENCHMARK=1 -DSTRINGZILLA_BUILD_SHARED=1 \\\n-    -DCMAKE_CXX_COMPILER=clang++-14 -DCMAKE_C_COMPILER=clang-14 \\\n+cmake -D CMAKE_BUILD_TYPE=Release -D STRINGZILLA_BUILD_BENCHMARK=1 -D STRINGZILLA_BUILD_SHARED=1 \\\n+    -D CMAKE_CXX_COMPILER=clang++-14 -D CMAKE_C_COMPILER=clang-14 \\\n     -B build_release/clang && cmake --build build_release/clang --config Release\n ```\n \n@@ -199,10 +212,10 @@ To simplify tracing and profiling, build with symbols using the `RelWithDebInfo`\n Here is an example for profiling one target - `stringzilla_bench_token`.\n \n ```bash\n-cmake -DSTRINGZILLA_BUILD_BENCHMARK=1 \\\n-    -DSTRINGZILLA_BUILD_TEST=1 \\\n-    -DSTRINGZILLA_BUILD_SHARED=1 \\\n-    -DCMAKE_BUILD_TYPE=RelWithDebInfo \\\n+cmake -D STRINGZILLA_BUILD_BENCHMARK=1 \\\n+    -D STRINGZILLA_BUILD_TEST=1 \\\n+    -D STRINGZILLA_BUILD_SHARED=1 \\\n+    -D CMAKE_BUILD_TYPE=RelWithDebInfo \\\n     -B build_profile\n cmake --build build_profile --config Release --target stringzilla_bench_token\n \n@@ -229,7 +242,7 @@ The base image is only ~3 MB, and it's based on musl libc, which is different fr\n sudo docker run -it --rm -v \"$(pwd)\":/workspace/StringZilla alpine:latest /bin/ash\n cd /workspace/StringZilla\n apk add --update make cmake g++ gcc\n-cmake -DSTRINGZILLA_BUILD_TEST=1 -DCMAKE_BUILD_TYPE=Debug -B build_debug\n+cmake -D STRINGZILLA_BUILD_TEST=1 -D CMAKE_BUILD_TYPE=Debug -B build_debug\n cmake --build build_debug --config Debug\n build_debug/stringzilla_test_cpp20\n ```\n@@ -237,7 +250,7 @@ build_debug/stringzilla_test_cpp20\n #### Intel Clear Linux\n \n Clear Linux is a distribution optimized for Intel hardware, and is known for its performance.\n-It has rolling releases, and is based on glibc.\n+It has rolling releases, and is based on `glibc`.\n It might be a good choice for compiling with Intel oneAPI compilers.\n \n ```bash\n@@ -245,7 +258,7 @@ sudo docker run -it --rm -v \"$(pwd)\":/workspace/StringZilla clearlinux:latest /b\n cd /workspace/StringZilla\n swupd update\n swupd bundle-add c-basic dev-utils\n-cmake -DSTRINGZILLA_BUILD_TEST=1 -DCMAKE_BUILD_TYPE=Debug -B build_debug\n+cmake -D STRINGZILLA_BUILD_TEST=1 -D CMAKE_BUILD_TYPE=Debug -B build_debug\n cmake --build build_debug --config Debug\n build_debug/stringzilla_test_cpp20\n ```\n@@ -253,7 +266,7 @@ build_debug/stringzilla_test_cpp20\n For benchmarks:\n \n ```bash\n-cmake -DSTRINGZILLA_BUILD_TEST=1 -DSTRINGZILLA_BUILD_BENCHMARK=1 -B build_release\n+cmake -D STRINGZILLA_BUILD_TEST=1 -D STRINGZILLA_BUILD_BENCHMARK=1 -B build_release\n cmake --build build_release --config Release\n ```\n \n@@ -265,8 +278,8 @@ For CentOS-based __Amazon Linux 2023__:\n sudo docker run -it --rm -v \"$(pwd)\":/workspace/StringZilla amazonlinux:2023 bash\n cd /workspace/StringZilla\n yum install -y make cmake3 gcc g++\n-cmake3 -DSTRINGZILLA_BUILD_TEST=1 -DCMAKE_BUILD_TYPE=Debug \\\n-    -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DSTRINGZILLA_TARGET_ARCH=\"ivybridge\" \\\n+cmake3 -D STRINGZILLA_BUILD_TEST=1 -D CMAKE_BUILD_TYPE=Debug \\\n+    -D CMAKE_CXX_COMPILER=g++ -D CMAKE_C_COMPILER=gcc -D STRINGZILLA_TARGET_ARCH=\"ivybridge\" \\\n     -B build_debug\n cmake3 --build build_debug --config Debug --target stringzilla_test_cpp11\n build_debug/stringzilla_test_cpp11\n@@ -279,8 +292,8 @@ Sadly, the newest GCC version it supports is 10, and it can't handle AVX-512 ins\n sudo docker run -it --rm -v \"$(pwd)\":/workspace/StringZilla amazonlinux:2 bash\n cd /workspace/StringZilla\n yum install -y make cmake3 gcc10 gcc10-c++\n-cmake3 -DSTRINGZILLA_BUILD_TEST=1 -DCMAKE_BUILD_TYPE=Debug \\\n-    -DCMAKE_CXX_COMPILER=g++ -DCMAKE_C_COMPILER=gcc -DSTRINGZILLA_TARGET_ARCH=\"ivybridge\" \\\n+cmake3 -D STRINGZILLA_BUILD_TEST=1 -D CMAKE_BUILD_TYPE=Debug \\\n+    -D CMAKE_CXX_COMPILER=g++ -D CMAKE_C_COMPILER=gcc -D STRINGZILLA_TARGET_ARCH=\"ivybridge\" \\\n     -B build_debug\n cmake3 --build build_debug --config Debug --target stringzilla_test_cpp11\n build_debug/stringzilla_test_cpp11\n@@ -328,11 +341,11 @@ export RANLIB=\"llvm-ranlib\"\n export TARGET_ARCH=\"aarch64-linux-gnu\" # Or \"x86_64-linux-gnu\"\n export BUILD_ARCH=\"arm64\" # Or \"amd64\"\n \n-cmake -DCMAKE_BUILD_TYPE=Release \\\n-    -DCMAKE_C_COMPILER_TARGET=${TARGET_ARCH} \\\n-    -DCMAKE_CXX_COMPILER_TARGET=${TARGET_ARCH} \\\n-    -DCMAKE_SYSTEM_NAME=Linux \\\n-    -DCMAKE_SYSTEM_PROCESSOR=${BUILD_ARCH} \\\n+cmake -D CMAKE_BUILD_TYPE=Release \\\n+    -D CMAKE_C_COMPILER_TARGET=${TARGET_ARCH} \\\n+    -D CMAKE_CXX_COMPILER_TARGET=${TARGET_ARCH} \\\n+    -D CMAKE_SYSTEM_NAME=Linux \\\n+    -D CMAKE_SYSTEM_PROCESSOR=${BUILD_ARCH} \\\n     -B build_artifacts\n cmake --build build_artifacts --config Release\n ```\n@@ -376,7 +389,7 @@ cibuildwheel --platform macos                   # works only on MacOS\n cibuildwheel --platform windows                 # works only on Windows\n ```\n \n-You may need root previligies for multi-architecture builds:\n+You may need root privileges for multi-architecture builds:\n \n ```bash\n sudo $(which cibuildwheel) --platform linux\n@@ -398,7 +411,7 @@ For benchmarking, the following scripts are provided.\n ```sh\n python scripts/bench_search.py --haystack_path \"your file\" --needle \"your pattern\" # real data\n python scripts/bench_search.py --haystack_pattern \"abcd\" --haystack_length 1e9 --needle \"abce\" # synthetic data\n-python scripts/similarity_bench.py --text_path \"your file\" # edit ditance computations\n+python scripts/similarity_bench.py --text_path \"your file\" # edit distance computations\n ```\n \n Alternatively, you can explore the Jupyter notebooks in `scripts/` directory.\n@@ -458,13 +471,22 @@ cargo package --list --allow-dirty\n \n If you want to run benchmarks against third-party implementations, check out the [`ashvardanian/memchr_vs_stringzilla`](https://github.com/ashvardanian/memchr_vs_stringzilla/) repository.\n \n-## General Performance Observations\n+## General Recommendations\n+\n+### Operations Not Worth Optimizing\n+\n+One of the hardest things to learn in HPC is when to stop optimizing, and where not to start.\n+\n+It doesn't make sense to optimize `sz_order`, because almost always, the relative order of two strings depends on the first bytes.\n+Fetching more bytes is not worth it.\n+In `sz_equal`, however, in rare cases, SIMD can help, if the user is comparing two mostly similar strings with identical hashes or checksums.\n \n ### Unaligned Loads\n \n One common surface of attack for performance optimizations is minimizing unaligned loads.\n Such solutions are beautiful from the algorithmic perspective, but often lead to worse performance.\n It's often cheaper to issue two interleaving wide-register loads, than try minimizing those loads at the cost of juggling registers.\n+Unaligned stores are a different story, especially on x86, where multiple reads can be issued in parallel, but only one write can be issued at a time.\n \n ### Register Pressure\n \n@@ -490,12 +512,20 @@ if (matches0 | matches1 | matches2 | matches3)\n A simpler solution would be to compare byte-by-byte, but in that case we would need to populate multiple registers, broadcasting different letters of the needle into them.\n That may not be noticeable on a micro-benchmark, but it would be noticeable on real-world workloads, where the CPU will speculatively interleave those search operations with something else happening in that context.\n \n-## Working on Alternative Hardware Backends\n+### Working on Alternative Hardware Backends\n \n-## Working on Faster Edit Distances\n+It's important to keep compiler support in mind when extending to new instruction sets.\n+Check the most recent CI pipeline configurations in `prerelease.yml` and `release.yml` to see which compilers are used.\n+When implementing dynamic dispatch, avoid compiler intrinsics and OS-specific APIs, as they may not be available on all platforms.\n+Instead, use inline assembly to check feature flags and dispatch them to the proper implementation.\n \n-## Working on Random String Generators\n+### Working on Faster Edit Distances\n \n-## Working on Sequence Processing and Sorting\n+When dealing with non-trivial algorithms, like edit distances, it's advisory to provide pseudo-code or a reference implementation in addition to the optimized one.\n+Ideally, include it in `scripts/` as a Python Jupyter Notebook with explanations and visualizations.\n \n+### Working on Sequence Processing and Sorting\n \n+Sorting algorithms for strings are a deeply studied area.\n+In general, string sorting algorithms discourage the use of comparisons, as they are expensive for variable-length data and also require pointer-chasing for most array layouts.\n+They are also harder to accelerate with SIMD, as most layouts imply 16-byte entries, which are often too big to benefit from simple SIMD techniques.\n\\ No newline at end of file\ndiff --git a/README.md b/README.md\nindex 09b3ef96..40b3258f 100644\n--- a/README.md\n+++ b/README.md\n@@ -766,6 +766,25 @@ To safely print those, pass the `string_length` to `printf` as well.\n printf(\"%.*s\\n\", (int)string_length, string_start);\n ```\n \n+### What's Wrong with the C Standard Library?\n+\n+StringZilla is not a drop-in replacement for the C Standard Library.\n+It's designed to be a safer and more modern alternative.\n+Conceptually:\n+\n+1. LibC strings are expected to be null-terminated, so to use the efficient LibC implementations on slices of larger strings, you'd have to copy them, which is more expensive than the original string operation.\n+2. LibC functionality is asymmetric - you can find the first and the last occurrence of a character within a string, but you can't find the last occurrence of a substring.\n+3. LibC function names are typically very short and cryptic.\n+4. LibC lacks crucial functionality like hashing and doesn't provide primitives for less critical but relevant operations like fuzzy matching.\n+\n+Something has to be said about its support for UTF8.\n+Aside from a single-byte `char` type, LibC provides `wchar_t`:\n+\n+- The size of `wchar_t` is not consistent across platforms. On Windows, it's typically 16 bits (suitable for UTF-16), while on Unix-like systems, it's usually 32 bits (suitable for UTF-32). This inconsistency can lead to portability issues when writing cross-platform code.\n+- `wchar_t` is designed to represent wide characters in a fixed-width format (UTF-16 or UTF-32). In contrast, UTF-8 is a variable-length encoding, where each character can take from 1 to 4 bytes. This fundamental difference means that `wchar_t` and UTF-8 are incompatible.\n+\n+StringZilla [partially addresses those issues](#unicode-utf-8-and-wide-characters).\n+\n ### What's Wrong with the C++ Standard Library?\n \n | C++ Code                             | Evaluation Result | Invoked Signature              |\n@@ -849,9 +868,9 @@ StringZilla provides a convenient `partition` function, which returns a tuple of\n ```cpp\n auto parts = haystack.partition(':'); // Matching a character\n auto [before, match, after] = haystack.partition(':'); // Structure unpacking\n-auto [before, match, after] = haystack.partition(char_set(\":;\")); // Character-set argument\n+auto [before, match, after] = haystack.partition(sz::char_set(\":;\")); // Character-set argument\n auto [before, match, after] = haystack.partition(\" : \"); // String argument\n-auto [before, match, after] = haystack.rpartition(sz::whitespaces); // Split around the last whitespace\n+auto [before, match, after] = haystack.rpartition(sz::whitespaces_set()); // Split around the last whitespace\n ```\n \n Combining those with the `split` function, one can easily parse a CSV file or HTTP headers.\n@@ -877,8 +896,8 @@ Here is a sneak peek of the most useful ones.\n ```cpp\n text.hash(); // -> 64 bit unsigned integer \n text.ssize(); // -> 64 bit signed length to avoid `static_cast<std::ssize_t>(text.size())`\n-text.contains_only(\" \\w\\t\"); // == text.find_first_not_of(char_set(\" \\w\\t\")) == npos;\n-text.contains(sz::whitespaces); // == text.find(char_set(sz::whitespaces)) != npos;\n+text.contains_only(\" \\w\\t\"); // == text.find_first_not_of(sz::char_set(\" \\w\\t\")) == npos;\n+text.contains(sz::whitespaces_set()); // == text.find(sz::char_set(sz::whitespaces_set())) != npos;\n \n // Simpler slicing than `substr`\n text.front(10); // -> sz::string_view\n@@ -890,9 +909,9 @@ text.front(10, cap) == text.front(std::min(10, text.size()));\n text.back(10, cap) == text.back(std::min(10, text.size()));\n \n // Character set filtering\n-text.lstrip(sz::whitespaces).rstrip(sz::newlines); // like Python\n-text.front(sz::whitespaces); // all leading whitespaces\n-text.back(sz::digits); // all numerical symbols forming the suffix\n+text.lstrip(sz::whitespaces_set()).rstrip(sz::newlines_set()); // like Python\n+text.front(sz::whitespaces_set()); // all leading whitespaces\n+text.back(sz::digits_set()); // all numerical symbols forming the suffix\n \n // Incremental construction\n using sz::string::unchecked;\n@@ -923,7 +942,7 @@ To avoid those, StringZilla provides lazily-evaluated ranges, compatible with th\n \n ```cpp\n for (auto line : haystack.split(\"\\r\\n\"))\n-    for (auto word : line.split(char_set(\" \\w\\t.,;:!?\")))\n+    for (auto word : line.split(sz::char_set(\" \\w\\t.,;:!?\")))\n         std::cout << word << std::endl;\n ```\n \n@@ -932,9 +951,9 @@ It also allows interleaving matches, if you want both inclusions of `xx` in `xxx\n Debugging pointer offsets is not a pleasant exercise, so keep the following functions in mind.\n \n - `haystack.[r]find_all(needle, interleaving)`\n-- `haystack.[r]find_all(char_set(\"\"))`\n+- `haystack.[r]find_all(sz::char_set(\"\"))`\n - `haystack.[r]split(needle)`\n-- `haystack.[r]split(char_set(\"\"))`\n+- `haystack.[r]split(sz::char_set(\"\"))`\n \n For $N$ matches the split functions will report $N+1$ matches, potentially including empty strings.\n Ranges have a few convenience methods as well:\n@@ -1348,6 +1367,23 @@ With that solved, the SIMD implementation will become 5x faster than the serial\n [faq-dipeptide]: https://en.wikipedia.org/wiki/Dipeptide\n [faq-titin]: https://en.wikipedia.org/wiki/Titin\n \n+### Memory Copying, Fills, and Moves\n+\n+A lot has been written about the time computers spend copying memory and how that operation is implemented in LibC.\n+Interestingly, the operation can still be improved, as most Assembly implementations use outdated instructions.\n+Even performance-oriented STL replacements, like Meta's [Folly v2024.09.23 focus on AVX2](https://github.com/facebook/folly/blob/main/folly/memset.S), and don't take advantage of the new masked instructions in AVX-512 or SVE.\n+\n+In AVX-512, StringZilla uses non-temporal stores to avoid cache pollution, when dealing with very large strings.\n+Moreover, it handles the unaligned head and the tails of the `target` buffer separately, ensuring that writes in big copies are always aligned to cache-line boundaries.\n+That's true for both AVX2 and AVX-512 backends.\n+\n+StringZilla also contains \"drafts\" of smarter, but less efficient algorithms, that minimize the number of unaligned loads, perfoming shuffles and permutations.\n+That's a topic for future research, as the performance gains are not yet satisfactory.\n+\n+> \u00a7 Reading materials.\n+> [`memset` benchmarks](https://github.com/nadavrot/memset_benchmark?tab=readme-ov-file) by Nadav Rotem.\n+> [Cache Associativity](https://en.algorithmica.org/hpc/cpu-cache/associativity/) by Sergey Slotin.\n+\n ### Random Generation\n \n Generating random strings from different alphabets is a very common operation.\n@@ -1368,11 +1404,8 @@ For lexicographic sorting of strings, StringZilla uses a \"hybrid-hybrid\" approac\n    1. IntroSort begins with a QuickSort.\n    2. If the recursion depth exceeds a certain threshold, it switches to a HeapSort.\n \n-Next design goals:\n-\n-- [ ] Generalize to arrays with over 4 billion entries.\n-- [ ] Algorithmic improvements may yield another 3x performance gain.\n-- [ ] SIMD-acceleration for the Radix slice.\n+A better algorithm is in development.\n+Check #173 for design goals and progress updates.\n \n ### Hashing\n \ndiff --git a/c/lib.c b/c/lib.c\nindex edffd14e..e523e377 100644\n--- a/c/lib.c\n+++ b/c/lib.c\n@@ -119,6 +119,7 @@ typedef struct sz_implementations_t {\n     sz_move_t copy;\n     sz_move_t move;\n     sz_fill_t fill;\n+    sz_look_up_transform_t look_up_transform;\n \n     sz_find_byte_t find_byte;\n     sz_find_byte_t rfind_byte;\n@@ -153,6 +154,7 @@ static void sz_dispatch_table_init(void) {\n     impl->copy = sz_copy_serial;\n     impl->move = sz_move_serial;\n     impl->fill = sz_fill_serial;\n+    impl->look_up_transform = sz_look_up_transform_serial;\n \n     impl->find = sz_find_serial;\n     impl->rfind = sz_rfind_serial;\n@@ -167,9 +169,14 @@ static void sz_dispatch_table_init(void) {\n \n #if SZ_USE_X86_AVX2\n     if (caps & sz_cap_x86_avx2_k) {\n+        impl->equal = sz_equal_avx2;\n+        impl->order = sz_order_avx2;\n+\n         impl->copy = sz_copy_avx2;\n         impl->move = sz_move_avx2;\n         impl->fill = sz_fill_avx2;\n+        impl->look_up_transform = sz_look_up_transform_avx2;\n+\n         impl->find_byte = sz_find_byte_avx2;\n         impl->rfind_byte = sz_rfind_byte_avx2;\n         impl->find = sz_find_avx2;\n@@ -183,6 +190,7 @@ static void sz_dispatch_table_init(void) {\n     if (caps & sz_cap_x86_avx512f_k) {\n         impl->equal = sz_equal_avx512;\n         impl->order = sz_order_avx512;\n+\n         impl->copy = sz_copy_avx512;\n         impl->move = sz_move_avx512;\n         impl->fill = sz_fill_avx512;\n@@ -200,11 +208,19 @@ static void sz_dispatch_table_init(void) {\n         impl->find_from_set = sz_find_charset_avx512;\n         impl->rfind_from_set = sz_rfind_charset_avx512;\n         impl->alignment_score = sz_alignment_score_avx512;\n+        impl->look_up_transform = sz_look_up_transform_avx512;\n     }\n #endif\n \n #if SZ_USE_ARM_NEON\n     if (caps & sz_cap_arm_neon_k) {\n+        impl->equal = sz_equal_neon;\n+\n+        impl->copy = sz_copy_neon;\n+        impl->move = sz_move_neon;\n+        impl->fill = sz_fill_neon;\n+        impl->look_up_transform = sz_look_up_transform_neon;\n+\n         impl->find = sz_find_neon;\n         impl->rfind = sz_rfind_neon;\n         impl->find_byte = sz_find_byte_neon;\n@@ -256,6 +272,10 @@ SZ_DYNAMIC void sz_fill(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n     sz_dispatch_table.fill(target, length, value);\n }\n \n+SZ_DYNAMIC void sz_look_up_transform(sz_cptr_t source, sz_size_t length, sz_cptr_t lut, sz_ptr_t target) {\n+    sz_dispatch_table.look_up_transform(source, length, lut, target);\n+}\n+\n SZ_DYNAMIC sz_cptr_t sz_find_byte(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle) {\n     return sz_dispatch_table.find_byte(haystack, h_length, needle);\n }\ndiff --git a/include/stringzilla/drafts.h b/include/stringzilla/drafts.h\nindex 17147f7e..bcba2233 100644\n--- a/include/stringzilla/drafts.h\n+++ b/include/stringzilla/drafts.h\n@@ -952,4 +952,374 @@ SZ_PUBLIC void sz_hashes_neon_readahead(sz_cptr_t start, sz_size_t length, sz_si\n } // extern \"C\"\n #endif\n \n-#endif // STRINGZILLA_EXPERIMENTAL_H_\n\\ No newline at end of file\n+#endif // STRINGZILLA_EXPERIMENTAL_H_\n+\n+SZ_PUBLIC sz_ordering_t sz_order_avx2(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n+\n+    // _bswap64;\n+\n+    // while (a_length >= 8 && b_length >= 8) {\n+    //     sz_u64_t a_u64 = *(sz_u64_t *)a;\n+    //     sz_u64_t b_u64 = *(sz_u64_t *)b;\n+    //     if (a_u64 != b_u64) return _sz_order_scalars(a_u64, b_u64);\n+    //     a += 8, b += 8, a_length -= 8, b_length -= 8;\n+    // }\n+\n+    // The rare case, when both string are very long surves as a great example to understand\n+    // the basic logic of the algorithm without the complexity of `(\"abc\\0\" < \"abc\")` corner cases.\n+    while ((a_length >= 64) & (b_length >= 64)) {\n+        a_vec.zmm = _mm512_loadu_si512(a);\n+        b_vec.zmm = _mm512_loadu_si512(b);\n+        // The AVX-512 `_mm512_mask_cmpneq_epi8_mask` intrinsics are generally handy in such environments.\n+        // They, however, have latency 3 on most modern CPUs. Using AVX2: `_mm256_cmpeq_epi8` would have\n+        // been cheaper, if we didn't have to apply `_mm256_movemask_epi8` afterwards.\n+        //\n+        //      __mmask64 mask_not_equal = _mm512_cmpneq_epi8_mask(a_vec.zmm, b_vec.zmm);\n+        //      if (mask_not_equal != 0) {\n+        //          sz_u64_t first_diff = _tzcnt_u64(mask_not_equal);\n+        //          char a_char = a[first_diff];\n+        //          char b_char = b[first_diff];\n+        //          return _sz_order_scalars(a_char, b_char);\n+        //      }\n+        //\n+        // A wiser approach to avoid serial code, is to perform 2 vector comparisons instead of quality check.\n+        __mmask64 less_mask = _mm512_cmplt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+        __mmask64 greater_mask = _mm512_cmpgt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+        // Let's assume both strings are exactly 64 bytes long, like `(\"abcdabcd...\" < \"acbdacbd...\")`.\n+        // In that case:\n+        //      - if `less_mask == 0 && greater_mask == 0`, the strings are equal, and we can skip 64 bytes.\n+        //      - if `_tzcnt_u64(less_mask) < _tzcnt_u64(greater_mask)` than the first string is less than the second.\n+        // The `_tzcnt_u64` trailing zeros computation, however, also has latency of 3 cycles.\n+        unsigned char all_equal = _kortestz_mask8_u8(less_mask, greater_mask);\n+        if (all_equal) { a += 64, b += 64, a_length -= 64, b_length -= 64; }\n+        else { return _sz_order_scalars(_tzcnt_u64(less_mask), _tzcnt_u64(greater_mask)); }\n+    }\n+\n+    // Assume a case like `(\"abc\\0\" < \"abc\")`.\n+    // Knowing the length masks of both strings, we can find the bytes that make up the difference\n+    // and enable them in the `greater_mask`, to signal the presence of null-characters in the end.\n+    //\n+    //      __mmask64 a_mask = _sz_u64_clamp_mask_until(a_length);\n+    //      __mmask64 b_mask = _sz_u64_clamp_mask_until(b_length);\n+    //      a_vec.zmm = _mm512_maskz_loadu_epi8(a_mask, a);\n+    //      b_vec.zmm = _mm512_maskz_loadu_epi8(b_mask, b);\n+    //      __mmask64 after_a_before_b_mask = _kandn_mask64(a_mask, b_mask);\n+    //      __mmask64 after_b_before_a_mask = _kandn_mask64(b_mask, a_mask);\n+    //      __mmask64 less_mask = _mm512_cmplt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+    //      __mmask64 greater_mask = _mm512_cmpgt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+    //      less_mask = _kor_mask64(less_mask, after_a_before_b_mask);\n+    //      greater_mask = _kor_mask64(greater_mask, after_b_before_a_mask);\n+    //      unsigned char all_equal = _kortestz_mask8_u8(less_mask, greater_mask);\n+    //      if (all_equal) { return sz_equal_k; }\n+    //      else { return earlier_in_less_mask ? sz_less_k : sz_greater_k; }\n+    return sz_order_serial(a, a_length, b, b_length);\n+}\n+\n+SZ_PUBLIC sz_ordering_t sz_order_avx512(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n+    sz_u512_vec_t a_vec, b_vec;\n+\n+    // The rare case, when both string are very long surves as a great example to understand\n+    // the basic logic of the algorithm without the complexity of `(\"abc\\0\" < \"abc\")` corner cases.\n+    while ((a_length >= 64) & (b_length >= 64)) {\n+        a_vec.zmm = _mm512_loadu_si512(a);\n+        b_vec.zmm = _mm512_loadu_si512(b);\n+        // The AVX-512 `_mm512_mask_cmpneq_epi8_mask` intrinsics are generally handy in such environments.\n+        // They, however, have latency 3 on most modern CPUs. Using AVX2: `_mm256_cmpeq_epi8` would have\n+        // been cheaper, if we didn't have to apply `_mm256_movemask_epi8` afterwards.\n+        //\n+        //      __mmask64 mask_not_equal = _mm512_cmpneq_epi8_mask(a_vec.zmm, b_vec.zmm);\n+        //      if (mask_not_equal != 0) {\n+        //          sz_u64_t first_diff = _tzcnt_u64(mask_not_equal);\n+        //          char a_char = a[first_diff];\n+        //          char b_char = b[first_diff];\n+        //          return _sz_order_scalars(a_char, b_char);\n+        //      }\n+        //\n+        // A wiser approach to avoid serial code, is to perform 2 vector comparisons instead of quality check.\n+        __mmask64 less_mask = _mm512_cmplt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+        __mmask64 greater_mask = _mm512_cmpgt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+        // Let's assume both strings are exactly 64 bytes long, like `(\"abcdabcd...\" < \"acbdacbd...\")`.\n+        // In that case:\n+        //      - if `less_mask == 0 && greater_mask == 0`, the strings are equal, and we can skip 64 bytes.\n+        //      - if `_tzcnt_u64(less_mask) < _tzcnt_u64(greater_mask)` than the first string is less than the second.\n+        // The `_tzcnt_u64` trailing zeros computation, however, also has latency of 3 cycles.\n+        unsigned char all_equal = _kortestz_mask8_u8(less_mask, greater_mask);\n+        if (all_equal) { a += 64, b += 64, a_length -= 64, b_length -= 64; }\n+        else { return _sz_order_scalars(_tzcnt_u64(less_mask), _tzcnt_u64(greater_mask)); }\n+    }\n+\n+    // Assume a case like `(\"abc\\0\" < \"abc\")`.\n+    // Knowing the length masks of both strings, we can find the bytes that make up the difference\n+    // and enable them in the `greater_mask`, to signal the presence of null-characters in the end.\n+    //\n+    //      __mmask64 a_mask = _sz_u64_clamp_mask_until(a_length);\n+    //      __mmask64 b_mask = _sz_u64_clamp_mask_until(b_length);\n+    //      a_vec.zmm = _mm512_maskz_loadu_epi8(a_mask, a);\n+    //      b_vec.zmm = _mm512_maskz_loadu_epi8(b_mask, b);\n+    //      __mmask64 after_a_before_b_mask = _kandn_mask64(a_mask, b_mask);\n+    //      __mmask64 after_b_before_a_mask = _kandn_mask64(b_mask, a_mask);\n+    //      __mmask64 less_mask = _mm512_cmplt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+    //      __mmask64 greater_mask = _mm512_cmpgt_epu8_mask(a_vec.zmm, b_vec.zmm);\n+    //      less_mask = _kor_mask64(less_mask, after_a_before_b_mask);\n+    //      greater_mask = _kor_mask64(greater_mask, after_b_before_a_mask);\n+    //      unsigned char all_equal = _kortestz_mask8_u8(less_mask, greater_mask);\n+    //      if (all_equal) { return sz_equal_k; }\n+    //      else { return earlier_in_less_mask ? sz_less_k : sz_greater_k; }\n+    return sz_order_serial(a, a_length, b, b_length);\n+}\n+\n+SZ_PUBLIC void sz_move_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    if (target == source) return; // Don't be silly, don't move the data if it's already there.\n+\n+    // If the regions don't overlap at all, just use \"copy\" and save some brain cells thinking about corner cases.\n+    if (target + length < source || target >= source + length) {\n+        sz_copy_avx512(target, source, length);\n+        return;\n+    }\n+\n+    // The absolute most common case of using \"moves\" is shifting the data within a continuous buffer\n+    // when adding a removing some values in it. In such cases, a typical shift is by 1, 2, 4, 8, 16,\n+    // or 32 bytes, rarely larger. For small shifts, under the size of the ZMM register, we can use shuffles.\n+    //\n+    // Remember: if we are shifting data left, that we are traversing to the right.\n+    int left_to_right_traversal = source > target;\n+    sz_size_t shift = left_to_right_traversal ? source - target : target - source;\n+\n+    if (left_to_right_traversal) {\n+\n+        // Shift until we reach the ZMM register boundary for the target to avoid unaligned loads.\n+        for (; (sz_size_t)target % 64 != 0 && length; ++target, ++source, --length) *target = *source;\n+\n+        // Small shifts of large buffers can minimize the number of times a specific cache line will be touched\n+        // to guarantee one read and one write per cache line.\n+        if (shift < 64 && length >= 128) {\n+\n+            // Now we guarantee, that the shift is from 1 to 63 bytes and the output is aligned.\n+            // Hopefully, we need to shift more than two ZMM registers, so we could consider `valignr` instruction.\n+            // Sadly, using `_mm512_alignr_epi8` doesn't make sense, as it operates at a 128-bit granularity.\n+            //\n+            //      - `_mm256_alignr_epi8` shifts entire 256-bit register, but we need many of them.\n+            //      - `_mm512_alignr_epi32` shifts 512-bit chunks, but only if the `shift` is a multiple of 4 bytes.\n+            //      - `_mm512_alignr_epi64` shifts 512-bit chunks by 8 bytes.\n+            //\n+            // All of those have a latency of 1 cycle, and the shift amount must be an immediate value!\n+            // For 1-byte-shift granularity, the `_mm512_permutex2var_epi8` has a latency of 6 and needs VBMI!\n+            // The most efficient and broadly compatible alternative would be to use a combination of align and shuffle.\n+            // A similar approach was outlined in \"Byte-wise alignr in AVX512F\" by Wojciech Mu\u0142a.\n+            // http://0x80.pl/notesen/2016-10-16-avx512-byte-alignr.html\n+            //\n+            // That solution, is extremely mouthful, assuming we need compile time constants for the shift amount.\n+            sz_u512_vec_t first_vec, second_vec, combined_vec;\n+            // The last `64 - shift` entries of the first register should be moved to its start.\n+            // The first `shift` entries of the second register should be moved to its end.\n+            // Then we will combine:\n+            //      - the first `64 - shift` entries of the first register with\n+            //      - the first `shift` entries of the second register.\n+#if 1\n+            sz_u512_vec_t selector_vec;\n+            sz_size_t shifted_idx = 0;\n+            for (; shifted_idx != 64; ++shifted_idx) selector_vec.u8s[shifted_idx] = (sz_u8_t)(shift + shifted_idx);\n+            // Now that the permutations are prepared, pre-load the first cache line and start the loop.\n+            first_vec.zmm = _mm512_load_si512(target);\n+            for (; length >= 128; target += 64, source += 64, length -= 64) {\n+                second_vec.zmm = _mm512_load_si512(target + 64);\n+                combined_vec.zmm = _mm512_permutex2var_epi8(first_vec.zmm, selector_vec.zmm, second_vec.zmm);\n+                sz_assert(combined_vec.u8s[0] == source[0]);\n+                sz_assert(combined_vec.u8s[63] == source[63]);\n+                _mm512_store_si512(target, combined_vec.zmm);\n+                first_vec.zmm = second_vec.zmm;\n+            }\n+#else\n+            sz_u512_vec_t first_byte_permute_vec, second_byte_permute_vec;\n+            sz_u512_vec_t first_shuffled_vec, second_shuffled_vec;\n+            for (sz_size_t shifted_idx = 0; shifted_idx != (64 - shift); ++shifted_idx)\n+                first_byte_permute_vec.u8s[shifted_idx] = (sz_u8_t)(shift + shifted_idx), //\n+                    second_byte_permute_vec.u8s[shifted_idx] = (sz_u8_t)0xFF;\n+            for (sz_size_t shifted_idx = 0; shifted_idx != shift; ++shifted_idx)\n+                first_byte_permute_vec.u8s[64 - shift + shifted_idx] = (sz_u8_t)0xFF, //\n+                    second_byte_permute_vec.u8s[64 - shift + shifted_idx] = (sz_u8_t)shifted_idx;\n+            // The `_mm512_shuffle_epi8` only works within lanes, so we need to permute the lanes.\n+            int first_lane_permute_mask, second_lane_permute_mask;\n+\n+            // Now that the permutations are prepared, pre-load the first cache line and start the loop.\n+            first_vec.zmm = _mm512_load_si512(target);\n+            for (; length >= 128; target += 64, source += 64, length -= 64) {\n+                second_vec.zmm = _mm512_load_si512(target + 64);\n+                first_shuffled_vec.zmm = _mm512_shuffle_epi8(first_vec.zmm, first_byte_permute_vec.zmm);\n+                second_shuffled_vec.zmm = _mm512_shuffle_epi8(second_vec.zmm, second_byte_permute_vec.zmm);\n+                sz_assert(first_shuffled_vec.u8s[0] == source[0]);\n+                sz_assert(second_shuffled_vec.u8s[63] == source[63]);\n+                combined_vec.zmm = _mm512_or_si512(first_shuffled_vec.zmm, second_shuffled_vec.zmm);\n+                _mm512_store_si512(target, combined_vec.zmm);\n+                first_vec.zmm = second_vec.zmm;\n+            }\n+#endif\n+            for (; length; ++target, ++source, --length) *target = *source;\n+        }\n+        // With really large shifts we are not going to touch the same register on the load and store.\n+        // Especially, if we align the stores to the ZMM register size.\n+        else {\n+            for (; length >= 64; target += 64, source += 64, length -= 64)\n+                _mm512_store_si512(target, _mm512_loadu_si512(source));\n+            // At this point the length is guaranteed to be under 64.\n+            __mmask64 mask = _sz_u64_mask_until(length);\n+            _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n+        }\n+    }\n+    else {\n+        // Shift until we reach the ZMM register boundary for the target to avoid unaligned loads.\n+        for (; (sz_size_t)(target + length) % 64 != 0 && length; --length) target[length - 1] = source[length - 1];\n+        // Jump to the end and walk backwards.\n+        for (target += length, source += length; length >= 64; length -= 64)\n+            _mm512_store_si512(target -= 64, _mm512_loadu_si512(source -= 64));\n+        // At this point the length is guaranteed to be under 64.\n+        __mmask64 mask = _sz_u64_mask_until(length);\n+        _mm512_mask_storeu_epi8(target - length, mask, _mm512_maskz_loadu_epi8(mask, source - length));\n+    }\n+}\n+\n+SZ_PUBLIC void sz_move_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    if (target == source) return; // Don't be silly, don't move the data if it's already there.\n+\n+    // If the regions don't overlap at all, just use \"copy\" and save some brain cells thinking about corner cases.\n+    if (target + length < source || target >= source + length) {\n+        sz_copy_avx512(target, source, length);\n+        return;\n+    }\n+\n+    // On very short buffers, that are one cache line in width or less, we don't need any loops.\n+    if (length <= 64) {\n+        __mmask64 mask = _sz_u64_mask_until(length);\n+        _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n+        return;\n+    }\n+\n+    // When the buffer is over 64 bytes, it's guaranteed to touch at least two cache lines - the head and tail,\n+    // and may include more cache-lines in-between. Knowing this, we can avoid expensive unaligned stores\n+    // by computing 2 masks - for the head and tail, using masked stores for the head and tail, and unmasked\n+    // for the body.\n+    sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+    sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+    sz_size_t body_length = length - head_length - tail_length;   // Multiple of 64.\n+    __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+    __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+\n+    // The absolute most common case of using \"moves\" is shifting the data within a continuous buffer\n+    // when adding a removing some values in it. In such cases, a typical shift is by 1, 2, 4, 8, 16,\n+    // or 32 bytes, rarely larger. For small shifts, under the size of the ZMM register, we can use shuffles.\n+    //\n+    // Remember:\n+    //      - if we are shifting data left, that we are traversing to the right.\n+    //      - if we are shifting data right, that we are traversing to the left.\n+    int const left_to_right_traversal = source > target;\n+\n+    // If both targets are equally aligned or misaligned, the efficient implementation is trivial.\n+    if ((sz_size_t)target % 64 == (sz_size_t)source % 64) {\n+        if (left_to_right_traversal) {\n+            // Head, body, and tail.\n+            _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+            target += head_length, source += head_length, body_length -= head_length;\n+            for (; body_length >= 64; target += 64, source += 64, body_length -= 64)\n+                _mm512_store_si512(target, _mm512_load_si512(source));\n+            _mm512_mask_storeu_epi8(target, tail_mask, _mm512_maskz_loadu_epi8(tail_mask, source));\n+        }\n+        else {\n+            // Tail, body, and head.\n+            _mm512_mask_storeu_epi8(target + head_length + body_length, tail_mask,\n+                                    _mm512_maskz_loadu_epi8(tail_mask, source + head_length + body_length));\n+            for (; body_length >= 64; body_length -= 64)\n+                _mm512_store_si512(target + head_length + body_length - 64,\n+                                   _mm512_load_si512(source + head_length + body_length - 64));\n+            _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+        }\n+        return;\n+    }\n+\n+    // Now we guarantee, that the relative shift within is from 1 to 63 bytes and the output is aligned.\n+    // Hopefully, we need to shift more than two ZMM registers, so we could consider `valignr` instruction.\n+    // Sadly, using `_mm512_alignr_epi8` doesn't make sense, as it operates at a 128-bit granularity.\n+    //\n+    //      - `_mm256_alignr_epi8` shifts entire 256-bit register, but we need many of them.\n+    //      - `_mm512_alignr_epi32` shifts 512-bit chunks, but only if the `shift` is a multiple of 4 bytes.\n+    //      - `_mm512_alignr_epi64` shifts 512-bit chunks by 8 bytes.\n+    //\n+    // All of those have a latency of 1 cycle, and the shift amount must be an immediate value!\n+    // For 1-byte-shift granularity, the `_mm512_permutex2var_epi8` has a latency of 6 and needs VBMI!\n+    // The most efficient and broadly compatible alternative could be to use a combination of align and shuffle.\n+    // A similar approach was outlined in \"Byte-wise alignr in AVX512F\" by Wojciech Mu\u0142a.\n+    // http://0x80.pl/notesen/2016-10-16-avx512-byte-alignr.html\n+    //\n+    // That solution, is extremely mouthful, assuming we need compile time constants for the shift amount.\n+    // A cleaner one, with a latency of 3 cycles, is to use `_mm512_permutexvar_epi8` or `_mm512_mask_permutexvar_epi8`,\n+    // which can be seen as combination of a cross-register shuffle and blend, and is available with VBMI.\n+    sz_size_t const shift = left_to_right_traversal ? source - target : target - source;\n+    sz_size_t const shift_in_page = shift % 64;\n+\n+    if (left_to_right_traversal) {\n+        // Head, body, and tail.\n+        _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+        target += head_length, source += head_length;\n+\n+        // Define the permutation vectors for the `permute2var` instruction for the body.\n+        sz_u512_vec_t first_vec, second_vec, combined_vec, selector_vec;\n+        selector_vec.zmm = _mm512_set_epi8(                                 //\n+            63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, //\n+            47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, //\n+            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, //\n+            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n+        selector_vec.zmm = _mm512_add_epi8(selector_vec.zmm, _mm512_set1_epi8(shift_in_page));\n+        selector_vec.zmm = _mm512_and_si512(selector_vec.zmm, _mm512_set1_epi8(63));\n+\n+        if (body_length >= 128) {\n+            // Now that the permutations are prepared, pre-load the first cache line and start the loop.\n+            __mmask64 blend_mask = _sz_u64_mask_until(shift_in_page);\n+            sz_cptr_t source_page = source - (sz_size_t)source % 64;\n+            first_vec.zmm = _mm512_load_si512(source_page);\n+            for (; body_length >= 128; target += 64, source += 64, source_page += 64, body_length -= 64) {\n+                second_vec.zmm = _mm512_load_si512(source_page + 64);\n+                second_vec.zmm = _mm512_permutexvar_epi8(selector_vec.zmm, second_vec.zmm);\n+                combined_vec.zmm = _mm512_mask_blend_epi8(blend_mask, second_vec.zmm, first_vec.zmm);\n+                sz_assert(combined_vec.u8s[0] == source[0]);\n+                sz_assert(combined_vec.u8s[63] == source[63]);\n+                _mm512_store_si512(target, combined_vec.zmm);\n+                first_vec.zmm = second_vec.zmm;\n+            }\n+        }\n+        if (body_length)\n+            _mm512_store_si512(target, _mm512_loadu_si512(source)), target += 64, source += 64, body_length -= 64;\n+        _mm512_mask_storeu_epi8(target, tail_mask, _mm512_maskz_loadu_epi8(tail_mask, source));\n+    }\n+    else {\n+        // Tail, body, and head.\n+        _mm512_mask_storeu_epi8(target + head_length + body_length, head_mask,\n+                                _mm512_maskz_loadu_epi8(head_mask, source + head_length + body_length));\n+\n+        // Define the permutation vectors for the `permute2var` instruction for the body.\n+        sz_u512_vec_t first_vec, second_vec, combined_vec, selector_vec;\n+        selector_vec.zmm = _mm512_set_epi8(                                 //\n+            63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, //\n+            47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, //\n+            31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, //\n+            15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0);\n+        selector_vec.zmm = _mm512_add_epi8(selector_vec.zmm, _mm512_set1_epi8(shift_in_page));\n+        selector_vec.zmm = _mm512_and_si512(selector_vec.zmm, _mm512_set1_epi8(63));\n+\n+        if (body_length >= 128) {\n+            // Now that the permutations are prepared, pre-load the first cache line and start the loop.\n+            __mmask64 blend_mask = _sz_u64_mask_until(shift_in_page);\n+            sz_cptr_t source_second_page = source + body_length - (sz_size_t)(source + body_length) % 64;\n+            first_vec.zmm = _mm512_load_si512(source_second_page);\n+            for (; body_length >= 128; source_second_page -= 64, body_length -= 64) {\n+                second_vec.zmm = _mm512_load_si512(source_second_page - 64);\n+                second_vec.zmm = _mm512_permutexvar_epi8(selector_vec.zmm, second_vec.zmm);\n+                combined_vec.zmm = _mm512_mask_blend_epi8(blend_mask, second_vec.zmm, first_vec.zmm);\n+                sz_assert(combined_vec.u8s[0] == source[0]);\n+                sz_assert(combined_vec.u8s[63] == source[63]);\n+                _mm512_store_si512(target + head_length + body_length, combined_vec.zmm);\n+                first_vec.zmm = second_vec.zmm;\n+            }\n+        }\n+        if (body_length) _mm512_store_si512(target + head_length, _mm512_loadu_si512(source + head_length));\n+        _mm512_mask_storeu_epi8(target, tail_mask, _mm512_maskz_loadu_epi8(tail_mask, source));\n+    }\n+}\n\\ No newline at end of file\ndiff --git a/include/stringzilla/stringzilla.h b/include/stringzilla/stringzilla.h\nindex 291dbf9c..0068c11f 100644\n--- a/include/stringzilla/stringzilla.h\n+++ b/include/stringzilla/stringzilla.h\n@@ -453,6 +453,25 @@ SZ_DYNAMIC sz_ordering_t sz_order(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b,\n /** @copydoc sz_order */\n SZ_PUBLIC sz_ordering_t sz_order_serial(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length);\n \n+/**\n+ *  @brief  Look Up Table @b (LUT) transformation of a string. Equivalent to `for (char & c : text) c = lut[c]`.\n+ *\n+ *  Can be used to implement some form of string normalization, partially masking punctuation marks,\n+ *  or converting between different character sets, like uppercase or lowercase. Surprisingly, also has\n+ *  broad implications in image processing, where image channel transformations are often done using LUTs.\n+ *\n+ *  @param text     String to be normalized.\n+ *  @param length   Number of bytes in the string.\n+ *  @param lut      Look Up Table to apply. Must be exactly @b 256 bytes long.\n+ *  @param result   Output string, can point to the same address as ::text.\n+ */\n+SZ_DYNAMIC void sz_look_up_transform(sz_cptr_t text, sz_size_t length, sz_cptr_t lut, sz_ptr_t result);\n+\n+typedef void (*sz_look_up_transform_t)(sz_cptr_t, sz_size_t, sz_cptr_t, sz_ptr_t);\n+\n+/** @copydoc sz_look_up_transform */\n+SZ_PUBLIC void sz_look_up_transform_serial(sz_cptr_t text, sz_size_t length, sz_cptr_t lut, sz_ptr_t result);\n+\n /**\n  *  @brief  Equivalent to `for (char & c : text) c = tolower(c)`.\n  *\n@@ -1159,16 +1178,18 @@ SZ_PUBLIC void sz_sort_intro(sz_sequence_t *sequence, sz_sequence_comparator_t l\n \n #if SZ_USE_X86_AVX512\n \n-/** @copydoc sz_equal_serial */\n+/** @copydoc sz_equal */\n SZ_PUBLIC sz_bool_t sz_equal_avx512(sz_cptr_t a, sz_cptr_t b, sz_size_t length);\n-/** @copydoc sz_order_serial */\n+/** @copydoc sz_order */\n SZ_PUBLIC sz_ordering_t sz_order_avx512(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length);\n-/** @copydoc sz_copy_serial */\n+/** @copydoc sz_copy */\n SZ_PUBLIC void sz_copy_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n-/** @copydoc sz_move_serial */\n+/** @copydoc sz_move */\n SZ_PUBLIC void sz_move_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n-/** @copydoc sz_fill_serial */\n+/** @copydoc sz_fill */\n SZ_PUBLIC void sz_fill_avx512(sz_ptr_t target, sz_size_t length, sz_u8_t value);\n+/** @copydoc sz_look_up_tranform */\n+SZ_PUBLIC void sz_look_up_tranform_avx512(sz_cptr_t source, sz_size_t length, sz_cptr_t table, sz_ptr_t target);\n /** @copydoc sz_find_byte */\n SZ_PUBLIC sz_cptr_t sz_find_byte_avx512(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle);\n /** @copydoc sz_rfind_byte */\n@@ -1194,12 +1215,18 @@ SZ_PUBLIC void sz_hashes_avx512(sz_cptr_t text, sz_size_t length, sz_size_t wind\n #endif\n \n #if SZ_USE_X86_AVX2\n+/** @copydoc sz_equal */\n+SZ_PUBLIC sz_bool_t sz_equal_avx2(sz_cptr_t a, sz_cptr_t b, sz_size_t length);\n+/** @copydoc sz_order */\n+SZ_PUBLIC sz_ordering_t sz_order_avx2(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length);\n /** @copydoc sz_copy */\n SZ_PUBLIC void sz_copy_avx2(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n /** @copydoc sz_move */\n SZ_PUBLIC void sz_move_avx2(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n /** @copydoc sz_fill */\n SZ_PUBLIC void sz_fill_avx2(sz_ptr_t target, sz_size_t length, sz_u8_t value);\n+/** @copydoc sz_look_up_transform */\n+SZ_PUBLIC void sz_look_up_transform_avx2(sz_cptr_t source, sz_size_t length, sz_cptr_t table, sz_ptr_t target);\n /** @copydoc sz_find_byte */\n SZ_PUBLIC sz_cptr_t sz_find_byte_avx2(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle);\n /** @copydoc sz_rfind_byte */\n@@ -1216,6 +1243,16 @@ SZ_PUBLIC void sz_hashes_avx2(sz_cptr_t text, sz_size_t length, sz_size_t window\n #if SZ_USE_ARM_NEON\n /** @copydoc sz_equal */\n SZ_PUBLIC sz_bool_t sz_equal_neon(sz_cptr_t a, sz_cptr_t b, sz_size_t length);\n+/** @copydoc sz_order */\n+SZ_PUBLIC sz_ordering_t sz_order_neon(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length);\n+/** @copydoc sz_copy */\n+SZ_PUBLIC void sz_copy_neon(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n+/** @copydoc sz_move */\n+SZ_PUBLIC void sz_move_neon(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n+/** @copydoc sz_fill */\n+SZ_PUBLIC void sz_fill_neon(sz_ptr_t target, sz_size_t length, sz_u8_t value);\n+/** @copydoc sz_look_up_transform */\n+SZ_PUBLIC void sz_look_up_transform_neon(sz_cptr_t source, sz_size_t length, sz_cptr_t table, sz_ptr_t target);\n /** @copydoc sz_find_byte */\n SZ_PUBLIC sz_cptr_t sz_find_byte_neon(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle);\n /** @copydoc sz_rfind_byte */\n@@ -1230,6 +1267,31 @@ SZ_PUBLIC sz_cptr_t sz_find_charset_neon(sz_cptr_t text, sz_size_t length, sz_ch\n SZ_PUBLIC sz_cptr_t sz_rfind_charset_neon(sz_cptr_t text, sz_size_t length, sz_charset_t const *set);\n #endif\n \n+#if SZ_USE_ARM_SVE\n+/** @copydoc sz_equal */\n+SZ_PUBLIC sz_bool_t sz_equal_sve(sz_cptr_t a, sz_cptr_t b, sz_size_t length);\n+/** @copydoc sz_order */\n+SZ_PUBLIC sz_ordering_t sz_order_sve(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length);\n+/** @copydoc sz_copy */\n+SZ_PUBLIC void sz_copy_sve(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n+/** @copydoc sz_move */\n+SZ_PUBLIC void sz_move_sve(sz_ptr_t target, sz_cptr_t source, sz_size_t length);\n+/** @copydoc sz_fill */\n+SZ_PUBLIC void sz_fill_sve(sz_ptr_t target, sz_size_t length, sz_u8_t value);\n+/** @copydoc sz_find_byte */\n+SZ_PUBLIC sz_cptr_t sz_find_byte_sve(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle);\n+/** @copydoc sz_rfind_byte */\n+SZ_PUBLIC sz_cptr_t sz_rfind_byte_sve(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle);\n+/** @copydoc sz_find */\n+SZ_PUBLIC sz_cptr_t sz_find_sve(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle, sz_size_t n_length);\n+/** @copydoc sz_rfind */\n+SZ_PUBLIC sz_cptr_t sz_rfind_sve(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle, sz_size_t n_length);\n+/** @copydoc sz_find_charset */\n+SZ_PUBLIC sz_cptr_t sz_find_charset_sve(sz_cptr_t text, sz_size_t length, sz_charset_t const *set);\n+/** @copydoc sz_rfind_charset */\n+SZ_PUBLIC sz_cptr_t sz_rfind_charset_sve(sz_cptr_t text, sz_size_t length, sz_charset_t const *set);\n+#endif\n+\n #pragma endregion\n \n #pragma GCC diagnostic push\n@@ -1289,12 +1351,13 @@ SZ_PUBLIC sz_cptr_t sz_rfind_charset_neon(sz_cptr_t text, sz_size_t length, sz_c\n #if SZ_DEBUG && defined(SZ_AVOID_LIBC) && !SZ_AVOID_LIBC && !defined(SZ_PIC)\n #include <stdio.h>  // `fprintf`\n #include <stdlib.h> // `EXIT_FAILURE`\n-#define sz_assert(condition)                                                                                \\\n-    do {                                                                                                    \\\n-        if (!(condition)) {                                                                                 \\\n-            fprintf(stderr, \"Assertion failed: %s, in file %s, line %d\\n\", #condition, __FILE__, __LINE__); \\\n-            exit(EXIT_FAILURE);                                                                             \\\n-        }                                                                                                   \\\n+SZ_PUBLIC void _sz_assert_failure(char const *condition, char const *file, int line) {\n+    fprintf(stderr, \"Assertion failed: %s, in file %s, line %d\\n\", condition, file, line);\n+    exit(EXIT_FAILURE);\n+}\n+#define sz_assert(condition)                                                      \\\n+    do {                                                                          \\\n+        if (!(condition)) { _sz_assert_failure(#condition, __FILE__, __LINE__); } \\\n     } while (0)\n #else\n #define sz_assert(condition) ((void)(condition))\n@@ -3063,6 +3126,14 @@ SZ_INTERNAL sz_u8_t sz_u8_divide(sz_u8_t number, sz_u8_t divisor) {\n     return (sz_u8_t)(t >> shift);\n }\n \n+SZ_PUBLIC void sz_look_up_transform_serial(sz_cptr_t text, sz_size_t length, sz_cptr_t lut, sz_ptr_t result) {\n+    sz_u8_t const *unsigned_lut = (sz_u8_t const *)lut;\n+    sz_u8_t const *unsigned_text = (sz_u8_t const *)text;\n+    sz_u8_t *unsigned_result = (sz_u8_t *)result;\n+    sz_u8_t const *end = unsigned_text + length;\n+    for (; unsigned_text != end; ++unsigned_text, ++unsigned_result) *unsigned_result = unsigned_lut[*unsigned_text];\n+}\n+\n SZ_PUBLIC void sz_tolower_serial(sz_cptr_t text, sz_size_t length, sz_ptr_t result) {\n     sz_u8_t *unsigned_result = (sz_u8_t *)result;\n     sz_u8_t const *unsigned_text = (sz_u8_t const *)text;\n@@ -3738,15 +3809,135 @@ typedef union sz_u256_vec_t {\n     sz_u8_t u8s[32];\n } sz_u256_vec_t;\n \n+SZ_PUBLIC sz_ordering_t sz_order_avx2(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n+    //! Before optimizing this, read the \"Operations Not Worth Optimizing\" in Contributions Guide:\n+    //! https://github.com/ashvardanian/StringZilla/blob/main/CONTRIBUTING.md#general-performance-observations\n+    return sz_order_serial(a, a_length, b, b_length);\n+}\n+\n+SZ_PUBLIC sz_bool_t sz_equal_avx2(sz_cptr_t a, sz_cptr_t b, sz_size_t length) {\n+    sz_u256_vec_t a_vec, b_vec;\n+\n+    while (length >= 32) {\n+        a_vec.ymm = _mm256_lddqu_si256((__m256i const *)a);\n+        b_vec.ymm = _mm256_lddqu_si256((__m256i const *)b);\n+        // One approach can be to use \"movemasks\", but we could also use a bitwise matching like `_mm256_testnzc_si256`.\n+        int difference_mask = ~_mm256_movemask_epi8(_mm256_cmpeq_epi8(a_vec.ymm, b_vec.ymm));\n+        if (difference_mask == 0) { a += 32, b += 32, length -= 32; }\n+        else { return sz_false_k; }\n+    }\n+\n+    if (length) return sz_equal_serial(a, b, length);\n+    return sz_true_k;\n+}\n+\n SZ_PUBLIC void sz_fill_avx2(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n-    for (; length >= 32; target += 32, length -= 32) _mm256_storeu_si256((__m256i *)target, _mm256_set1_epi8(value));\n-    sz_fill_serial(target, length, value);\n+    char value_char = *(char *)&value;\n+    __m256i value_vec = _mm256_set1_epi8(value_char);\n+    // The naive implementation of this function is very simple.\n+    // It assumes the CPU is great at handling unaligned \"stores\".\n+    //\n+    //    for (; length >= 32; target += 32, length -= 32) _mm256_storeu_si256(target, value_vec);\n+    //    sz_fill_serial(target, length, value);\n+    //\n+    // When the buffer is small, there isn't much to innovate.\n+    if (length <= 32) sz_fill_serial(target, length, value);\n+    // When the buffer is aligned, we can avoid any split-stores.\n+    else {\n+        sz_size_t head_length = (32 - ((sz_size_t)target % 32)) % 32; // 31 or less.\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 32;    // 31 or less.\n+        sz_size_t body_length = length - head_length - tail_length;   // Multiple of 32.\n+        sz_u16_t value16 = (sz_u16_t)value * 0x0101u;\n+        sz_u32_t value32 = (sz_u32_t)value16 * 0x00010001u;\n+        sz_u64_t value64 = (sz_u64_t)value32 * 0x0000000100000001ull;\n+\n+        // Fill the head of the buffer. This part is much cleaner with AVX-512.\n+        if (head_length & 1) *(sz_u8_t *)target = value, target++, head_length--;\n+        if (head_length & 2) *(sz_u16_t *)target = value16, target += 2, head_length -= 2;\n+        if (head_length & 4) *(sz_u32_t *)target = value32, target += 4, head_length -= 4;\n+        if (head_length & 8) *(sz_u64_t *)target = value64, target += 8, head_length -= 8;\n+        if (head_length & 16)\n+            _mm_store_si128((__m128i *)target, _mm_set1_epi8(value_char)), target += 16, head_length -= 16;\n+        sz_assert((sz_size_t)target % 32 == 0 && \"Target is supposed to be aligned to the YMM register size.\");\n+\n+        // Fill the aligned body of the buffer.\n+        for (; body_length >= 32; target += 32, body_length -= 32) _mm256_store_si256((__m256i *)target, value_vec);\n+\n+        // Fill the tail of the buffer. This part is much cleaner with AVX-512.\n+        sz_assert((sz_size_t)target % 32 == 0 && \"Target is supposed to be aligned to the YMM register size.\");\n+        if (tail_length & 16)\n+            _mm_store_si128((__m128i *)target, _mm_set1_epi8(value_char)), target += 16, tail_length -= 16;\n+        if (tail_length & 8) *(sz_u64_t *)target = value64, target += 8, tail_length -= 8;\n+        if (tail_length & 4) *(sz_u32_t *)target = value32, target += 4, tail_length -= 4;\n+        if (tail_length & 2) *(sz_u16_t *)target = value16, target += 2, tail_length -= 2;\n+        if (tail_length & 1) *(sz_u8_t *)target = value, target++, tail_length--;\n+    }\n }\n \n SZ_PUBLIC void sz_copy_avx2(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n-    for (; length >= 32; target += 32, source += 32, length -= 32)\n-        _mm256_storeu_si256((__m256i *)target, _mm256_lddqu_si256((__m256i const *)source));\n-    sz_copy_serial(target, source, length);\n+    // The naive implementation of this function is very simple.\n+    // It assumes the CPU is great at handling unaligned \"stores\" and \"loads\".\n+    //\n+    //    for (; length >= 32; target += 32, source += 32, length -= 32)\n+    //        _mm256_storeu_si256((__m256i *)target, _mm256_lddqu_si256((__m256i const *)source));\n+    //    sz_copy_serial(target, source, length);\n+    //\n+    // A typical AWS Skylake instance can have 32 KB x 2 blocks of L1 data cache per core,\n+    // 1 MB x 2 blocks of L2 cache per core, and one shared L3 cache buffer.\n+    // For now, let's avoid the cases beyond the L2 size.\n+    int is_huge = length > 1ull * 1024ull * 1024ull;\n+    if (length <= 32) { sz_copy_serial(target, source, length); }\n+    // When dealing wirh larger arrays, the optimization is not as simple as with the `sz_fill_avx2` function,\n+    // as both buffers may be unaligned. If we are lucky and the requested operation is some huge page transfer,\n+    // we can use aligned loads and stores, and the performance will be great.\n+    else if ((sz_size_t)target % 32 == 0 && (sz_size_t)source % 32 == 0 && !is_huge) {\n+        for (; length >= 32; target += 32, source += 32, length -= 32)\n+            _mm256_store_si256((__m256i *)target, _mm256_load_si256((__m256i const *)source));\n+        if (length) sz_copy_serial(target, source, length);\n+    }\n+    // The trickiest case is when both `source` and `target` are not aligned.\n+    // In such and simpler cases we can copy enough bytes into `target` to reach its cacheline boundary,\n+    // and then combine unaligned loads with aligned stores.\n+    else {\n+        sz_size_t head_length = (32 - ((sz_size_t)target % 32)) % 32; // 31 or less.\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 32;    // 31 or less.\n+        sz_size_t body_length = length - head_length - tail_length;   // Multiple of 32.\n+\n+        // Fill the head of the buffer. This part is much cleaner with AVX-512.\n+        if (head_length & 1) *(sz_u8_t *)target = *(sz_u8_t *)source, target++, source++, head_length--;\n+        if (head_length & 2) *(sz_u16_t *)target = *(sz_u16_t *)source, target += 2, source += 2, head_length -= 2;\n+        if (head_length & 4) *(sz_u32_t *)target = *(sz_u32_t *)source, target += 4, source += 4, head_length -= 4;\n+        if (head_length & 8) *(sz_u64_t *)target = *(sz_u64_t *)source, target += 8, source += 8, head_length -= 8;\n+        if (head_length & 16)\n+            _mm_store_si128((__m128i *)target, _mm_lddqu_si128((__m128i const *)source)), target += 16, source += 16,\n+                head_length -= 16;\n+        sz_assert((sz_size_t)target % 32 == 0 && \"Target is supposed to be aligned to the YMM register size.\");\n+\n+        // Fill the aligned body of the buffer.\n+        if (!is_huge) {\n+            for (; body_length >= 32; target += 32, source += 32, body_length -= 32)\n+                _mm256_store_si256((__m256i *)target, _mm256_lddqu_si256((__m256i const *)source));\n+        }\n+        // When the biffer is huge, we can traverse it in 2 directions.\n+        else {\n+            for (; body_length >= 64; target += 32, source += 32, body_length -= 64) {\n+                _mm256_store_si256((__m256i *)(target), _mm256_lddqu_si256((__m256i const *)(source)));\n+                _mm256_store_si256((__m256i *)(target + body_length - 32),\n+                                   _mm256_lddqu_si256((__m256i const *)(source + body_length - 32)));\n+            }\n+            if (body_length) _mm256_store_si256((__m256i *)target, _mm256_lddqu_si256((__m256i const *)source));\n+        }\n+\n+        // Fill the tail of the buffer. This part is much cleaner with AVX-512.\n+        sz_assert((sz_size_t)target % 32 == 0 && \"Target is supposed to be aligned to the YMM register size.\");\n+        if (tail_length & 16)\n+            _mm_store_si128((__m128i *)target, _mm_lddqu_si128((__m128i const *)source)), target += 16, source += 16,\n+                tail_length -= 16;\n+        if (tail_length & 8) *(sz_u64_t *)target = *(sz_u64_t *)source, target += 8, source += 8, tail_length -= 8;\n+        if (tail_length & 4) *(sz_u32_t *)target = *(sz_u32_t *)source, target += 4, source += 4, tail_length -= 4;\n+        if (tail_length & 2) *(sz_u16_t *)target = *(sz_u16_t *)source, target += 2, source += 2, tail_length -= 2;\n+        if (tail_length & 1) *(sz_u8_t *)target = *(sz_u8_t *)source, target++, source++, tail_length--;\n+    }\n }\n \n SZ_PUBLIC void sz_move_avx2(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n@@ -3763,6 +3954,142 @@ SZ_PUBLIC void sz_move_avx2(sz_ptr_t target, sz_cptr_t source, sz_size_t length)\n     }\n }\n \n+SZ_PUBLIC void sz_look_up_transform_avx2(sz_cptr_t source, sz_size_t length, sz_cptr_t lut, sz_ptr_t target) {\n+\n+    // If the input is tiny (especially smaller than the look-up table itself), we may end up paying\n+    // more for organizing the SIMD registers and changing the CPU state, than for the actual computation.\n+    // But if at least 3 cache lines are touched, the AVX-2 implementation should be faster.\n+    if (length <= 128) {\n+        sz_look_up_transform_serial(source, length, lut, target);\n+        return;\n+    }\n+\n+    // We need to pull the lookup table into 8x YMM registers.\n+    // The biggest issue is reorganizing the data in the lookup table, as AVX2 doesn't have 256-bit shuffle,\n+    // it only has 128-bit \"within-lane\" shuffle. Still, it's wiser to use full YMM registers, instead of XMM,\n+    // so that we can at least compensate high latency with twice larger window and one more level of lookup.\n+    sz_u256_vec_t lut_0_to_15_vec, lut_16_to_31_vec, lut_32_to_47_vec, lut_48_to_63_vec, //\n+        lut_64_to_79_vec, lut_80_to_95_vec, lut_96_to_111_vec, lut_112_to_127_vec,       //\n+        lut_128_to_143_vec, lut_144_to_159_vec, lut_160_to_175_vec, lut_176_to_191_vec,  //\n+        lut_192_to_207_vec, lut_208_to_223_vec, lut_224_to_239_vec, lut_240_to_255_vec;\n+\n+    lut_0_to_15_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut)));\n+    lut_16_to_31_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 16)));\n+    lut_32_to_47_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 32)));\n+    lut_48_to_63_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 48)));\n+    lut_64_to_79_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 64)));\n+    lut_80_to_95_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 80)));\n+    lut_96_to_111_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 96)));\n+    lut_112_to_127_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 112)));\n+    lut_128_to_143_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 128)));\n+    lut_144_to_159_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 144)));\n+    lut_160_to_175_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 160)));\n+    lut_176_to_191_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 176)));\n+    lut_192_to_207_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 192)));\n+    lut_208_to_223_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 208)));\n+    lut_224_to_239_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 224)));\n+    lut_240_to_255_vec.ymm = _mm256_broadcastsi128_si256(_mm_lddqu_si128((__m128i const *)(lut + 240)));\n+\n+    // Assuming each lookup is performed within 16 elements of 256, we need to reduce the scope by 16x = 2^4.\n+    sz_u256_vec_t not_first_bit_vec, not_second_bit_vec, not_third_bit_vec, not_fourth_bit_vec;\n+\n+    /// Top and bottom nibbles of the source are used separately.\n+    sz_u256_vec_t source_vec, source_bot_vec;\n+    sz_u256_vec_t blended_0_to_31_vec, blended_32_to_63_vec, blended_64_to_95_vec, blended_96_to_127_vec,\n+        blended_128_to_159_vec, blended_160_to_191_vec, blended_192_to_223_vec, blended_224_to_255_vec;\n+\n+    // Handling the head.\n+    while (length >= 32) {\n+        // Load and separate the nibbles of each byte in the source.\n+        source_vec.ymm = _mm256_lddqu_si256((__m256i const *)source);\n+        source_bot_vec.ymm = _mm256_and_si256(source_vec.ymm, _mm256_set1_epi8((char)0x0F));\n+\n+        // In the first round, we select using the 4th bit.\n+        not_fourth_bit_vec.ymm = _mm256_cmpeq_epi8( //\n+            _mm256_and_si256(_mm256_set1_epi8((char)0x10), source_vec.ymm), _mm256_setzero_si256());\n+        blended_0_to_31_vec.ymm = _mm256_blendv_epi8(                      //\n+            _mm256_shuffle_epi8(lut_16_to_31_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_0_to_15_vec.ymm, source_bot_vec.ymm),  //\n+            not_fourth_bit_vec.ymm);\n+        blended_32_to_63_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_48_to_63_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_32_to_47_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+        blended_64_to_95_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_80_to_95_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_64_to_79_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+        blended_96_to_127_vec.ymm = _mm256_blendv_epi8(                      //\n+            _mm256_shuffle_epi8(lut_112_to_127_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_96_to_111_vec.ymm, source_bot_vec.ymm),  //\n+            not_fourth_bit_vec.ymm);\n+        blended_128_to_159_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_144_to_159_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_128_to_143_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+        blended_160_to_191_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_176_to_191_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_160_to_175_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+        blended_192_to_223_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_208_to_223_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_192_to_207_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+        blended_224_to_255_vec.ymm = _mm256_blendv_epi8(                     //\n+            _mm256_shuffle_epi8(lut_240_to_255_vec.ymm, source_bot_vec.ymm), //\n+            _mm256_shuffle_epi8(lut_224_to_239_vec.ymm, source_bot_vec.ymm), //\n+            not_fourth_bit_vec.ymm);\n+\n+        // Perform a tree-like reduction of the 8x \"blended\" YMM registers, depending on the \"source\" content.\n+        // The first round selects using the 3rd bit.\n+        not_third_bit_vec.ymm = _mm256_cmpeq_epi8( //\n+            _mm256_and_si256(_mm256_set1_epi8((char)0x20), source_vec.ymm), _mm256_setzero_si256());\n+        blended_0_to_31_vec.ymm = _mm256_blendv_epi8( //\n+            blended_32_to_63_vec.ymm,                 //\n+            blended_0_to_31_vec.ymm,                  //\n+            not_third_bit_vec.ymm);\n+        blended_64_to_95_vec.ymm = _mm256_blendv_epi8( //\n+            blended_96_to_127_vec.ymm,                 //\n+            blended_64_to_95_vec.ymm,                  //\n+            not_third_bit_vec.ymm);\n+        blended_128_to_159_vec.ymm = _mm256_blendv_epi8( //\n+            blended_160_to_191_vec.ymm,                  //\n+            blended_128_to_159_vec.ymm,                  //\n+            not_third_bit_vec.ymm);\n+        blended_192_to_223_vec.ymm = _mm256_blendv_epi8( //\n+            blended_224_to_255_vec.ymm,                  //\n+            blended_192_to_223_vec.ymm,                  //\n+            not_third_bit_vec.ymm);\n+\n+        // The second round selects using the 2nd bit.\n+        not_second_bit_vec.ymm = _mm256_cmpeq_epi8( //\n+            _mm256_and_si256(_mm256_set1_epi8((char)0x40), source_vec.ymm), _mm256_setzero_si256());\n+        blended_0_to_31_vec.ymm = _mm256_blendv_epi8( //\n+            blended_64_to_95_vec.ymm,                 //\n+            blended_0_to_31_vec.ymm,                  //\n+            not_second_bit_vec.ymm);\n+        blended_128_to_159_vec.ymm = _mm256_blendv_epi8( //\n+            blended_192_to_223_vec.ymm,                  //\n+            blended_128_to_159_vec.ymm,                  //\n+            not_second_bit_vec.ymm);\n+\n+        // The third round selects using the 1st bit.\n+        not_first_bit_vec.ymm = _mm256_cmpeq_epi8( //\n+            _mm256_and_si256(_mm256_set1_epi8((char)0x80), source_vec.ymm), _mm256_setzero_si256());\n+        blended_0_to_31_vec.ymm = _mm256_blendv_epi8( //\n+            blended_128_to_159_vec.ymm,               //\n+            blended_0_to_31_vec.ymm,                  //\n+            not_first_bit_vec.ymm);\n+\n+        // And dump the result into the target.\n+        _mm256_storeu_si256((__m256i *)target, blended_0_to_31_vec.ymm);\n+        source += 32, target += 32, length -= 32;\n+    }\n+\n+    // Handle the tail.\n+    if (length) sz_look_up_transform_serial(source, length, lut, target);\n+}\n+\n SZ_PUBLIC sz_cptr_t sz_find_byte_avx2(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n) {\n     int mask;\n     sz_u256_vec_t h_vec, n_vec;\n@@ -4160,17 +4487,38 @@ SZ_INTERNAL __mmask64 _sz_u64_mask_until(sz_size_t n) {\n \n SZ_PUBLIC sz_ordering_t sz_order_avx512(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n     sz_u512_vec_t a_vec, b_vec;\n-    __mmask64 a_mask, b_mask, mask_not_equal;\n+\n+    // Pointer arithmetic is cheap, fetching memory is not!\n+    // So we can use the masked loads to fetch at most one cache-line for each string,\n+    // compare the prefixes, and only then move forward.\n+    sz_size_t a_head_length = 64 - ((sz_size_t)a % 64); // 63 or less.\n+    sz_size_t b_head_length = 64 - ((sz_size_t)b % 64); // 63 or less.\n+    a_head_length = a_head_length < a_length ? a_head_length : a_length;\n+    b_head_length = b_head_length < b_length ? b_head_length : b_length;\n+    sz_size_t head_length = a_head_length < b_head_length ? a_head_length : b_head_length;\n+    __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+    a_vec.zmm = _mm512_maskz_loadu_epi8(head_mask, a);\n+    b_vec.zmm = _mm512_maskz_loadu_epi8(head_mask, b);\n+    __mmask64 mask_not_equal = _mm512_cmpneq_epi8_mask(a_vec.zmm, b_vec.zmm);\n+    if (mask_not_equal != 0) {\n+        sz_u64_t first_diff = _tzcnt_u64(mask_not_equal);\n+        char a_char = a_vec.u8s[first_diff];\n+        char b_char = b_vec.u8s[first_diff];\n+        return _sz_order_scalars(a_char, b_char);\n+    }\n+    else if (head_length == a_length && head_length == b_length) { return sz_equal_k; }\n+    else { a += head_length, b += head_length, a_length -= head_length, b_length -= head_length; }\n \n     // The rare case, when both string are very long.\n+    __mmask64 a_mask, b_mask;\n     while ((a_length >= 64) & (b_length >= 64)) {\n         a_vec.zmm = _mm512_loadu_si512(a);\n         b_vec.zmm = _mm512_loadu_si512(b);\n         mask_not_equal = _mm512_cmpneq_epi8_mask(a_vec.zmm, b_vec.zmm);\n         if (mask_not_equal != 0) {\n             sz_u64_t first_diff = _tzcnt_u64(mask_not_equal);\n-            char a_char = a[first_diff];\n-            char b_char = b[first_diff];\n+            char a_char = a_vec.u8s[first_diff];\n+            char b_char = b_vec.u8s[first_diff];\n             return _sz_order_scalars(a_char, b_char);\n         }\n         a += 64, b += 64, a_length -= 64, b_length -= 64;\n@@ -4188,17 +4536,16 @@ SZ_PUBLIC sz_ordering_t sz_order_avx512(sz_cptr_t a, sz_size_t a_length, sz_cptr\n         mask_not_equal = _mm512_cmpneq_epi8_mask(a_vec.zmm, b_vec.zmm);\n         if (mask_not_equal != 0) {\n             sz_u64_t first_diff = _tzcnt_u64(mask_not_equal);\n-            char a_char = a[first_diff];\n-            char b_char = b[first_diff];\n+            char a_char = a_vec.u8s[first_diff];\n+            char b_char = b_vec.u8s[first_diff];\n             return _sz_order_scalars(a_char, b_char);\n         }\n-        else\n-            // From logic perspective, the hardest cases are \"abc\\0\" and \"abc\".\n-            // The result must be `sz_greater_k`, as the latter is shorter.\n-            return _sz_order_scalars(a_length, b_length);\n+        // From logic perspective, the hardest cases are \"abc\\0\" and \"abc\".\n+        // The result must be `sz_greater_k`, as the latter is shorter.\n+        else { return _sz_order_scalars(a_length, b_length); }\n     }\n-    else\n-        return sz_equal_k;\n+\n+    return sz_equal_k;\n }\n \n SZ_PUBLIC sz_bool_t sz_equal_avx512(sz_cptr_t a, sz_cptr_t b, sz_size_t length) {\n@@ -4221,39 +4568,220 @@ SZ_PUBLIC sz_bool_t sz_equal_avx512(sz_cptr_t a, sz_cptr_t b, sz_size_t length)\n         mask = _mm512_mask_cmpneq_epi8_mask(mask, a_vec.zmm, b_vec.zmm);\n         return (sz_bool_t)(mask == 0);\n     }\n-    else\n-        return sz_true_k;\n+\n+    return sz_true_k;\n }\n \n SZ_PUBLIC void sz_fill_avx512(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n-    for (; length >= 64; target += 64, length -= 64) _mm512_storeu_si512(target, _mm512_set1_epi8(value));\n-    // At this point the length is guaranteed to be under 64.\n-    _mm512_mask_storeu_epi8(target, _sz_u64_mask_until(length), _mm512_set1_epi8(value));\n+    __m512i value_vec = _mm512_set1_epi8(value);\n+    // The naive implementation of this function is very simple.\n+    // It assumes the CPU is great at handling unaligned \"stores\".\n+    //\n+    //    for (; length >= 64; target += 64, length -= 64) _mm512_storeu_si512(target, value_vec);\n+    //    _mm512_mask_storeu_epi8(target, _sz_u64_mask_until(length), value_vec);\n+    //\n+    // When the buffer is small, there isn't much to innovate.\n+    if (length <= 64) {\n+        __mmask64 mask = _sz_u64_mask_until(length);\n+        _mm512_mask_storeu_epi8(target, mask, value_vec);\n+    }\n+    // When the buffer is over 64 bytes, it's guaranteed to touch at least two cache lines - the head and tail,\n+    // and may include more cache-lines in-between. Knowing this, we can avoid expensive unaligned stores\n+    // by computing 2 masks - for the head and tail, using masked stores for the head and tail, and unmasked\n+    // for the body.\n+    else {\n+        sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+        sz_size_t body_length = length - head_length - tail_length;   // Multiple of 64.\n+        __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+        __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+        _mm512_mask_storeu_epi8(target, head_mask, value_vec);\n+        for (target += head_length; body_length >= 64; target += 64, body_length -= 64)\n+            _mm512_store_si512(target, value_vec);\n+        _mm512_mask_storeu_epi8(target, tail_mask, value_vec);\n+    }\n }\n \n SZ_PUBLIC void sz_copy_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n-    for (; length >= 64; target += 64, source += 64, length -= 64)\n-        _mm512_storeu_si512(target, _mm512_loadu_si512(source));\n-    // At this point the length is guaranteed to be under 64.\n-    __mmask64 mask = _sz_u64_mask_until(length);\n-    _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n-}\n+    // The naive implementation of this function is very simple.\n+    // It assumes the CPU is great at handling unaligned \"stores\" and \"loads\".\n+    //\n+    //    for (; length >= 64; target += 64, source += 64, length -= 64)\n+    //        _mm512_storeu_si512(target, _mm512_loadu_si512(source));\n+    //    __mmask64 mask = _sz_u64_mask_until(length);\n+    //    _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n+    //\n+    // A typical AWS Sapphire Rapids instance can have 48 KB x 2 blocks of L1 data cache per core,\n+    // 2 MB x 2 blocks of L2 cache per core, and one shared 60 MB buffer of L3 cache.\n+    // With two strings, we may consider the overal workload huge, if each exceeds 1 MB in length.\n+    int const is_huge = length >= 1ull * 1024ull * 1024ull;\n \n-SZ_PUBLIC void sz_move_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n-    if (target < source || target >= source + length) {\n+    // When the buffer is small, there isn't much to innovate.\n+    if (length <= 64) {\n+        __mmask64 mask = _sz_u64_mask_until(length);\n+        _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n+    }\n+    // When dealing wirh larger arrays, the optimization is not as simple as with the `sz_fill_avx512` function,\n+    // as both buffers may be unaligned. If we are lucky and the requested operation is some huge page transfer,\n+    // we can use aligned loads and stores, and the performance will be great.\n+    else if ((sz_size_t)target % 64 == 0 && (sz_size_t)source % 64 == 0 && !is_huge) {\n         for (; length >= 64; target += 64, source += 64, length -= 64)\n-            _mm512_storeu_si512(target, _mm512_loadu_si512(source));\n+            _mm512_store_si512(target, _mm512_load_si512(source));\n         // At this point the length is guaranteed to be under 64.\n         __mmask64 mask = _sz_u64_mask_until(length);\n+        // Aligned load and stores would work too, but it's not defined.\n         _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n     }\n+    // The trickiest case is when both `source` and `target` are not aligned.\n+    // In such and simpler cases we can copy enough bytes into `target` to reach its cacheline boundary,\n+    // and then combine unaligned loads with aligned stores.\n+    else if (!is_huge) {\n+        sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+        sz_size_t body_length = length - head_length - tail_length;   // Multiple of 64.\n+        __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+        __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+        _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+        for (target += head_length, source += head_length; body_length >= 64;\n+             target += 64, source += 64, body_length -= 64)\n+            _mm512_store_si512(target, _mm512_loadu_si512(source)); // Unaligned load, but aligned store!\n+        _mm512_mask_storeu_epi8(target, tail_mask, _mm512_maskz_loadu_epi8(tail_mask, source));\n+    }\n+    // For gigantic buffers, exceeding typical L1 cache sizes, there are other tricks we can use.\n+    //\n+    //      1. Moving in both directions to maximize the throughput, when fetching from multiple\n+    //         memory pages. Also helps with cache set-associativity issues, as we won't always\n+    //         be fetching the same entries in the lookup table.\n+    //      2. Using non-temporal stores to avoid polluting the cache.\n+    //      3. Prefetching the next cache line, to avoid stalling the CPU. This generally useless\n+    //         for predictable patterns, so disregard this advice.\n+    //\n+    // Bidirectional traversal adds about 10%, accelerating from 11 GB/s to 12 GB/s.\n+    // Using \"streaming stores\" boosts us from 12 GB/s to 19 GB/s.\n     else {\n-        // Jump to the end and walk backwards.\n-        for (target += length, source += length; length >= 64; length -= 64)\n-            _mm512_storeu_si512(target -= 64, _mm512_loadu_si512(source -= 64));\n-        // At this point the length is guaranteed to be under 64.\n+        sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64;\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 64;\n+        sz_size_t body_length = length - head_length - tail_length;\n+        __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+        __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+        _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+        _mm512_mask_storeu_epi8(target + head_length + body_length, tail_mask,\n+                                _mm512_maskz_loadu_epi8(tail_mask, source));\n+\n+        // Now in the main loop, we can use non-temporal loads and stores,\n+        // performing the operation in both directions.\n+        for (target += head_length, source += head_length; //\n+             body_length >= 128;                           //\n+             target += 64, source += 64, body_length -= 128) {\n+            _mm512_stream_si512((__m512i *)(target), _mm512_loadu_si512(source));\n+            _mm512_stream_si512((__m512i *)(target + body_length - 64), _mm512_loadu_si512(source + body_length - 64));\n+        }\n+        if (body_length >= 64) _mm512_stream_si512((__m512i *)target, _mm512_loadu_si512(source));\n+    }\n+}\n+\n+SZ_PUBLIC void sz_move_avx512(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    if (target == source) return; // Don't be silly, don't move the data if it's already there.\n+\n+    // On very short buffers, that are one cache line in width or less, we don't need any loops.\n+    // We can also avoid any data-dependencies between iterations, assuming we have 32 registers\n+    // to pre-load the data, before writing it back.\n+    if (length <= 64) {\n         __mmask64 mask = _sz_u64_mask_until(length);\n-        _mm512_mask_storeu_epi8(target - length, mask, _mm512_maskz_loadu_epi8(mask, source - length));\n+        _mm512_mask_storeu_epi8(target, mask, _mm512_maskz_loadu_epi8(mask, source));\n+    }\n+    else if (length <= 128) {\n+        sz_size_t last_length = length - 64;\n+        __mmask64 mask = _sz_u64_mask_until(last_length);\n+        __m512i source0 = _mm512_loadu_epi8(source);\n+        __m512i source1 = _mm512_maskz_loadu_epi8(mask, source + 64);\n+        _mm512_storeu_epi8(target, source0);\n+        _mm512_mask_storeu_epi8(target + 64, mask, source1);\n+    }\n+    else if (length <= 192) {\n+        sz_size_t last_length = length - 128;\n+        __mmask64 mask = _sz_u64_mask_until(last_length);\n+        __m512i source0 = _mm512_loadu_epi8(source);\n+        __m512i source1 = _mm512_loadu_epi8(source + 64);\n+        __m512i source2 = _mm512_maskz_loadu_epi8(mask, source + 128);\n+        _mm512_storeu_epi8(target, source0);\n+        _mm512_storeu_epi8(target + 64, source1);\n+        _mm512_mask_storeu_epi8(target + 128, mask, source2);\n+    }\n+    else if (length <= 256) {\n+        sz_size_t last_length = length - 192;\n+        __mmask64 mask = _sz_u64_mask_until(last_length);\n+        __m512i source0 = _mm512_loadu_epi8(source);\n+        __m512i source1 = _mm512_loadu_epi8(source + 64);\n+        __m512i source2 = _mm512_loadu_epi8(source + 128);\n+        __m512i source3 = _mm512_maskz_loadu_epi8(mask, source + 192);\n+        _mm512_storeu_epi8(target, source0);\n+        _mm512_storeu_epi8(target + 64, source1);\n+        _mm512_storeu_epi8(target + 128, source2);\n+        _mm512_mask_storeu_epi8(target + 192, mask, source3);\n+    }\n+\n+    // If the regions don't overlap at all, just use \"copy\" and save some brain cells thinking about corner cases.\n+    else if (target + length < source || target >= source + length) { sz_copy_avx512(target, source, length); }\n+\n+    // When the buffer is over 64 bytes, it's guaranteed to touch at least two cache lines - the head and tail,\n+    // and may include more cache-lines in-between. Knowing this, we can avoid expensive unaligned stores\n+    // by computing 2 masks - for the head and tail, using masked stores for the head and tail, and unmasked\n+    // for the body.\n+    else {\n+        sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+        sz_size_t body_length = length - head_length - tail_length;   // Multiple of 64.\n+        __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+        __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+\n+        // The absolute most common case of using \"moves\" is shifting the data within a continuous buffer\n+        // when adding a removing some values in it. In such cases, a typical shift is by 1, 2, 4, 8, 16,\n+        // or 32 bytes, rarely larger. For small shifts, under the size of the ZMM register, we can use shuffles.\n+        //\n+        // Remember:\n+        //      - if we are shifting data left, that we are traversing to the right.\n+        //      - if we are shifting data right, that we are traversing to the left.\n+        int const left_to_right_traversal = source > target;\n+\n+        // Now we guarantee, that the relative shift within registers is from 1 to 63 bytes and the output is aligned.\n+        // Hopefully, we need to shift more than two ZMM registers, so we could consider `valignr` instruction.\n+        // Sadly, using `_mm512_alignr_epi8` doesn't make sense, as it operates at a 128-bit granularity.\n+        //\n+        //      - `_mm256_alignr_epi8` shifts entire 256-bit register, but we need many of them.\n+        //      - `_mm512_alignr_epi32` shifts 512-bit chunks, but only if the `shift` is a multiple of 4 bytes.\n+        //      - `_mm512_alignr_epi64` shifts 512-bit chunks by 8 bytes.\n+        //\n+        // All of those have a latency of 1 cycle, and the shift amount must be an immediate value!\n+        // For 1-byte-shift granularity, the `_mm512_permutex2var_epi8` has a latency of 6 and needs VBMI!\n+        // The most efficient and broadly compatible alternative could be to use a combination of align and shuffle.\n+        // A similar approach was outlined in \"Byte-wise alignr in AVX512F\" by Wojciech Mu\u0142a.\n+        // http://0x80.pl/notesen/2016-10-16-avx512-byte-alignr.html\n+        //\n+        // That solution, is extremely mouthful, assuming we need compile time constants for the shift amount.\n+        // A cleaner one, with a latency of 3 cycles, is to use `_mm512_permutexvar_epi8` or\n+        // `_mm512_mask_permutexvar_epi8`, which can be seen as combination of a cross-register shuffle and blend,\n+        // and is available with VBMI. That solution is still noticeably slower than AVX2.\n+        //\n+        // The GLibC implementation also uses non-temporal stores for larger buffers, we don't.\n+        // https://codebrowser.dev/glibc/glibc/sysdeps/x86_64/multiarch/memmove-avx512-no-vzeroupper.S.html\n+        if (left_to_right_traversal) {\n+            // Head, body, and tail.\n+            _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+            for (target += head_length, source += head_length; body_length >= 64;\n+                 target += 64, source += 64, body_length -= 64)\n+                _mm512_store_si512(target, _mm512_loadu_si512(source));\n+            _mm512_mask_storeu_epi8(target, tail_mask, _mm512_maskz_loadu_epi8(tail_mask, source));\n+        }\n+        else {\n+            // Tail, body, and head.\n+            _mm512_mask_storeu_epi8(target + head_length + body_length, tail_mask,\n+                                    _mm512_maskz_loadu_epi8(tail_mask, source + head_length + body_length));\n+            for (; body_length >= 64; body_length -= 64)\n+                _mm512_store_si512(target + head_length + body_length - 64,\n+                                   _mm512_loadu_si512(source + head_length + body_length - 64));\n+            _mm512_mask_storeu_epi8(target, head_mask, _mm512_maskz_loadu_epi8(head_mask, source));\n+        }\n     }\n }\n \n@@ -4299,22 +4827,63 @@ SZ_PUBLIC sz_cptr_t sz_find_avx512(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n,\n     n_last_vec.zmm = _mm512_set1_epi8(n[offset_last]);\n \n     // Scan through the string.\n-    for (; h_length >= n_length + 64; h += 64, h_length -= 64) {\n-        h_first_vec.zmm = _mm512_loadu_si512(h + offset_first);\n-        h_mid_vec.zmm = _mm512_loadu_si512(h + offset_mid);\n-        h_last_vec.zmm = _mm512_loadu_si512(h + offset_last);\n-        matches = _kand_mask64(_kand_mask64( // Intersect the masks\n-                                   _mm512_cmpeq_epi8_mask(h_first_vec.zmm, n_first_vec.zmm),\n-                                   _mm512_cmpeq_epi8_mask(h_mid_vec.zmm, n_mid_vec.zmm)),\n-                               _mm512_cmpeq_epi8_mask(h_last_vec.zmm, n_last_vec.zmm));\n-        while (matches) {\n-            int potential_offset = sz_u64_ctz(matches);\n-            if (n_length <= 3 || sz_equal_avx512(h + potential_offset, n, n_length)) return h + potential_offset;\n-            matches &= matches - 1;\n-        }\n+    // We have several optimized versions of the lagorithm for shorter strings,\n+    // but they all mimic the default case for unbounded length needles\n+    if (n_length >= 64) {\n+        for (; h_length >= n_length + 64; h += 64, h_length -= 64) {\n+            h_first_vec.zmm = _mm512_loadu_si512(h + offset_first);\n+            h_mid_vec.zmm = _mm512_loadu_si512(h + offset_mid);\n+            h_last_vec.zmm = _mm512_loadu_si512(h + offset_last);\n+            matches = _kand_mask64(_kand_mask64( // Intersect the masks\n+                                       _mm512_cmpeq_epi8_mask(h_first_vec.zmm, n_first_vec.zmm),\n+                                       _mm512_cmpeq_epi8_mask(h_mid_vec.zmm, n_mid_vec.zmm)),\n+                                   _mm512_cmpeq_epi8_mask(h_last_vec.zmm, n_last_vec.zmm));\n+            while (matches) {\n+                int potential_offset = sz_u64_ctz(matches);\n+                if (sz_equal_avx512(h + potential_offset, n, n_length)) return h + potential_offset;\n+                matches &= matches - 1;\n+            }\n \n-        // TODO: If the last character contains a bad byte, we can reposition the start of the next iteration.\n-        // This will be very helpful for very long needles.\n+            // TODO: If the last character contains a bad byte, we can reposition the start of the next iteration.\n+            // This will be very helpful for very long needles.\n+        }\n+    }\n+    // If there are only 2 or 3 characters in the needle, we don't even need the nested loop.\n+    else if (n_length <= 3) {\n+        for (; h_length >= n_length + 64; h += 64, h_length -= 64) {\n+            h_first_vec.zmm = _mm512_loadu_si512(h + offset_first);\n+            h_mid_vec.zmm = _mm512_loadu_si512(h + offset_mid);\n+            h_last_vec.zmm = _mm512_loadu_si512(h + offset_last);\n+            matches = _kand_mask64(_kand_mask64( // Intersect the masks\n+                                       _mm512_cmpeq_epi8_mask(h_first_vec.zmm, n_first_vec.zmm),\n+                                       _mm512_cmpeq_epi8_mask(h_mid_vec.zmm, n_mid_vec.zmm)),\n+                                   _mm512_cmpeq_epi8_mask(h_last_vec.zmm, n_last_vec.zmm));\n+            if (matches) return h + sz_u64_ctz(matches);\n+        }\n+    }\n+    // If the needle is smaller than the size of the ZMM register, we can use masked comparisons\n+    // to avoid the the inner-most nested loop and compare the entire needle against a haystack\n+    // slice in 3 CPU cycles.\n+    else {\n+        __mmask64 n_mask = _sz_u64_mask_until(n_length);\n+        sz_u512_vec_t n_full_vec, h_full_vec;\n+        n_full_vec.zmm = _mm512_maskz_loadu_epi8(n_mask, n);\n+        for (; h_length >= n_length + 64; h += 64, h_length -= 64) {\n+            h_first_vec.zmm = _mm512_loadu_si512(h + offset_first);\n+            h_mid_vec.zmm = _mm512_loadu_si512(h + offset_mid);\n+            h_last_vec.zmm = _mm512_loadu_si512(h + offset_last);\n+            matches = _kand_mask64(_kand_mask64( // Intersect the masks\n+                                       _mm512_cmpeq_epi8_mask(h_first_vec.zmm, n_first_vec.zmm),\n+                                       _mm512_cmpeq_epi8_mask(h_mid_vec.zmm, n_mid_vec.zmm)),\n+                                   _mm512_cmpeq_epi8_mask(h_last_vec.zmm, n_last_vec.zmm));\n+            while (matches) {\n+                int potential_offset = sz_u64_ctz(matches);\n+                h_full_vec.zmm = _mm512_maskz_loadu_epi8(n_mask, h + potential_offset);\n+                if (_mm512_mask_cmpneq_epi8_mask(n_mask, h_full_vec.zmm, n_full_vec.zmm) == 0)\n+                    return h + potential_offset;\n+                matches &= matches - 1;\n+            }\n+        }\n     }\n \n     // The \"tail\" of the function uses masked loads to process the remaining bytes.\n@@ -4715,6 +5284,108 @@ SZ_PUBLIC void sz_hashes_avx512(sz_cptr_t start, sz_size_t length, sz_size_t win\n #pragma clang attribute push(__attribute__((target(\"avx,avx512f,avx512vl,avx512bw,avx512vbmi,avx512vbmi2,bmi,bmi2\"))), \\\n                              apply_to = function)\n \n+SZ_PUBLIC void sz_look_up_transform_avx512(sz_cptr_t source, sz_size_t length, sz_cptr_t lut, sz_ptr_t target) {\n+\n+    // If the input is tiny (especially smaller than the look-up table itself), we may end up paying\n+    // more for organizing the SIMD registers and changing the CPU state, than for the actual computation.\n+    // But if at least 3 cache lines are touched, the AVX-512 implementation should be faster.\n+    if (length <= 128) {\n+        sz_look_up_transform_serial(source, length, lut, target);\n+        return;\n+    }\n+\n+    // When the buffer is over 64 bytes, it's guaranteed to touch at least two cache lines - the head and tail,\n+    // and may include more cache-lines in-between. Knowing this, we can avoid expensive unaligned stores\n+    // by computing 2 masks - for the head and tail, using masked stores for the head and tail, and unmasked\n+    // for the body.\n+    sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+    sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+    __mmask64 head_mask = _sz_u64_mask_until(head_length);\n+    __mmask64 tail_mask = _sz_u64_mask_until(tail_length);\n+\n+    // We need to pull the lookup table into 4x ZMM registers.\n+    // We can use `vpermi2b` instruction to perform the look in two ZMM registers with `_mm512_permutex2var_epi8`\n+    // intrinsics, but it has a 6-cycle latency on Sapphire Rapids and requires AVX512-VBMI. Assuming we need to\n+    // operate on 4 registers, it might be cleaner to use 2x separate `_mm512_permutexvar_epi8` calls.\n+    // Combining the results with 2x `_mm512_test_epi8_mask` and 3x blends afterwards.\n+    //\n+    //  - `_mm512_mask_blend_epi8` - 1 cycle latency, and generally 2x can run in parallel.\n+    //  - `_mm512_test_epi8_mask` - 3 cycles latency, same as most comparison functions in AVX-512.\n+    sz_u512_vec_t lut_0_to_63_vec, lut_64_to_127_vec, lut_128_to_191_vec, lut_192_to_255_vec;\n+    lut_0_to_63_vec.zmm = _mm512_loadu_si512((lut));\n+    lut_64_to_127_vec.zmm = _mm512_loadu_si512((lut + 64));\n+    lut_128_to_191_vec.zmm = _mm512_loadu_si512((lut + 128));\n+    lut_192_to_255_vec.zmm = _mm512_loadu_si512((lut + 192));\n+\n+    sz_u512_vec_t first_bit_vec, second_bit_vec;\n+    first_bit_vec.zmm = _mm512_set1_epi8((char)0x80);\n+    second_bit_vec.zmm = _mm512_set1_epi8((char)0x40);\n+\n+    __mmask64 first_bit_mask, second_bit_mask;\n+    sz_u512_vec_t source_vec;\n+    // If the top bit is set in each word of `source_vec`, than we use `lookup_128_to_191_vec` or\n+    // `lookup_192_to_255_vec`. If the second bit is set, we use `lookup_64_to_127_vec` or `lookup_192_to_255_vec`.\n+    sz_u512_vec_t lookup_0_to_63_vec, lookup_64_to_127_vec, lookup_128_to_191_vec, lookup_192_to_255_vec;\n+    sz_u512_vec_t blended_0_to_127_vec, blended_128_to_255_vec, blended_0_to_255_vec;\n+\n+    // Handling the head.\n+    if (head_length) {\n+        source_vec.zmm = _mm512_maskz_loadu_epi8(head_mask, source);\n+        lookup_0_to_63_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_0_to_63_vec.zmm);\n+        lookup_64_to_127_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_64_to_127_vec.zmm);\n+        lookup_128_to_191_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_128_to_191_vec.zmm);\n+        lookup_192_to_255_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_192_to_255_vec.zmm);\n+        first_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, first_bit_vec.zmm);\n+        second_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, second_bit_vec.zmm);\n+        blended_0_to_127_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_0_to_63_vec.zmm, lookup_64_to_127_vec.zmm);\n+        blended_128_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_128_to_191_vec.zmm, lookup_192_to_255_vec.zmm);\n+        blended_0_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(first_bit_mask, blended_0_to_127_vec.zmm, blended_128_to_255_vec.zmm);\n+        _mm512_mask_storeu_epi8(target, head_mask, blended_0_to_255_vec.zmm);\n+        source += head_length, target += head_length, length -= head_length;\n+    }\n+\n+    // Handling the body in 64-byte chunks aligned to cache-line boundaries with respect to `target`.\n+    while (length >= 64) {\n+        source_vec.zmm = _mm512_loadu_si512(source);\n+        lookup_0_to_63_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_0_to_63_vec.zmm);\n+        lookup_64_to_127_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_64_to_127_vec.zmm);\n+        lookup_128_to_191_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_128_to_191_vec.zmm);\n+        lookup_192_to_255_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_192_to_255_vec.zmm);\n+        first_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, first_bit_vec.zmm);\n+        second_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, second_bit_vec.zmm);\n+        blended_0_to_127_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_0_to_63_vec.zmm, lookup_64_to_127_vec.zmm);\n+        blended_128_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_128_to_191_vec.zmm, lookup_192_to_255_vec.zmm);\n+        blended_0_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(first_bit_mask, blended_0_to_127_vec.zmm, blended_128_to_255_vec.zmm);\n+        _mm512_store_si512(target, blended_0_to_255_vec.zmm); //! Aligned store, our main weapon!\n+        source += 64, target += 64, length -= 64;\n+    }\n+\n+    // Handling the tail.\n+    if (tail_length) {\n+        source_vec.zmm = _mm512_maskz_loadu_epi8(tail_mask, source);\n+        lookup_0_to_63_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_0_to_63_vec.zmm);\n+        lookup_64_to_127_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_64_to_127_vec.zmm);\n+        lookup_128_to_191_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_128_to_191_vec.zmm);\n+        lookup_192_to_255_vec.zmm = _mm512_permutexvar_epi8(source_vec.zmm, lut_192_to_255_vec.zmm);\n+        first_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, first_bit_vec.zmm);\n+        second_bit_mask = _mm512_test_epi8_mask(source_vec.zmm, second_bit_vec.zmm);\n+        blended_0_to_127_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_0_to_63_vec.zmm, lookup_64_to_127_vec.zmm);\n+        blended_128_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(second_bit_mask, lookup_128_to_191_vec.zmm, lookup_192_to_255_vec.zmm);\n+        blended_0_to_255_vec.zmm =\n+            _mm512_mask_blend_epi8(first_bit_mask, blended_0_to_127_vec.zmm, blended_128_to_255_vec.zmm);\n+        _mm512_mask_storeu_epi8(target, tail_mask, blended_0_to_255_vec.zmm);\n+        source += tail_length, target += tail_length, length -= tail_length;\n+    }\n+}\n+\n SZ_PUBLIC sz_cptr_t sz_find_charset_avx512(sz_cptr_t text, sz_size_t length, sz_charset_t const *filter) {\n \n     // Before initializing the AVX-512 vectors, we may want to run the sequential code for the first few bytes.\n@@ -4729,7 +5400,7 @@ SZ_PUBLIC sz_cptr_t sz_find_charset_avx512(sz_cptr_t text, sz_size_t length, sz_\n     // Let's unzip even and odd elements and replicate them into both lanes of the YMM register.\n     // That way when we invoke `_mm512_shuffle_epi8` we can use the same mask for both lanes.\n     sz_u512_vec_t filter_even_vec, filter_odd_vec;\n-    __m256i filter_ymm = _mm256_loadu_si256((__m256i const *)filter);\n+    __m256i filter_ymm = _mm256_lddqu_si256((__m256i const *)filter);\n     // There are a few way to initialize filters without having native strided loads.\n     // In the cronological order of experiments:\n     // - serial code initializing 128 bytes of odd and even mask\n@@ -5079,6 +5750,9 @@ SZ_INTERNAL sz_ssize_t sz_alignment_score_avx512( //\n #pragma region ARM NEON\n \n #if SZ_USE_ARM_NEON\n+#pragma GCC push_options\n+#pragma GCC target(\"arch=armv8.2-a+simd\")\n+#pragma clang attribute push(__attribute__((target(\"arch=armv8.2-a+simd\"))), apply_to = function)\n \n /**\n  *  @brief  Helper structure to simplify work with 64-bit words.\n@@ -5094,12 +5768,139 @@ typedef union sz_u128_vec_t {\n     sz_u8_t u8s[16];\n } sz_u128_vec_t;\n \n-SZ_INTERNAL sz_u64_t vreinterpretq_u8_u4(uint8x16_t vec) {\n+SZ_INTERNAL sz_u64_t _sz_vreinterpretq_u8_u4(uint8x16_t vec) {\n     // Use `vshrn` to produce a bitmask, similar to `movemask` in SSE.\n     // https://community.arm.com/arm-community-blogs/b/infrastructure-solutions-blog/posts/porting-x86-vector-bitmask-optimizations-to-arm-neon\n     return vget_lane_u64(vreinterpret_u64_u8(vshrn_n_u16(vreinterpretq_u16_u8(vec), 4)), 0) & 0x8888888888888888ull;\n }\n \n+SZ_PUBLIC sz_ordering_t sz_order_neon(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n+    //! Before optimizing this, read the \"Operations Not Worth Optimizing\" in Contributions Guide:\n+    //! https://github.com/ashvardanian/StringZilla/blob/main/CONTRIBUTING.md#general-performance-observations\n+    return sz_order_serial(a, a_length, b, b_length);\n+}\n+\n+SZ_PUBLIC sz_bool_t sz_equal_neon(sz_cptr_t a, sz_cptr_t b, sz_size_t length) {\n+    sz_u128_vec_t a_vec, b_vec;\n+    for (; length >= 16; a += 16, b += 16, length -= 16) {\n+        a_vec.u8x16 = vld1q_u8((sz_u8_t const *)a);\n+        b_vec.u8x16 = vld1q_u8((sz_u8_t const *)b);\n+        uint8x16_t cmp = vceqq_u8(a_vec.u8x16, b_vec.u8x16);\n+        if (vmaxvq_u8(cmp) != 255) { return sz_false_k; } // Check if all bytes match\n+    }\n+\n+    // Handle remaining bytes\n+    if (length) return sz_equal_serial(a, b, length);\n+    return sz_true_k;\n+}\n+\n+SZ_PUBLIC void sz_copy_neon(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    // In most cases the `source` and the `target` are not aligned, but we should\n+    // at least make sure that writes don't touch many cache lines.\n+    // NEON has an instruction to load and write 64 bytes at once.\n+    //\n+    //    sz_size_t head_length = (64 - ((sz_size_t)target % 64)) % 64; // 63 or less.\n+    //    sz_size_t tail_length = (sz_size_t)(target + length) % 64;    // 63 or less.\n+    //    for (; head_length; target += 1, source += 1, head_length -= 1) *target = *source;\n+    //    length -= head_length;\n+    //    for (; length >= 64; target += 64, source += 64, length -= 64)\n+    //        vst4q_u8((sz_u8_t *)target, vld1q_u8_x4((sz_u8_t const *)source));\n+    //    for (; tail_length; target += 1, source += 1, tail_length -= 1) *target = *source;\n+    //\n+    // Sadly, those instructions end up being 20% slower than the code processing 16 bytes at a time:\n+    for (; length >= 16; target += 16, source += 16, length -= 16)\n+        vst1q_u8((sz_u8_t *)target, vld1q_u8((sz_u8_t const *)source));\n+    if (length) sz_copy_serial(target, source, length);\n+}\n+\n+SZ_PUBLIC void sz_move_neon(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    // When moving small buffers, using a small buffer on stack as a temporary storage is faster.\n+\n+    if (target < source || target >= source + length) {\n+        // Non-overlapping, proceed forward\n+        sz_copy_neon(target, source, length);\n+    }\n+    else {\n+        // Overlapping, proceed backward\n+        target += length;\n+        source += length;\n+\n+        sz_u128_vec_t src_vec;\n+        while (length >= 16) {\n+            target -= 16, source -= 16, length -= 16;\n+            src_vec.u8x16 = vld1q_u8((sz_u8_t const *)source);\n+            vst1q_u8((sz_u8_t *)target, src_vec.u8x16);\n+        }\n+        while (length) {\n+            target -= 1, source -= 1, length -= 1;\n+            *target = *source;\n+        }\n+    }\n+}\n+\n+SZ_PUBLIC void sz_fill_neon(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n+    uint8x16_t fill_vec = vdupq_n_u8(value); // Broadcast the value across the register\n+\n+    while (length >= 16) {\n+        vst1q_u8((sz_u8_t *)target, fill_vec);\n+        target += 16;\n+        length -= 16;\n+    }\n+\n+    // Handle remaining bytes\n+    if (length) sz_fill_serial(target, length, value);\n+}\n+\n+SZ_PUBLIC void sz_look_up_transform_neon(sz_cptr_t source, sz_size_t length, sz_cptr_t lut, sz_ptr_t target) {\n+\n+    // If the input is tiny (especially smaller than the look-up table itself), we may end up paying\n+    // more for organizing the SIMD registers and changing the CPU state, than for the actual computation.\n+    if (length <= 128) {\n+        sz_look_up_transform_serial(source, length, lut, target);\n+        return;\n+    }\n+\n+    sz_size_t head_length = (16 - ((sz_size_t)target % 16)) % 16; // 15 or less.\n+    sz_size_t tail_length = (sz_size_t)(target + length) % 16;    // 15 or less.\n+\n+    // We need to pull the lookup table into 16x NEON registers. We have a total of 32 such registers.\n+    // According to the Neoverse V2 manual, the 4-table lookup has a latency of 6 cycles, and 4x throughput.\n+    uint8x16x4_t lut_0_to_63_vec, lut_64_to_127_vec, lut_128_to_191_vec, lut_192_to_255_vec;\n+    lut_0_to_63_vec = vld1q_u8_x4((sz_u8_t const *)(lut + 0));\n+    lut_64_to_127_vec = vld1q_u8_x4((sz_u8_t const *)(lut + 64));\n+    lut_128_to_191_vec = vld1q_u8_x4((sz_u8_t const *)(lut + 128));\n+    lut_192_to_255_vec = vld1q_u8_x4((sz_u8_t const *)(lut + 192));\n+\n+    sz_u128_vec_t source_vec;\n+    // If the top bit is set in each word of `source_vec`, than we use `lookup_128_to_191_vec` or\n+    // `lookup_192_to_255_vec`. If the second bit is set, we use `lookup_64_to_127_vec` or `lookup_192_to_255_vec`.\n+    sz_u128_vec_t lookup_0_to_63_vec, lookup_64_to_127_vec, lookup_128_to_191_vec, lookup_192_to_255_vec;\n+    sz_u128_vec_t blended_0_to_255_vec;\n+\n+    // Process the head with serial code\n+    for (; head_length; target += 1, source += 1, head_length -= 1) *target = lut[*(sz_u8_t const *)source];\n+\n+    // Table lookups on Arm are much simpler to use than on x86, as we can use the `vqtbl4q_u8` instruction\n+    // to perform a 4-table lookup in a single instruction. The XORs are used to adjust the lookup position\n+    // within each 64-byte range of the table.\n+    // Details on the 4-table lookup: https://lemire.me/blog/2019/07/23/arbitrary-byte-to-byte-maps-using-arm-neon/\n+    length -= head_length;\n+    length -= tail_length;\n+    for (; length >= 16; source += 16, target += 16, length -= 16) {\n+        source_vec.u8x16 = vld1q_u8((sz_u8_t const *)source);\n+        lookup_0_to_63_vec.u8x16 = vqtbl4q_u8(lut_0_to_63_vec, source_vec.u8x16);\n+        lookup_64_to_127_vec.u8x16 = vqtbl4q_u8(lut_64_to_127_vec, veorq_u8(source_vec.u8x16, vdupq_n_u8(0x40)));\n+        lookup_128_to_191_vec.u8x16 = vqtbl4q_u8(lut_128_to_191_vec, veorq_u8(source_vec.u8x16, vdupq_n_u8(0x80)));\n+        lookup_192_to_255_vec.u8x16 = vqtbl4q_u8(lut_192_to_255_vec, veorq_u8(source_vec.u8x16, vdupq_n_u8(0xc0)));\n+        blended_0_to_255_vec.u8x16 = vorrq_u8(vorrq_u8(lookup_0_to_63_vec.u8x16, lookup_64_to_127_vec.u8x16),\n+                                              vorrq_u8(lookup_128_to_191_vec.u8x16, lookup_192_to_255_vec.u8x16));\n+        vst1q_u8((sz_u8_t *)target, blended_0_to_255_vec.u8x16);\n+    }\n+\n+    // Process the tail with serial code\n+    for (; tail_length; target += 1, source += 1, tail_length -= 1) *target = lut[*(sz_u8_t const *)source];\n+}\n+\n SZ_PUBLIC sz_cptr_t sz_find_byte_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n) {\n     sz_u64_t matches;\n     sz_u128_vec_t h_vec, n_vec, matches_vec;\n@@ -5111,7 +5912,7 @@ SZ_PUBLIC sz_cptr_t sz_find_byte_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t\n         // In Arm NEON we don't have a `movemask` to combine it with `ctz` and get the offset of the match.\n         // But assuming the `vmaxvq` is cheap, we can use it to find the first match, by blending (bitwise selecting)\n         // the vector with a relative offsets array.\n-        matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+        matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n         if (matches) return h + sz_u64_ctz(matches) / 4;\n \n         h += 16, h_length -= 16;\n@@ -5128,7 +5929,7 @@ SZ_PUBLIC sz_cptr_t sz_rfind_byte_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_\n     while (h_length >= 16) {\n         h_vec.u8x16 = vld1q_u8((sz_u8_t const *)h + h_length - 16);\n         matches_vec.u8x16 = vceqq_u8(h_vec.u8x16, n_vec.u8x16);\n-        matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+        matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n         if (matches) return h + h_length - 1 - sz_u64_clz(matches) / 4;\n         h_length -= 16;\n     }\n@@ -5153,7 +5954,7 @@ SZ_PUBLIC sz_u64_t _sz_find_charset_neon_register(sz_u128_vec_t h_vec, uint8x16_\n     uint8x16_t matches_vec = vorrq_u8(matches_top_vec, matches_bottom_vec);\n     // Istead of pure `vandq_u8`, we can immediately broadcast a match presence across each 8-bit word.\n     matches_vec = vtstq_u8(matches_vec, byte_mask_vec);\n-    return vreinterpretq_u8_u4(matches_vec);\n+    return _sz_vreinterpretq_u8_u4(matches_vec);\n }\n \n SZ_PUBLIC sz_cptr_t sz_find_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n, sz_size_t n_length) {\n@@ -5178,7 +5979,7 @@ SZ_PUBLIC sz_cptr_t sz_find_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n, s\n             h_last_vec.u8x16 = vld1q_u8((sz_u8_t const *)(h + 1));\n             matches_vec.u8x16 =\n                 vandq_u8(vceqq_u8(h_first_vec.u8x16, n_first_vec.u8x16), vceqq_u8(h_last_vec.u8x16, n_last_vec.u8x16));\n-            matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+            matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n             if (matches) return h + sz_u64_ctz(matches) / 4;\n         }\n     }\n@@ -5200,7 +6001,7 @@ SZ_PUBLIC sz_cptr_t sz_find_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n, s\n                     vceqq_u8(h_first_vec.u8x16, n_first_vec.u8x16), //\n                     vceqq_u8(h_mid_vec.u8x16, n_mid_vec.u8x16)),\n                 vceqq_u8(h_last_vec.u8x16, n_last_vec.u8x16));\n-            matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+            matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n             if (matches) return h + sz_u64_ctz(matches) / 4;\n         }\n     }\n@@ -5224,7 +6025,7 @@ SZ_PUBLIC sz_cptr_t sz_find_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n, s\n                     vceqq_u8(h_first_vec.u8x16, n_first_vec.u8x16), //\n                     vceqq_u8(h_mid_vec.u8x16, n_mid_vec.u8x16)),\n                 vceqq_u8(h_last_vec.u8x16, n_last_vec.u8x16));\n-            matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+            matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n             while (matches) {\n                 int potential_offset = sz_u64_ctz(matches) / 4;\n                 if (sz_equal(h + potential_offset, n, n_length)) return h + potential_offset;\n@@ -5264,7 +6065,7 @@ SZ_PUBLIC sz_cptr_t sz_rfind_neon(sz_cptr_t h, sz_size_t h_length, sz_cptr_t n,\n                 vceqq_u8(h_first_vec.u8x16, n_first_vec.u8x16), //\n                 vceqq_u8(h_mid_vec.u8x16, n_mid_vec.u8x16)),\n             vceqq_u8(h_last_vec.u8x16, n_last_vec.u8x16));\n-        matches = vreinterpretq_u8_u4(matches_vec.u8x16);\n+        matches = _sz_vreinterpretq_u8_u4(matches_vec.u8x16);\n         while (matches) {\n             int potential_offset = sz_u64_clz(matches) / 4;\n             if (sz_equal(h + h_length - n_length - potential_offset, n, n_length))\n@@ -5309,10 +6110,135 @@ SZ_PUBLIC sz_cptr_t sz_rfind_charset_neon(sz_cptr_t h, sz_size_t h_length, sz_ch\n     return sz_rfind_charset_serial(h, h_length, set);\n }\n \n+#pragma clang attribute pop\n+#pragma GCC pop_options\n #endif // Arm Neon\n \n #pragma endregion\n \n+/*  @brief  Implementation of the string search algorithms using the Arm SVE variable-length registers, available\n+ *          in Arm v9 processors.\n+ *\n+ *  Implements:\n+ *      - memory: {copy, move, fill}\n+ *      - comparisons: {equal, order}\n+ *      - search: {substring, character, character set} x {forward, reverse}.\n+ */\n+#pragma region ARM SVE\n+\n+#if SZ_USE_ARM_SVE\n+#pragma GCC push_options\n+#pragma GCC target(\"arch=armv8.2-a+sve\")\n+#pragma clang attribute push(__attribute__((target(\"arch=armv8.2-a+sve\"))), apply_to = function)\n+\n+SZ_PUBLIC void sz_fill_sve(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n+    svuint8_t value_vec = svdup_u8(value);\n+    sz_size_t vec_len = svcntb(); // Vector length in bytes (scalable)\n+\n+    if (length <= vec_len) {\n+        // Small buffer case: use mask to handle small writes\n+        svbool_t mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)length);\n+        svst1_u8(mask, (unsigned char *)target, value_vec);\n+    }\n+    else {\n+        // Calculate head, body, and tail sizes\n+        sz_size_t head_length = vec_len - ((sz_size_t)target % vec_len);\n+        sz_size_t tail_length = (sz_size_t)(target + length) % vec_len;\n+        sz_size_t body_length = length - head_length - tail_length;\n+\n+        // Handle unaligned head\n+        svbool_t head_mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)head_length);\n+        svst1_u8(head_mask, (unsigned char *)target, value_vec);\n+        target += head_length;\n+\n+        // Aligned body loop\n+        for (; body_length >= vec_len; target += vec_len, body_length -= vec_len) {\n+            svst1_u8(svptrue_b8(), (unsigned char *)target, value_vec);\n+        }\n+\n+        // Handle unaligned tail\n+        svbool_t tail_mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)tail_length);\n+        svst1_u8(tail_mask, (unsigned char *)target, value_vec);\n+    }\n+}\n+\n+SZ_PUBLIC void sz_copy_sve(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n+    sz_size_t vec_len = svcntb(); // Vector length in bytes\n+\n+    // Arm Neoverse V2 cores in Graviton 4, for example, come with 256 KB of L1 data cache per core,\n+    // and 8 MB of L2 cache per core. Moreover, the L1 cache is fully associative.\n+    // With two strings, we may consider the overal workload huge, if each exceeds 1 MB in length.\n+    //\n+    //      int is_huge = length >= 4ull * 1024ull * 1024ull;\n+    //\n+    // When the buffer is small, there isn't much to innovate.\n+    if (length <= vec_len) {\n+        // Small buffer case: use mask to handle small writes\n+        svbool_t mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)length);\n+        svuint8_t data = svld1_u8(mask, (unsigned char *)source);\n+        svst1_u8(mask, (unsigned char *)target, data);\n+    }\n+    // When dealing with larger buffers, similar to AVX-512, we want minimize unaligned operations\n+    // and handle the head, body, and tail separately. We can also traverse the buffer in both directions\n+    // as Arm generally supports more simultaneous stores than x86 CPUs.\n+    //\n+    // For gigantic datasets, similar to AVX-512, non-temporal \"loads\" and \"stores\" can be used.\n+    // Sadly, if the register size (16 byte or larger) is smaller than a cache-line (64 bytes)\n+    // we will pay a huge penalty on loads, fetching the same content many times.\n+    // It may be better to allow caching (and subsequent eviction), in favor of using four-element\n+    // tuples, wich will be guaranteed to be a multiple of a cache line.\n+    //\n+    // Another approach is to use the `LD4B` instructions, which will populate four registers at once.\n+    // This however, further decreases the performance from LibC-like 29 GB/s to 20 GB/s.\n+    else {\n+        // Calculating head, body, and tail sizes depends on the `vec_len`,\n+        // but it's runtime constant, and the modulo operation is expensive!\n+        // Instead we use the fact, that it's always a multiple of 128 bits or 16 bytes.\n+        sz_size_t head_length = 16 - ((sz_size_t)target % 16);\n+        sz_size_t tail_length = (sz_size_t)(target + length) % 16;\n+        sz_size_t body_length = length - head_length - tail_length;\n+\n+        // Handle unaligned parts\n+        svbool_t head_mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)head_length);\n+        svuint8_t head_data = svld1_u8(head_mask, (unsigned char *)source);\n+        svst1_u8(head_mask, (unsigned char *)target, head_data);\n+        svbool_t tail_mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)tail_length);\n+        svuint8_t tail_data = svld1_u8(tail_mask, (unsigned char *)source + head_length + body_length);\n+        svst1_u8(tail_mask, (unsigned char *)target + head_length + body_length, tail_data);\n+        target += head_length;\n+        source += head_length;\n+\n+        // Aligned body loop, walking in two directions\n+        for (; body_length >= vec_len * 2; target += vec_len, source += vec_len, body_length -= vec_len * 2) {\n+            svuint8_t forward_data = svld1_u8(svptrue_b8(), (unsigned char *)source);\n+            svuint8_t backward_data = svld1_u8(svptrue_b8(), (unsigned char *)source + body_length - vec_len);\n+            svst1_u8(svptrue_b8(), (unsigned char *)target, forward_data);\n+            svst1_u8(svptrue_b8(), (unsigned char *)target + body_length - vec_len, backward_data);\n+        }\n+        // Up to (vec_len * 2 - 1) bytes of data may be left in the body,\n+        // so we can unroll the last two optional loop iterations.\n+        if (body_length > vec_len) {\n+            svbool_t mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)body_length);\n+            svuint8_t data = svld1_u8(mask, (unsigned char *)source);\n+            svst1_u8(mask, (unsigned char *)target, data);\n+            body_length -= vec_len;\n+            source += body_length;\n+            target += body_length;\n+        }\n+        if (body_length) {\n+            svbool_t mask = svwhilelt_b8((sz_u32_t)0ull, (sz_u32_t)body_length);\n+            svuint8_t data = svld1_u8(mask, (unsigned char *)source);\n+            svst1_u8(mask, (unsigned char *)target, data);\n+        }\n+    }\n+}\n+\n+#pragma clang attribute pop\n+#pragma GCC pop_options\n+#endif // Arm SVE\n+\n+#pragma endregion\n+\n /*\n  *  @brief  Pick the right implementation for the string search algorithms.\n  */\n@@ -5346,6 +6272,10 @@ SZ_PUBLIC void sz_hashes_fingerprint(sz_cptr_t start, sz_size_t length, sz_size_\n SZ_DYNAMIC sz_bool_t sz_equal(sz_cptr_t a, sz_cptr_t b, sz_size_t length) {\n #if SZ_USE_X86_AVX512\n     return sz_equal_avx512(a, b, length);\n+#elif SZ_USE_X86_AVX2\n+    return sz_equal_avx2(a, b, length);\n+#elif SZ_USE_ARM_NEON\n+    return sz_equal_neon(a, b, length);\n #else\n     return sz_equal_serial(a, b, length);\n #endif\n@@ -5354,6 +6284,10 @@ SZ_DYNAMIC sz_bool_t sz_equal(sz_cptr_t a, sz_cptr_t b, sz_size_t length) {\n SZ_DYNAMIC sz_ordering_t sz_order(sz_cptr_t a, sz_size_t a_length, sz_cptr_t b, sz_size_t b_length) {\n #if SZ_USE_X86_AVX512\n     return sz_order_avx512(a, a_length, b, b_length);\n+#elif SZ_USE_X86_AVX2\n+    return sz_order_avx2(a, a_length, b, b_length);\n+#elif SZ_USE_ARM_NEON\n+    return sz_order_neon(a, a_length, b, b_length);\n #else\n     return sz_order_serial(a, a_length, b, b_length);\n #endif\n@@ -5364,6 +6298,8 @@ SZ_DYNAMIC void sz_copy(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n     sz_copy_avx512(target, source, length);\n #elif SZ_USE_X86_AVX2\n     sz_copy_avx2(target, source, length);\n+#elif SZ_USE_ARM_NEON\n+    sz_copy_neon(target, source, length);\n #else\n     sz_copy_serial(target, source, length);\n #endif\n@@ -5374,6 +6310,8 @@ SZ_DYNAMIC void sz_move(sz_ptr_t target, sz_cptr_t source, sz_size_t length) {\n     sz_move_avx512(target, source, length);\n #elif SZ_USE_X86_AVX2\n     sz_move_avx2(target, source, length);\n+#elif SZ_USE_ARM_NEON\n+    sz_move_neon(target, source, length);\n #else\n     sz_move_serial(target, source, length);\n #endif\n@@ -5384,11 +6322,25 @@ SZ_DYNAMIC void sz_fill(sz_ptr_t target, sz_size_t length, sz_u8_t value) {\n     sz_fill_avx512(target, length, value);\n #elif SZ_USE_X86_AVX2\n     sz_fill_avx2(target, length, value);\n+#elif SZ_USE_ARM_NEON\n+    sz_fill_neon(target, length, value);\n #else\n     sz_fill_serial(target, length, value);\n #endif\n }\n \n+SZ_DYNAMIC void sz_look_up_transform(sz_cptr_t source, sz_size_t length, sz_cptr_t lut, sz_ptr_t target) {\n+#if SZ_USE_X86_AVX512\n+    sz_look_up_transform_avx512(source, length, lut, target);\n+#elif SZ_USE_X86_AVX2\n+    sz_look_up_transform_avx2(source, length, lut, target);\n+#elif SZ_USE_ARM_NEON\n+    sz_look_up_transform_neon(source, length, lut, target);\n+#else\n+    sz_look_up_transform_serial(source, length, lut, target);\n+#endif\n+}\n+\n SZ_DYNAMIC sz_cptr_t sz_find_byte(sz_cptr_t haystack, sz_size_t h_length, sz_cptr_t needle) {\n #if SZ_USE_X86_AVX512\n     return sz_find_byte_avx512(haystack, h_length, needle);\n@@ -5452,6 +6404,8 @@ SZ_DYNAMIC sz_cptr_t sz_find_charset(sz_cptr_t text, sz_size_t length, sz_charse\n SZ_DYNAMIC sz_cptr_t sz_rfind_charset(sz_cptr_t text, sz_size_t length, sz_charset_t const *set) {\n #if SZ_USE_X86_AVX512\n     return sz_rfind_charset_avx512(text, length, set);\n+#elif SZ_USE_X86_AVX2\n+    return sz_rfind_charset_avx2(text, length, set);\n #elif SZ_USE_ARM_NEON\n     return sz_rfind_charset_neon(text, length, set);\n #else\ndiff --git a/include/stringzilla/stringzilla.hpp b/include/stringzilla/stringzilla.hpp\nindex d7324a85..6a65038f 100644\n--- a/include/stringzilla/stringzilla.hpp\n+++ b/include/stringzilla/stringzilla.hpp\n@@ -79,6 +79,40 @@ using string_view = basic_string_slice<char const>;\n template <std::size_t count_characters>\n using carray = char[count_characters];\n \n+#pragma region Memory Operations\n+\n+/**\n+ *  @brief  Analog to @b `std::memset`, but with a more efficient implementation.\n+ *  @param  target The pointer to the target memory region.\n+ *  @param  value The byte value to set.\n+ *  @param  n The number of bytes to copy.\n+ */\n+inline void memset(void *target, char value, std::size_t n) noexcept {\n+    return sz_fill(reinterpret_cast<sz_ptr_t>(target), n, value);\n+}\n+\n+/**\n+ *  @brief  Analog to @b `std::memmove`, but with a more efficient implementation.\n+ *  @param  target The pointer to the target memory region.\n+ *  @param  source The pointer to the source memory region.\n+ *  @param  n The number of bytes to copy.\n+ */\n+inline void memmove(void *target, void const *source, std::size_t n) noexcept {\n+    return sz_move(reinterpret_cast<sz_ptr_t>(target), reinterpret_cast<sz_cptr_t>(source), n);\n+}\n+\n+/**\n+ *  @brief  Analog to @b `std::memcpy`, but with a more efficient implementation.\n+ *  @param  target The pointer to the target memory region.\n+ *  @param  source The pointer to the source memory region.\n+ *  @param  n The number of bytes to copy.\n+ */\n+inline void memcpy(void *target, void const *source, std::size_t n) noexcept {\n+    return sz_copy(reinterpret_cast<sz_ptr_t>(target), reinterpret_cast<sz_cptr_t>(source), n);\n+}\n+\n+#pragma endregion\n+\n #pragma region Character Sets\n \n /**\n@@ -306,6 +340,55 @@ inline char_set whitespaces_set() { return char_set {whitespaces()}; }\n inline char_set newlines_set() { return char_set {newlines()}; }\n inline char_set base64_set() { return char_set {base64()}; }\n \n+/**\n+ *  @brief  A look-up table for character replacement operations.\n+ *          Exactly 256 bytes for byte-to-byte replacement.\n+ *          ! For larger character types should be allocated on the heap.\n+ */\n+template <typename char_type_ = char>\n+class basic_look_up_table {\n+    static_assert(sizeof(char_type_) == 1 || sizeof(char_type_) == 2 || sizeof(char_type_) == 4,\n+                  \"Character type must be 1, 2, or 4 bytes long\");\n+    static constexpr std::size_t size_k = sizeof(char_type_) == 1   ? 256ul\n+                                          : sizeof(char_type_) == 2 ? 65536ul\n+                                                                    : 4294967296ul;\n+    static constexpr std::size_t bytes_k = size_k * sizeof(char_type_);\n+    using usnigned_type_ = typename std::make_unsigned<char_type_>::type;\n+\n+    char_type_ lut_[size_k];\n+\n+  public:\n+    using char_type = char_type_;\n+\n+    basic_look_up_table() noexcept { memset(&lut_[0], 0, bytes_k); }\n+    explicit basic_look_up_table(char_type const (&chars)[size_k]) noexcept { memcpy(&lut_[0], chars, bytes_k); }\n+    basic_look_up_table(std::array<char_type, size_k> const &chars) noexcept {\n+        memcpy(&lut_[0], chars.data(), bytes_k);\n+    }\n+\n+    basic_look_up_table(basic_look_up_table const &other) noexcept { memcpy(&lut_[0], other.lut_, bytes_k); }\n+    basic_look_up_table &operator=(basic_look_up_table const &other) noexcept {\n+        memcpy(&lut_[0], other.lut_, bytes_k);\n+        return *this;\n+    }\n+\n+    /**\n+     *  @brief  Creates a look-up table with a one-to-one mapping of characters to themselves.\n+     *  Similar to `std::iota` filling, but properly handles signed integer casts.\n+     */\n+    static basic_look_up_table identity() noexcept {\n+        basic_look_up_table result;\n+        for (std::size_t i = 0; i < size_k; ++i) { result.lut_[i] = static_cast<usnigned_type_>(i); }\n+        return result;\n+    }\n+\n+    inline sz_cptr_t raw() const noexcept { return reinterpret_cast<sz_cptr_t>(&lut_[0]); }\n+    inline char_type &operator[](char_type c) noexcept { return lut_[sz_bitcast(usnigned_type_, c)]; }\n+    inline char_type const &operator[](char_type c) const noexcept { return lut_[sz_bitcast(usnigned_type_, c)]; }\n+};\n+\n+using look_up_table = basic_look_up_table<char>;\n+\n #pragma endregion\n \n #pragma region Ranges of Search Matches\n@@ -1576,12 +1659,18 @@ class basic_string_slice {\n     /**  @brief  Split the string into three parts, before the match, the match itself, and after it. */\n     partition_type partition(string_view pattern) const noexcept { return partition_(pattern, pattern.length()); }\n \n+    /**  @brief  Split the string into three parts, before the match, the match itself, and after it. */\n+    partition_type partition(value_type pattern) const noexcept { return partition_(string_view(&pattern, 1), 1); }\n+\n     /**  @brief  Split the string into three parts, before the match, the match itself, and after it. */\n     partition_type partition(char_set pattern) const noexcept { return partition_(pattern, 1); }\n \n     /**  @brief  Split the string into three parts, before the @b last match, the last match itself, and after it. */\n     partition_type rpartition(string_view pattern) const noexcept { return rpartition_(pattern, pattern.length()); }\n \n+    /**  @brief  Split the string into three parts, before the @b last match, the last match itself, and after it. */\n+    partition_type rpartition(value_type pattern) const noexcept { return rpartition_(string_view(&pattern, 1), 1); }\n+\n     /**  @brief  Split the string into three parts, before the @b last match, the last match itself, and after it. */\n     partition_type rpartition(char_set pattern) const noexcept { return rpartition_(pattern, 1); }\n \n@@ -3315,6 +3404,24 @@ class basic_string {\n         return try_replace_all_<char_set>(pattern, replacement);\n     }\n \n+    /**\n+     *  @brief  Replaces ( @b in-place ) all characters in the string using the provided lookup table.\n+     */\n+    basic_string &transform(look_up_table const &table) noexcept {\n+        transform(table, data());\n+        return *this;\n+    }\n+\n+    /**\n+     *  @brief  Maps all chatacters in the current string into another buffer using the provided lookup table.\n+     */\n+    void transform(look_up_table const &table, pointer output) const noexcept {\n+        sz_ptr_t start;\n+        sz_size_t length;\n+        sz_string_range(&string_, &start, &length);\n+        sz_look_up_transform((sz_cptr_t)start, (sz_size_t)length, (sz_cptr_t)table.raw(), (sz_ptr_t)output);\n+    }\n+\n   private:\n     template <typename pattern_type>\n     bool try_replace_all_(pattern_type pattern, string_view replacement) noexcept;\n@@ -3757,6 +3864,26 @@ void randomize(basic_string_slice<char_type_> string, generator_type_ &generator\n     sz_generate(alphabet.data(), alphabet.size(), string.data(), string.size(), generator_callback, &generator);\n }\n \n+/**\n+ *  @brief  Replaces ( @b in-place ) all characters in the string using the provided lookup table.\n+ */\n+template <typename char_type_>\n+void transform(basic_string_slice<char_type_> string, basic_look_up_table<char_type_> const &table) noexcept {\n+    static_assert(sizeof(char_type_) == 1, \"The character type must be 1 byte long.\");\n+    sz_look_up_transform((sz_cptr_t)string.data(), (sz_size_t)string.size(), (sz_cptr_t)table.raw(),\n+                         (sz_ptr_t)string.data());\n+}\n+\n+/**\n+ *  @brief  Maps all chatacters in the current string into another buffer using the provided lookup table.\n+ */\n+template <typename char_type_>\n+void transform(basic_string_slice<char_type_ const> source, basic_look_up_table<char_type_> const &table,\n+               char_type_ *target) noexcept {\n+    static_assert(sizeof(char_type_) == 1, \"The character type must be 1 byte long.\");\n+    sz_look_up_transform((sz_cptr_t)source.data(), (sz_size_t)source.size(), (sz_cptr_t)table.raw(), (sz_ptr_t)target);\n+}\n+\n /**\n  *  @brief  Overwrites the string slice with random characters from the given alphabet\n  *          using `std::rand` as the random generator.\ndiff --git a/pyproject.toml b/pyproject.toml\nindex 8fcdcfb9..38bca547 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -79,40 +79,43 @@ before-build = [\"rd /s /q {project}\\\\build || echo Done\"]\n [[tool.cibuildwheel.overrides]]\n select = \"*-win_amd64\"\n inherit.environment = \"append\"\n-environment.SZ_X86_64=\"1\"\n+environment.SZ_X86_64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-manylinux*_x86_64\"\n inherit.environment = \"append\"\n-environment.SZ_X86_64=\"1\"\n+environment.SZ_X86_64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-musllinux*_x86_64\"\n inherit.environment = \"append\"\n-environment.SZ_X86_64=\"1\"\n+environment.SZ_X86_64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-macos*_x86_64\"\n inherit.environment = \"append\"\n-environment.SZ_X86_64=\"1\"\n+environment.SZ_X86_64 = \"1\"\n \n # Detect ARM 64-bit builds\n [[tool.cibuildwheel.overrides]]\n select = \"*-win_arm64\"\n inherit.environment = \"append\"\n-environment.SZ_ARM64=\"1\"\n+environment.SZ_ARM64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-manylinux*_aarch64\"\n inherit.environment = \"append\"\n-environment.SZ_ARM64=\"1\"\n+environment.SZ_ARM64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-musllinux*_aarch64\"\n inherit.environment = \"append\"\n-environment.SZ_ARM64=\"1\"\n+environment.SZ_ARM64 = \"1\"\n \n [[tool.cibuildwheel.overrides]]\n select = \"*-macos*_arm64\"\n inherit.environment = \"append\"\n-environment.SZ_ARM64=\"1\"\n+environment.SZ_ARM64 = \"1\"\n+\n+[tool.cibuildwheel.macos.environment]\n+MACOSX_DEPLOYMENT_TARGET = \"10.11\"\ndiff --git a/python/lib.c b/python/lib.c\nindex 75093a87..85aef1aa 100644\n--- a/python/lib.c\n+++ b/python/lib.c\n@@ -1927,6 +1927,53 @@ static PyObject *Str_endswith(PyObject *self, PyObject *args, PyObject *kwargs)\n     else { Py_RETURN_FALSE; }\n }\n \n+static PyObject *Str_translate(PyObject *self, PyObject *args, PyObject *kwargs) {\n+    int is_member = self != NULL && PyObject_TypeCheck(self, &StrType);\n+    Py_ssize_t nargs = PyTuple_Size(args);\n+    if (nargs < !is_member + 1 || nargs > !is_member + 3) {\n+        PyErr_Format(PyExc_TypeError, \"Invalid number of arguments\");\n+        return NULL;\n+    }\n+\n+    PyObject *str_obj = is_member ? self : PyTuple_GET_ITEM(args, 0);\n+    PyObject *look_up_table_obj = PyTuple_GET_ITEM(args, !is_member);\n+    PyObject *start_obj = nargs > !is_member + 1 ? PyTuple_GET_ITEM(args, !is_member + 1) : NULL;\n+    PyObject *end_obj = nargs > !is_member + 2 ? PyTuple_GET_ITEM(args, !is_member + 2) : NULL;\n+\n+    // Optional start and end arguments\n+    Py_ssize_t start = 0, end = PY_SSIZE_T_MAX;\n+\n+    if (start_obj && ((start = PyLong_AsSsize_t(start_obj)) == -1 && PyErr_Occurred())) {\n+        PyErr_SetString(PyExc_TypeError, \"start must be an integer\");\n+        return NULL;\n+    }\n+\n+    if (end_obj && ((end = PyLong_AsSsize_t(end_obj)) == -1 && PyErr_Occurred())) {\n+        PyErr_SetString(PyExc_TypeError, \"end must be an integer\");\n+        return NULL;\n+    }\n+\n+    sz_string_view_t str, look_up_table;\n+    if (!export_string_like(str_obj, &str.start, &str.length) ||\n+        !export_string_like(look_up_table_obj, &look_up_table.start, &look_up_table.length)) {\n+        PyErr_SetString(PyExc_TypeError, \"Both arguments must be string-like\");\n+        return NULL;\n+    }\n+\n+    // Apply start and end arguments\n+    str.start += start;\n+    str.length -= start;\n+    if (end != PY_SSIZE_T_MAX && end - start < str.length) { str.length = end - start; }\n+\n+    if (look_up_table.length != 256) {\n+        PyErr_SetString(PyExc_ValueError, \"The look-up table must be exactly 256 bytes long\");\n+        return NULL;\n+    }\n+\n+    sz_look_up_transform(str.start, str.length, look_up_table.start, str.start);\n+    return Py_None;\n+}\n+\n static PyObject *Str_find_first_of(PyObject *self, PyObject *args, PyObject *kwargs) {\n     Py_ssize_t signed_offset;\n     sz_string_view_t text;\n@@ -2438,6 +2485,7 @@ static PyMethodDef Str_methods[] = {\n     {\"splitlines\", Str_splitlines, SZ_METHOD_FLAGS, \"Split a string by line breaks.\"},\n     {\"startswith\", Str_startswith, SZ_METHOD_FLAGS, \"Check if a string starts with a given prefix.\"},\n     {\"endswith\", Str_endswith, SZ_METHOD_FLAGS, \"Check if a string ends with a given suffix.\"},\n+    {\"translate\", Str_translate, SZ_METHOD_FLAGS, \"Look-Up Table in-place transformation of a byte-string.\"},\n     {\"decode\", Str_decode, SZ_METHOD_FLAGS, \"Decode the bytes into `str` with a given encoding\"},\n \n     // Bidirectional operations\n@@ -3139,6 +3187,7 @@ static PyMethodDef stringzilla_methods[] = {\n     {\"splitlines\", Str_splitlines, SZ_METHOD_FLAGS, \"Split a string by line breaks.\"},\n     {\"startswith\", Str_startswith, SZ_METHOD_FLAGS, \"Check if a string starts with a given prefix.\"},\n     {\"endswith\", Str_endswith, SZ_METHOD_FLAGS, \"Check if a string ends with a given suffix.\"},\n+    {\"translate\", Str_translate, SZ_METHOD_FLAGS, \"Look-Up Table in-place transformation of a byte-string.\"},\n     {\"decode\", Str_decode, SZ_METHOD_FLAGS, \"Decode the bytes into `str` with a given encoding\"},\n \n     // Bidirectional operations\ndiff --git a/scripts/bench.hpp b/scripts/bench.hpp\nindex 03bc4d1e..ecdf3bb2 100644\n--- a/scripts/bench.hpp\n+++ b/scripts/bench.hpp\n@@ -27,6 +27,11 @@ namespace scripts {\n \n using seconds_t = double;\n \n+template <std::size_t multiple>\n+std::size_t round_up_to_multiple(std::size_t n) {\n+    return n == 0 ? multiple : ((n + multiple - 1) / multiple) * multiple;\n+}\n+\n struct benchmark_result_t {\n     std::size_t iterations = 0;\n     std::size_t bytes_passed = 0;\n@@ -156,7 +161,7 @@ inline std::vector<result_string_type> filter_by_length(std::vector<from_string_\n     return result;\n }\n \n-inline static std::size_t seconds_per_benchmark = 5;\n+inline static std::size_t seconds_per_benchmark = SZ_DEBUG ? 1 : 5;\n \n struct dataset_t {\n     std::string text;\ndiff --git a/scripts/bench_memory.cpp b/scripts/bench_memory.cpp\nnew file mode 100644\nindex 00000000..eb72fc96\n--- /dev/null\n+++ b/scripts/bench_memory.cpp\n@@ -0,0 +1,278 @@\n+/**\n+ *  @file   bench_memory.cpp\n+ *  @brief  Benchmarks for memory operations like copying, moving, and comparing.\n+ *\n+ *  This file is the sibling of `bench_sort.cpp`, `bench_token.cpp` and `bench_similarity.cpp`.\n+ *  It accepts a file with a list of words, and benchmarks the memory operations on them.\n+ */\n+#include <cstring> // `memmem`\n+#include <memory>  // `std::unique_ptr`\n+#include <numeric> // `std::iota`\n+#include <string>  // `std::string`\n+\n+#ifdef _WIN32\n+#include <malloc.h> // `_aligned_malloc`\n+#else\n+#include <cstdlib> // `std::aligned_alloc`\n+#endif\n+\n+#define SZ_USE_MISALIGNED_LOADS (1)\n+#include <bench.hpp>\n+\n+using namespace ashvardanian::stringzilla::scripts;\n+constexpr std::size_t max_shift_length = 299;\n+\n+/**\n+ *  @brief  Wraps platform-specific @b aligned memory allocation and deallocation functions.\n+ *          Compatible with `std::unique_ptr` as the second template argument, to free the memory.\n+ */\n+struct page_alloc_and_free_t {\n+#ifdef _WIN32\n+    inline char *operator()(std::size_t alignment, std::size_t size) const noexcept {\n+        return reinterpret_cast<char *>(_aligned_malloc(size, alignment));\n+    }\n+    inline void operator()(char *ptr) const noexcept { _aligned_free(ptr); }\n+#else\n+    inline char *operator()(std::size_t alignment, std::size_t size) const noexcept {\n+        return reinterpret_cast<char *>(std::aligned_alloc(alignment, size));\n+    }\n+    inline void operator()(char *ptr) const noexcept { std::free(ptr); }\n+#endif\n+};\n+\n+/**\n+ *  @brief  Benchmarks `memcpy`-like operations in 2 modes: aligned @b output buffer and unaligned.\n+ *\n+ *  In the aligned case we copy a random part of the input string into the start of a matching cache line in the output.\n+ *  In the unaligned case we also locate a matching cache line in the output, but shift by one to guarantee unaligned\n+ *  writes.\n+ *\n+ *  Multiple calls to the provided functions even with the same arguments won't change the input or output.\n+ *  So the kernels can be compared against the baseline `memcpy` function.\n+ *\n+ *  @param  output_buffer_ptr Aligned output buffer.\n+ */\n+template <bool aligned_output>\n+tracked_unary_functions_t copy_functions(sz_cptr_t dataset_start_ptr, sz_ptr_t output_buffer_ptr) {\n+    std::string suffix = aligned_output ? \"<aligned>\" : \"<unaligned>\";\n+    auto wrap_sz = [dataset_start_ptr, output_buffer_ptr](auto function) -> unary_function_t {\n+        return unary_function_t([function, dataset_start_ptr, output_buffer_ptr](std::string_view slice) {\n+            std::size_t output_offset = slice.data() - dataset_start_ptr;\n+            // Round down to the nearest multiple of a cache line width for aligned writes\n+            output_offset = round_up_to_multiple<SZ_CACHE_LINE_WIDTH>(output_offset) - SZ_CACHE_LINE_WIDTH;\n+            // Ensure unaligned exports if needed\n+            if constexpr (!aligned_output) output_offset += 1;\n+            function(output_buffer_ptr + output_offset, slice.data(), slice.size());\n+            return slice.size();\n+        });\n+    };\n+    tracked_unary_functions_t result = {\n+        {\"memcpy\" + suffix, wrap_sz(memcpy)},\n+        {\"sz_copy_serial\" + suffix, wrap_sz(sz_copy_serial)},\n+#if SZ_USE_X86_AVX512\n+        {\"sz_copy_avx512\" + suffix, wrap_sz(sz_copy_avx512)},\n+#endif\n+#if SZ_USE_X86_AVX2\n+        {\"sz_copy_avx2\" + suffix, wrap_sz(sz_copy_avx2)},\n+#endif\n+#if SZ_USE_ARM_SVE\n+        {\"sz_copy_sve\" + suffix, wrap_sz(sz_copy_sve)},\n+#endif\n+#if SZ_USE_ARM_NEON\n+        {\"sz_copy_neon\" + suffix, wrap_sz(sz_copy_neon)},\n+#endif\n+    };\n+    return result;\n+}\n+\n+/**\n+ *  @brief  Benchmarks `memset`-like operations overwriting regions of output memory filling\n+ *          them with the first byte of the input regions.\n+ *\n+ *  Multiple calls to the provided functions even with the same arguments won't change the input or output.\n+ *  So the kernels can be compared against the baseline `memset` function.\n+ *\n+ *  @param  output_buffer_ptr Aligned output buffer.\n+ */\n+tracked_unary_functions_t fill_functions(sz_cptr_t dataset_start_ptr, sz_ptr_t output_buffer_ptr) {\n+    auto wrap_sz = [dataset_start_ptr, output_buffer_ptr](auto function) -> unary_function_t {\n+        return unary_function_t([function, dataset_start_ptr, output_buffer_ptr](std::string_view slice) {\n+            std::size_t output_offset = (std::size_t)(slice.data() - dataset_start_ptr);\n+            function(output_buffer_ptr + output_offset, slice.size(), slice.front());\n+            return slice.size();\n+        });\n+    };\n+    tracked_unary_functions_t result = {\n+        {\"memset\", unary_function_t([dataset_start_ptr, output_buffer_ptr](std::string_view slice) {\n+             std::size_t output_offset = (std::size_t)(slice.data() - dataset_start_ptr);\n+             memset(output_buffer_ptr + output_offset, slice.front(), slice.size());\n+             return slice.size();\n+         })},\n+        {\"sz_fill_serial\", wrap_sz(sz_fill_serial)},\n+#if SZ_USE_X86_AVX512\n+        {\"sz_fill_avx512\", wrap_sz(sz_fill_avx512)},\n+#endif\n+#if SZ_USE_X86_AVX2\n+        {\"sz_fill_avx2\", wrap_sz(sz_fill_avx2)},\n+#endif\n+#if SZ_USE_ARM_SVE\n+        {\"sz_fill_sve\", wrap_sz(sz_fill_sve)},\n+#endif\n+#if SZ_USE_ARM_NEON\n+        {\"sz_fill_neon\", wrap_sz(sz_fill_neon)},\n+#endif\n+    };\n+    return result;\n+}\n+\n+/**\n+ *  @brief  Benchmarks `memmove`-like operations shuffling back and forth the regions of output memory.\n+ *\n+ *  Multiple calls to the provided functions even with the same arguments won't change the input or output.\n+ *  This is achieved by performing a combination of a forward and a backward move.\n+ *  So the kernels can be compared against the baseline `memmove` function.\n+ *\n+ *  @param  output_buffer_ptr Aligned output buffer, that ahs at least `shift` bytes of space at the end.\n+ */\n+tracked_unary_functions_t move_functions(sz_cptr_t dataset_start_ptr, sz_ptr_t output_buffer_ptr, std::size_t shift) {\n+    std::string suffix = \"<shift\" + std::to_string(shift) + \">\";\n+    auto wrap_sz = [dataset_start_ptr, output_buffer_ptr, shift](auto function) -> unary_function_t {\n+        return unary_function_t([function, dataset_start_ptr, output_buffer_ptr, shift](std::string_view slice) {\n+            std::size_t output_offset = slice.data() - dataset_start_ptr;\n+            // Shift forward\n+            function(output_buffer_ptr + output_offset + shift, output_buffer_ptr + output_offset, slice.size());\n+            // Shift backward to revert the changes\n+            function(output_buffer_ptr + output_offset, output_buffer_ptr + output_offset + shift, slice.size());\n+            return slice.size() * 2;\n+        });\n+    };\n+    tracked_unary_functions_t result = {\n+        {\"memmove\" + suffix, wrap_sz(memmove)},\n+        {\"sz_move_serial\" + suffix, wrap_sz(sz_move_serial)},\n+#if SZ_USE_X86_AVX512\n+        {\"sz_move_avx512\" + suffix, wrap_sz(sz_move_avx512)},\n+#endif\n+#if SZ_USE_X86_AVX2\n+        {\"sz_move_avx2\" + suffix, wrap_sz(sz_move_avx2)},\n+#endif\n+#if SZ_USE_ARM_NEON\n+        {\"sz_move_neon\" + suffix, wrap_sz(sz_move_neon)},\n+#endif\n+    };\n+    return result;\n+}\n+\n+/**\n+ *  @brief  Benchmarks look-up transformations on the provided slices, updating them inplace.\n+ *\n+ *  Performs a simple cyclical rotation of the alphabet, to test the performance of the different\n+ * \"look-up table\"-based transformations.\n+ */\n+tracked_unary_functions_t transform_functions() {\n+    static unsigned char look_up_table[256];\n+    std::iota(std::begin(look_up_table), std::end(look_up_table), 0);\n+    std::rotate(std::begin(look_up_table), std::begin(look_up_table) + 1, std::end(look_up_table));\n+\n+    auto wrap_sz = [](auto function) -> unary_function_t {\n+        return unary_function_t([function](std::string_view slice) {\n+            char *output = const_cast<char *>(slice.data());\n+            function((sz_cptr_t)output, (sz_size_t)slice.size(), (sz_cptr_t)look_up_table, (sz_ptr_t)output);\n+            return slice.size();\n+        });\n+    };\n+    tracked_unary_functions_t result = {\n+        {\"str::transform<lookup>\", unary_function_t([](std::string_view slice) {\n+             char *output = const_cast<char *>(slice.data());\n+             std::transform(slice.begin(), slice.end(), output, [](char c) { return look_up_table[(unsigned char)c]; });\n+             return slice.size();\n+         })},\n+        {\"str::transform<increment>\", unary_function_t([](std::string_view slice) {\n+             char *output = const_cast<char *>(slice.data());\n+             std::transform(slice.begin(), slice.end(), output, [](char c) { return c + 1; });\n+             return slice.size();\n+         })},\n+        {\"sz_look_up_transform_serial\", wrap_sz(sz_look_up_transform_serial)},\n+#if SZ_USE_X86_AVX512\n+        {\"sz_look_up_transform_avx512\", wrap_sz(sz_look_up_transform_avx512)},\n+#endif\n+#if SZ_USE_X86_AVX2\n+        {\"sz_look_up_transform_avx2\", wrap_sz(sz_look_up_transform_avx2)},\n+#endif\n+#if SZ_USE_ARM_NEON\n+        {\"sz_look_up_transform_neon\", wrap_sz(sz_look_up_transform_neon)},\n+#endif\n+    };\n+    return result;\n+}\n+\n+void bench_memory(std::vector<std::string_view> const &slices, tracked_unary_functions_t &&variants) {\n+\n+    for (std::size_t variant_idx = 0; variant_idx != variants.size(); ++variant_idx) {\n+        auto &variant = variants[variant_idx];\n+\n+        // Tests\n+        if (variant.function && variant.needs_testing) {\n+            std::fprintf(stderr, \"Testing is not currently implemented.\\n\");\n+            exit(1);\n+        }\n+\n+        // Benchmarks\n+        if (variant.function) variant.results = bench_on_tokens(slices, variant.function);\n+        variant.print();\n+    }\n+}\n+\n+void bench_memory(std::vector<std::string_view> const &slices, sz_cptr_t dataset_start_ptr,\n+                  sz_ptr_t output_buffer_ptr) {\n+\n+    if (slices.size() == 0) return;\n+    (void)dataset_start_ptr;\n+    (void)output_buffer_ptr;\n+\n+    bench_memory(slices, copy_functions<true>(dataset_start_ptr, output_buffer_ptr));\n+    bench_memory(slices, copy_functions<false>(dataset_start_ptr, output_buffer_ptr));\n+    bench_memory(slices, fill_functions(dataset_start_ptr, output_buffer_ptr));\n+    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 1));\n+    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, 8));\n+    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, SZ_CACHE_LINE_WIDTH));\n+    // bench_memory(slices, move_functions(dataset_start_ptr, output_buffer_ptr, max_shift_length));\n+    // bench_memory(slices, transform_functions());\n+}\n+\n+int main(int argc, char const **argv) {\n+    std::printf(\"StringZilla. Starting memory benchmarks.\\n\");\n+\n+    dataset_t dataset = prepare_benchmark_environment(argc, argv);\n+    sz_cptr_t const dataset_start_ptr = dataset.text.data();\n+\n+    // These benchmarks should be heavier than substring search and other less critical operations.\n+    if (!SZ_DEBUG) seconds_per_benchmark *= 5;\n+\n+    // Create an aligned buffer for the output\n+    std::unique_ptr<char, page_alloc_and_free_t> output_buffer;\n+    // Add space for at least one cache line to simplify unaligned exports\n+    std::size_t const output_length = round_up_to_multiple<4096>(dataset.text.size() + max_shift_length);\n+    output_buffer.reset(page_alloc_and_free_t {}(4096, output_length));\n+    if (!output_buffer) {\n+        std::fprintf(stderr, \"Failed to allocate an output buffer of %zu bytes.\\n\", output_length);\n+        return 1;\n+    }\n+    std::memcpy(output_buffer.get(), dataset.text.data(), dataset.text.size());\n+\n+    // Baseline benchmarks for present tokens, coming in all lengths\n+    std::printf(\"Benchmarking on entire dataset:\\n\");\n+    bench_memory({dataset.text}, dataset_start_ptr, output_buffer.get());\n+    std::printf(\"Benchmarking on lines:\\n\");\n+    bench_memory(dataset.lines, dataset_start_ptr, output_buffer.get());\n+    std::printf(\"Benchmarking on tokens:\\n\");\n+    bench_memory(dataset.tokens, dataset_start_ptr, output_buffer.get());\n+\n+    // Run benchmarks on tokens of different length\n+    for (std::size_t token_length : {1, 2, 3, 4, 5, 6, 7, 8, 16, 32}) {\n+        std::printf(\"Benchmarking on tokens of length %zu:\\n\", token_length);\n+        bench_memory(filter_by_length<std::string_view>(dataset.tokens, token_length), dataset_start_ptr,\n+                     output_buffer.get());\n+    }\n+    std::printf(\"All benchmarks passed.\\n\");\n+    return 0;\n+}\n\\ No newline at end of file\ndiff --git a/scripts/bench_token.cpp b/scripts/bench_token.cpp\nindex e1f9d15e..d1fffba2 100644\n--- a/scripts/bench_token.cpp\n+++ b/scripts/bench_token.cpp\n@@ -7,8 +7,6 @@\n #include <bench.hpp>\n #include <test.hpp> // `random_string`\n \n-#include <stringzilla/drafts.h> // `sz_hashes_neon`\n-\n using namespace ashvardanian::stringzilla::scripts;\n \n tracked_unary_functions_t hashing_functions() {\n@@ -37,11 +35,6 @@ tracked_unary_functions_t sliding_hashing_functions(std::size_t window_width, st\n #endif\n #if SZ_USE_X86_AVX2\n         {\"sz_hashes_avx2:\" + suffix, wrap_sz(sz_hashes_avx2)},\n-#endif\n-#if SZ_USE_ARM_NEON\n-        {\"sz_hashes_neon_naive:\" + suffix, wrap_sz(sz_hashes_neon_naive)},\n-        {\"sz_hashes_neon_readahead:\" + suffix, wrap_sz(sz_hashes_neon_readahead)},\n-        {\"sz_hashes_neon_reusing_loads:\" + suffix, wrap_sz(sz_hashes_neon_reusing_loads)},\n #endif\n         {\"sz_hashes_serial:\" + suffix, wrap_sz(sz_hashes_serial)},\n     };\n@@ -99,6 +92,9 @@ tracked_binary_functions_t equality_functions() {\n     tracked_binary_functions_t result = {\n         {\"std::string_view.==\", [](std::string_view a, std::string_view b) { return (a == b); }},\n         {\"sz_equal_serial\", wrap_sz(sz_equal_serial), true},\n+#if SZ_USE_X86_AVX2\n+        {\"sz_equal_avx2\", wrap_sz(sz_equal_avx2), true},\n+#endif\n #if SZ_USE_X86_AVX512\n         {\"sz_equal_avx512\", wrap_sz(sz_equal_avx512), true},\n #endif\n@@ -123,6 +119,12 @@ tracked_binary_functions_t ordering_functions() {\n              return (order == 0 ? sz_equal_k : (order < 0 ? sz_less_k : sz_greater_k));\n          }},\n         {\"sz_order_serial\", wrap_sz(sz_order_serial), true},\n+#if SZ_USE_X86_AVX2\n+        {\"sz_order_avx2\", wrap_sz(sz_order_avx2), true},\n+#endif\n+#if SZ_USE_X86_AVX512\n+        {\"sz_order_avx512\", wrap_sz(sz_order_avx512), true},\n+#endif\n         {\"memcmp\",\n          [](std::string_view a, std::string_view b) {\n              auto order = memcmp(a.data(), b.data(), a.size() < b.size() ? a.size() : b.size());\n@@ -186,6 +188,10 @@ void bench_on_input_data(int argc, char const **argv) {\n     bench_unary_functions<std::vector<std::string_view>>({dataset.text}, fingerprinting_functions(128, 1024 * 1024));\n \n     // Baseline benchmarks for real words, coming in all lengths\n+    std::printf(\"Benchmarking on entire dataset:\\n\");\n+    bench<std::vector<std::string_view>>({dataset.text});\n+    std::printf(\"Benchmarking on real lines:\\n\");\n+    bench(dataset.lines);\n     std::printf(\"Benchmarking on real words:\\n\");\n     bench(dataset.tokens);\n \ndiff --git a/setup.py b/setup.py\nindex 5573a59a..47e96e7f 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -65,6 +65,7 @@ def linux_settings() -> Tuple[List[str], List[str], List[Tuple[str]]]:\n \n \n def darwin_settings() -> Tuple[List[str], List[str], List[Tuple[str]]]:\n+\n     compile_args = [\n         \"-std=c99\",  # use the C 99 language dialect\n         \"-pedantic\",  # stick close to the C language standard, avoid compiler extensions\n@@ -75,6 +76,8 @@ def darwin_settings() -> Tuple[List[str], List[str], List[Tuple[str]]]:\n         \"-Wno-incompatible-pointer-types\",  # like: passing argument 4 of \u2018sz_export_prefix_u32\u2019 from incompatible pointer type\n         \"-Wno-discarded-qualifiers\",  # like: passing argument 1 of \u2018free\u2019 discards \u2018const\u2019 qualifier from pointer target type\n         \"-fPIC\",  # to enable dynamic dispatch\n+        \"-mfloat-abi=hard\",  # NEON intrinsics not available with the soft-float ABI\n+        \"-mmacosx-version-min=11.0\",  # minimum macOS version\n     ]\n     link_args = [\n         \"-fPIC\",  # to enable dynamic dispatch\n", "instance_id": "ashvardanian__StringZilla-174", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear, as it describes a specific compilation error encountered when using the `partition` method with a single character argument in the StringZilla library. It provides a code snippet to reproduce the issue, the expected behavior, and even suggests a potential solution by pointing out the lack of an overload for the `partition` function. The issue is well-documented with details about the OS, hardware architecture, and library version. However, there are minor ambiguities: the problem statement does not explicitly clarify if the issue affects only certain platforms or compiler versions beyond Fedora Linux 40, and it lacks detailed discussion of potential edge cases or constraints for the fix (e.g., performance implications or compatibility requirements). Additionally, while the expected behavior is mentioned, it could be more detailed with respect to the exact output or behavior for various inputs. Thus, it falls under \"Mostly Clear\" with minor details missing.", "difficulty_explanation": "The difficulty of solving this problem is rated as Easy (0.25) on the scale of 0.0 to 1.0. The issue involves a compilation error due to a missing overload for the `partition` method when a single character is passed as an argument. The suggested fix, as provided in the problem statement, is straightforward\u2014adding a single function overload to handle a `char` pattern, which maps to an existing implementation using a `char_set`. This requires minimal code changes, likely confined to a single file or class definition in the StringZilla library (specifically in `stringzilla.hpp` as seen in the code changes). The task does not demand deep understanding of the broader codebase architecture, complex algorithm design, or handling of intricate edge cases beyond ensuring the overload works as expected for basic inputs. It also does not appear to impact performance or require significant refactoring. The code changes provided in the diff are extensive but unrelated to the core issue described (they mostly pertain to build system updates and other features), so the actual fix for the reported bug is a small, isolated modification. Therefore, this task aligns with the Easy category, requiring understanding of some code logic and making a simple function modification."}
{"problem_statement": "context-fill inconsistent with browser rendering\n## Test SVG\r\n\r\n```svg\r\n<svg width=\"100mm\" height=\"100mm\" viewBox=\"0 0 100 100\" version=\"1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns=\"http://www.w3.org/2000/svg\" >\r\n   <defs>\r\n      <pattern patternUnits=\"userSpaceOnUse\" width=\"2\" height=\"2\" viewBox=\"0 0 2 2\" id=\"circular-pattern\">\r\n         <circle fill=\"#117611\" stroke=\"none\" id=\"circle-in-pattern\" cx=\"1\" cy=\"1\" r=\"1\" />\r\n      </pattern>\r\n      <marker orient=\"auto\" id=\"test-marker\" refX=\"0\" refY=\"1\" markerWidth=\"10\"\r\n         markerHeight=\"10\" viewBox=\"0 0 2 2\" preserveAspectRatio=\"xMidYMid\">\r\n         <rect x=\"0\" y=\"0\" width=\"2\" height=\"2\" fill=\"context-fill\" fill-rule=\"evenodd\" stroke=\"none\" />\r\n      </marker>\r\n   </defs>\r\n   <path fill=\"url(#circular-pattern)\" stroke=\"#ff0000\" stroke-width=\"1\" marker-end=\"url(#test-marker)\" d=\"M 25,50 H 75\" id=\"test-path\" />\r\n</svg>\r\n```\r\n\r\n## Output\r\n\r\nI'm not sure which rendering is correct.\r\n\r\n![context-fill](https://github.com/RazrFalcon/resvg/assets/2784308/9ed09893-2877-418c-87fa-dcd3a26a8b0c)\r\n\r\nPlease test with Chrome 126.0.6425.0 or above, they just fixed an [issue](https://chromiumdash.appspot.com/commit/9cf8ac20f215f9a9b29089729e9d302ec8fcf930).\r\n\n", "patch": "diff --git a/crates/usvg/src/parser/converter.rs b/crates/usvg/src/parser/converter.rs\nindex a53acd981..a95a59124 100644\n--- a/crates/usvg/src/parser/converter.rs\n+++ b/crates/usvg/src/parser/converter.rs\n@@ -817,7 +817,11 @@ fn convert_path(\n \n     let mut marker = None;\n     if marker::is_valid(node) && visibility == Visibility::Visible {\n-        let mut marker_group = Group::empty();\n+        let mut marker_group = Group {\n+            abs_transform: parent.abs_transform,\n+            ..Group::empty()\n+        };\n+\n         let mut marker_state = state.clone();\n \n         let bbox = tiny_skia_path\n", "instance_id": "linebender__resvg-744", "clarity": 1, "difficulty": 0.5, "clarity_explanation": "The problem statement is valid but suffers from significant ambiguities. The goal of addressing an inconsistency between `context-fill` rendering in the provided SVG and browser rendering (specifically Chrome 126.0.6425.0 or above) is mentioned, but critical details are missing. There is no clear explanation of what the expected behavior should be or how the inconsistency manifests beyond a vague reference to a rendering difference and a linked image. The problem statement does not specify whether the goal is to match Chrome's rendering or to adhere to a specific SVG standard. Additionally, there are no explicit input/output expectations or constraints provided beyond the test SVG. The mention of a recently fixed issue in Chrome adds some context but does not clarify the desired outcome or requirements for the fix. Overall, the lack of precise objectives and detailed requirements makes it difficult to fully understand the problem without additional research or assumptions.", "difficulty_explanation": "The difficulty of this problem is rated as medium (0.50) based on the provided code changes and the nature of the issue. Here's the breakdown based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes**: The provided diff shows a small modification in a single file (`crates/usvg/src/parser/converter.rs`), specifically in the handling of a `Group` object for SVG marker rendering. The change involves setting the `abs_transform` field to match the parent's transform, which suggests a targeted fix related to coordinate transformations. The change is localized and does not appear to impact the broader system architecture or require modifications across multiple modules. The amount of code change is minimal, indicating a focused intervention.\n\n2. **Number of Technical Concepts**: Solving this problem requires understanding SVG rendering, particularly the `context-fill` property and how it interacts with markers and transformations in the rendering pipeline. Familiarity with the `usvg` crate's internal representation of SVG elements (like `Group` and transformations) is necessary. Additionally, knowledge of coordinate systems and how absolute transformations (`abs_transform`) are applied in rendering is critical. While these concepts are not overly complex for someone familiar with graphics programming, they do require domain-specific knowledge beyond general programming skills.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases or error conditions, but the nature of SVG rendering implies potential challenges with different marker configurations, viewBox settings, or transformation hierarchies. The code change does not introduce new error handling logic, but ensuring correctness might involve testing various SVG inputs to confirm that the rendering matches the expected behavior (e.g., Chrome's rendering). The complexity of edge cases is moderate, as SVG rendering can be sensitive to subtle differences in input.\n\n4. **Overall Complexity**: The problem falls into the medium difficulty range because it requires a moderate understanding of the codebase (specifically the rendering logic in `usvg`) and domain knowledge of SVG standards and rendering. The fix itself is straightforward, but determining the correct behavior and validating it against browser rendering or SVG specifications adds complexity. It does not appear to require deep architectural changes or advanced algorithms, nor does it involve extensive performance optimization or system-level considerations.\n\nIn summary, this problem is of medium difficulty due to the need for domain-specific knowledge in SVG rendering and moderate complexity in understanding the rendering pipeline, despite the simplicity of the actual code change."}
{"problem_statement": "Weird black bar in rendered SVG\nOriginally reported at https://github.com/typst/typst/issues/5174.\r\n\r\nWith the following SVG:\r\n\r\n![test](https://github.com/user-attachments/assets/3caf3779-f120-438b-8644-df1658c7adcc)\r\n\r\n`resvg` renders it as:\r\n![test](https://github.com/user-attachments/assets/0cdc81f4-eb09-4b14-b7a8-4b51a7b0e87d)\r\n\r\nOne problem is obviously the different font, but this is a known issue since we don't support `font-face` yet. However, another issue is that there is this weird black box for one path. In Chrome, it looks like that instead:\r\n<img width=\"779\" alt=\"image\" src=\"https://github.com/user-attachments/assets/6f332edd-1555-4f3e-b8ee-6247c5e58652\">\r\n\r\nI'll try to get a MRE when I find the time to do so.\n", "patch": "diff --git a/crates/usvg/src/parser/use_node.rs b/crates/usvg/src/parser/use_node.rs\nindex 20dc17f7a..723a0107b 100644\n--- a/crates/usvg/src/parser/use_node.rs\n+++ b/crates/usvg/src/parser/use_node.rs\n@@ -54,6 +54,32 @@ pub(crate) fn convert(\n     let linked_to_symbol = child.tag_name() == Some(EId::Symbol);\n \n     if linked_to_symbol {\n+        // If a `use` element has a width/height attribute and references a symbol\n+        // then relative units (like percentages) should be resolved relative\n+        // to the width/height of the `use` element, and not the original SVG.\n+        // This is why we need to (potentially) adapt the view box here.\n+        use_state.view_box = {\n+            let def = Length::new(100.0, LengthUnit::Percent);\n+            let x = use_state.view_box.x();\n+            let y = use_state.view_box.y();\n+\n+            let width = if node.has_attribute(AId::Width) {\n+                node.convert_user_length(AId::Width, &use_state, def)\n+            } else {\n+                use_state.view_box.width()\n+            };\n+\n+            let height = if node.has_attribute(AId::Height) {\n+                node.convert_user_length(AId::Height, &use_state, def)\n+            } else {\n+                use_state.view_box.height()\n+            };\n+\n+            NonZeroRect::from_xywh(x, y, width, height)\n+                // Fail silently if the rect is not valid.\n+                .unwrap_or(use_state.view_box)\n+        };\n+\n         if let Some(ts) = viewbox_transform(node, child, &use_state) {\n             new_ts = new_ts.pre_concat(ts);\n         }\n", "instance_id": "linebender__resvg-832", "clarity": 1, "difficulty": 0.5, "clarity_explanation": "The problem statement is valid but suffers from significant ambiguities and lacks critical details. The goal is vaguely described as addressing a \"weird black bar\" in a rendered SVG, with references to visual outputs in different renderers (e.g., Chrome vs. resvg). However, there is no clear definition of the expected behavior or output beyond visual comparisons in attached images, which are not accessible in this text format. Additionally, there is no minimal reproducible example (MRE) provided, as the author mentions they will try to create one later. Constraints, specific input formats, or detailed requirements for the fix are entirely absent. This makes it difficult to fully understand the problem without additional context or access to the referenced issue and images. The statement is not comprehensive and leaves much to interpretation, warranting a low clarity score.", "difficulty_explanation": "The difficulty of this problem is rated as medium (0.50) based on the provided code changes and the inferred complexity of the issue. Here's the breakdown based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes**: The code changes are confined to a single file (`use_node.rs`) and involve a specific modification to handle view box calculations for `use` elements referencing a `symbol` in SVG rendering. The change is relatively small (about 26 lines of code) and does not appear to impact the broader system architecture or multiple modules. However, it requires understanding the specific logic of SVG rendering and view box transformations, which adds some complexity.\n\n2. **Number of Technical Concepts**: Solving this problem requires knowledge of SVG rendering principles, particularly how `use` elements and `symbol` references work, as well as handling relative units (e.g., percentages) in view box calculations. Familiarity with the `usvg` crate's internals and specific methods like `convert_user_length` and `NonZeroRect` is necessary. While these concepts are not extremely advanced, they are domain-specific and require a moderate level of expertise in graphics rendering or SVG parsing libraries.\n\n3. **Potential Edge Cases and Error Handling**: The code change includes a fallback mechanism (`unwrap_or`) to handle invalid rectangles silently, indicating some consideration of edge cases. However, the problem statement does not explicitly mention specific edge cases or error conditions to address. The complexity of edge cases appears moderate, as the fix focuses on adjusting view box dimensions based on `use` element attributes, which could have various invalid or unexpected inputs (e.g., missing attributes, negative values).\n\n4. **Overall Complexity**: The problem does not seem to require deep architectural changes or advanced algorithms, but it does demand a targeted understanding of SVG rendering logic and the specific behavior of `use` and `symbol` elements. The fix is not trivial, as it involves correctly interpreting and adapting view box calculations, which could have subtle implications on rendering output.\n\nGiven these factors, the problem falls into the medium difficulty range. It is not a simple bug fix or basic feature addition (which would be 0.2-0.4), nor does it involve extensive refactoring or highly complex logic (which would be 0.6-0.8). It requires a moderate level of understanding and careful implementation to ensure the rendering issue is resolved without introducing new bugs."}
