{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_load_image_file", "test": "def test_load_image_file(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    self.assertEqual(img.shape, (1137, 910, 3))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::load_image_file", "code": "def load_image_file(file, mode='RGB'):\n    \"\"\"\n    Loads an image file (.jpg, .png, etc) into a numpy array\n\n    :param file: image file name or file object to load\n    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n    :return: image contents as numpy array\n    \"\"\"\n    im = PIL.Image.open(file)\n    if mode:\n        im = im.convert(mode)\n    return np.array(im)\n", "docstring": "Loads an image file (.jpg, .png, etc) into a numpy array\n\n:param file: image file name or file object to load\n:param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n:return: image contents as numpy array"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_load_image_file_32bit", "test": "def test_load_image_file_32bit(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', '32bit.png'))\n    self.assertEqual(img.shape, (1200, 626, 3))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::load_image_file", "code": "def load_image_file(file, mode='RGB'):\n    \"\"\"\n    Loads an image file (.jpg, .png, etc) into a numpy array\n\n    :param file: image file name or file object to load\n    :param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n    :return: image contents as numpy array\n    \"\"\"\n    im = PIL.Image.open(file)\n    if mode:\n        im = im.convert(mode)\n    return np.array(im)\n", "docstring": "Loads an image file (.jpg, .png, etc) into a numpy array\n\n:param file: image file name or file object to load\n:param mode: format to convert the image to. Only 'RGB' (8-bit RGB, 3 channels) and 'L' (black and white) are supported.\n:return: image contents as numpy array"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_raw_face_locations", "test": "def test_raw_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    detected_faces = api._raw_face_locations(img)\n    self.assertEqual(len(detected_faces), 1)\n    self.assertEqual(detected_faces[0].top(), 142)\n    self.assertEqual(detected_faces[0].bottom(), 409)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_locations", "code": "def _raw_face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of dlib 'rect' objects of found face locations\n    \"\"\"\n    if model == 'cnn':\n        return cnn_face_detector(img, number_of_times_to_upsample)\n    else:\n        return face_detector(img, number_of_times_to_upsample)\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of dlib 'rect' objects of found face locations"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_cnn_raw_face_locations", "test": "def test_cnn_raw_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    detected_faces = api._raw_face_locations(img, model='cnn')\n    self.assertEqual(len(detected_faces), 1)\n    self.assertAlmostEqual(detected_faces[0].rect.top(), 144, delta=25)\n    self.assertAlmostEqual(detected_faces[0].rect.bottom(), 389, delta=25)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_locations", "code": "def _raw_face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of dlib 'rect' objects of found face locations\n    \"\"\"\n    if model == 'cnn':\n        return cnn_face_detector(img, number_of_times_to_upsample)\n    else:\n        return face_detector(img, number_of_times_to_upsample)\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of dlib 'rect' objects of found face locations"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_raw_face_locations_32bit_image", "test": "def test_raw_face_locations_32bit_image(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', '32bit.png'))\n    detected_faces = api._raw_face_locations(img)\n    self.assertEqual(len(detected_faces), 1)\n    self.assertEqual(detected_faces[0].top(), 290)\n    self.assertEqual(detected_faces[0].bottom(), 558)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_locations", "code": "def _raw_face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of dlib 'rect' objects of found face locations\n    \"\"\"\n    if model == 'cnn':\n        return cnn_face_detector(img, number_of_times_to_upsample)\n    else:\n        return face_detector(img, number_of_times_to_upsample)\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of dlib 'rect' objects of found face locations"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_cnn_raw_face_locations_32bit_image", "test": "def test_cnn_raw_face_locations_32bit_image(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', '32bit.png'))\n    detected_faces = api._raw_face_locations(img, model='cnn')\n    self.assertEqual(len(detected_faces), 1)\n    self.assertAlmostEqual(detected_faces[0].rect.top(), 259, delta=25)\n    self.assertAlmostEqual(detected_faces[0].rect.bottom(), 552, delta=25)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_locations", "code": "def _raw_face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of dlib 'rect' objects of found face locations\n    \"\"\"\n    if model == 'cnn':\n        return cnn_face_detector(img, number_of_times_to_upsample)\n    else:\n        return face_detector(img, number_of_times_to_upsample)\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of dlib 'rect' objects of found face locations"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_face_locations", "test": "def test_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    detected_faces = api.face_locations(img)\n    self.assertEqual(len(detected_faces), 1)\n    self.assertEqual(detected_faces[0], (142, 617, 409, 349))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_locations", "code": "def face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n    \"\"\"\n    if model == 'cnn':\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, 'cnn')]\n    else:\n        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of tuples of found face locations in css (top, right, bottom, left) order"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_cnn_face_locations", "test": "def test_cnn_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    detected_faces = api.face_locations(img, model='cnn')\n    self.assertEqual(len(detected_faces), 1)\n    self.assertAlmostEqual(detected_faces[0][0], 144, delta=25)\n    self.assertAlmostEqual(detected_faces[0][1], 608, delta=25)\n    self.assertAlmostEqual(detected_faces[0][2], 389, delta=25)\n    self.assertAlmostEqual(detected_faces[0][3], 363, delta=25)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_locations", "code": "def face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n    \"\"\"\n    if model == 'cnn':\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, 'cnn')]\n    else:\n        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of tuples of found face locations in css (top, right, bottom, left) order"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_partial_face_locations", "test": "def test_partial_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama_partial_face.jpg'))\n    detected_faces = api.face_locations(img)\n    self.assertEqual(len(detected_faces), 1)\n    self.assertEqual(detected_faces[0], (142, 191, 365, 0))\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama_partial_face2.jpg'))\n    detected_faces = api.face_locations(img)\n    self.assertEqual(len(detected_faces), 1)\n    self.assertEqual(detected_faces[0], (142, 551, 409, 349))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_locations", "code": "def face_locations(img, number_of_times_to_upsample=1, model='hog'):\n    \"\"\"\n    Returns an array of bounding boxes of human faces in a image\n\n    :param img: An image (as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n                  deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n    \"\"\"\n    if model == 'cnn':\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, 'cnn')]\n    else:\n        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]\n", "docstring": "Returns an array of bounding boxes of human faces in a image\n\n:param img: An image (as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param model: Which face detection model to use. \"hog\" is less accurate but faster on CPUs. \"cnn\" is a more accurate\n              deep-learning model which is GPU/CUDA accelerated (if available). The default is \"hog\".\n:return: A list of tuples of found face locations in css (top, right, bottom, left) order"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_raw_face_locations_batched", "test": "def test_raw_face_locations_batched(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    images = [img, img, img]\n    batched_detected_faces = api._raw_face_locations_batched(images, number_of_times_to_upsample=0)\n    for detected_faces in batched_detected_faces:\n        self.assertEqual(len(detected_faces), 1)\n        self.assertEqual(detected_faces[0].rect.top(), 154)\n        self.assertEqual(detected_faces[0].rect.bottom(), 390)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_locations_batched", "code": "def _raw_face_locations_batched(images, number_of_times_to_upsample=1, batch_size=128):\n    \"\"\"\n    Returns an 2d array of dlib rects of human faces in a image using the cnn face detector\n\n    :param img: A list of images (each as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :return: A list of dlib 'rect' objects of found face locations\n    \"\"\"\n    return cnn_face_detector(images, number_of_times_to_upsample, batch_size=batch_size)\n", "docstring": "Returns an 2d array of dlib rects of human faces in a image using the cnn face detector\n\n:param img: A list of images (each as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:return: A list of dlib 'rect' objects of found face locations"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_batched_face_locations", "test": "def test_batched_face_locations(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    images = [img, img, img]\n    batched_detected_faces = api.batch_face_locations(images, number_of_times_to_upsample=0)\n    for detected_faces in batched_detected_faces:\n        self.assertEqual(len(detected_faces), 1)\n        self.assertEqual(detected_faces[0], (154, 611, 390, 375))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::batch_face_locations", "code": "def batch_face_locations(images, number_of_times_to_upsample=1, batch_size=128):\n    \"\"\"\n    Returns an 2d array of bounding boxes of human faces in a image using the cnn face detector\n    If you are using a GPU, this can give you much faster results since the GPU\n    can process batches of images at once. If you aren't using a GPU, you don't need this function.\n\n    :param img: A list of images (each as a numpy array)\n    :param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n    :param batch_size: How many images to include in each GPU processing batch.\n    :return: A list of tuples of found face locations in css (top, right, bottom, left) order\n    \"\"\"\n\n    def convert_cnn_detections_to_css(detections):\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), images[0].shape) for face in detections]\n    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)\n    return list(map(convert_cnn_detections_to_css, raw_detections_batched))\n", "docstring": "Returns an 2d array of bounding boxes of human faces in a image using the cnn face detector\nIf you are using a GPU, this can give you much faster results since the GPU\ncan process batches of images at once. If you aren't using a GPU, you don't need this function.\n\n:param img: A list of images (each as a numpy array)\n:param number_of_times_to_upsample: How many times to upsample the image looking for faces. Higher numbers find smaller faces.\n:param batch_size: How many images to include in each GPU processing batch.\n:return: A list of tuples of found face locations in css (top, right, bottom, left) order"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_raw_face_landmarks", "test": "def test_raw_face_landmarks(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    face_landmarks = api._raw_face_landmarks(img)\n    example_landmark = face_landmarks[0].parts()[10]\n    self.assertEqual(len(face_landmarks), 1)\n    self.assertEqual(face_landmarks[0].num_parts, 68)\n    self.assertEqual((example_landmark.x, example_landmark.y), (552, 399))\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::_raw_face_landmarks", "code": "def _raw_face_landmarks(face_image, face_locations=None, model='large'):\n    if face_locations is None:\n        face_locations = _raw_face_locations(face_image)\n    else:\n        face_locations = [_css_to_rect(face_location) for face_location in face_locations]\n    pose_predictor = pose_predictor_68_point\n    if model == 'small':\n        pose_predictor = pose_predictor_5_point\n    return [pose_predictor(face_image, face_location) for face_location in face_locations]\n", "docstring": ""}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_face_landmarks", "test": "def test_face_landmarks(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    face_landmarks = api.face_landmarks(img)\n    self.assertEqual(set(face_landmarks[0].keys()), set(['chin', 'left_eyebrow', 'right_eyebrow', 'nose_bridge', 'nose_tip', 'left_eye', 'right_eye', 'top_lip', 'bottom_lip']))\n    self.assertEqual(face_landmarks[0]['chin'], [(369, 220), (372, 254), (378, 289), (384, 322), (395, 353), (414, 382), (437, 407), (464, 424), (495, 428), (527, 420), (552, 399), (576, 372), (594, 344), (604, 314), (610, 282), (613, 250), (615, 219)])\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_landmarks", "code": "def face_landmarks(face_image, face_locations=None):\n    \"\"\"\n    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\n\n    :param face_image: image to search\n    :param face_locations: Optionally provide a list of face locations to check.\n    :return: A list of dicts of face feature locations (eyes, nose, etc)\n    \"\"\"\n    landmarks = _raw_face_landmarks(face_image, face_locations)\n    landmarks_as_tuples = [[(p.x, p.y) for p in landmark.parts()] for landmark in landmarks]\n    return [{'chin': points[0:17], 'left_eyebrow': points[17:22], 'right_eyebrow': points[22:27], 'nose_bridge': points[27:31], 'nose_tip': points[31:36], 'left_eye': points[36:42], 'right_eye': points[42:48], 'top_lip': points[48:55] + [points[64]] + [points[63]] + [points[62]] + [points[61]] + [points[60]], 'bottom_lip': points[54:60] + [points[48]] + [points[60]] + [points[67]] + [points[66]] + [points[65]] + [points[64]]} for points in landmarks_as_tuples]\n", "docstring": "Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\n\n:param face_image: image to search\n:param face_locations: Optionally provide a list of face locations to check.\n:return: A list of dicts of face feature locations (eyes, nose, etc)"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_face_encodings", "test": "def test_face_encodings(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    encodings = api.face_encodings(img)\n    self.assertEqual(len(encodings), 1)\n    self.assertEqual(len(encodings[0]), 128)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_encodings", "code": "def face_encodings(face_image, known_face_locations=None, num_jitters=1):\n    \"\"\"\n    Given an image, return the 128-dimension face encoding for each face in the image.\n\n    :param face_image: The image that contains one or more faces\n    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n    :return: A list of 128-dimensional face encodings (one for each face in the image)\n    \"\"\"\n    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model='small')\n    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n", "docstring": "Given an image, return the 128-dimension face encoding for each face in the image.\n\n:param face_image: The image that contains one or more faces\n:param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n:param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n:return: A list of 128-dimensional face encodings (one for each face in the image)"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_face_distance", "test": "def test_face_distance(self):\n    img_a1 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    img_a2 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama2.jpg'))\n    img_a3 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama3.jpg'))\n    img_b1 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'biden.jpg'))\n    face_encoding_a1 = api.face_encodings(img_a1)[0]\n    face_encoding_a2 = api.face_encodings(img_a2)[0]\n    face_encoding_a3 = api.face_encodings(img_a3)[0]\n    face_encoding_b1 = api.face_encodings(img_b1)[0]\n    faces_to_compare = [face_encoding_a2, face_encoding_a3, face_encoding_b1]\n    distance_results = api.face_distance(faces_to_compare, face_encoding_a1)\n    self.assertEqual(type(distance_results), np.ndarray)\n    self.assertLessEqual(distance_results[0], 0.6)\n    self.assertLessEqual(distance_results[1], 0.6)\n    self.assertGreater(distance_results[2], 0.6)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_distance", "code": "def face_distance(face_encodings, face_to_compare):\n    \"\"\"\n    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n    for each comparison face. The distance tells you how similar the faces are.\n\n    :param faces: List of face encodings to compare\n    :param face_to_compare: A face encoding to compare against\n    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n    \"\"\"\n    if len(face_encodings) == 0:\n        return np.empty(0)\n    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n", "docstring": "Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\nfor each comparison face. The distance tells you how similar the faces are.\n\n:param faces: List of face encodings to compare\n:param face_to_compare: A face encoding to compare against\n:return: A numpy ndarray with the distance for each face in the same order as the 'faces' array"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_face_distance_empty_lists", "test": "def test_face_distance_empty_lists(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'biden.jpg'))\n    face_encoding = api.face_encodings(img)[0]\n    faces_to_compare = []\n    distance_results = api.face_distance(faces_to_compare, face_encoding)\n    self.assertEqual(type(distance_results), np.ndarray)\n    self.assertEqual(len(distance_results), 0)\n    faces_to_compare = np.array([])\n    distance_results = api.face_distance(faces_to_compare, face_encoding)\n    self.assertEqual(type(distance_results), np.ndarray)\n    self.assertEqual(len(distance_results), 0)\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::face_distance", "code": "def face_distance(face_encodings, face_to_compare):\n    \"\"\"\n    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n    for each comparison face. The distance tells you how similar the faces are.\n\n    :param faces: List of face encodings to compare\n    :param face_to_compare: A face encoding to compare against\n    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n    \"\"\"\n    if len(face_encodings) == 0:\n        return np.empty(0)\n    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n", "docstring": "Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\nfor each comparison face. The distance tells you how similar the faces are.\n\n:param faces: List of face encodings to compare\n:param face_to_compare: A face encoding to compare against\n:return: A numpy ndarray with the distance for each face in the same order as the 'faces' array"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_compare_faces", "test": "def test_compare_faces(self):\n    img_a1 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama.jpg'))\n    img_a2 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama2.jpg'))\n    img_a3 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'obama3.jpg'))\n    img_b1 = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'biden.jpg'))\n    face_encoding_a1 = api.face_encodings(img_a1)[0]\n    face_encoding_a2 = api.face_encodings(img_a2)[0]\n    face_encoding_a3 = api.face_encodings(img_a3)[0]\n    face_encoding_b1 = api.face_encodings(img_b1)[0]\n    faces_to_compare = [face_encoding_a2, face_encoding_a3, face_encoding_b1]\n    match_results = api.compare_faces(faces_to_compare, face_encoding_a1)\n    self.assertEqual(type(match_results), list)\n    self.assertTrue(match_results[0])\n    self.assertTrue(match_results[1])\n    self.assertFalse(match_results[2])\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::compare_faces", "code": "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n    \"\"\"\n    Compare a list of face encodings against a candidate encoding to see if they match.\n\n    :param known_face_encodings: A list of known face encodings\n    :param face_encoding_to_check: A single face encoding to compare against the list\n    :param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\n    \"\"\"\n    return list(face_distance(known_face_encodings, face_encoding_to_check) <= tolerance)\n", "docstring": "Compare a list of face encodings against a candidate encoding to see if they match.\n\n:param known_face_encodings: A list of known face encodings\n:param face_encoding_to_check: A single face encoding to compare against the list\n:param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n:return: A list of True/False values indicating which known_face_encodings match the face encoding to check"}
{"test_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/tests/test_face_recognition.py::Test_face_recognition::test_compare_faces_empty_lists", "test": "def test_compare_faces_empty_lists(self):\n    img = api.load_image_file(os.path.join(os.path.dirname(__file__), 'test_images', 'biden.jpg'))\n    face_encoding = api.face_encodings(img)[0]\n    faces_to_compare = []\n    match_results = api.compare_faces(faces_to_compare, face_encoding)\n    self.assertEqual(type(match_results), list)\n    self.assertListEqual(match_results, [])\n    faces_to_compare = np.array([])\n    match_results = api.compare_faces(faces_to_compare, face_encoding)\n    self.assertEqual(type(match_results), list)\n    self.assertListEqual(match_results, [])\n", "code_id": "ageitgey-face_recognition/ageitgey-face_recognition-59cff93/face_recognition/api.py::compare_faces", "code": "def compare_faces(known_face_encodings, face_encoding_to_check, tolerance=0.6):\n    \"\"\"\n    Compare a list of face encodings against a candidate encoding to see if they match.\n\n    :param known_face_encodings: A list of known face encodings\n    :param face_encoding_to_check: A single face encoding to compare against the list\n    :param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n    :return: A list of True/False values indicating which known_face_encodings match the face encoding to check\n    \"\"\"\n    return list(face_distance(known_face_encodings, face_encoding_to_check) <= tolerance)\n", "docstring": "Compare a list of face encodings against a candidate encoding to see if they match.\n\n:param known_face_encodings: A list of known face encodings\n:param face_encoding_to_check: A single face encoding to compare against the list\n:param tolerance: How much distance between faces to consider it a match. Lower is more strict. 0.6 is typical best performance.\n:return: A list of True/False values indicating which known_face_encodings match the face encoding to check"}
