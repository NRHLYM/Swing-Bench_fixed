{"problem_statement": "MRML panics when using mj-divider inside mj-text\nHi!\r\n\r\nWe recently noticed that MRML is panicking, when we use `<mj-divider>` inside `<mj-text>`. It is reproducable with the following MJML:\r\n\r\n```mjml\r\n<mjml>\r\n  <mj-body>\r\n    <mj-section>\r\n      <mj-column>\r\n        <mj-text>\r\n          <mj-divider></mj-divider>\r\n        </mj-text>\r\n      </mj-column>\r\n    </mj-section>\r\n  </mj-body>\r\n</mjml>\r\n```\r\n\r\nIt panics with:\r\n\r\n```\r\nthread 'main' panicked at mrml-4.0.1/src/mj_divider/render.rs:34:61:\r\ncalled `Option::unwrap()` on a `None` value\r\nstack backtrace:\r\n   0:     0x5a5d9fb00ff5 - <std::sys_common::backtrace::_print::DisplayBacktrace as core::fmt::Display>::fmt::h5380d7966cb17a9f\r\n   1:     0x5a5d9fb28bd3 - core::fmt::write::h6fa818808d2fec0f\r\n   2:     0x5a5d9fafdc5f - std::io::Write::write_fmt::hbfd4c6dab598cc2c\r\n   3:     0x5a5d9fb00e00 - std::sys_common::backtrace::print::hb21cc8c989d23e92\r\n   4:     0x5a5d9fb020b5 - std::panicking::default_hook::{{closure}}::h51c1387cbe610b14\r\n   5:     0x5a5d9fb01e0d - std::panicking::default_hook::hb83d6607ca85d71e\r\n   6:     0x5a5d9fb02544 - std::panicking::rust_panic_with_hook::h31c39679964b4a51\r\n   7:     0x5a5d9fb023eb - std::panicking::begin_panic_handler::{{closure}}::hc9bfccb70659e9b8\r\n   8:     0x5a5d9fb014e9 - std::sys_common::backtrace::__rust_end_short_backtrace::h075f1cf7d2316222\r\n   9:     0x5a5d9fb02177 - rust_begin_unwind\r\n  10:     0x5a5d9f7d01e3 - core::panicking::panic_fmt::hd482fa9e8da4b1ed\r\n  11:     0x5a5d9f7d028c - core::panicking::panic::h5ebb97ce3fdc8cc6\r\n  12:     0x5a5d9f7d0189 - core::option::unwrap_failed::h95d864315f6c4c63\r\n  13:     0x5a5d9f958452 - mrml::mj_divider::render::<impl mrml::prelude::render::Renderer<mrml::mj_divider::MjDivider,()>>::get_outlook_width::ha459ee01adf0ba30\r\n  14:     0x5a5d9f9587b2 - mrml::mj_divider::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mj_divider::MjDivider,()>>::render::h02e7c4d8e0080e40\r\n  15:     0x5a5d9f97d627 - mrml::mj_text::render::<impl mrml::prelude::render::Renderer<mrml::mj_text::MjText,()>>::render_content::hb2b3fd75d53f76b8\r\n  16:     0x5a5d9f97dd24 - mrml::mj_text::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mj_text::MjText,()>>::render::h40d6a44d6d78893b\r\n  17:     0x5a5d9f95597b - mrml::mj_column::render::<impl mrml::prelude::render::Renderer<mrml::mj_column::MjColumn,mrml::mj_column::render::MjColumnExtra>>::render_column::h654dc8e691f00fca\r\n  18:     0x5a5d9f957b7b - mrml::mj_column::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mj_column::MjColumn,mrml::mj_column::render::MjColumnExtra>>::render::h30506b30a7e4c00c\r\n  19:     0x5a5d9f96fa2e - mrml::mj_section::render::SectionLikeRender::render_wrapped_children::hb82e5e6f22d3ccce\r\n  20:     0x5a5d9f973327 - mrml::mj_section::render::SectionLikeRender::render_section::h3fc4e8da1c3d07f2\r\n  21:     0x5a5d9f975800 - mrml::mj_section::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mj_section::MjSection,()>>::render::hbb6f58df474c31b4\r\n  22:     0x5a5d9f944813 - mrml::mj_body::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mj_body::MjBody,()>>::render::h01322d76b229c5e4\r\n  23:     0x5a5d9f9824bc - mrml::mjml::render::<impl mrml::prelude::render::Render for mrml::prelude::render::Renderer<mrml::mjml::Mjml,()>>::render::h6e38890b7ff5b7e6\r\n  24:     0x5a5d9f92aac9 - mrml::mjml::render::<impl mrml::mjml::Mjml>::render::h91b9362809157b27\r\n  25:     0x5a5d9f7f42e2 - mrml::main::h4221d81053c67f42\r\n  26:     0x5a5d9f8219a3 - std::sys_common::backtrace::__rust_begin_short_backtrace::h2e892df33ae86956\r\n  27:     0x5a5d9f8316a9 - std::rt::lang_start::{{closure}}::h542e0133c458501e\r\n  28:     0x5a5d9faf737f - std::rt::lang_start_internal::h0ae654f50e15aeea\r\n  29:     0x5a5d9f7f8f55 - main\r\n  30:     0x70f505b21e08 - <unknown>\r\n  31:     0x70f505b21ecc - __libc_start_main\r\n  32:     0x5a5d9f7d0895 - _start\r\n  33:                0x0 - <unknown>\r\n```\r\n\r\nThe Javascript implemention renders it without errors.\r\n\n", "patch": "diff --git a/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.html b/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.html\nnew file mode 100644\nindex 00000000..e5965df3\n--- /dev/null\n+++ b/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.html\n@@ -0,0 +1,115 @@\n+<!doctype html>\n+<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:v=\"urn:schemas-microsoft-com:vml\" xmlns:o=\"urn:schemas-microsoft-com:office:office\">\n+\n+<head>\n+  <title></title>\n+  <!--[if !mso]><!-->\n+  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n+  <!--<![endif]-->\n+  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n+  <style type=\"text/css\">\n+    #outlook a {\n+      padding: 0;\n+    }\n+\n+    body {\n+      margin: 0;\n+      padding: 0;\n+      -webkit-text-size-adjust: 100%;\n+      -ms-text-size-adjust: 100%;\n+    }\n+\n+    table,\n+    td {\n+      border-collapse: collapse;\n+      mso-table-lspace: 0pt;\n+      mso-table-rspace: 0pt;\n+    }\n+\n+    img {\n+      border: 0;\n+      height: auto;\n+      line-height: 100%;\n+      outline: none;\n+      text-decoration: none;\n+      -ms-interpolation-mode: bicubic;\n+    }\n+\n+    p {\n+      display: block;\n+      margin: 13px 0;\n+    }\n+\n+  </style>\n+  <!--[if mso]>\n+    <noscript>\n+    <xml>\n+    <o:OfficeDocumentSettings>\n+      <o:AllowPNG/>\n+      <o:PixelsPerInch>96</o:PixelsPerInch>\n+    </o:OfficeDocumentSettings>\n+    </xml>\n+    </noscript>\n+    <![endif]-->\n+  <!--[if lte mso 11]>\n+    <style type=\"text/css\">\n+      .mj-outlook-group-fix { width:100% !important; }\n+    </style>\n+    <![endif]-->\n+  <!--[if !mso]><!-->\n+  <link href=\"https://fonts.googleapis.com/css?family=Ubuntu:300,400,500,700\" rel=\"stylesheet\" type=\"text/css\">\n+  <style type=\"text/css\">\n+    @import url(https://fonts.googleapis.com/css?family=Ubuntu:300,400,500,700);\n+\n+  </style>\n+  <!--<![endif]-->\n+  <style type=\"text/css\">\n+    @media only screen and (min-width:480px) {\n+      .mj-column-per-100 {\n+        width: 100% !important;\n+        max-width: 100%;\n+      }\n+    }\n+\n+  </style>\n+  <style media=\"screen and (min-width:480px)\">\n+    .moz-text-html .mj-column-per-100 {\n+      width: 100% !important;\n+      max-width: 100%;\n+    }\n+\n+  </style>\n+</head>\n+\n+<body style=\"word-spacing:normal;\">\n+  <div style=\"\">\n+    <!--[if mso | IE]><table align=\"center\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"\" role=\"presentation\" style=\"width:600px;\" width=\"600\" ><tr><td style=\"line-height:0px;font-size:0px;mso-line-height-rule:exactly;\"><![endif]-->\n+    <div style=\"margin:0px auto;max-width:600px;\">\n+      <table align=\"center\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" role=\"presentation\" style=\"width:100%;\">\n+        <tbody>\n+          <tr>\n+            <td style=\"direction:ltr;font-size:0px;padding:20px 0;text-align:center;\">\n+              <!--[if mso | IE]><table role=\"presentation\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\"><tr><td class=\"\" style=\"vertical-align:top;width:600px;\" ><![endif]-->\n+              <div class=\"mj-column-per-100 mj-outlook-group-fix\" style=\"font-size:0px;text-align:left;direction:ltr;display:inline-block;vertical-align:top;width:100%;\">\n+                <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" role=\"presentation\" style=\"vertical-align:top;\" width=\"100%\">\n+                  <tbody>\n+                    <tr>\n+                      <td align=\"left\" style=\"font-size:0px;padding:10px 25px;word-break:break-word;\">\n+                        <div style=\"font-family:Ubuntu, Helvetica, Arial, sans-serif;font-size:13px;line-height:1;text-align:left;color:#000000;\"><mj-divider></mj-divider></div>\n+                      </td>\n+                    </tr>\n+                  </tbody>\n+                </table>\n+              </div>\n+              <!--[if mso | IE]></td></tr></table><![endif]-->\n+            </td>\n+          </tr>\n+        </tbody>\n+      </table>\n+    </div>\n+    <!--[if mso | IE]></td></tr></table><![endif]-->\n+  </div>\n+</body>\n+\n+</html>\ndiff --git a/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.mjml b/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.mjml\nnew file mode 100644\nindex 00000000..94626b6c\n--- /dev/null\n+++ b/packages/mrml-core/resources/compare/success/mj-divider-in-mj-text.mjml\n@@ -0,0 +1,11 @@\n+<mjml>\n+    <mj-body>\n+        <mj-section>\n+            <mj-column>\n+                <mj-text>\n+                    <mj-divider></mj-divider>\n+                </mj-text>\n+            </mj-column>\n+        </mj-section>\n+    </mj-body>\n+</mjml>\ndiff --git a/packages/mrml-core/src/mj_text/mod.rs b/packages/mrml-core/src/mj_text/mod.rs\nindex 2687380f..ad768b22 100644\n--- a/packages/mrml-core/src/mj_text/mod.rs\n+++ b/packages/mrml-core/src/mj_text/mod.rs\n@@ -1,6 +1,6 @@\n use std::marker::PhantomData;\n \n-use crate::mj_body::MjBodyChild;\n+use crate::mj_raw::MjRawChild;\n use crate::prelude::{Component, StaticTag};\n \n #[cfg(feature = \"json\")]\n@@ -22,4 +22,4 @@ impl StaticTag for MjTextTag {\n     }\n }\n \n-pub type MjText = Component<PhantomData<MjTextTag>, crate::prelude::AttributeMap, Vec<MjBodyChild>>;\n+pub type MjText = Component<PhantomData<MjTextTag>, crate::prelude::AttributeMap, Vec<MjRawChild>>;\n", "instance_id": "jdrouet__mrml-478", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: MRML panics when using `<mj-divider>` inside `<mj-text>` in an MJML template. It provides a reproducible example of the MJML code that causes the panic and includes a detailed stack trace, which helps in pinpointing the source of the error (an `Option::unwrap()` on a `None` value in the `mj_divider/render.rs` file). The goal is implicitly understood as fixing the panic to allow rendering of the provided MJML structure. However, there are minor ambiguities: the problem statement does not explicitly specify the expected behavior (e.g., how `<mj-divider>` should render inside `<mj-text>`), nor does it mention any constraints or edge cases to consider. Additionally, while it references a working JavaScript implementation, it lacks details on how the output should match or differ from it. These missing details prevent it from being fully comprehensive, but the issue is still well-defined enough to proceed with a solution.", "difficulty_explanation": "The difficulty of this problem falls in the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The provided code change is minimal, involving a single-line modification in `mj_text/mod.rs` to change the child type of `MjText` from `MjBodyChild` to `MjRawChild`. This suggests the fix is localized to adjusting how child components are handled within the `MjText` component, likely to allow raw rendering of elements like `<mj-divider>`. There is no indication of widespread changes across multiple files or significant architectural impact, as the change appears to be a type adjustment rather than a deep refactoring.\n\n2. **Technical Concepts Involved**: Solving this issue requires a basic understanding of Rust's type system and how the MRML library handles component hierarchies and rendering. The panic is caused by an `unwrap()` on a `None` value, which suggests a missing or incorrect assumption in the rendering logic of `mj-divider` when nested inside `mj-text`. The fix involves understanding the difference between `MjBodyChild` and `MjRawChild` in the context of the library, which is a relatively straightforward concept for someone familiar with Rust and the codebase. No advanced algorithms, design patterns, or domain-specific knowledge beyond MJML rendering are required.\n\n3. **Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the panic itself indicates a failure to handle a specific nesting scenario (`<mj-divider>` inside `<mj-text>`). The code change does not directly address error handling (e.g., adding checks to prevent `unwrap()` panics), but rather adjusts the type to potentially bypass the issue. Additional work might be needed to ensure robust error handling, but this does not appear to be complex based on the provided diff.\n\n4. **Overall Complexity**: The stack trace points to a specific location (`mj_divider/render.rs`), and the fix is a simple type change, suggesting that the root cause is not deeply buried in complex logic. While understanding the rendering pipeline of MRML might require some familiarity with the codebase, the modification itself is straightforward and does not involve intricate logic or performance considerations.\n\nGiven these points, a difficulty score of 0.30 reflects an \"Easy\" problem that requires understanding some code logic and making a simple modification, with minimal impact on the broader system.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "`INSTA_WORKSPACE_ROOT` should also work with `assert_snapshot!` at runtime, for manual test binaries\nI am evaluating insta with a project that uses [Buck2](https://github.com/facebook/buck2) (and also a very happy user using it with Cargo as part of [Jujutsu](https://github.com/martinvonz/jj)). When using a project with Buck2, Cargo is not used, and so tests for example are run \"manually\" by the build system itself after compilation with `--cfg=test`\r\n\r\nCurrently, I'm using inline snapshots, with a test like this:\r\n\r\n```rust\r\n#[cfg(test)]\r\nmod tests {\r\n    fn split_words(s: &str) -> Vec<&str> {\r\n        s.split_whitespace().collect()\r\n    }\r\n\r\n    #[test]\r\n    fn test_split_words() {\r\n        let words = split_words(\"goodbye from the other side\");\r\n        insta::assert_snapshot!(format!(\"{:?}\", words), @\"\");\r\n    }\r\n}\r\n```\r\n\r\nBy default, when I compile this with `buck2 build`, I get an error like so:\r\n\r\n```\r\nerror: environment variable `CARGO_MANIFEST_DIR` not defined at compile time\r\n   --> src/qq-cli/commands/script.rs:148:9\r\n    |\r\n148 |         insta::assert_snapshot!(format!(\"{:?}\", words), @\"\");\r\n    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\nBuck2 executes all tests from the root of the project, so luckily I can set `CARGO_MANIFEST_DIR=.` during the compilation of these tests which solves the problem. But it's a bit ugly I think.\r\n\r\nWhile using Code Search to browse the source code to figure out how the macro worked, it looks like `INSTA_WORKSPACE_ROOT` also has a similar function. It would at least be more *explanatory* when I write `INSTA_WORKSPACE_ROOT=.` in the source code why it exists. However, it seems like it only works when you use `cargo insta`.\r\n\r\nAlternatively, some other more general form or utility for `assert_snapshot!()` to work in the presence of non-Cargo systems would be nice.\n`INSTA_WORKSPACE_ROOT` should also work with `assert_snapshot!` at runtime, for manual test binaries\nI am evaluating insta with a project that uses [Buck2](https://github.com/facebook/buck2) (and also a very happy user using it with Cargo as part of [Jujutsu](https://github.com/martinvonz/jj)). When using a project with Buck2, Cargo is not used, and so tests for example are run \"manually\" by the build system itself after compilation with `--cfg=test`\r\n\r\nCurrently, I'm using inline snapshots, with a test like this:\r\n\r\n```rust\r\n#[cfg(test)]\r\nmod tests {\r\n    fn split_words(s: &str) -> Vec<&str> {\r\n        s.split_whitespace().collect()\r\n    }\r\n\r\n    #[test]\r\n    fn test_split_words() {\r\n        let words = split_words(\"goodbye from the other side\");\r\n        insta::assert_snapshot!(format!(\"{:?}\", words), @\"\");\r\n    }\r\n}\r\n```\r\n\r\nBy default, when I compile this with `buck2 build`, I get an error like so:\r\n\r\n```\r\nerror: environment variable `CARGO_MANIFEST_DIR` not defined at compile time\r\n   --> src/qq-cli/commands/script.rs:148:9\r\n    |\r\n148 |         insta::assert_snapshot!(format!(\"{:?}\", words), @\"\");\r\n    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\nBuck2 executes all tests from the root of the project, so luckily I can set `CARGO_MANIFEST_DIR=.` during the compilation of these tests which solves the problem. But it's a bit ugly I think.\r\n\r\nWhile using Code Search to browse the source code to figure out how the macro worked, it looks like `INSTA_WORKSPACE_ROOT` also has a similar function. It would at least be more *explanatory* when I write `INSTA_WORKSPACE_ROOT=.` in the source code why it exists. However, it seems like it only works when you use `cargo insta`.\r\n\r\nAlternatively, some other more general form or utility for `assert_snapshot!()` to work in the presence of non-Cargo systems would be nice.\n", "patch": "diff --git a/insta/src/env.rs b/insta/src/env.rs\nindex 776ef8b0..63ea8c4e 100644\n--- a/insta/src/env.rs\n+++ b/insta/src/env.rs\n@@ -12,18 +12,16 @@ use crate::{\n \n lazy_static::lazy_static! {\n     static ref WORKSPACES: Mutex<BTreeMap<String, Arc<PathBuf>>> = Mutex::new(BTreeMap::new());\n-    static ref TOOL_CONFIGS: Mutex<BTreeMap<String, Arc<ToolConfig>>> = Mutex::new(BTreeMap::new());\n+    static ref TOOL_CONFIGS: Mutex<BTreeMap<PathBuf, Arc<ToolConfig>>> = Mutex::new(BTreeMap::new());\n }\n \n-pub fn get_tool_config(manifest_dir: &str) -> Arc<ToolConfig> {\n-    let mut configs = TOOL_CONFIGS.lock().unwrap();\n-    if let Some(rv) = configs.get(manifest_dir) {\n-        return rv.clone();\n-    }\n-    let config =\n-        Arc::new(ToolConfig::from_manifest_dir(manifest_dir).expect(\"failed to load tool config\"));\n-    configs.insert(manifest_dir.to_string(), config.clone());\n-    config\n+pub fn get_tool_config(workspace_dir: &Path) -> Arc<ToolConfig> {\n+    TOOL_CONFIGS\n+        .lock()\n+        .unwrap()\n+        .entry(workspace_dir.to_path_buf())\n+        .or_insert_with(|| ToolConfig::from_workspace(workspace_dir).unwrap().into())\n+        .clone()\n }\n \n /// The test runner to use.\n@@ -125,11 +123,6 @@ pub struct ToolConfig {\n }\n \n impl ToolConfig {\n-    /// Loads the tool config for a specific manifest.\n-    pub fn from_manifest_dir(manifest_dir: &str) -> Result<ToolConfig, Error> {\n-        ToolConfig::from_workspace(&get_cargo_workspace(manifest_dir))\n-    }\n-\n     /// Loads the tool config from a cargo workspace.\n     pub fn from_workspace(workspace_dir: &Path) -> Result<ToolConfig, Error> {\n         let mut cfg = None;\n@@ -411,43 +404,61 @@ pub fn snapshot_update_behavior(tool_config: &ToolConfig, unseen: bool) -> Snaps\n \n /// Returns the cargo workspace for a manifest\n pub fn get_cargo_workspace(manifest_dir: &str) -> Arc<PathBuf> {\n-    // we really do not care about poisoning here.\n-    let mut workspaces = WORKSPACES.lock().unwrap_or_else(|x| x.into_inner());\n-    if let Some(rv) = workspaces.get(manifest_dir) {\n-        rv.clone()\n-    } else {\n-        // If INSTA_WORKSPACE_ROOT environment variable is set, use the value\n-        // as-is. This is useful for those users where the compiled in\n-        // CARGO_MANIFEST_DIR points to some transient location. This can easily\n-        // happen if the user builds the test in one directory but then tries to\n-        // run it in another: even if sources are available in the new\n-        // directory, in the past we would always go with the compiled-in value.\n-        // The compiled-in directory may not even exist anymore.\n-        let path = if let Ok(workspace_root) = std::env::var(\"INSTA_WORKSPACE_ROOT\") {\n-            Arc::new(PathBuf::from(workspace_root))\n-        } else {\n+    // If INSTA_WORKSPACE_ROOT environment variable is set, use the value as-is.\n+    // This is useful where CARGO_MANIFEST_DIR at compilation points to some\n+    // transient location. This can easily happen when building the test in one\n+    // directory but running it in another.\n+    if let Ok(workspace_root) = env::var(\"INSTA_WORKSPACE_ROOT\") {\n+        return PathBuf::from(workspace_root).into();\n+    }\n+\n+    let error_message = || {\n+        format!(\n+            \"`cargo metadata --format-version=1 --no-deps` in path `{}`\",\n+            manifest_dir\n+        )\n+    };\n+\n+    WORKSPACES\n+        .lock()\n+        // we really do not care about poisoning here.\n+        .unwrap()\n+        .entry(manifest_dir.to_string())\n+        .or_insert_with(|| {\n             let output = std::process::Command::new(\n-                env::var(\"CARGO\")\n-                    .ok()\n-                    .unwrap_or_else(|| \"cargo\".to_string()),\n+                env::var(\"CARGO\").unwrap_or_else(|_| \"cargo\".to_string()),\n             )\n-            .arg(\"metadata\")\n-            .arg(\"--format-version=1\")\n-            .arg(\"--no-deps\")\n+            .args([\"metadata\", \"--format-version=1\", \"--no-deps\"])\n             .current_dir(manifest_dir)\n             .output()\n-            .unwrap();\n-            let docs = crate::content::yaml::vendored::yaml::YamlLoader::load_from_str(\n+            .unwrap_or_else(|e| panic!(\"failed to run {}\\n\\n{}\", error_message(), e));\n+\n+            crate::content::yaml::vendored::yaml::YamlLoader::load_from_str(\n                 std::str::from_utf8(&output.stdout).unwrap(),\n             )\n-            .unwrap();\n-            let manifest = docs.first().expect(\"Unable to parse cargo manifest\");\n-            let workspace_root = PathBuf::from(manifest[\"workspace_root\"].as_str().unwrap());\n-            Arc::new(workspace_root)\n-        };\n-        workspaces.insert(manifest_dir.to_string(), path.clone());\n-        path\n-    }\n+            .map_err(|e| e.to_string())\n+            .and_then(|docs| {\n+                docs.into_iter()\n+                    .next()\n+                    .ok_or_else(|| \"No content found in yaml\".to_string())\n+            })\n+            .and_then(|metadata| {\n+                metadata[\"workspace_root\"]\n+                    .clone()\n+                    .into_string()\n+                    .ok_or_else(|| \"Couldn't find `workspace_root`\".to_string())\n+            })\n+            .map(|path| PathBuf::from(path).into())\n+            .unwrap_or_else(|e| {\n+                panic!(\n+                    \"failed to parse cargo metadata output from {}: {}\\n\\n{:?}\",\n+                    error_message(),\n+                    e,\n+                    output.stdout\n+                )\n+            })\n+        })\n+        .clone()\n }\n \n #[cfg(feature = \"_cargo_insta_internal\")]\ndiff --git a/insta/src/glob.rs b/insta/src/glob.rs\nindex e901702d..faec3a8b 100644\n--- a/insta/src/glob.rs\n+++ b/insta/src/glob.rs\n@@ -38,7 +38,7 @@ lazy_static::lazy_static! {\n     };\n }\n \n-pub fn glob_exec<F: FnMut(&Path)>(manifest_dir: &str, base: &Path, pattern: &str, mut f: F) {\n+pub fn glob_exec<F: FnMut(&Path)>(workspace_dir: &Path, base: &Path, pattern: &str, mut f: F) {\n     // If settings.allow_empty_glob() == true and `base` doesn't exist, skip\n     // everything. This is necessary as `base` is user-controlled via `glob!/3`\n     // and may not exist.\n@@ -61,7 +61,7 @@ pub fn glob_exec<F: FnMut(&Path)>(manifest_dir: &str, base: &Path, pattern: &str\n     GLOB_STACK.lock().unwrap().push(GlobCollector {\n         failed: 0,\n         show_insta_hint: false,\n-        fail_fast: get_tool_config(manifest_dir).glob_fail_fast(),\n+        fail_fast: get_tool_config(workspace_dir).glob_fail_fast(),\n     });\n \n     // step 1: collect all matching files\ndiff --git a/insta/src/macros.rs b/insta/src/macros.rs\nindex ba837e40..fd453acb 100644\n--- a/insta/src/macros.rs\n+++ b/insta/src/macros.rs\n@@ -15,6 +15,19 @@ macro_rules! _function_name {\n     }};\n }\n \n+#[doc(hidden)]\n+#[macro_export]\n+macro_rules! _get_workspace_root {\n+    () => {{\n+        use std::env;\n+\n+        // Note the `env!(\"CARGO_MANIFEST_DIR\")` needs to be in the macro (in\n+        // contrast to a function in insta) because the macro needs to capture\n+        // the value in the caller library, an exclusive property of macros.\n+        $crate::_macro_support::get_cargo_workspace(env!(\"CARGO_MANIFEST_DIR\"))\n+    }};\n+}\n+\n /// Asserts a `Serialize` snapshot in CSV format.\n ///\n /// **Feature:** `csv` (disabled by default)\n@@ -349,7 +362,7 @@ macro_rules! _assert_snapshot_base {\n             $name.into(),\n             #[allow(clippy::redundant_closure_call)]\n             &$transform(&$value),\n-            env!(\"CARGO_MANIFEST_DIR\"),\n+            $crate::_get_workspace_root!().as_path(),\n             $crate::_function_name!(),\n             module_path!(),\n             file!(),\n@@ -485,9 +498,13 @@ macro_rules! with_settings {\n #[cfg_attr(docsrs, doc(cfg(feature = \"glob\")))]\n #[macro_export]\n macro_rules! glob {\n+    // TODO: I think we could remove the three-argument version of this macro\n+    // and just support a pattern such as\n+    // `glob!(\"../test_data/inputs/*.txt\"...`.\n     ($base_path:expr, $glob:expr, $closure:expr) => {{\n         use std::path::Path;\n-        let base = $crate::_macro_support::get_cargo_workspace(env!(\"CARGO_MANIFEST_DIR\"))\n+\n+        let base = $crate::_get_workspace_root!()\n             .join(Path::new(file!()).parent().unwrap())\n             .join($base_path)\n             .to_path_buf();\n@@ -495,7 +512,12 @@ macro_rules! glob {\n         // we try to canonicalize but on some platforms (eg: wasm) that might not work, so\n         // we instead silently fall back.\n         let base = base.canonicalize().unwrap_or_else(|_| base);\n-        $crate::_macro_support::glob_exec(env!(\"CARGO_MANIFEST_DIR\"), &base, $glob, $closure);\n+        $crate::_macro_support::glob_exec(\n+            $crate::_get_workspace_root!().as_path(),\n+            &base,\n+            $glob,\n+            $closure,\n+        );\n     }};\n \n     ($glob:expr, $closure:expr) => {{\ndiff --git a/insta/src/runtime.rs b/insta/src/runtime.rs\nindex c2c363ed..4b5eba60 100644\n--- a/insta/src/runtime.rs\n+++ b/insta/src/runtime.rs\n@@ -8,14 +8,14 @@ use std::str;\n use std::sync::{Arc, Mutex};\n use std::{borrow::Cow, env};\n \n-use crate::output::SnapshotPrinter;\n use crate::settings::Settings;\n use crate::snapshot::{MetaData, PendingInlineSnapshot, Snapshot, SnapshotContents};\n use crate::utils::{path_to_storage, style};\n+use crate::{env::get_tool_config, output::SnapshotPrinter};\n use crate::{\n     env::{\n-        get_cargo_workspace, get_tool_config, memoize_snapshot_file, snapshot_update_behavior,\n-        OutputBehavior, SnapshotUpdateBehavior, ToolConfig,\n+        memoize_snapshot_file, snapshot_update_behavior, OutputBehavior, SnapshotUpdateBehavior,\n+        ToolConfig,\n     },\n     snapshot::SnapshotKind,\n };\n@@ -218,7 +218,7 @@ fn get_snapshot_filename(\n #[derive(Debug)]\n struct SnapshotAssertionContext<'a> {\n     tool_config: Arc<ToolConfig>,\n-    cargo_workspace: Arc<PathBuf>,\n+    workspace: &'a Path,\n     module_path: &'a str,\n     snapshot_name: Option<Cow<'a, str>>,\n     snapshot_file: Option<PathBuf>,\n@@ -233,14 +233,13 @@ struct SnapshotAssertionContext<'a> {\n impl<'a> SnapshotAssertionContext<'a> {\n     fn prepare(\n         refval: ReferenceValue<'a>,\n-        manifest_dir: &'a str,\n+        workspace: &'a Path,\n         function_name: &'a str,\n         module_path: &'a str,\n         assertion_file: &'a str,\n         assertion_line: u32,\n     ) -> Result<SnapshotAssertionContext<'a>, Box<dyn Error>> {\n-        let tool_config = get_tool_config(manifest_dir);\n-        let cargo_workspace = get_cargo_workspace(manifest_dir);\n+        let tool_config = get_tool_config(workspace);\n         let snapshot_name;\n         let mut duplication_key = None;\n         let mut snapshot_file = None;\n@@ -268,7 +267,7 @@ impl<'a> SnapshotAssertionContext<'a> {\n                     module_path,\n                     assertion_file,\n                     &name,\n-                    &cargo_workspace,\n+                    workspace,\n                     assertion_file,\n                     is_doctest,\n                 );\n@@ -290,7 +289,7 @@ impl<'a> SnapshotAssertionContext<'a> {\n                 snapshot_name = detect_snapshot_name(function_name, module_path)\n                     .ok()\n                     .map(Cow::Owned);\n-                let mut pending_file = cargo_workspace.join(assertion_file);\n+                let mut pending_file = workspace.join(assertion_file);\n                 pending_file.set_file_name(format!(\n                     \".{}.pending-snap\",\n                     pending_file\n@@ -311,7 +310,7 @@ impl<'a> SnapshotAssertionContext<'a> {\n \n         Ok(SnapshotAssertionContext {\n             tool_config,\n-            cargo_workspace,\n+            workspace,\n             module_path,\n             snapshot_name,\n             snapshot_file,\n@@ -326,8 +325,8 @@ impl<'a> SnapshotAssertionContext<'a> {\n \n     /// Given a path returns the local path within the workspace.\n     pub fn localize_path(&self, p: &Path) -> Option<PathBuf> {\n-        let workspace = self.cargo_workspace.canonicalize().ok()?;\n-        let p = self.cargo_workspace.join(p).canonicalize().ok()?;\n+        let workspace = self.workspace.canonicalize().ok()?;\n+        let p = self.workspace.join(p).canonicalize().ok()?;\n         p.strip_prefix(&workspace).ok().map(|x| x.to_path_buf())\n     }\n \n@@ -454,11 +453,8 @@ impl<'a> SnapshotAssertionContext<'a> {\n \n     /// This prints the information about the snapshot\n     fn print_snapshot_info(&self, new_snapshot: &Snapshot) {\n-        let mut printer = SnapshotPrinter::new(\n-            self.cargo_workspace.as_path(),\n-            self.old_snapshot.as_ref(),\n-            new_snapshot,\n-        );\n+        let mut printer =\n+            SnapshotPrinter::new(self.workspace, self.old_snapshot.as_ref(), new_snapshot);\n         printer.set_line(Some(self.assertion_line));\n         printer.set_snapshot_file(self.snapshot_file.as_deref());\n         printer.set_title(Some(\"Snapshot Summary\"));\n@@ -572,8 +568,7 @@ fn record_snapshot_duplicate(\n     if let Some(prev_snapshot) = results.get(key) {\n         if prev_snapshot.contents() != snapshot.contents() {\n             println!(\"Snapshots in allow-duplicates block do not match.\");\n-            let mut printer =\n-                SnapshotPrinter::new(ctx.cargo_workspace.as_path(), Some(prev_snapshot), snapshot);\n+            let mut printer = SnapshotPrinter::new(ctx.workspace, Some(prev_snapshot), snapshot);\n             printer.set_line(Some(ctx.assertion_line));\n             printer.set_snapshot_file(ctx.snapshot_file.as_deref());\n             printer.set_title(Some(\"Differences in Block\"));\n@@ -623,7 +618,7 @@ where\n pub fn assert_snapshot(\n     refval: ReferenceValue,\n     new_snapshot_value: &str,\n-    manifest_dir: &str,\n+    workspace: &Path,\n     function_name: &str,\n     module_path: &str,\n     assertion_file: &str,\n@@ -632,7 +627,7 @@ pub fn assert_snapshot(\n ) -> Result<(), Box<dyn Error>> {\n     let ctx = SnapshotAssertionContext::prepare(\n         refval,\n-        manifest_dir,\n+        workspace,\n         function_name,\n         module_path,\n         assertion_file,\n", "instance_id": "mitsuhiko__insta-614", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "\nThe problem statement is mostly clear in describing the issue: the `insta` library's `assert_snapshot!` macro does not work seamlessly with non-Cargo build systems like Buck2 due to reliance on the `CARGO_MANIFEST_DIR` environment variable at compile time. The goal is to make `INSTA_WORKSPACE_ROOT` functional at runtime for manual test binaries, providing a more intuitive solution for such environments. The statement includes a relevant code example and error message, which helps in understanding the context. However, there are minor ambiguities and missing details. For instance, it does not explicitly define the expected behavior of `INSTA_WORKSPACE_ROOT` in all scenarios (e.g., precedence over other variables, fallback mechanisms) nor does it mention specific edge cases or constraints for non-Cargo systems. Additionally, while an alternative utility is suggested, it lacks specificity on what form this utility should take. Overall, the problem is valid and mostly clear but could benefit from additional details on edge cases and precise requirements.\n", "difficulty_explanation": "\nI assign a difficulty score of 0.65, placing this problem in the \"Hard\" category, due to several factors:\n\n1. **Scope and Depth of Code Changes**: The provided code changes span multiple files (`env.rs`, `glob.rs`, `macros.rs`, `runtime.rs`) within the `insta` library, indicating a non-trivial modification across different modules. The changes involve refactoring how workspace paths are determined and used, replacing reliance on `CARGO_MANIFEST_DIR` with a more flexible approach using `INSTA_WORKSPACE_ROOT` at runtime. This impacts core functionality related to snapshot testing and requires understanding the interaction between macros, environment variables, and runtime behavior. While the changes do not appear to alter the system's architecture fundamentally, they affect critical logic for path resolution and configuration loading, which are central to the library's operation.\n\n2. **Number of Technical Concepts**: Solving this problem requires a solid grasp of several Rust-specific concepts, including macros (defining and using them to capture compile-time environment variables), environment variable handling, path manipulation with `std::path::PathBuf`, and synchronization primitives like `Mutex` for managing static state. Additionally, familiarity with the `insta` library's internal design (e.g., how snapshots are stored and compared) and Cargo's workspace metadata handling is necessary. The changes also involve error handling improvements in the `get_cargo_workspace` function, requiring knowledge of Rust's error handling patterns. These concepts are moderately to highly complex, especially for someone not deeply familiar with Rust's macro system or the `insta` library.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes suggest several that need consideration, such as when `INSTA_WORKSPACE_ROOT` is not set, when paths cannot be canonicalized (e.g., on platforms like Wasm), or when `cargo metadata` commands fail. The modifications include enhanced error messages and panic handling in `get_cargo_workspace`, indicating attention to robustness. These edge cases add complexity, as they require ensuring the library remains functional across diverse environments (Cargo and non-Cargo) and handles failures gracefully.\n\n4. **Overall Complexity**: The task requires a deep understanding of the `insta` library's internals and Rust's compile-time and runtime behaviors. The changes, while not architectural, are intricate due to the need to maintain compatibility with existing functionality while extending support for non-Cargo systems. This involves balancing compile-time constraints with runtime flexibility, which is a nuanced problem. The difficulty is further elevated by the need to ensure backward compatibility and avoid introducing regressions in snapshot handling.\n\nIn summary, this problem is challenging due to the breadth of code changes, the depth of Rust-specific knowledge required, and the implicit handling of edge cases. It falls short of \"Very Hard\" (0.8-1.0) as it does not involve system-level redesign or highly specialized domain knowledge, but it is beyond \"Medium\" (0.4-0.6) due to the complexity of the concepts and the impact on core library functionality.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Infinite loop after decoding error\nSimilar to behavior in #96 but different enough to warrant its own issue. Notably #97 does not fix this problem.\r\n\r\nAfter a decoding error `try_finish` goes into an infinite loop:\r\n```\r\n#[test]\r\nfn write_invalid() {\r\n    let contents = b\"BZh\\xfb\";\r\n    let mut decoder = bzip2::write::BzDecoder::new(Vec::new());\r\n    dbg!(decoder.write(&contents[..]));\r\n    dbg!(decoder.try_finish());\r\n}\r\n```\r\n\r\nI'm explicitly calling `try_finish` here to show the problem. But since the `Drop` implementation calls `try_finish` this cannot be avoided by not calling `try_finish`.\n", "patch": "diff --git a/src/write.rs b/src/write.rs\nindex 5d80000e..24d5e247 100644\n--- a/src/write.rs\n+++ b/src/write.rs\n@@ -254,11 +254,13 @@ impl<W: Write> Write for BzDecoder<W> {\n             let res = self.data.decompress_vec(data, &mut self.buf);\n             let written = (self.total_in() - before) as usize;\n \n-            let res = res.map_err(|e| io::Error::new(io::ErrorKind::InvalidInput, e))?;\n+            // make sure that a subsequent call exits early when there is nothing useful left to do\n+            self.done |= matches!(res, Err(_) | Ok(Status::StreamEnd));\n \n-            if res == Status::StreamEnd {\n-                self.done = true;\n+            if let Err(e) = res {\n+                return Err(io::Error::new(io::ErrorKind::InvalidInput, e));\n             }\n+\n             if written > 0 || data.is_empty() || self.done {\n                 return Ok(written);\n             }\n@@ -309,6 +311,14 @@ mod tests {\n         assert_eq!(&data[..], b\"\");\n     }\n \n+    #[test]\n+    fn write_invalid() {\n+        // see https://github.com/trifectatechfoundation/bzip2-rs/issues/98\n+        let mut d = BzDecoder::new(Vec::new());\n+        let e = d.write(b\"BZh\\xfb\").unwrap_err();\n+        assert_eq!(e.kind(), std::io::ErrorKind::InvalidInput);\n+    }\n+\n     #[test]\n     fn qc() {\n         ::quickcheck::quickcheck(test as fn(_) -> _);\n", "instance_id": "trifectatechfoundation__bzip2-rs-99", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: an infinite loop occurs in the `try_finish` method after a decoding error in the `bzip2-rs` library. It provides a minimal reproducible example in the form of a test case, which helps in understanding the problem context. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly describe the expected behavior after a decoding error (e.g., should it terminate gracefully, return a specific error, etc.?). Additionally, while it references related issues (#96 and #97), it lacks context about those issues, which could be critical for a complete understanding. Constraints or edge cases beyond the provided test are not mentioned, leaving some room for interpretation. Overall, the statement is valid and clear enough to start working on, but it could benefit from more detailed requirements or expected outcomes.", "difficulty_explanation": "The difficulty of this problem falls in the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes:** The code changes are localized to a single file (`write.rs`) and involve a small number of lines. The modification primarily focuses on updating the logic in the `Write` implementation for `BzDecoder` to handle decoding errors by setting a `done` flag early and returning an error. Additionally, a new test case is added to validate the fix. The changes do not impact the broader architecture of the system or require modifications across multiple modules, keeping the scope limited.\n\n2. **Technical Concepts Involved:** Solving this problem requires a basic understanding of Rust's I/O handling (specifically the `Write` trait and `io::Error`), control flow, and state management within a struct (using the `done` flag). The concepts are relatively straightforward for someone familiar with Rust, and no advanced algorithms, design patterns, or domain-specific knowledge (beyond basic compression library behavior) are needed. The fix involves simple logic to detect and handle an error condition to prevent an infinite loop.\n\n3. **Edge Cases and Error Handling:** The problem statement highlights a specific error condition (decoding error leading to an infinite loop), and the provided test case covers this scenario. The code change addresses this by ensuring the loop exits early when an error occurs or the stream ends. However, no additional edge cases (e.g., partial writes, buffer overflows, or other invalid inputs) are mentioned or handled in the changes, so the complexity of error handling remains low.\n\n4. **Overall Complexity:** The problem requires understanding a small part of the codebase (the `BzDecoder` struct and its `Write` implementation) and making a targeted fix. While it involves debugging an infinite loop, the root cause is identifiable from the test case, and the solution is a simple state update and early return. This does not demand deep architectural knowledge or extensive experience, making it accessible to developers with intermediate Rust skills.\n\nA score of 0.35 reflects that this is slightly more challenging than a trivial fix (e.g., changing a constant) due to the need to understand the error condition and modify control flow, but it remains in the easy category as it does not involve complex logic, multiple files, or advanced concepts.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Support `allow_hyphen_values` in native completions\n### Please complete the following tasks\n\n- [X] I have searched the [discussions](https://github.com/clap-rs/clap/discussions)\n- [X] I have searched the [open](https://github.com/clap-rs/clap/issues) and [rejected](https://github.com/clap-rs/clap/issues?q=is%3Aissue+label%3AS-wont-fix+is%3Aclosed) issues\n\n### Clap Version\n\nmaster\n\n### Describe your use case\n\n```\r\nuse clap::{CommandFactory, Parser};\r\nuse clap_complete::dynamic::shells::CompleteCommand;\r\n#[derive(Parser, Debug)]\r\n#[clap(name = \"dynamic\", about = \"A dynamic command line tool\")]\r\nstruct Cli {\r\n    /// The subcommand to run complete\r\n    #[command(subcommand)]\r\n    complete: Option<CompleteCommand>,\r\n    /// Output format\r\n    #[clap(short = 'F', long, value_parser = [\"--json\", \"--yaml\", \"--toml\"], allow_hyphen_values = true)]\r\n    format: Option<String>,\r\n    #[clap(long)]\r\n    json: Option<String>,\r\n}\r\nfn main() {\r\n    let cli = Cli::parse();\r\n    if let Some(completions) = cli.complete {\r\n        completions.complete(&mut Cli::command());\r\n    }\r\n    // normal logic continues...\r\n}\r\n```\r\nFor the command line:\r\n```\r\ndynamic --format --json --js[TAB]\r\n```\r\nThere is no completion generated.\r\nit should be:\r\n```\r\ndynamic --format --json --json \r\n```\r\n\r\nThis seems to be a very specific use case, but it shows that there is an error in parsing during dynamic completion when the allow_hyphen_values setting is enabled, or that allow_hyphen_values is not being considered.\n\n### Describe the solution you'd like\n\nhttps://github.com/clap-rs/clap/blob/5efa52ad4501393d50e236d10a979313a61d4929/clap_complete/src/dynamic/completer.rs#L76\r\nhttps://github.com/clap-rs/clap/blob/5efa52ad4501393d50e236d10a979313a61d4929/clap_complete/src/dynamic/completer.rs#L79\r\nhttps://github.com/clap-rs/clap/blob/5efa52ad4501393d50e236d10a979313a61d4929/clap_complete/src/dynamic/completer.rs#L112\r\ndo something more in these branches\n\n### Alternatives, if applicable\n\n_No response_\n\n### Additional Context\n\nThere are also user cases related to the mistaken parsing.\r\n## Case 1\r\n```\r\nuse clap::{CommandFactory, Parser};\r\nuse clap_complete::dynamic::shells::CompleteCommand;\r\n#[derive(Parser, Debug)]\r\n#[clap(name = \"dynamic\", about = \"A dynamic command line tool\")]\r\nstruct Cli {\r\n    /// The subcommand to run complete\r\n    #[command(subcommand)]\r\n    complete: Option<CompleteCommand>,\r\n    /// Output format\r\n    #[clap(short = 'F', long, value_parser = [\"json\", \"yaml\", \"toml\"], allow_hyphen_values = true)]\r\n    format: Option<String>,\r\n    #[clap(value_parser = [\"--pos_a\"], index = 1)]\r\n    positional_a: Option<String>,\r\n    #[clap(value_parser = [\"pos_b\"], index = 2)]\r\n    positional_b: Option<String>,\r\n}\r\nfn main() {\r\n    let cli = Cli::parse();\r\n    if let Some(completions) = cli.complete {\r\n        completions.complete(&mut Cli::command());\r\n    }\r\n    // normal logic continues...\r\n}\r\n```\r\nFor the command line\r\n```\r\ndynamic --format json --pos_a [TAB]\r\n```\r\ncompletions are:\r\n```\r\n--format  --help    --pos_a   -F        -h        help\r\n```\r\nit should be:\r\n```\r\npos_b --format  --help    -F        -h        help\r\n```\r\n\r\n## Case 2\r\n```\r\nuse clap::{CommandFactory, Parser};\r\nuse clap_complete::dynamic::shells::CompleteCommand;\r\n#[derive(Parser, Debug)]\r\n#[clap(name = \"dynamic\", about = \"A dynamic command line tool\")]\r\nstruct Cli {\r\n    /// The subcommand to run complete\r\n    #[command(subcommand)]\r\n    complete: Option<CompleteCommand>,\r\n    /// Output format\r\n    #[clap(short = 'F', long, value_parser = [\"json\", \"yaml\", \"toml\"], allow_hyphen_values = true)]\r\n    format: Option<String>,\r\n    #[clap(value_parser = [\"-a\"], index = 1)]\r\n    positional_a: Option<String>,\r\n    #[clap(value_parser = [\"pos_b\"], index = 2)]\r\n    positional_b: Option<String>,\r\n}\r\nfn main() {\r\n    let cli = Cli::parse();\r\n    if let Some(completions) = cli.complete {\r\n        completions.complete(&mut Cli::command());\r\n    }\r\n    // normal logic continues...\r\n}\r\n```\r\nFor the command line\r\n```\r\ndynamic --format json -a [TAB]\r\n```\r\ncompletions are:\r\n```\r\n--format  --help    -F        -a        -h        help\r\n```\r\nit should be:\r\n```\r\npos_b --format  --help    -F        -h        help\r\n```\n", "patch": "diff --git a/clap_complete/src/engine/complete.rs b/clap_complete/src/engine/complete.rs\nindex b9bb252293e..75dad1b2b14 100644\n--- a/clap_complete/src/engine/complete.rs\n+++ b/clap_complete/src/engine/complete.rs\n@@ -58,6 +58,11 @@ pub fn complete(\n                 parse_positional(current_cmd, pos_index, is_escaped, current_state);\n         } else if arg.is_escape() {\n             is_escaped = true;\n+        } else if opt_allows_hyphen(&current_state, &arg) {\n+            match current_state {\n+                ParseState::Opt((opt, count)) => next_state = parse_opt_value(opt, count),\n+                _ => unreachable!(\"else branch is only reachable in Opt state\"),\n+            }\n         } else if let Some((flag, value)) = arg.to_long() {\n             if let Ok(flag) = flag {\n                 let opt = current_cmd.get_arguments().find(|a| {\n@@ -69,10 +74,14 @@ pub fn complete(\n                     });\n                     is_find.unwrap_or(false)\n                 });\n-                if opt.map(|o| o.get_action().takes_values()).unwrap_or(false) {\n-                    if value.is_none() {\n-                        next_state = ParseState::Opt((opt.unwrap(), 1));\n+\n+                if let Some(opt) = opt {\n+                    if opt.get_action().takes_values() && value.is_none() {\n+                        next_state = ParseState::Opt((opt, 1));\n                     };\n+                } else if pos_allows_hyphen(current_cmd, pos_index) {\n+                    (next_state, pos_index) =\n+                        parse_positional(current_cmd, pos_index, is_escaped, current_state);\n                 }\n             }\n         } else if let Some(short) = arg.to_short() {\n@@ -81,6 +90,9 @@ pub fn complete(\n                 if short.next_value_os().is_none() {\n                     next_state = ParseState::Opt((opt, 1));\n                 }\n+            } else if pos_allows_hyphen(current_cmd, pos_index) {\n+                (next_state, pos_index) =\n+                    parse_positional(current_cmd, pos_index, is_escaped, current_state);\n             }\n         } else {\n             match current_state {\n@@ -88,14 +100,7 @@ pub fn complete(\n                     (next_state, pos_index) =\n                         parse_positional(current_cmd, pos_index, is_escaped, current_state);\n                 }\n-\n-                ParseState::Opt((opt, count)) => {\n-                    let range = opt.get_num_args().expect(\"built\");\n-                    let max = range.max_values();\n-                    if count < max {\n-                        next_state = ParseState::Opt((opt, count + 1));\n-                    }\n-                }\n+                ParseState::Opt((opt, count)) => next_state = parse_opt_value(opt, count),\n             }\n         }\n     }\n@@ -546,3 +551,32 @@ fn parse_positional<'a>(\n         ),\n     }\n }\n+\n+/// Parse optional flag argument. Return new state\n+fn parse_opt_value(opt: &clap::Arg, count: usize) -> ParseState<'_> {\n+    let range = opt.get_num_args().expect(\"built\");\n+    let max = range.max_values();\n+    if count < max {\n+        ParseState::Opt((opt, count + 1))\n+    } else {\n+        ParseState::ValueDone\n+    }\n+}\n+\n+fn pos_allows_hyphen(cmd: &clap::Command, pos_index: usize) -> bool {\n+    cmd.get_positionals()\n+        .find(|a| a.get_index() == Some(pos_index))\n+        .map(|p| p.is_allow_hyphen_values_set())\n+        .unwrap_or(false)\n+}\n+\n+fn opt_allows_hyphen(state: &ParseState<'_>, arg: &clap_lex::ParsedArg<'_>) -> bool {\n+    let val = arg.to_value_os();\n+    if val.starts_with(\"-\") {\n+        if let ParseState::Opt((opt, _)) = state {\n+            return opt.is_allow_hyphen_values_set();\n+        }\n+    }\n+\n+    false\n+}\n", "instance_id": "clap-rs__clap-5628", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in describing the issue with dynamic command-line completions in the `clap-rs` library when the `allow_hyphen_values` setting is enabled. It provides specific use cases with code examples and expected versus actual behavior, which helps in understanding the problem. The goal is evident: to support `allow_hyphen_values` in native completions by fixing parsing errors. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define all edge cases or constraints related to hyphenated values (e.g., how nested or complex hyphenated arguments should be handled). Additionally, while it points to specific lines in the codebase for potential fixes, it lacks detailed guidance on the exact logic or approach to resolve the issue, leaving some interpretation to the developer. Overall, it is clear enough to start working on but could benefit from more comprehensive edge case documentation and solution direction.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes is relatively focused, primarily affecting the `clap_complete` module's parsing logic in a single file (`complete.rs`). However, the changes require a deep understanding of the `clap` library's internal parsing mechanisms and state management, which are non-trivial. The developer must grasp specific technical concepts such as argument parsing states (`ParseState`), handling of optional and positional arguments, and the behavior of `allow_hyphen_values`, which involves nuanced logic to differentiate between flags and values starting with hyphens. The code changes introduce new helper functions (`pos_allows_hyphen`, `opt_allows_hyphen`, `parse_opt_value`) and modify existing control flow, indicating a moderate level of complexity in implementation. Additionally, the problem involves handling edge cases related to hyphenated values and positional arguments, as demonstrated in the provided use cases, which adds to the challenge of ensuring correctness across various input scenarios. While the changes do not impact the broader system architecture, they require careful consideration of interactions within the parsing engine. Overall, this problem demands a solid understanding of Rust, the `clap` library's internals, and precise logic to handle specific parsing rules, justifying a difficulty score of 0.65.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Nushell completions should use `glob` type for paths\n### Please complete the following tasks\r\n\r\n- [X] I have searched the [discussions](https://github.com/clap-rs/clap/discussions)\r\n- [x] I have searched the [open](https://github.com/clap-rs/clap/issues) and [rejected](https://github.com/clap-rs/clap/issues?q=is%3Aissue+label%3AS-wont-fix+is%3Aclosed) issues\r\n\r\n### Rust Version\r\n\r\nrustc 1.80.0 (051478957 2024-07-21) (Alpine Linux 1.80.0-r0)\r\n\r\n### Clap Version\r\n\r\n4.4.6 (4.5.3 for `clap_complete_nushell`)\r\n\r\n### Minimal reproducible code\r\n\r\n```rust\r\nuse clap::{CommandFactory, Parser};\r\nuse clap_complete::generate;\r\nuse clap_complete_nushell::Nushell;\r\n\r\nuse std::path::PathBuf;\r\n\r\n#[derive(Parser)]\r\npub struct Options {\r\n    path: PathBuf,\r\n\r\n    rest: Vec<PathBuf>,\r\n}\r\n\r\nfn main() {\r\n    let mut cmd = Options::command();\r\n    generate(Nushell, &mut cmd, \"sd\", &mut std::io::stdout());\r\n}\r\n```\r\n\r\n\r\n### Steps to reproduce the bug with the above code\r\n\r\n`cargo run`\r\n\r\n### Actual Behaviour\r\n\r\nThe following completion is generated:\r\n\r\n```Nushell\r\nmodule completions {\r\n\r\n  export extern sd [\r\n    path: string\r\n    ...rest: string\r\n    --help(-h)                # Print help\r\n  ]\r\n\r\n}\r\n\r\nexport use completions *\r\n```\r\n\r\n### Expected Behaviour\r\n\r\n- Arguments with type `PathBuf` should have the `path` type in the completions, so that the native path completion works.\r\n- Arguments with type `Vec<PathBuf>` should have the `glob` type, otherwise globbing breaks: `sd a *` will return an error, because path `*` doesn't exist. \r\n\r\n### Additional Context\r\n\r\n_No response_\r\n\r\n### Debug Output\r\n\r\n```\r\n[clap_builder::builder::command]Command::_build: name=\"compl\"\r\n[clap_builder::builder::command]Command::_propagate:compl\r\n[clap_builder::builder::command]Command::_check_help_and_version:compl expand_help_tree=true\r\n[clap_builder::builder::command]Command::long_help_exists\r\n[clap_builder::builder::command]Command::_check_help_and_version: Building default --help\r\n[clap_builder::builder::command]Command::_propagate_global_args:compl\r\n[clap_builder::builder::debug_asserts]Command::_debug_asserts\r\n[clap_builder::builder::debug_asserts]Arg::_debug_asserts:path\r\n[clap_builder::builder::debug_asserts]Arg::_debug_asserts:rest\r\n[clap_builder::builder::debug_asserts]Arg::_debug_asserts:help\r\n[clap_builder::builder::debug_asserts]Command::_verify_positionals\r\n[clap_builder::builder::command]Command::_build_bin_names\r\n[ clap_builder::output::usage]Usage::get_required_usage_from: incls=[], matcher=false, incl_last=true\r\n[ clap_builder::output::usage]Usage::get_required_usage_from: unrolled_reqs=[\"path\"]\r\n[ clap_builder::output::usage]Usage::get_required_usage_from:iter:\"path\" arg is_present=false\r\n[ clap_builder::output::usage]Usage::get_required_usage_from: ret_val=[StyledStr(\"<PATH>\")]\r\n```\n", "patch": "diff --git a/clap_complete_nushell/src/lib.rs b/clap_complete_nushell/src/lib.rs\nindex e7f064e2d4a..b95a835e526 100644\n--- a/clap_complete_nushell/src/lib.rs\n+++ b/clap_complete_nushell/src/lib.rs\n@@ -23,6 +23,7 @@\n #![warn(clippy::print_stdout)]\n \n use clap::builder::StyledStr;\n+use clap::ValueHint;\n use clap::{builder::PossibleValue, Arg, ArgAction, Command};\n use clap_complete::Generator;\n \n@@ -65,7 +66,23 @@ fn append_value_completion_and_help(\n         .unwrap_or(false);\n \n     if takes_values {\n-        s.push_str(\": string\");\n+        let nu_type = match arg.get_value_hint() {\n+            ValueHint::Unknown => \"string\",\n+            ValueHint::Other => \"string\",\n+            ValueHint::AnyPath => \"path\",\n+            ValueHint::FilePath => \"path\",\n+            ValueHint::DirPath => \"path\",\n+            ValueHint::ExecutablePath => \"path\",\n+            ValueHint::CommandName => \"string\",\n+            ValueHint::CommandString => \"string\",\n+            ValueHint::CommandWithArguments => \"string\",\n+            ValueHint::Username => \"string\",\n+            ValueHint::Hostname => \"string\",\n+            ValueHint::Url => \"string\",\n+            ValueHint::EmailAddress => \"string\",\n+            _ => \"string\",\n+        };\n+        s.push_str(format!(\": {nu_type}\").as_str());\n \n         if !possible_values.is_empty() {\n             s.push_str(format!(r#\"@\"nu-complete {} {}\"\"#, name, arg.get_id()).as_str());\n", "instance_id": "clap-rs__clap-5865", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear, providing a specific goal: to modify the Nushell completions generated by `clap_complete_nushell` so that arguments of type `PathBuf` use the `path` type and `Vec<PathBuf>` use the `glob` type. It includes a minimal reproducible code example, steps to reproduce, actual behavior, and expected behavior, which helps in understanding the issue. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly address potential edge cases (e.g., how to handle mixed types or invalid paths) or constraints around the implementation (e.g., performance considerations or backward compatibility). Additionally, while the context of `clap` and `nushell` integration is implied, it could be better detailed for someone unfamiliar with these tools. Overall, it is clear enough for someone with relevant context to proceed, but it lacks comprehensive coverage of edge cases and broader implications.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The code change is localized to a single file (`lib.rs` in the `clap_complete_nushell` crate) and involves modifying a specific part of the completion generation logic. The diff provided shows a straightforward update to map `ValueHint` types from `clap` to appropriate Nushell types (`path` or `string`). It does not impact the broader architecture of the system or require changes across multiple modules. The amount of code change is minimal, focusing on a single conditional block.\n\n2. **Technical Concepts Involved**: Solving this requires a basic understanding of Rust, specifically how `clap` handles argument metadata via `ValueHint` and how completions are generated for Nushell. The concepts are not particularly complex\u2014mainly pattern matching and string formatting. Familiarity with `clap`\u2019s API and Nushell\u2019s completion system is helpful but not deeply intricate for a senior engineer. No advanced algorithms, design patterns, or domain-specific knowledge beyond command-line tool development are needed.\n\n3. **Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, and the code change does not introduce new error handling logic. However, there is an implicit need to ensure that the mapping of `ValueHint` to Nushell types is correct for all possible hints (handled by the catch-all `_ => \"string\"` in the match). The complexity of edge cases is low, as the change primarily affects type annotations in generated output rather than runtime behavior.\n\n4. **Overall Complexity**: The task involves understanding a small part of the `clap_complete_nushell` logic and making a targeted modification. It does not require deep knowledge of the entire codebase or significant refactoring. The primary challenge might be verifying that the change works as expected across different argument configurations, but this is relatively straightforward with testing.\n\nGiven these points, a difficulty score of 0.35 reflects a problem that is slightly more involved than a trivial fix (e.g., changing a constant) due to the need to understand `ValueHint` and Nushell type mappings, but it remains an easy task for someone with moderate Rust experience and familiarity with command-line tools.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "text_editor::Content.text() gives inconsistent/misleading results\n### Is your issue REALLY a bug?\n\n- [x] My issue is indeed a bug!\n- [x] I am not crazy! I will not fill out this form just to ask a question or request a feature. Pinky promise.\n\n### Is there an existing issue for this?\n\n- [x] I have searched the existing issues.\n\n### Is this issue related to iced?\n\n- [x] My hardware is compatible and my graphics drivers are up-to-date.\n\n### What happened?\n\n`text_editor::Content::text()` appends a newline character ('\\n') to the end of the returned string if there is not one present.\n\nThis causes issues/inconsistencies when the actual content of the `text_editor` genuinely ends with a newline character.\n\nFor example, if I have a `text_editor` with no content in it, it displays on the screen as a box with a single line. At this point calling `text()` on its content returns a string with a length of 1 and content of \"\\n\".\n\nIf I then focus on the text_editor and hit return, the display correctly changes to a box with two lines. At this point, however, calling `text()` on the content returns a string with a length of 1 and content of \"\\n\".\n\nClearly at this stage the actual content of the `text_editor`s is different but I have no way of determining this when calling `text()` as it returns identical results for two different situations.\n\nThis issue is due to the check on lines 410-412 of [widget/src/text_editor.rs](https://github.com/iced-rs/iced/blob/2b920235b528590694930da542e77db973d82be7/widget/src/text_editor.rs#L410-L412):\n```\n        if !text.ends_with('\\n') {\n            text.push('\\n');\n        }\n```\n\n### What is the expected behavior?\n\nI expect to be able to unambiguously determine the content of the `text_editor` and relate it correctly to what is displayed on the screen.\n\nOptions I can see for this are:\n - Always add a newline character to the string returned by `text()`, allowing the consumer to handle removing the newline to get to the actual content\n - Never add a newline, leaving the consumer to add their own newline should that fit their purposes\n\nPersonally, I would prefer that the response didn't add the newline so that what is returned to me is what is actually in the `text_editor`.\n\n### Version\n\nmaster\n\n### Operating System\n\nLinux\n\n### Do you have any log output?\n\n```shell\n\n```\n", "patch": "diff --git a/core/src/renderer/null.rs b/core/src/renderer/null.rs\nindex bbcdd8ffd3..5732c41bb9 100644\n--- a/core/src/renderer/null.rs\n+++ b/core/src/renderer/null.rs\n@@ -137,7 +137,7 @@ impl text::Editor for () {\n         None\n     }\n \n-    fn line(&self, _index: usize) -> Option<&str> {\n+    fn line(&self, _index: usize) -> Option<text::editor::Line<'_>> {\n         None\n     }\n \ndiff --git a/core/src/text/editor.rs b/core/src/text/editor.rs\nindex cd30db3a38..6921c61c6b 100644\n--- a/core/src/text/editor.rs\n+++ b/core/src/text/editor.rs\n@@ -3,6 +3,7 @@ use crate::text::highlighter::{self, Highlighter};\n use crate::text::{LineHeight, Wrapping};\n use crate::{Pixels, Point, Rectangle, Size};\n \n+use std::borrow::Cow;\n use std::sync::Arc;\n \n /// A component that can be used by widgets to edit multi-line text.\n@@ -28,7 +29,7 @@ pub trait Editor: Sized + Default {\n     fn selection(&self) -> Option<String>;\n \n     /// Returns the text of the given line in the [`Editor`], if it exists.\n-    fn line(&self, index: usize) -> Option<&str>;\n+    fn line(&self, index: usize) -> Option<Line<'_>>;\n \n     /// Returns the amount of lines in the [`Editor`].\n     fn line_count(&self) -> usize;\n@@ -189,3 +190,41 @@ pub enum Cursor {\n     /// Cursor selecting a range of text\n     Selection(Vec<Rectangle>),\n }\n+\n+/// A line of an [`Editor`].\n+#[derive(Clone, Debug, Default, Eq, PartialEq)]\n+pub struct Line<'a> {\n+    /// The raw text of the [`Line`].\n+    pub text: Cow<'a, str>,\n+    /// The line ending of the [`Line`].\n+    pub ending: LineEnding,\n+}\n+\n+/// The line ending of a [`Line`].\n+#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]\n+pub enum LineEnding {\n+    /// Use `\\n` for line ending (POSIX-style)\n+    #[default]\n+    Lf,\n+    /// Use `\\r\\n` for line ending (Windows-style)\n+    CrLf,\n+    /// Use `\\r` for line ending (many legacy systems)\n+    Cr,\n+    /// Use `\\n\\r` for line ending (some legacy systems)\n+    LfCr,\n+    /// No line ending\n+    None,\n+}\n+\n+impl LineEnding {\n+    /// Gets the string representation of the [`LineEnding`].\n+    pub fn as_str(self) -> &'static str {\n+        match self {\n+            Self::Lf => \"\\n\",\n+            Self::CrLf => \"\\r\\n\",\n+            Self::Cr => \"\\r\",\n+            Self::LfCr => \"\\n\\r\",\n+            Self::None => \"\",\n+        }\n+    }\n+}\ndiff --git a/examples/editor/src/main.rs b/examples/editor/src/main.rs\nindex 7032324a5a..c039672e0f 100644\n--- a/examples/editor/src/main.rs\n+++ b/examples/editor/src/main.rs\n@@ -117,8 +117,16 @@ impl Editor {\n                 } else {\n                     self.is_loading = true;\n \n+                    let mut text = self.content.text();\n+\n+                    if let Some(ending) = self.content.line_ending() {\n+                        if !text.ends_with(ending.as_str()) {\n+                            text.push_str(ending.as_str());\n+                        }\n+                    }\n+\n                     Task::perform(\n-                        save_file(self.file.clone(), self.content.text()),\n+                        save_file(self.file.clone(), text),\n                         Message::FileSaved,\n                     )\n                 }\ndiff --git a/graphics/src/text/editor.rs b/graphics/src/text/editor.rs\nindex 1f1d0050c8..c73d189c8e 100644\n--- a/graphics/src/text/editor.rs\n+++ b/graphics/src/text/editor.rs\n@@ -9,6 +9,7 @@ use crate::text;\n \n use cosmic_text::Edit as _;\n \n+use std::borrow::Cow;\n use std::fmt;\n use std::sync::{self, Arc};\n \n@@ -89,11 +90,17 @@ impl editor::Editor for Editor {\n             || (buffer.lines.len() == 1 && buffer.lines[0].text().is_empty())\n     }\n \n-    fn line(&self, index: usize) -> Option<&str> {\n-        self.buffer()\n-            .lines\n-            .get(index)\n-            .map(cosmic_text::BufferLine::text)\n+    fn line(&self, index: usize) -> Option<editor::Line<'_>> {\n+        self.buffer().lines.get(index).map(|line| editor::Line {\n+            text: Cow::Borrowed(line.text()),\n+            ending: match line.ending() {\n+                cosmic_text::LineEnding::Lf => editor::LineEnding::Lf,\n+                cosmic_text::LineEnding::CrLf => editor::LineEnding::CrLf,\n+                cosmic_text::LineEnding::Cr => editor::LineEnding::Cr,\n+                cosmic_text::LineEnding::LfCr => editor::LineEnding::LfCr,\n+                cosmic_text::LineEnding::None => editor::LineEnding::None,\n+            },\n+        })\n     }\n \n     fn line_count(&self) -> usize {\ndiff --git a/widget/src/text_editor.rs b/widget/src/text_editor.rs\nindex ad852ce984..a347076861 100644\n--- a/widget/src/text_editor.rs\n+++ b/widget/src/text_editor.rs\n@@ -50,12 +50,13 @@ use crate::core::{\n     Rectangle, Shell, Size, SmolStr, Theme, Vector,\n };\n \n+use std::borrow::Cow;\n use std::cell::RefCell;\n use std::fmt;\n use std::ops::DerefMut;\n use std::sync::Arc;\n \n-pub use text::editor::{Action, Edit, Motion};\n+pub use text::editor::{Action, Edit, Line, LineEnding, Motion};\n \n /// A multi-line text input.\n ///\n@@ -349,69 +350,47 @@ where\n     }\n \n     /// Returns the text of the line at the given index, if it exists.\n-    pub fn line(\n-        &self,\n-        index: usize,\n-    ) -> Option<impl std::ops::Deref<Target = str> + '_> {\n-        std::cell::Ref::filter_map(self.0.borrow(), |internal| {\n-            internal.editor.line(index)\n+    pub fn line(&self, index: usize) -> Option<Line<'_>> {\n+        let internal = self.0.borrow();\n+        let line = internal.editor.line(index)?;\n+\n+        Some(Line {\n+            text: Cow::Owned(line.text.into_owned()),\n+            ending: line.ending,\n         })\n-        .ok()\n     }\n \n     /// Returns an iterator of the text of the lines in the [`Content`].\n-    pub fn lines(\n-        &self,\n-    ) -> impl Iterator<Item = impl std::ops::Deref<Target = str> + '_> {\n-        struct Lines<'a, Renderer: text::Renderer> {\n-            internal: std::cell::Ref<'a, Internal<Renderer>>,\n-            current: usize,\n-        }\n-\n-        impl<'a, Renderer: text::Renderer> Iterator for Lines<'a, Renderer> {\n-            type Item = std::cell::Ref<'a, str>;\n-\n-            fn next(&mut self) -> Option<Self::Item> {\n-                let line = std::cell::Ref::filter_map(\n-                    std::cell::Ref::clone(&self.internal),\n-                    |internal| internal.editor.line(self.current),\n-                )\n-                .ok()?;\n-\n-                self.current += 1;\n-\n-                Some(line)\n-            }\n-        }\n-\n-        Lines {\n-            internal: self.0.borrow(),\n-            current: 0,\n-        }\n+    pub fn lines(&self) -> impl Iterator<Item = Line<'_>> {\n+        (0..)\n+            .map(|i| self.line(i))\n+            .take_while(Option::is_some)\n+            .flatten()\n     }\n \n     /// Returns the text of the [`Content`].\n-    ///\n-    /// Lines are joined with `'\\n'`.\n     pub fn text(&self) -> String {\n-        let mut text = self.lines().enumerate().fold(\n-            String::new(),\n-            |mut contents, (i, line)| {\n-                if i > 0 {\n-                    contents.push('\\n');\n-                }\n+        let mut contents = String::new();\n+        let mut lines = self.lines().peekable();\n \n-                contents.push_str(&line);\n+        while let Some(line) = lines.next() {\n+            contents.push_str(&line.text);\n \n-                contents\n-            },\n-        );\n-\n-        if !text.ends_with('\\n') {\n-            text.push('\\n');\n+            if lines.peek().is_some() {\n+                contents.push_str(if line.ending == LineEnding::None {\n+                    LineEnding::default().as_str()\n+                } else {\n+                    line.ending.as_str()\n+                });\n+            }\n         }\n \n-        text\n+        contents\n+    }\n+\n+    /// Returns the kind of [`LineEnding`] used for separating lines in the [`Content`].\n+    pub fn line_ending(&self) -> Option<LineEnding> {\n+        Some(self.line(0)?.ending)\n     }\n \n     /// Returns the selected text of the [`Content`].\n", "instance_id": "iced-rs__iced-2759", "clarity": 2, "difficulty": 0.55, "clarity_explanation": "\nThe problem statement is mostly clear in describing the issue with `text_editor::Content::text()` appending a newline character, which leads to inconsistent results when determining the actual content of the text editor. The goal is well-defined: to ensure the returned text accurately reflects the content without misleading modifications. The issue is supported by a specific example (empty content vs. content with a newline) and references the problematic code snippet. However, there are minor ambiguities, such as the lack of detailed discussion on edge cases (e.g., handling of different line ending styles across platforms) and the absence of explicit constraints or requirements for backward compatibility. Additionally, while two potential solutions are suggested (always add or never add a newline), the expected behavior isn't definitively mandated, leaving some room for interpretation. Overall, the statement is valid and clear but misses some minor details that could make it comprehensive.\n", "difficulty_explanation": "\nI rate the difficulty of this problem as medium (0.55) based on the following analysis of the factors:\n\n1. **Scope and Depth of Code Changes**: The code changes span multiple files (`core/src/text/editor.rs`, `graphics/src/text/editor.rs`, `widget/src/text_editor.rs`, and others), indicating a need to modify several parts of the codebase. The changes involve restructuring how lines and line endings are handled, including introducing new types (`Line` and `LineEnding`) and updating method signatures and implementations. While the changes are not architecturally disruptive, they require careful coordination across modules to ensure consistency in how text content is represented and accessed. The amount of code change is moderate, with significant logic updates in `text()` and related methods.\n\n2. **Number of Technical Concepts**: Solving this requires understanding Rust's ownership and borrowing model (e.g., using `Cow` for efficient string handling), familiarity with text rendering and editing libraries (like `cosmic_text`), and knowledge of line ending conventions across different platforms (e.g., LF, CRLF). Additionally, it involves API design considerations to ensure the new `Line` and `LineEnding` abstractions are intuitive and maintainable. These concepts are not overly advanced but require a solid intermediate-level understanding of Rust and text processing.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes reveal a need to handle various line ending styles (LF, CRLF, CR, etc.) and ensure that the `text()` method correctly reconstructs content without unintended modifications. Edge cases like empty content, single-line content with or without endings, and mixed line endings in multi-line content must be considered. The error handling logic isn't significantly complex, but ensuring correctness across these scenarios adds to the challenge.\n\n4. **Overall Complexity**: The problem falls into the medium difficulty range because it requires understanding and modifying multiple interconnected components, introducing new data structures, and handling subtle edge cases related to text representation. It is not a simple bug fix (e.g., changing a single condition) nor a highly complex architectural overhaul (e.g., redesigning the entire text editor system). It demands a good grasp of the existing codebase and careful implementation to avoid introducing new inconsistencies, but it does not require advanced domain-specific knowledge or system-level optimizations.\n\nThus, a score of 0.55 reflects a medium-level challenge that is approachable for developers with intermediate experience in Rust and text processing, while still requiring attention to detail and cross-module coordination.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Column heading of `hx --health languages` invisible on light terminal theme\n### Summary\n\nRunning `hx --health languages` on GNOME Terminal with the default light theme doesn't show the column names, only an empty line before printing the rest, rendering the checkmarks fairly useless if you don't already know what they mean.\r\n\r\nTrying to select the line doesn't help, only by changing to the dark terminal theme was I able to read the column names.\n\n### Reproduction Steps\n\n<!-- Ideally provide a key sequence and/or asciinema.org recording. --> \r\n\r\nI tried this:\r\n\r\n1. `hx --health languages`\r\n\r\nI expected this to happen:\r\n\r\nInstead, this happened:\r\n\n\n### Helix log\n\n<details><summary>~/.cache/helix/helix.log</summary>\r\n\r\n```\r\nplease provide a copy of `~/.cache/helix/helix.log` here if possible, you may need to redact some of the lines\r\n```\r\n\r\n</details>\r\n\n\n### Platform\n\nLinux\n\n### Terminal Emulator\n\nGNOME Terminal\n\n### Helix Version\n\nhelix 22.12 (96ff64a8)\n", "patch": "diff --git a/helix-term/src/health.rs b/helix-term/src/health.rs\nindex 88e7b27be4d7..faf632d8731c 100644\n--- a/helix-term/src/health.rs\n+++ b/helix-term/src/health.rs\n@@ -1,6 +1,6 @@\n use crate::config::{Config, ConfigLoadError};\n use crossterm::{\n-    style::{Color, Print, Stylize},\n+    style::{Color, StyledContent, Stylize},\n     tty::IsTty,\n };\n use helix_core::config::{default_lang_config, user_lang_config};\n@@ -164,25 +164,20 @@ pub fn languages_all() -> std::io::Result<()> {\n     let column_width = terminal_cols as usize / headings.len();\n     let is_terminal = std::io::stdout().is_tty();\n \n-    let column = |item: &str, color: Color| {\n-        let mut data = format!(\n-            \"{:width$}\",\n-            item.get(..column_width - 2)\n+    let fit = |s: &str| -> StyledContent<String> {\n+        format!(\n+            \"{:column_width$}\",\n+            s.get(..column_width - 2)\n                 .map(|s| format!(\"{}\u2026\", s))\n-                .unwrap_or_else(|| item.to_string()),\n-            width = column_width,\n-        );\n-        if is_terminal {\n-            data = data.stylize().with(color).to_string();\n-        }\n-\n-        // We can't directly use println!() because of\n-        // https://github.com/crossterm-rs/crossterm/issues/589\n-        let _ = crossterm::execute!(std::io::stdout(), Print(data));\n+                .unwrap_or_else(|| s.to_string())\n+        )\n+        .stylize()\n     };\n+    let color = |s: StyledContent<String>, c: Color| if is_terminal { s.with(c) } else { s };\n+    let bold = |s: StyledContent<String>| if is_terminal { s.bold() } else { s };\n \n     for heading in headings {\n-        column(heading, Color::White);\n+        write!(stdout, \"{}\", bold(fit(heading)))?;\n     }\n     writeln!(stdout)?;\n \n@@ -192,14 +187,14 @@ pub fn languages_all() -> std::io::Result<()> {\n \n     let check_binary = |cmd: Option<&str>| match cmd {\n         Some(cmd) => match helix_stdx::env::which(cmd) {\n-            Ok(_) => column(&format!(\"\u2713 {}\", cmd), Color::Green),\n-            Err(_) => column(&format!(\"\u2718 {}\", cmd), Color::Red),\n+            Ok(_) => color(fit(&format!(\"\u2713 {}\", cmd)), Color::Green),\n+            Err(_) => color(fit(&format!(\"\u2718 {}\", cmd)), Color::Red),\n         },\n-        None => column(\"None\", Color::Yellow),\n+        None => color(fit(\"None\"), Color::Yellow),\n     };\n \n     for lang in &syn_loader_conf.language {\n-        column(&lang.language_id, Color::Reset);\n+        write!(stdout, \"{}\", fit(&lang.language_id))?;\n \n         let mut cmds = lang.language_servers.iter().filter_map(|ls| {\n             syn_loader_conf\n@@ -207,28 +202,28 @@ pub fn languages_all() -> std::io::Result<()> {\n                 .get(&ls.name)\n                 .map(|config| config.command.as_str())\n         });\n-        check_binary(cmds.next());\n+        write!(stdout, \"{}\", check_binary(cmds.next()))?;\n \n         let dap = lang.debugger.as_ref().map(|dap| dap.command.as_str());\n-        check_binary(dap);\n+        write!(stdout, \"{}\", check_binary(dap))?;\n \n         let formatter = lang\n             .formatter\n             .as_ref()\n             .map(|formatter| formatter.command.as_str());\n-        check_binary(formatter);\n+        write!(stdout, \"{}\", check_binary(formatter))?;\n \n         for ts_feat in TsFeature::all() {\n             match load_runtime_file(&lang.language_id, ts_feat.runtime_filename()).is_ok() {\n-                true => column(\"\u2713\", Color::Green),\n-                false => column(\"\u2718\", Color::Red),\n+                true => write!(stdout, \"{}\", color(fit(\"\u2713\"), Color::Green))?,\n+                false => write!(stdout, \"{}\", color(fit(\"\u2718\"), Color::Red))?,\n             }\n         }\n \n         writeln!(stdout)?;\n \n         for cmd in cmds {\n-            column(\"\", Color::Reset);\n+            write!(stdout, \"{}\", fit(\"\"))?;\n             check_binary(Some(cmd));\n             writeln!(stdout)?;\n         }\n", "instance_id": "helix-editor__helix-12355", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in describing the issue: the column headings for the `hx --health languages` command are invisible on a light terminal theme in GNOME Terminal. The summary effectively communicates the core problem, and the reproduction steps, though minimal, are sufficient to understand how to replicate the issue. However, there are minor ambiguities and missing details. For instance, the \"expected\" and \"actual\" outcomes are not explicitly filled out in the reproduction steps, which could leave some room for interpretation. Additionally, there are no specific mentions of edge cases, desired behavior across different terminals or themes, or constraints on how the solution should be implemented. Despite these minor gaps, the problem is valid and the intent is understandable, especially when paired with the provided code changes. Hence, a score of 2 (Mostly Clear) is appropriate.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to several factors. First, the scope of the code changes is limited to a single file (`health.rs`) and focuses on modifying the rendering logic for terminal output, specifically how text is styled and displayed. The changes involve refactoring the way text is formatted and styled using the `crossterm` library, which requires a basic understanding of terminal styling and Rust's ownership model. The technical concepts involved are relatively straightforward: familiarity with Rust's standard I/O operations, the `crossterm` crate for terminal manipulation, and basic string formatting. The code changes are moderate in size but do not impact the broader architecture of the system, nor do they require deep knowledge of the overall codebase or complex interactions between modules. There are no explicit edge cases or error handling requirements mentioned in the problem statement, and the provided code changes do not introduce significant new error handling logic. The primary challenge lies in ensuring that the text is visible across different terminal themes, which is addressed by adjusting the styling logic (e.g., avoiding hardcoded colors that may not display well on light themes). Overall, this is a straightforward bug fix that a developer with basic to intermediate Rust experience can handle, justifying a difficulty score of 0.25.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "`bracketSameLine` not respected if comment before last parameter\n### Environment information\n\n```bash\nCLI:\r\n  Version:                      1.9.4\r\n  Color support:                true\r\n\r\nPlatform:\r\n  CPU Architecture:             aarch64\r\n  OS:                           macos\r\n\r\nEnvironment:\r\n  BIOME_LOG_PATH:               unset\r\n  BIOME_LOG_PREFIX_NAME:        unset\r\n  BIOME_CONFIG_PATH:            unset\r\n  NO_COLOR:                     unset\r\n  TERM:                         \"xterm-256color\"\r\n  JS_RUNTIME_VERSION:           \"v21.2.0\"\r\n  JS_RUNTIME_NAME:              \"node\"\r\n  NODE_PACKAGE_MANAGER:         \"yarn/4.5.3\"\r\n\r\nBiome Configuration:\r\n  Status:                       Loaded successfully\r\n  Formatter disabled:           false\r\n  Linter disabled:              false\r\n  Organize imports disabled:    false\r\n  VCS disabled:                 true\r\n\r\nFormatter:\r\n  Format with errors:           false\r\n  Indent style:                 Space\r\n  Indent width:                 4\r\n  Line ending:                  Lf\r\n  Line width:                   120\r\n  Attribute position:           Auto\r\n  Bracket spacing:              BracketSpacing(true)\r\n  Ignore:                       []\r\n  Include:                      []\r\n\r\nJavaScript Formatter:\r\n  Enabled:                      false\r\n  JSX quote style:              Double\r\n  Quote properties:             AsNeeded\r\n  Trailing commas:              All\r\n  Semicolons:                   Always\r\n  Arrow parentheses:            Always\r\n  Bracket spacing:              unset\r\n  Bracket same line:            true\r\n  Quote style:                  Double\r\n  Indent style:                 unset\r\n  Indent width:                 unset\r\n  Line ending:                  unset\r\n  Line width:                   unset\r\n  Attribute position:           unset\r\n\r\nJSON Formatter:\r\n  Enabled:                      true\r\n  Indent style:                 unset\r\n  Indent width:                 unset\r\n  Line ending:                  unset\r\n  Line width:                   unset\r\n  Trailing Commas:              unset\r\n\r\nCSS Formatter:\r\n  Enabled:                      true\r\n  Indent style:                 unset\r\n  Indent width:                 unset\r\n  Line ending:                  unset\r\n  Line width:                   unset\r\n  Quote style:                  Double\r\n\r\nGraphQL Formatter:\r\n  Enabled:                      false\r\n  Indent style:                 unset\r\n  Indent width:                 unset\r\n  Line ending:                  unset\r\n  Line width:                   unset\r\n  Bracket spacing:              unset\r\n  Quote style:                  unset\r\n\r\nWorkspace:\r\n  Open Documents:               0\n```\n\n\n### Configuration\n\n```JSON\n{\r\n    \"$schema\": \"https://biomejs.dev/schemas/1.9.4/schema.json\",\r\n    \"formatter\": {\r\n        \"enabled\": true,\r\n        \"formatWithErrors\": false,\r\n        \"indentStyle\": \"space\",\r\n        \"indentWidth\": 4,\r\n        \"lineEnding\": \"lf\",\r\n        \"lineWidth\": 120\r\n    },\r\n    \"javascript\": {\r\n        \"formatter\": {\r\n            \"bracketSameLine\": true\r\n        }\r\n    }\r\n}\n```\n\n\n### Playground link\n\nhttps://biomejs.dev/playground/?indentStyle=space&indentWidth=4&bracketSameLine=true&code=ZgB1AG4AYwB0AGkAbwBuACAAdABlAHMAdAAoACkAIAB7AAoAIAAgAHIAZQB0AHUAcgBuACAAPABTAG8AbQBlAHQAaABpAG4AZwAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwA9ACIAMQAiAAoAIAAgACAAIAAgACAAIAAgACAAIAAgAHMAbwBtAGUAdABoAGkAbgBnADIAPQAiADEAIgAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwAzAD0AIgAxACIACgAgACAAIAAgACAAIAAgACAAIAAgACAAcwBvAG0AZQB0AGgAaQBuAGcANAA9ACIAMQAiAAoAIAAgACAAIAAgACAAIAAgACAAIAAgAHMAbwBtAGUAdABoAGkAbgBnADUAPQAiADEAIgAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwA2AD0AIgAxACIACgAgACAAIAAgACAAIAAgACAAIAAgACAALwAvACAAQwBvAG0AbQBlAG4AdAAKACAAIAAgACAAIAAgACAAIAAgACAAIABlAGwAcwBlAD0AIgAyACIAPgAKACAAIAAgACAAQwBvAG4AdABlAG4AdAAKACAAIAA8AC8AUwBvAG0AZQB0AGgAaQBuAGcAPgAKAH0ACgAKAGYAdQBuAGMAdABpAG8AbgAgAHQAZQBzAHQAMgAoACkAIAB7AAoAIAAgAHIAZQB0AHUAcgBuACAAPABTAG8AbQBlAHQAaABpAG4AZwAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwA9ACIAMQAiAAoAIAAgACAAIAAgACAAIAAgACAAIAAgAHMAbwBtAGUAdABoAGkAbgBnADIAPQAiADEAIgAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwAzAD0AIgAxACIACgAgACAAIAAgACAAIAAgACAAIAAgACAAcwBvAG0AZQB0AGgAaQBuAGcANAA9ACIAMQAiAAoAIAAgACAAIAAgACAAIAAgACAAIAAgAHMAbwBtAGUAdABoAGkAbgBnADUAPQAiADEAIgAKACAAIAAgACAAIAAgACAAIAAgACAAIABzAG8AbQBlAHQAaABpAG4AZwA2AD0AIgAxACIACgAgACAAIAAgACAAIAAgACAAIAAgACAAZQBsAHMAZQA9ACIAMgAiAD4ACgAgACAAIAAgAEMAbwBuAHQAZQBuAHQACgAgACAAPAAvAFMAbwBtAGUAdABoAGkAbgBnAD4ACgB9AA%3D%3D\n\n### Code of Conduct\n\n- [X] I agree to follow Biome's Code of Conduct\n", "patch": "diff --git a/CHANGELOG.md b/CHANGELOG.md\nindex 34ef8f6c34bc..3e6ad3e3c32c 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -89,6 +89,8 @@ our [guidelines for writing a good changelog entry](https://github.com/biomejs/b\n \n - `noDuplicateProperties` now throws lint errors properly when we use `@supports` (fix [#4756](https://github.com/biomejs/biome/issues/4756)) Contributed by @mehm8128\n \n+- Fix [#4719](https://github.com/biomejs/biome/issues/4719), `bracketSameLine` now performs as expected when a comment is placed before the last JSX attribute. Contributed by @bushuai\n+\n ### JavaScript APIs\n \n ### Linter\ndiff --git a/crates/biome_js_formatter/src/jsx/tag/opening_element.rs b/crates/biome_js_formatter/src/jsx/tag/opening_element.rs\nindex 704b075a1ac3..7116f685521e 100644\n--- a/crates/biome_js_formatter/src/jsx/tag/opening_element.rs\n+++ b/crates/biome_js_formatter/src/jsx/tag/opening_element.rs\n@@ -152,6 +152,9 @@ impl AnyJsxOpeningElement {\n     fn compute_layout(&self, comments: &JsComments) -> SyntaxResult<OpeningElementLayout> {\n         let attributes = self.attributes();\n         let name = self.name()?;\n+        let last_attribute_has_comments = self.attributes().last().map_or(false, |attribute| {\n+            comments.has_trailing_comments(attribute.syntax())\n+        });\n \n         let name_has_comments = comments.has_comments(name.syntax())\n             || self\n@@ -171,7 +174,7 @@ impl AnyJsxOpeningElement {\n         } else {\n             OpeningElementLayout::IndentAttributes {\n                 name_has_comments,\n-                last_attribute_has_comments: has_last_attribute_comments(self, comments),\n+                last_attribute_has_comments,\n             }\n         };\n \n@@ -249,18 +252,3 @@ fn as_string_literal_attribute_value(attribute: &AnyJsxAttribute) -> Option<JsxS\n         JsxSpreadAttribute(_) => None,\n     }\n }\n-\n-fn has_last_attribute_comments(element: &AnyJsxOpeningElement, comments: &JsComments) -> bool {\n-    let has_comments_on_last_attribute = element\n-        .attributes()\n-        .last()\n-        .map_or(false, |attribute| comments.has_comments(attribute.syntax()));\n-\n-    let last_attribute_has_comments = element\n-        .syntax()\n-        .tokens()\n-        .map(|token| token.text().contains('>') && token.has_leading_comments())\n-        .any(|has_comment| has_comment);\n-\n-    has_comments_on_last_attribute || last_attribute_has_comments\n-}\n", "instance_id": "biomejs__biome-4835", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: the `bracketSameLine` configuration in Biome (a JavaScript formatter) is not respected when a comment appears before the last parameter/attribute in a JSX opening element. The environment information, configuration details, and a playground link provide sufficient context to understand the issue's scope and reproduce it. However, the problem statement lacks explicit mention of expected behavior beyond \"not respected,\" and there are no specific examples of input/output formatting to clarify the desired outcome. Additionally, edge cases or constraints (e.g., specific types of comments or attribute structures) are not detailed, which introduces minor ambiguity. Overall, while the goal is understandable, these missing details prevent it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The code changes are localized to a single file (`opening_element.rs`) within the Biome JS formatter crate. The modifications involve updating logic for detecting comments on the last attribute and removing an outdated function. The changeset is small (a few lines added and a redundant function removed), and it does not impact the broader system architecture or require changes across multiple modules.\n\n2. **Technical Concepts Involved**: Solving this requires understanding Rust syntax and logic, specifically working with syntax trees and comment handling in a formatter context. The concepts are relatively straightforward\u2014checking for trailing comments on attributes and adjusting layout logic. No advanced algorithms, design patterns, or domain-specific knowledge beyond basic formatter mechanics are needed.\n\n3. **Edge Cases and Error Handling**: The problem indirectly deals with an edge case (comments before the last attribute), but the solution does not introduce complex error handling or additional edge case considerations beyond the provided fix. The change focuses on correctly identifying comments, which is a narrow and manageable scope.\n\n4. **Overall Complexity**: The task requires understanding the specific behavior of `bracketSameLine` and how comments influence formatting layout in JSX elements. While this involves some code logic comprehension, it is not particularly deep or intricate. The fix is a targeted adjustment rather than a broad refactoring or feature addition.\n\nA score of 0.35 reflects that this is slightly more involved than a trivial fix (e.g., changing a constant) due to the need to understand comment handling and layout logic in a formatter, but it remains within the easy category as it does not demand extensive codebase knowledge or complex modifications.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "\ud83d\udc1b `noUnusedVariables` makes the semantic model panics on invalid code\n### Environment information\r\n\r\n```block\r\nMain\r\n```\r\n\r\n\r\n### What happened?\r\n\r\nGiven the following file named `main,js`:\r\n\r\n```js\r\nc;\r\nconst c = 0;\r\n```\r\n\r\nExecute the following command:\r\n\r\n```shell\r\nbiome lint --only=correctness/noUnusedVariables main.js\r\n````\r\n\r\nAnd then notice the panics:\r\n\r\n```shell\r\nBiome encountered an unexpected error\r\n\r\nThis is a bug in Biome, not an error in your code, and we would appreciate it if you could report it to https://github.com/biomejs/biome/issues/ along with the following information to help us fixing the issue:\r\n\r\nSource Location: crates/biome_js_semantic/src/semantic_model/model.rs:138:21\r\nThread Name: biome::worker_4\r\nMessage: internal error: entered unreachable code: Expected global scope not present\r\n\r\nmain.js internalError/panic  INTERNAL  \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n\r\n  \u2716 processing panicked: internal error: entered unreachable code: Expected global scope not present\r\n  \r\n  \u26a0 This diagnostic was derived from an internal Biome error. Potential bug, please report it if necessary.\r\n  \r\n\r\nChecked 0 files in 1558\u00b5s. No fixes applied.\r\ninternalError/io \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\r\n\r\n  \u2716 No files were processed in the specified paths.\r\n```\r\n\r\n### Expected result\r\n\r\nBiome should not panic.\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow Biome's Code of Conduct\n", "patch": "diff --git a/CHANGELOG.md b/CHANGELOG.md\nindex 10b3283d1cc7..de1864582c7b 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -105,6 +105,8 @@ our [guidelines for writing a good changelog entry](https://github.com/biomejs/b\n \n   Contributed by @Conaclos\n \n+- [noUnusedVariables](https://biomejs.dev/linter/rules/no-unused-variables/) no longer panics when suggesting the renaming of a variable at the start of a file ([#4114](https://github.com/biomejs/biome/issues/4114)). Contributed by @Conaclos\n+\n - [noUselessEscapeInRegex](https://biomejs.dev/linter/rules/no-useless-escape-in-regex/) no longer panics on regexes that start with an empty character class. Contributed by @Conaclos\n \n - [noUselessStringConcat](https://biomejs.dev/linter/rules/no-useless-string-concat/) no longer panics when it encounters malformed code. Contributed by @Conaclos\ndiff --git a/crates/biome_js_semantic/src/semantic_model/model.rs b/crates/biome_js_semantic/src/semantic_model/model.rs\nindex 436aad7771f4..97e34d49bb11 100644\n--- a/crates/biome_js_semantic/src/semantic_model/model.rs\n+++ b/crates/biome_js_semantic/src/semantic_model/model.rs\n@@ -124,13 +124,16 @@ impl SemanticModelData {\n \n     /// Returns the [ScopeId] which the syntax is part of.\n     pub(crate) fn scope(&self, range: TextRange) -> ScopeId {\n+        // Seeking an interval in `self.scope_by_range` require a non-empty interval\n+        debug_assert!(range.len() > 0.into(), \"the range must not be empty.\");\n         let start = range.start().into();\n         let end = range.end().into();\n         let scopes = self\n             .scope_by_range\n+            // Find overlapping intervals\n             .find(start, end)\n+            // Only take intersecting intervals\n             .filter(|x| !(start < x.start || end > x.stop));\n-\n         // We always want the most tight scope\n         match scopes.map(|x| x.val).max() {\n             Some(val) => val,\ndiff --git a/crates/biome_js_semantic/src/semantic_model/reference.rs b/crates/biome_js_semantic/src/semantic_model/reference.rs\nindex 105d89813584..25ac83b610af 100644\n--- a/crates/biome_js_semantic/src/semantic_model/reference.rs\n+++ b/crates/biome_js_semantic/src/semantic_model/reference.rs\n@@ -58,9 +58,12 @@ impl Reference {\n \n     /// Returns the scope of this reference\n     pub fn scope(&self) -> Scope {\n-        let id = self\n-            .data\n-            .scope(TextRange::new(self.range_start(), self.range_start()));\n+        let start = self.range_start();\n+        let id = self.data.scope(TextRange::new(\n+            start,\n+            // SAFETY: A reference name has at least a length of 1 byte.\n+            start + TextSize::from(1),\n+        ));\n         Scope {\n             data: self.data.clone(),\n             id,\n", "instance_id": "biomejs__biome-4144", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "The problem statement is mostly clear in describing the issue: a panic occurs in the Biome tool when running the `noUnusedVariables` lint rule on invalid JavaScript code. It provides a specific example of the problematic code, the command to reproduce the issue, and the resulting error message. The expected result (no panic) is also stated. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly discuss the root cause of the panic (e.g., why the global scope is not present) or provide guidance on how the fix should be approached. Additionally, edge cases or other scenarios that might trigger similar panics are not mentioned. While the issue is reproducible and the goal is clear, these missing details prevent it from being fully comprehensive.", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the scope of the code changes is relatively narrow, affecting only a couple of files (`model.rs` and `reference.rs`) within the `biome_js_semantic` crate. The changes involve modifying how scopes are determined for a given text range, specifically ensuring non-empty ranges and adjusting the logic for reference scope calculation. This requires a moderate understanding of the semantic model in the Biome tool and how text ranges map to scopes, which is a non-trivial concept but not overly complex for someone familiar with compiler or linter internals. The number of technical concepts involved is limited to understanding Rust's ownership and borrowing model, text range handling, and the internal data structures of the semantic model (e.g., interval searching). The changes do not significantly impact the broader architecture of the system, and the amount of code modified is small. However, the problem does require careful handling of edge cases, such as ensuring that text ranges are valid (non-empty) to prevent panics, as seen in the debug assertion added. Overall, this problem requires a moderate level of expertise in Rust and familiarity with the specific codebase, but it does not demand deep architectural changes or advanced domain-specific knowledge, placing it at the lower end of the medium difficulty range.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Invalid pointer arithmetic\n### Describe the bug\n\nNushell 0.102.0 fails to compile on 32-bit targets because it uses invalid pointer arithmetic.\n\nhttps://github.com/nushell/nushell/blob/1aa2ed1947a0b891398558fcf4e4289849cc5a1d/crates/nu-command/src/conversions/into/duration.rs#L173-L185\n\nSince it deals with pointers, it should use wrapping arithmetic, like [`subslice_range`](https://doc.rust-lang.org/std/primitive.slice.html#method.subslice_range) [does](https://doc.rust-lang.org/src/core/slice/mod.rs.html#4647-4666).\n\n### How to reproduce\n\nhttps://gitlab.alpinelinux.org/nibon7/aports/-/jobs/1718350\n\n### Expected behavior\n\nNo panics.\n\n### Configuration\n\n0.102.0.  The build failed in CI, but it should be the usual Alpine configuration: `x86_64-alpine-linux-musl` target, 1.83.0 rustc/cargo.\n", "patch": "diff --git a/crates/nu-command/src/conversions/into/duration.rs b/crates/nu-command/src/conversions/into/duration.rs\nindex d11cfeffc2c6f..3d11b83afb74d 100644\n--- a/crates/nu-command/src/conversions/into/duration.rs\n+++ b/crates/nu-command/src/conversions/into/duration.rs\n@@ -170,16 +170,20 @@ fn into_duration(\n     )\n }\n \n-// convert string list of duration values to duration NS.\n-// technique for getting substrings and span based on: https://stackoverflow.com/a/67098851/2036651\n-#[inline]\n-fn addr_of(s: &str) -> usize {\n-    s.as_ptr() as usize\n-}\n-\n fn split_whitespace_indices(s: &str, span: Span) -> impl Iterator<Item = (&str, Span)> {\n     s.split_whitespace().map(move |sub| {\n-        let start_offset = span.start + addr_of(sub) - addr_of(s);\n+        // Gets the offset of the `sub` substring inside the string `s`.\n+        // `wrapping_` operations are necessary because the pointers can\n+        // overflow on 32-bit platforms.  The result will not overflow, because\n+        // `sub` is within `s`, and the end of `s` has to be a valid memory\n+        // address.\n+        //\n+        // XXX: this should be replaced with `str::substr_range` from the\n+        // standard library when it's stabilized.\n+        let start_offset = span\n+            .start\n+            .wrapping_add(sub.as_ptr() as usize)\n+            .wrapping_sub(s.as_ptr() as usize);\n         (sub, Span::new(start_offset, start_offset + sub.len()))\n     })\n }\n", "instance_id": "nushell__nushell-15031", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: a compilation failure on 32-bit targets due to invalid pointer arithmetic in the Nushell codebase. It provides a specific location in the code, links to relevant documentation, and a reproduction scenario via a CI job link. However, there are minor ambiguities and missing details. For instance, the expected behavior is vaguely described as \"no panics,\" which could be more explicit about whether this refers to compilation success or runtime behavior. Additionally, while the problem points to pointer arithmetic as the issue, it does not elaborate on the specific constraints or requirements for the fix beyond suggesting wrapping arithmetic. Edge cases or potential side effects of the change are not mentioned, which could be critical given the nature of pointer operations. Overall, the statement is valid and clear but lacks some depth in detailing the full scope of the issue and its implications.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to several factors. First, the scope of the code change is limited to a single function in a single file (`duration.rs`), specifically replacing unsafe pointer arithmetic with wrapping operations to handle potential overflows on 32-bit platforms. The provided diff shows a small, focused change of about 10-15 lines, with no impact on the broader system architecture or interactions between modules. Second, the technical concepts involved are relatively straightforward for a Rust developer with moderate experience: understanding pointer arithmetic, Rust's safety guarantees, and the use of wrapping operations (`wrapping_add`, `wrapping_sub`) to prevent undefined behavior. While pointer operations can be tricky, the solution is well-documented in the diff and aligns with standard Rust practices (as hinted by the reference to `subslice_range`). Third, no specific edge cases or error handling requirements are mentioned in the problem statement, and the code change does not introduce new error handling logic beyond ensuring arithmetic safety. The primary challenge lies in understanding why the original pointer arithmetic fails on 32-bit targets, which requires some knowledge of platform-specific behavior, but this is not overly complex. Overall, this task requires a basic-to-intermediate understanding of Rust's memory model and safe arithmetic, making it a relatively easy fix for someone familiar with the language.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Don't construct an error inside of `config.get_metric` for comments and demonstrations\nRight now when we send demonstrations to the gateway we get 200s on the client but we also log the following (BAD, WRONG, SCARY) warning: \r\n```tensorzero-gateway-ner-fine-tuning-demonstrations     | {\"timestamp\":\"2025-01-14T17:54:09.538237Z\",\"level\":\"WARN\",\"message\":\"Unknown metric: demonstration\",\"spans\":[{\"metric_name\":\"demonstration\",\"name\":\"feedback\"}]}```\r\n\r\nWe should not construct an error in this case so the warning doesn't get logged.\n", "patch": "diff --git a/gateway/src/config_parser.rs b/gateway/src/config_parser.rs\nindex d3e79b767..9047de4a9 100644\n--- a/gateway/src/config_parser.rs\n+++ b/gateway/src/config_parser.rs\n@@ -219,8 +219,8 @@ impl<'c> Config<'c> {\n         })\n     }\n \n-    /// Get a metric by name\n-    pub fn get_metric<'a>(&'a self, metric_name: &str) -> Result<&'a MetricConfig, Error> {\n+    /// Get a metric by name, producing an error if it's not found\n+    pub fn get_metric_or_err<'a>(&'a self, metric_name: &str) -> Result<&'a MetricConfig, Error> {\n         self.metrics.get(metric_name).ok_or_else(|| {\n             Error::new(ErrorDetails::UnknownMetric {\n                 name: metric_name.to_string(),\n@@ -228,6 +228,11 @@ impl<'c> Config<'c> {\n         })\n     }\n \n+    /// Get a metric by name\n+    pub fn get_metric<'a>(&'a self, metric_name: &str) -> Option<&'a MetricConfig> {\n+        self.metrics.get(metric_name)\n+    }\n+\n     /// Get a tool by name\n     pub fn get_tool<'a>(&'a self, tool_name: &str) -> Result<&'a StaticToolConfig, Error> {\n         self.tools.get(tool_name).ok_or_else(|| {\ndiff --git a/gateway/src/endpoints/feedback.rs b/gateway/src/endpoints/feedback.rs\nindex 222322198..a5b27435b 100644\n--- a/gateway/src/endpoints/feedback.rs\n+++ b/gateway/src/endpoints/feedback.rs\n@@ -170,21 +170,21 @@ fn get_feedback_metadata<'a>(\n     }\n     let metric = config.get_metric(metric_name);\n     let feedback_type = match metric.as_ref() {\n-        Ok(metric) => {\n+        Some(metric) => {\n             let feedback_type: FeedbackType = (&metric.r#type).into();\n             Ok(feedback_type)\n         }\n-        Err(e) => match metric_name {\n+        None => match metric_name {\n             \"comment\" => Ok(FeedbackType::Comment),\n             \"demonstration\" => Ok(FeedbackType::Demonstration),\n-            _ => Err(Error::new(ErrorDetails::InvalidRequest {\n-                message: e.to_string(),\n+            _ => Err(Error::new(ErrorDetails::UnknownMetric {\n+                name: metric_name.to_string(),\n             })),\n         },\n     }?;\n     let feedback_level = match metric {\n-        Ok(metric) => Ok(&metric.level),\n-        Err(_) => match feedback_type {\n+        Some(metric) => Ok(&metric.level),\n+        None => match feedback_type {\n             FeedbackType::Demonstration => Ok(&MetricConfigLevel::Inference),\n             _ => match (inference_id, episode_id) {\n                 (Some(_), None) => Ok(&MetricConfigLevel::Inference),\n@@ -284,7 +284,8 @@ async fn write_float(\n         tags,\n         ..\n     } = params;\n-    let metric_config: &crate::config_parser::MetricConfig = config.get_metric(metric_name)?;\n+    let metric_config: &crate::config_parser::MetricConfig =\n+        config.get_metric_or_err(metric_name)?;\n     // Verify that the function name exists.\n     let _ = throttled_get_function_name(&connection_info, &metric_config.level, &target_id).await?;\n \n@@ -318,7 +319,7 @@ async fn write_boolean(\n         tags,\n         ..\n     } = params;\n-    let metric_config = config.get_metric(metric_name)?;\n+    let metric_config = config.get_metric_or_err(metric_name)?;\n     // Verify that the function name exists.\n     let _ = throttled_get_function_name(&connection_info, &metric_config.level, &target_id).await?;\n     let value = value.as_bool().ok_or_else(|| {\n@@ -742,6 +743,31 @@ mod tests {\n         );\n     }\n \n+    #[tokio::test]\n+    async fn test_feedback_missing_metric() {\n+        let metrics = HashMap::new();\n+        let config = Config {\n+            gateway: GatewayConfig::default(),\n+            models: ModelTable::default(),\n+            embedding_models: HashMap::new(),\n+            metrics,\n+            functions: HashMap::new(),\n+            tools: HashMap::new(),\n+            templates: TemplateConfig::new(),\n+        };\n+        let inference_id = Uuid::now_v7();\n+        let metadata_err =\n+            get_feedback_metadata(&config, \"missing_metric_name\", None, Some(inference_id))\n+                .unwrap_err();\n+        let details = metadata_err.get_owned_details();\n+        assert_eq!(\n+            details,\n+            ErrorDetails::UnknownMetric {\n+                name: \"missing_metric_name\".to_string(),\n+            }\n+        );\n+    }\n+\n     #[tokio::test]\n     async fn test_feedback_handler() {\n         // Test a Comment Feedback\n", "instance_id": "tensorzero__tensorzero-760", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in its intent: it aims to prevent logging a warning message for specific metric types (\"comment\" and \"demonstration\") by avoiding error construction in the `config.get_metric` method. The issue is well-illustrated with a log snippet showing the unwanted warning. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define the expected behavior for other unknown metrics (i.e., whether they should still trigger errors or warnings). Additionally, it lacks mention of potential edge cases or constraints, such as how to handle invalid or malformed metric names beyond the two specified cases. Despite these minor gaps, the goal is understandable, and the provided code changes align with the described intent, making the statement \"Mostly Clear.\"", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The changes are relatively localized, affecting two files (`config_parser.rs` and `feedback.rs`). The modifications involve refactoring a single method (`get_metric`) into two variants (one returning an `Option` and another returning a `Result` with an error) and updating the call sites in the feedback endpoint logic. The changes do not impact the broader system architecture and are limited to a small number of lines (adding a new method and adjusting error handling logic). The test addition (`test_feedback_missing_metric`) is straightforward and confirms the error behavior for unknown metrics.\n\n2. **Number of Technical Concepts**: The solution requires basic familiarity with Rust's type system, specifically `Option` and `Result` types, and understanding of error handling patterns. No advanced language features, complex algorithms, or domain-specific knowledge are needed. The logic involves simple conditional checks to handle specific metric names (\"comment\" and \"demonstration\") differently from others.\n\n3. **Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases beyond the two specific metric types. The code changes introduce a nuanced error handling approach by distinguishing between known special cases and unknown metrics, but the complexity of these edge cases is minimal. The added test covers a basic scenario of a missing metric, which is a good start but does not explore more intricate edge cases (e.g., empty strings or malformed metric names).\n\n4. **Overall Complexity**: The task requires understanding the intent behind the warning suppression and making targeted modifications to achieve it. While it involves some logic adjustments across a couple of files, the changes are straightforward and do not require deep knowledge of the codebase or intricate refactoring. The problem is more complex than a trivial fix (e.g., changing a constant) but does not reach the level of implementing a new feature or handling complex interactions.\n\nThus, a score of 0.35 reflects an \"Easy\" problem that requires moderate code logic understanding and simple modifications, with minimal impact on the broader system.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "The cursor disappears in the preview panel when resizing yazi.\n### What system are you running Yazi on?\n\nLinux Wayland\n\n### What terminal are you running Yazi in?\n\nkitty 0.35.2\n\n### `yazi --debug` output\n\n```Shell\nYazi\r\n    Version: 0.3.0 (4150f401 2024-08-09)\r\n    Debug  : false\r\n    OS     : linux-x86_64 (unix)\r\n\r\nYa\r\n    Version: 0.3.0\r\n\r\nEmulator\r\n    Emulator.via_env: (\"xterm-kitty\", \"\")\r\n    Emulator.via_csi: Ok(Kitty)\r\n    Emulator.detect : Kitty\r\n\r\nAdapter\r\n    Adapter.matches: Kitty\r\n\r\nDesktop\r\n    XDG_SESSION_TYPE: Some(\"wayland\")\r\n    WAYLAND_DISPLAY : Some(\"wayland-0\")\r\n    DISPLAY         : Some(\":0\")\r\n\r\nSSH\r\n    shared.in_ssh_connection: false\r\n\r\nWSL\r\n    /proc/sys/fs/binfmt_misc/WSLInterop: false\r\n\r\nVariables\r\n    SHELL              : Some(\"/usr/bin/fish\")\r\n    EDITOR             : Some(\"nvim\")\r\n    YAZI_FILE_ONE      : None\r\n    YAZI_CONFIG_HOME   : None\r\n    ZELLIJ_SESSION_NAME: None\r\n\r\nText Opener\r\n    default: Some(Opener { run: \"${EDITOR:-vi} \\\"$@\\\"\", block: true, orphan: false, desc: \"$EDITOR\", for_: None, spread: true })\r\n    block  : Some(Opener { run: \"${EDITOR:-vi} \\\"$@\\\"\", block: true, orphan: false, desc: \"$EDITOR\", for_: None, spread: true })\r\n\r\ntmux\r\n    TMUX   : false\r\n    Version: 3.4\r\n\r\nDependencies\r\n    file             : 5.45\r\n    ueberzugpp       : 2.9.6\r\n    ffmpegthumbnailer: 2.2.2\r\n    magick           : 7.1.1-36\r\n    fzf              : 0.54.3\r\n    fd               : 10.1.0\r\n    rg               : 14.1.0\r\n    chafa            : 1.14.1\r\n    zoxide           : 0.9.4\r\n    7z               : 17.05\r\n    7zz              : No such file or directory (os error 2)\r\n    jq               : 1.7.1\r\n\r\n\r\n--------------------------------------------------\r\nWhen reporting a bug, please also upload the `yazi.log` log file - only upload the most recent content by time.\r\nYou can find it in the \"/home/tlss/.local/state/yazi\" directory.\n```\n\n\n### Did you try the latest nightly build to see if the problem got fixed?\n\nYes, and I updated the debug information above (`yazi --debug`) to the nightly that I tried\n\n### Describe the bug\n\nWhen the window size is reduced, the out-of-bounds cursor cannot be displayed in the preview pane.\r\n\r\nPreview panel cursor shows in fullscreen.\r\n![\u5c4f\u5e55\u622a\u56fe_20240810_154511](https://github.com/user-attachments/assets/4add4c97-4416-475b-9265-2529c86810ae)\r\n\r\nPreview panel cursor disappears after resizing the window.\r\n![\u5c4f\u5e55\u622a\u56fe_20240810_154538](https://github.com/user-attachments/assets/ab07f8ba-d29d-4213-9124-19f5cf970786)\r\n\r\n\n\n### Minimal reproducer\n\n1. Open yazi in fullscreen.\r\n2. Enter the directory with a bunch of files.\r\n3. Go to the bottom of this directory.\r\n4. Resize the yazi window.\n\n### Anything else?\n\n_No response_\n", "patch": "diff --git a/yazi-fs/src/folder.rs b/yazi-fs/src/folder.rs\nindex d6be66525..be6727aab 100644\n--- a/yazi-fs/src/folder.rs\n+++ b/yazi-fs/src/folder.rs\n@@ -63,7 +63,7 @@ impl Folder {\n \n \tpub fn arrow(&mut self, step: impl Into<Step>) -> bool {\n \t\tlet step = step.into() as Step;\n-\t\tlet b = if self.files.is_empty() {\n+\t\tlet mut b = if self.files.is_empty() {\n \t\t\t(self.cursor, self.offset, self.tracing) = (0, 0, false);\n \t\t\tfalse\n \t\t} else if step.is_positive() {\n@@ -72,8 +72,10 @@ impl Folder {\n \t\t\tself.prev(step)\n \t\t};\n \n-\t\tself.sync_page(false);\n \t\tself.tracing |= b;\n+\t\tb |= self.squeeze_offset();\n+\n+\t\tself.sync_page(false);\n \t\tb\n \t}\n \n@@ -111,10 +113,10 @@ impl Folder {\n \t\tlet scrolloff = (limit / 2).min(MANAGER.scrolloff as usize);\n \n \t\tself.cursor = step.add(self.cursor, limit).min(len.saturating_sub(1));\n-\t\tself.offset = if self.cursor >= (self.offset + limit).min(len).saturating_sub(scrolloff) {\n-\t\t\tlen.saturating_sub(limit).min(self.offset + self.cursor - old.0)\n-\t\t} else {\n+\t\tself.offset = if self.cursor < (self.offset + limit).min(len).saturating_sub(scrolloff) {\n \t\t\tself.offset.min(len.saturating_sub(1))\n+\t\t} else {\n+\t\t\tlen.saturating_sub(limit).min(self.offset + self.cursor - old.0)\n \t\t};\n \n \t\told != (self.cursor, self.offset)\n@@ -136,6 +138,22 @@ impl Folder {\n \n \t\told != (self.cursor, self.offset)\n \t}\n+\n+\tfn squeeze_offset(&mut self) -> bool {\n+\t\tlet old = self.offset;\n+\t\tlet len = self.files.len();\n+\n+\t\tlet limit = LAYOUT.load().current.height as usize;\n+\t\tlet scrolloff = (limit / 2).min(MANAGER.scrolloff as usize);\n+\n+\t\tself.offset = if self.cursor < (self.offset + limit).min(len).saturating_sub(scrolloff) {\n+\t\t\tlen.saturating_sub(limit).min(self.offset)\n+\t\t} else {\n+\t\t\tlen.saturating_sub(limit).min(self.cursor.saturating_sub(limit) + scrolloff)\n+\t\t};\n+\n+\t\told != self.offset\n+\t}\n }\n \n impl Folder {\n", "instance_id": "sxyazi__yazi-1500", "clarity": 2, "difficulty": 0.5, "clarity_explanation": "The problem statement is mostly clear in describing the issue: the cursor in the preview panel of the Yazi application disappears when the window is resized on a Linux Wayland system using the Kitty terminal. The statement includes relevant debug output, system details, and screenshots to illustrate the issue (cursor visible in fullscreen, disappearing after resizing). A minimal reproducer is provided, which helps in understanding how to replicate the bug. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define the expected behavior (e.g., should the cursor always remain visible, or adjust position?) nor does it mention specific edge cases or constraints related to window resizing (e.g., minimum window size, behavior with different file counts in the directory). These omissions prevent it from being fully comprehensive, hence a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of solving this problem is rated as medium (0.50) based on the following analysis of the factors:\n\n1. **Clarity and Complexity of the Problem Description**: While the issue is mostly clear, the lack of explicit expected behavior and edge case definitions adds some uncertainty to the solution approach. The logic behind cursor visibility during resizing involves understanding UI rendering and window event handling, which is moderately complex.\n\n2. **Scope and Depth of Code Changes**: The provided code changes are confined to a single file (`folder.rs`) and focus on modifying the logic for cursor positioning and offset calculation during navigation and resizing. The changes involve a few functions (`arrow`, `next`, `prev`, and a new `squeeze_offset` method), indicating a localized impact. However, these changes require understanding the interaction between cursor position, offset, and the visible area (limit), which suggests a moderate level of codebase familiarity. The overall amount of code change is small (adding a new method and adjusting existing logic), and it does not appear to impact the broader system architecture significantly.\n\n3. **Number of Technical Concepts**: Solving this requires understanding Rust-specific features (e.g., mutable state management, integer arithmetic with saturation), as well as domain-specific concepts related to terminal UI rendering (e.g., cursor positioning, scroll offset, viewport limits). The logic for adjusting the offset to keep the cursor within view involves moderate algorithmic thinking, but no advanced design patterns or external libraries are needed. The concepts are not overly complex but require a solid grasp of UI rendering logic in a terminal context.\n\n4. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes suggest handling scenarios like empty file lists, cursor movement beyond bounds, and resizing impacts on visible area limits. The new `squeeze_offset` method aims to adjust the offset to keep the cursor in view, which implies handling edge cases like cursor near the top/bottom of the list or resizing to very small window sizes. However, no explicit error handling logic is added or modified in the diff, and the complexity of these edge cases appears moderate (e.g., ensuring offset calculations don't result in invalid states).\n\nOverall, this problem falls into the medium difficulty range (0.4-0.6) because it requires understanding specific parts of the codebase (cursor and offset logic in a terminal UI), making targeted but non-trivial modifications, and implicitly handling edge cases related to resizing. It does not demand deep architectural changes or advanced technical knowledge beyond intermediate Rust and UI rendering concepts, hence a score of 0.50.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "IPC broken when sharing context between WebViews on Linux\n**Describe the bug**\r\nIf I spawn multiple WebViews with a shared WebContext, IPC callbacks (from JS to Rust) are routed incorrectly. It is as if each window sent the same event separately.\r\n\r\n**Steps To Reproduce**\r\n\r\nApply the following changes to `examples/multiwindow.rs`. It makes the windows use a shared WebContext.\r\n<details><summary>Diff</summary>\r\n<p>\r\n\r\n```diff\r\ndiff --git a/examples/multiwindow.rs b/examples/multiwindow.rs\r\nindex 1a95c09..5b50a2a 100644\r\n--- a/examples/multiwindow.rs\r\n+++ b/examples/multiwindow.rs\r\n@@ -8,7 +8,7 @@ use tao::{\r\n   event_loop::{ControlFlow, EventLoopBuilder, EventLoopProxy, EventLoopWindowTarget},\r\n   window::{Window, WindowBuilder, WindowId},\r\n };\r\n-use wry::{http::Request, WebView, WebViewBuilder};\r\n+use wry::{http::Request, WebContext, WebView, WebViewBuilder};\r\n \r\n enum UserEvent {\r\n   CloseWindow(WindowId),\r\n@@ -20,11 +20,13 @@ fn main() -> wry::Result<()> {\r\n   let event_loop = EventLoopBuilder::<UserEvent>::with_user_event().build();\r\n   let mut webviews = HashMap::new();\r\n   let proxy = event_loop.create_proxy();\r\n+  let mut web_context = WebContext::new(None);\r\n \r\n   let new_window = create_new_window(\r\n     format!(\"Window {}\", webviews.len() + 1),\r\n     &event_loop,\r\n     proxy.clone(),\r\n+    &mut web_context,\r\n   );\r\n   webviews.insert(new_window.0.id(), (new_window.0, new_window.1));\r\n \r\n@@ -47,6 +49,7 @@ fn main() -> wry::Result<()> {\r\n           format!(\"Window {}\", webviews.len() + 1),\r\n           event_loop,\r\n           proxy.clone(),\r\n+          &mut web_context,\r\n         );\r\n         webviews.insert(new_window.0.id(), (new_window.0, new_window.1));\r\n       }\r\n@@ -69,6 +72,7 @@ fn create_new_window(\r\n   title: String,\r\n   event_loop: &EventLoopWindowTarget<UserEvent>,\r\n   proxy: EventLoopProxy<UserEvent>,\r\n+  web_context: &mut WebContext,\r\n ) -> (Window, WebView) {\r\n   let window = WindowBuilder::new()\r\n     .with_title(title)\r\n@@ -114,6 +118,7 @@ fn create_new_window(\r\n   };\r\n \r\n   let webview = builder\r\n+    .with_web_context(web_context)\r\n     .with_html(\r\n       r#\"\r\n         <button onclick=\"window.ipc.postMessage('new-window')\">Open a new window</button>\r\n```\r\n\r\n</p>\r\n</details> \r\n\r\n[Full example](https://gist.github.com/ollpu/76f7cea00788c0753209c95b3e6979e3)\r\n\r\nThen:\r\n- Start the example with `cargo run --example multiwindow`\r\n- Open a new window using the button\r\n- Try to change the title of either of the windows. Both windows change their title.\r\n- Press the \"new window\" button again. This time two new windows open.\r\n\r\n**Expected behavior**\r\nAs with the original example,\r\n- only the current window changes its title based on the text field\r\n- only one new window is opened each time the button is pressed\r\n\r\n**Screenshots**\r\n![image](https://github.com/tauri-apps/wry/assets/7241014/c5e902bb-6288-405f-9dd9-deae0f943ac9)\r\n\r\n\r\n**Platform and Versions:**\r\nOS: Ubuntu 22.04.4\r\nRustc: rustc 1.77.2 (25ef9e3d8 2024-04-09)\r\n\r\n**Additional context**\r\nI primarily want to share the WebContext between WebViews so that the `BroadcastChannel` API would work. It seems that on Linux / WebKitGTK, it doesn't work if the views are in separate contexts. (Same with live localStorage changes, etc.)\r\n\r\nIn Tauri the WebViews are currently always set up with separate contexts, **unless** `TAURI_AUTOMATION=true` (Tauri v1) or `TAURI_WEBVIEW_AUTOMATION=true` (Tauri v2) is set, in which case this bug is exhibited.\n", "patch": "diff --git a/.changes/linux-shared-webcontext-ipc.md b/.changes/linux-shared-webcontext-ipc.md\nnew file mode 100644\nindex 000000000..bcb966ffd\n--- /dev/null\n+++ b/.changes/linux-shared-webcontext-ipc.md\n@@ -0,0 +1,5 @@\n+---\n+\"wry\": patch\n+---\n+\n+Fix Linux IPC handler and initialization scripts when sharing a WebContext between multiple WebViews.\ndiff --git a/src/webkitgtk/mod.rs b/src/webkitgtk/mod.rs\nindex 5cb548b28..e92ee5651 100644\n--- a/src/webkitgtk/mod.rs\n+++ b/src/webkitgtk/mod.rs\n@@ -28,7 +28,7 @@ use webkit2gtk::{\n   AutoplayPolicy, InputMethodContextExt, LoadEvent, NavigationPolicyDecision,\n   NavigationPolicyDecisionExt, NetworkProxyMode, NetworkProxySettings, PolicyDecisionType,\n   PrintOperationExt, SettingsExt, URIRequest, URIRequestExt, UserContentInjectedFrames,\n-  UserContentManagerExt, UserScript, UserScriptInjectionTime,\n+  UserContentManager, UserContentManagerExt, UserScript, UserScriptInjectionTime,\n   WebContextExt as Webkit2gtkWeContextExt, WebView, WebViewExt, WebsiteDataManagerExt,\n   WebsiteDataManagerExtManual, WebsitePolicies,\n };\n@@ -266,7 +266,7 @@ impl InnerWebView {\n     Self::attach_handlers(&webview, web_context, &mut attributes);\n \n     // IPC handler\n-    Self::attach_ipc_handler(webview.clone(), web_context, &mut attributes);\n+    Self::attach_ipc_handler(webview.clone(), &mut attributes);\n \n     // Drag drop handler\n     if let Some(drag_drop_handler) = attributes.drag_drop_handler.take() {\n@@ -339,7 +339,7 @@ impl InnerWebView {\n \n   fn create_webview(web_context: &WebContext, attributes: &WebViewAttributes) -> WebView {\n     let mut builder = WebView::builder()\n-      .user_content_manager(web_context.manager())\n+      .user_content_manager(&UserContentManager::new())\n       .web_context(web_context.context())\n       .is_controlled_by_automation(web_context.allows_automation());\n \n@@ -511,14 +511,12 @@ impl InnerWebView {\n     is_in_fixed_parent\n   }\n \n-  fn attach_ipc_handler(\n-    webview: WebView,\n-    web_context: &WebContext,\n-    attributes: &mut WebViewAttributes,\n-  ) {\n+  fn attach_ipc_handler(webview: WebView, attributes: &mut WebViewAttributes) {\n     // Message handler\n     let ipc_handler = attributes.ipc_handler.take();\n-    let manager = web_context.manager();\n+    let manager = webview\n+      .user_content_manager()\n+      .expect(\"WebView does not have UserContentManager\");\n \n     // Connect before registering as recommended by the docs\n     manager.connect_script_message_received(None, move |_m, msg| {\ndiff --git a/src/webkitgtk/web_context.rs b/src/webkitgtk/web_context.rs\nindex df12dec89..90c93f9e8 100644\n--- a/src/webkitgtk/web_context.rs\n+++ b/src/webkitgtk/web_context.rs\n@@ -22,14 +22,13 @@ use std::{\n use webkit2gtk::{\n   ApplicationInfo, AutomationSessionExt, CookiePersistentStorage, DownloadExt, LoadEvent,\n   SecurityManagerExt, URIRequest, URIRequestExt, URISchemeRequest, URISchemeRequestExt,\n-  URISchemeResponse, URISchemeResponseExt, UserContentManager, WebContext,\n-  WebContextExt as Webkit2gtkContextExt, WebView, WebViewExt,\n+  URISchemeResponse, URISchemeResponseExt, WebContext, WebContextExt as Webkit2gtkContextExt,\n+  WebView, WebViewExt,\n };\n \n #[derive(Debug)]\n pub struct WebContextImpl {\n   context: WebContext,\n-  manager: UserContentManager,\n   webview_uri_loader: Rc<WebViewUriLoader>,\n   registered_protocols: HashSet<String>,\n   automation: bool,\n@@ -90,7 +89,6 @@ impl WebContextImpl {\n     Self {\n       context,\n       automation,\n-      manager: UserContentManager::new(),\n       registered_protocols: Default::default(),\n       webview_uri_loader: Rc::default(),\n       app_info: Some(app_info),\n@@ -108,9 +106,6 @@ pub trait WebContextExt {\n   /// The GTK [`WebContext`] of all webviews in the context.\n   fn context(&self) -> &WebContext;\n \n-  /// The GTK [`UserContentManager`] of all webviews in the context.\n-  fn manager(&self) -> &UserContentManager;\n-\n   /// Register a custom protocol to the web context.\n   ///\n   /// When duplicate schemes are registered, the duplicate handler will still be submitted and the\n@@ -157,10 +152,6 @@ impl WebContextExt for super::WebContext {\n     &self.os.context\n   }\n \n-  fn manager(&self) -> &UserContentManager {\n-    &self.os.manager\n-  }\n-\n   fn register_uri_scheme<F>(&mut self, name: &str, handler: F) -> crate::Result<()>\n   where\n     F: Fn(Request<Vec<u8>>, RequestAsyncResponder) + 'static,\n", "instance_id": "tauri-apps__wry-1326", "clarity": 2, "difficulty": 0.75, "clarity_explanation": "\nThe problem statement is mostly clear and provides a detailed description of the bug related to IPC (Inter-Process Communication) when sharing a WebContext between multiple WebViews on Linux. The goal is well-defined: to fix the incorrect routing of IPC callbacks when a shared WebContext is used. The steps to reproduce the issue are provided with a diff to modify an example, and the expected behavior is explicitly stated. Additionally, there are screenshots and platform-specific details that aid in understanding the issue. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly discuss potential edge cases or constraints beyond the shared WebContext scenario. It also lacks clarity on whether the fix should maintain compatibility with other platforms or if there are specific performance requirements. While the context about `BroadcastChannel` and `localStorage` is helpful, it does not directly relate to the IPC issue, which could slightly distract from the core problem. Overall, the statement is valid and clear but misses some minor details that would make it comprehensive.\n", "difficulty_explanation": "\nI rate the difficulty of this problem as 0.75, placing it in the \"Hard\" category. This assessment is based on several factors:\n\n1. **Scope and Depth of Code Changes**: The code changes provided in the diff impact multiple files (`webkitgtk/mod.rs` and `webkitgtk/web_context.rs`) and involve modifications to core components of the WebView system, specifically how the `UserContentManager` is handled and how IPC handlers are attached. The changes are not trivial; they require restructuring the way WebContext and WebView interact, moving away from a shared `UserContentManager` to individual instances per WebView. This impacts the architecture of how IPC messages are managed, which is a significant change to the system's behavior when using shared contexts.\n\n2. **Number of Technical Concepts**: Solving this problem requires a deep understanding of several complex concepts, including:\n   - WebKitGTK internals, particularly how `WebContext`, `UserContentManager`, and IPC mechanisms work on Linux.\n   - Rust's ownership and borrowing model, as the code manipulates references and mutable state across multiple components.\n   - Cross-platform GUI programming and event handling, as the issue is specific to Linux but must not break other platforms.\n   - Asynchronous communication and event routing, given the nature of IPC callbacks.\n   These concepts are advanced and require significant experience with both Rust and WebKitGTK.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the nature of the bug (incorrect IPC routing) implies several potential issues, such as race conditions, message duplication, or conflicts between WebViews. The code changes must ensure that IPC messages are routed correctly to the intended WebView, which may involve additional synchronization or identification mechanisms. Error handling logic might need to be added or modified to handle scenarios where WebViews are created or destroyed dynamically while messages are in transit. These considerations add to the complexity of the solution.\n\n4. **Overall Complexity**: The problem requires a deep understanding of the `wry` library's architecture and WebKitGTK's behavior on Linux. The solution involves not just fixing a bug but rethinking how shared contexts are managed for IPC, which could have broader implications for features like `BroadcastChannel` and `localStorage` (as mentioned in the additional context). This level of impact and the need for precise modifications across multiple modules make this a challenging task. It falls short of \"Very Hard\" (0.8-1.0) because it does not appear to require system-level programming or entirely new protocol implementations, but it is still a complex issue that demands expertise.\n\nIn summary, this problem is hard due to the architectural impact of the changes, the advanced technical knowledge required, and the potential for subtle edge cases in IPC routing. It is suitable for a senior engineer with experience in Rust and GUI frameworks like WebKitGTK.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "impl From<EmojiId> for ReactionType doesn't produce a valid reaction\nWhen attempting to create a reaction with a `ReactionType` directly generated by this impl all requests will fail, The name cannot be `None`, but it can be anything else, consider using something like \"reaction\" for the name instead.\r\n\r\nWhat happens when you try and use a ReactionType without a name:\r\n```\r\nHttp(UnsuccessfulRequest(ErrorResponse { status_code: 400, url: \"https://discord.com/api/v10/channels/1235087573421133824/messages/1241909429977481246/reactions/:1218258296272715836/@me\", method: PUT, error: DiscordJsonError { code: 10014, message: \"Unknown Emoji\", errors: [] } }))\r\n```\r\n\n", "patch": "diff --git a/src/model/channel/reaction.rs b/src/model/channel/reaction.rs\nindex 91e211b8a18..510c2b1e0a9 100644\n--- a/src/model/channel/reaction.rs\n+++ b/src/model/channel/reaction.rs\n@@ -414,7 +414,7 @@ impl From<EmojiId> for ReactionType {\n         ReactionType::Custom {\n             animated: false,\n             id: emoji_id,\n-            name: None,\n+            name: Some(\"emoji\".to_string()),\n         }\n     }\n }\n", "instance_id": "serenity-rs__serenity-2870", "clarity": 2, "difficulty": 0.1, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: the `From<EmojiId> for ReactionType` implementation produces a `ReactionType` with a `name` field set to `None`, which causes HTTP requests to fail with a specific error (400 Bad Request, \"Unknown Emoji\"). The goal is to fix this by ensuring the `name` field is not `None`, and a suggestion is provided to use a placeholder like \"reaction\". The error message and context are helpful in understanding the problem. However, there are minor ambiguities: the statement does not explicitly define what constitutes a \"valid\" reaction beyond `name` not being `None`, nor does it specify if the placeholder name (\"reaction\" or \"emoji\" as in the code change) has any specific requirements or constraints from the Discord API. Additionally, edge cases or potential side effects of changing the `name` value are not mentioned. Overall, the problem is clear enough to act on, but these missing details prevent it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem is very low, as it involves a straightforward fix with minimal code change. The provided diff shows a single-line modification in one file, changing the `name` field from `None` to `Some(\"emoji\".to_string())` in the `From<EmojiId> for ReactionType` implementation. This requires only basic understanding of Rust syntax and the specific struct being modified. The scope is extremely limited, affecting only one function and not requiring interaction with other parts of the codebase or deeper architectural changes. No complex technical concepts, algorithms, or domain-specific knowledge beyond basic struct field initialization are needed. Edge cases and error handling are not a significant concern here, as the change is a simple value substitution to meet an API requirement, and the problem statement does not hint at additional complications. This task falls into the \"very easy\" category, as it is essentially a one-line bug fix with no broader impact or complexity.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Enable disable All traffic feature for users\nIn the Settings \"Enterprise features\" tab add a \"toggle\" for enabling/disabling users the ability to use: \"All traffic\".\nIf ability to use \"All traffic\" is disabled, the client on the (i) information box should have a help message: *This option is disabled by the instance administrator.* and the option should be disabled (always on the Predefined traffic).\n\nDepends on #717 - as information about this feature needs to be synced with \"Enterprise\" license state.\n", "patch": "diff --git a/.sqlx/query-35950188e70029c8314055621857ea0091c302e9c27de798a2f50901ffd747e0.json b/.sqlx/query-48223bdfca4f2bd5c7cd14594f5d81db67dfb1c0c2c01cf1fd9c8df421f366ef.json\nsimilarity index 57%\nrename from .sqlx/query-35950188e70029c8314055621857ea0091c302e9c27de798a2f50901ffd747e0.json\nrename to .sqlx/query-48223bdfca4f2bd5c7cd14594f5d81db67dfb1c0c2c01cf1fd9c8df421f366ef.json\nindex 3fa364d32..2eb5251a9 100644\n--- a/.sqlx/query-35950188e70029c8314055621857ea0091c302e9c27de798a2f50901ffd747e0.json\n+++ b/.sqlx/query-48223bdfca4f2bd5c7cd14594f5d81db67dfb1c0c2c01cf1fd9c8df421f366ef.json\n@@ -1,16 +1,17 @@\n {\n   \"db_name\": \"PostgreSQL\",\n-  \"query\": \"UPDATE \\\"enterprisesettings\\\" SET \\\"admin_device_management\\\" = $2,\\\"only_client_activation\\\" = $3 WHERE id = $1\",\n+  \"query\": \"UPDATE \\\"enterprisesettings\\\" SET \\\"admin_device_management\\\" = $2,\\\"disable_all_traffic\\\" = $3,\\\"only_client_activation\\\" = $4 WHERE id = $1\",\n   \"describe\": {\n     \"columns\": [],\n     \"parameters\": {\n       \"Left\": [\n         \"Int8\",\n         \"Bool\",\n+        \"Bool\",\n         \"Bool\"\n       ]\n     },\n     \"nullable\": []\n   },\n-  \"hash\": \"35950188e70029c8314055621857ea0091c302e9c27de798a2f50901ffd747e0\"\n+  \"hash\": \"48223bdfca4f2bd5c7cd14594f5d81db67dfb1c0c2c01cf1fd9c8df421f366ef\"\n }\ndiff --git a/.sqlx/query-6332fe33694ebd090eba2ef0777ea91e86978f827cbff94a6a28338a7b0bf6ee.json b/.sqlx/query-68fc762354c30e66a83ba47746a0d4707e9b8e9829965bf6e4b334d1ab41bb6b.json\nsimilarity index 59%\nrename from .sqlx/query-6332fe33694ebd090eba2ef0777ea91e86978f827cbff94a6a28338a7b0bf6ee.json\nrename to .sqlx/query-68fc762354c30e66a83ba47746a0d4707e9b8e9829965bf6e4b334d1ab41bb6b.json\nindex b861d4934..010db59cc 100644\n--- a/.sqlx/query-6332fe33694ebd090eba2ef0777ea91e86978f827cbff94a6a28338a7b0bf6ee.json\n+++ b/.sqlx/query-68fc762354c30e66a83ba47746a0d4707e9b8e9829965bf6e4b334d1ab41bb6b.json\n@@ -1,6 +1,6 @@\n {\n   \"db_name\": \"PostgreSQL\",\n-  \"query\": \"SELECT id \\\"id?\\\", \\\"admin_device_management\\\",\\\"only_client_activation\\\" FROM \\\"enterprisesettings\\\" WHERE id = $1\",\n+  \"query\": \"SELECT id \\\"id?\\\", \\\"admin_device_management\\\",\\\"disable_all_traffic\\\",\\\"only_client_activation\\\" FROM \\\"enterprisesettings\\\" WHERE id = $1\",\n   \"describe\": {\n     \"columns\": [\n       {\n@@ -15,6 +15,11 @@\n       },\n       {\n         \"ordinal\": 2,\n+        \"name\": \"disable_all_traffic\",\n+        \"type_info\": \"Bool\"\n+      },\n+      {\n+        \"ordinal\": 3,\n         \"name\": \"only_client_activation\",\n         \"type_info\": \"Bool\"\n       }\n@@ -25,10 +30,11 @@\n       ]\n     },\n     \"nullable\": [\n+      false,\n       false,\n       false,\n       false\n     ]\n   },\n-  \"hash\": \"6332fe33694ebd090eba2ef0777ea91e86978f827cbff94a6a28338a7b0bf6ee\"\n+  \"hash\": \"68fc762354c30e66a83ba47746a0d4707e9b8e9829965bf6e4b334d1ab41bb6b\"\n }\ndiff --git a/.sqlx/query-bd0665f9401b5919b55e8b68ef238b514c12becf8e9dfbb8641b02e4deb8b5e5.json b/.sqlx/query-834d5b83aebddf1e23511025d5f98b8a69e1227e8bfbd2b1d0110c8def72f8aa.json\nsimilarity index 64%\nrename from .sqlx/query-bd0665f9401b5919b55e8b68ef238b514c12becf8e9dfbb8641b02e4deb8b5e5.json\nrename to .sqlx/query-834d5b83aebddf1e23511025d5f98b8a69e1227e8bfbd2b1d0110c8def72f8aa.json\nindex b2dae11eb..96a0c7b4e 100644\n--- a/.sqlx/query-bd0665f9401b5919b55e8b68ef238b514c12becf8e9dfbb8641b02e4deb8b5e5.json\n+++ b/.sqlx/query-834d5b83aebddf1e23511025d5f98b8a69e1227e8bfbd2b1d0110c8def72f8aa.json\n@@ -1,6 +1,6 @@\n {\n   \"db_name\": \"PostgreSQL\",\n-  \"query\": \"INSERT INTO \\\"enterprisesettings\\\" (\\\"admin_device_management\\\",\\\"only_client_activation\\\") VALUES ($1,$2) RETURNING id\",\n+  \"query\": \"INSERT INTO \\\"enterprisesettings\\\" (\\\"admin_device_management\\\",\\\"disable_all_traffic\\\",\\\"only_client_activation\\\") VALUES ($1,$2,$3) RETURNING id\",\n   \"describe\": {\n     \"columns\": [\n       {\n@@ -11,6 +11,7 @@\n     ],\n     \"parameters\": {\n       \"Left\": [\n+        \"Bool\",\n         \"Bool\",\n         \"Bool\"\n       ]\n@@ -19,5 +20,5 @@\n       false\n     ]\n   },\n-  \"hash\": \"bd0665f9401b5919b55e8b68ef238b514c12becf8e9dfbb8641b02e4deb8b5e5\"\n+  \"hash\": \"834d5b83aebddf1e23511025d5f98b8a69e1227e8bfbd2b1d0110c8def72f8aa\"\n }\ndiff --git a/.sqlx/query-205507ac888563e614157c6977abb744104284cb6bc7070127797bd6df0ac7af.json b/.sqlx/query-e2483b9d167af9476ba49c63fa20a07aa53bfe7f783fcb9257312304094d5edc.json\nsimilarity index 59%\nrename from .sqlx/query-205507ac888563e614157c6977abb744104284cb6bc7070127797bd6df0ac7af.json\nrename to .sqlx/query-e2483b9d167af9476ba49c63fa20a07aa53bfe7f783fcb9257312304094d5edc.json\nindex 749e67273..beb848d75 100644\n--- a/.sqlx/query-205507ac888563e614157c6977abb744104284cb6bc7070127797bd6df0ac7af.json\n+++ b/.sqlx/query-e2483b9d167af9476ba49c63fa20a07aa53bfe7f783fcb9257312304094d5edc.json\n@@ -1,6 +1,6 @@\n {\n   \"db_name\": \"PostgreSQL\",\n-  \"query\": \"SELECT id \\\"id?\\\", \\\"admin_device_management\\\",\\\"only_client_activation\\\" FROM \\\"enterprisesettings\\\"\",\n+  \"query\": \"SELECT id \\\"id?\\\", \\\"admin_device_management\\\",\\\"disable_all_traffic\\\",\\\"only_client_activation\\\" FROM \\\"enterprisesettings\\\"\",\n   \"describe\": {\n     \"columns\": [\n       {\n@@ -15,6 +15,11 @@\n       },\n       {\n         \"ordinal\": 2,\n+        \"name\": \"disable_all_traffic\",\n+        \"type_info\": \"Bool\"\n+      },\n+      {\n+        \"ordinal\": 3,\n         \"name\": \"only_client_activation\",\n         \"type_info\": \"Bool\"\n       }\n@@ -23,10 +28,11 @@\n       \"Left\": []\n     },\n     \"nullable\": [\n+      false,\n       false,\n       false,\n       false\n     ]\n   },\n-  \"hash\": \"205507ac888563e614157c6977abb744104284cb6bc7070127797bd6df0ac7af\"\n+  \"hash\": \"e2483b9d167af9476ba49c63fa20a07aa53bfe7f783fcb9257312304094d5edc\"\n }\ndiff --git a/migrations/20240902103930_add_option_to_disable_all_traffic.down.sql b/migrations/20240902103930_add_option_to_disable_all_traffic.down.sql\nnew file mode 100644\nindex 000000000..d07635dbc\n--- /dev/null\n+++ b/migrations/20240902103930_add_option_to_disable_all_traffic.down.sql\n@@ -0,0 +1,1 @@\n+ALTER TABLE enterprisesettings DROP COLUMN disable_all_traffic;\ndiff --git a/migrations/20240902103930_add_option_to_disable_all_traffic.up.sql b/migrations/20240902103930_add_option_to_disable_all_traffic.up.sql\nnew file mode 100644\nindex 000000000..21de95022\n--- /dev/null\n+++ b/migrations/20240902103930_add_option_to_disable_all_traffic.up.sql\n@@ -0,0 +1,1 @@\n+ALTER TABLE enterprisesettings ADD COLUMN disable_all_traffic BOOLEAN NOT NULL DEFAULT FALSE;\ndiff --git a/proto b/proto\nindex d069a0e53..de58067ab 160000\n--- a/proto\n+++ b/proto\n@@ -1,1 +1,1 @@\n-Subproject commit d069a0e5304281cfc8b09e949a8e7a9feb5fc115\n+Subproject commit de58067ab652f6e5ddf84c7bbc6e4d2363914738\ndiff --git a/src/db/models/polling_token.rs b/src/db/models/polling_token.rs\nindex 3235f6b05..99f611909 100644\n--- a/src/db/models/polling_token.rs\n+++ b/src/db/models/polling_token.rs\n@@ -2,9 +2,8 @@ use chrono::{NaiveDateTime, Utc};\n use model_derive::Model;\n use sqlx::{query_as, Error as SqlxError};\n \n-use crate::random::gen_alphanumeric;\n-\n use super::DbPool;\n+use crate::random::gen_alphanumeric;\n \n // Token used for polling requests.\n #[derive(Clone, Debug, Model)]\ndiff --git a/src/enterprise/db/models/enterprise_settings.rs b/src/enterprise/db/models/enterprise_settings.rs\nindex cebf54e74..6b1a4f33c 100644\n--- a/src/enterprise/db/models/enterprise_settings.rs\n+++ b/src/enterprise/db/models/enterprise_settings.rs\n@@ -11,6 +11,8 @@ pub struct EnterpriseSettings {\n     pub id: Option<i64>,\n     // If true, only admins can manage devices\n     pub admin_device_management: bool,\n+    // If true, the option to route all traffic through the vpn is disabled in the client\n+    pub disable_all_traffic: bool,\n     // If true, manual WireGuard setup is disabled\n     pub only_client_activation: bool,\n }\n@@ -22,6 +24,7 @@ impl Default for EnterpriseSettings {\n         Self {\n             id: None,\n             admin_device_management: false,\n+            disable_all_traffic: false,\n             only_client_activation: false,\n         }\n     }\ndiff --git a/src/enterprise/grpc/polling.rs b/src/enterprise/grpc/polling.rs\nindex f351a89be..88fb28a07 100644\n--- a/src/enterprise/grpc/polling.rs\n+++ b/src/enterprise/grpc/polling.rs\n@@ -1,11 +1,13 @@\n+use tonic::Status;\n+\n use crate::{\n     db::{models::polling_token::PollingToken, DbPool, Device, User},\n     enterprise::license::{get_cached_license, validate_license},\n-    grpc::utils::build_device_config_response,\n+    grpc::{\n+        proto::{InstanceInfoRequest, InstanceInfoResponse},\n+        utils::{build_device_config_response, build_instance_config_response},\n+    },\n };\n-use tonic::Status;\n-\n-use crate::grpc::proto::{InstanceInfoRequest, InstanceInfoResponse};\n \n pub struct PollingServer {\n     pool: DbPool,\n@@ -81,8 +83,10 @@ impl PollingServer {\n         // Build & return polling info\n         let device_config =\n             build_device_config_response(&self.pool, &device.wireguard_pubkey).await?;\n+        let instance_config = build_instance_config_response(&self.pool).await?;\n         Ok(InstanceInfoResponse {\n             device_config: Some(device_config),\n+            instance_config: Some(instance_config),\n         })\n     }\n }\ndiff --git a/src/enterprise/handlers/openid_login.rs b/src/enterprise/handlers/openid_login.rs\nindex e02d57bda..e180d9c26 100644\n--- a/src/enterprise/handlers/openid_login.rs\n+++ b/src/enterprise/handlers/openid_login.rs\n@@ -1,32 +1,38 @@\n-use axum::extract::State;\n-use axum::http::StatusCode;\n-use axum::Json;\n+use axum::{extract::State, http::StatusCode, Json};\n use axum_client_ip::{InsecureClientIp, LeftmostXForwardedFor};\n-use axum_extra::extract::cookie::{Cookie, SameSite};\n-use axum_extra::extract::{CookieJar, PrivateCookieJar};\n-use axum_extra::headers::UserAgent;\n-use axum_extra::TypedHeader;\n-use openidconnect::core::{\n-    CoreClient, CoreGenderClaim, CoreJsonWebKeyType, CoreJweContentEncryptionAlgorithm,\n-    CoreJwsSigningAlgorithm, CoreResponseType,\n+use axum_extra::{\n+    extract::{\n+        cookie::{Cookie, SameSite},\n+        CookieJar, PrivateCookieJar,\n+    },\n+    headers::UserAgent,\n+    TypedHeader,\n };\n use openidconnect::{\n-    core::CoreProviderMetadata, reqwest::async_http_client, ClientId, ClientSecret, IssuerUrl,\n-    ProviderMetadata, RedirectUrl,\n+    core::{\n+        CoreClient, CoreGenderClaim, CoreJsonWebKeyType, CoreJweContentEncryptionAlgorithm,\n+        CoreJwsSigningAlgorithm, CoreProviderMetadata, CoreResponseType,\n+    },\n+    reqwest::async_http_client,\n+    AuthenticationFlow, ClientId, ClientSecret, CsrfToken, EmptyAdditionalClaims, IdToken,\n+    IssuerUrl, Nonce, ProviderMetadata, RedirectUrl, Scope,\n };\n-use openidconnect::{AuthenticationFlow, CsrfToken, EmptyAdditionalClaims, IdToken, Nonce, Scope};\n use serde_json::json;\n use time::Duration;\n \n use super::LicenseInfo;\n-use crate::appstate::AppState;\n-use crate::db::{DbPool, MFAInfo, Session, SessionState, Settings, User, UserInfo};\n-use crate::enterprise::db::models::openid_provider::OpenIdProvider;\n-use crate::error::WebError;\n-use crate::handlers::user::{check_username, prune_username};\n-use crate::handlers::{ApiResponse, AuthResponse, SESSION_COOKIE_NAME, SIGN_IN_COOKIE_NAME};\n-use crate::headers::{check_new_device_login, get_user_agent_device, parse_user_agent};\n-use crate::server_config;\n+use crate::{\n+    appstate::AppState,\n+    db::{DbPool, MFAInfo, Session, SessionState, Settings, User, UserInfo},\n+    enterprise::db::models::openid_provider::OpenIdProvider,\n+    error::WebError,\n+    handlers::{\n+        user::{check_username, prune_username},\n+        ApiResponse, AuthResponse, SESSION_COOKIE_NAME, SIGN_IN_COOKIE_NAME,\n+    },\n+    headers::{check_new_device_login, get_user_agent_device, parse_user_agent},\n+    server_config,\n+};\n \n type ProvMeta = ProviderMetadata<\n     openidconnect::EmptyAdditionalProviderMetadata,\ndiff --git a/src/grpc/enrollment.rs b/src/grpc/enrollment.rs\nindex 6cf74f4c5..21ac12f78 100644\n--- a/src/grpc/enrollment.rs\n+++ b/src/grpc/enrollment.rs\n@@ -1,16 +1,18 @@\n use std::sync::Arc;\n \n-use super::InstanceInfo;\n use ipnetwork::IpNetwork;\n use sqlx::Transaction;\n use tokio::sync::{broadcast::Sender, mpsc::UnboundedSender};\n use tonic::Status;\n use uaparser::UserAgentParser;\n \n-use super::proto::{\n-    ActivateUserRequest, AdminInfo, Device as ProtoDevice, DeviceConfig as ProtoDeviceConfig,\n-    DeviceConfigResponse, EnrollmentStartRequest, EnrollmentStartResponse, ExistingDevice,\n-    InitialUserInfo, NewDevice,\n+use super::{\n+    proto::{\n+        ActivateUserRequest, AdminInfo, Device as ProtoDevice, DeviceConfig as ProtoDeviceConfig,\n+        DeviceConfigResponse, EnrollmentStartRequest, EnrollmentStartResponse, ExistingDevice,\n+        InitialUserInfo, NewDevice,\n+    },\n+    InstanceInfo,\n };\n use crate::{\n     db::{\ndiff --git a/src/grpc/mod.rs b/src/grpc/mod.rs\nindex 63c36e6c7..ef6390714 100644\n--- a/src/grpc/mod.rs\n+++ b/src/grpc/mod.rs\n@@ -9,7 +9,6 @@ use std::{\n     sync::{Arc, Mutex},\n };\n \n-use crate::enterprise::grpc::polling::PollingServer;\n use chrono::{Duration as ChronoDuration, NaiveDateTime, Utc};\n use reqwest::Url;\n use serde::Serialize;\n@@ -46,6 +45,7 @@ use self::{\n use crate::{\n     auth::failed_login::FailedLoginMap,\n     db::{AppEvent, Settings},\n+    enterprise::grpc::polling::PollingServer,\n     handlers::mail::send_gateway_disconnected_email,\n     mail::Mail,\n     server_config,\ndiff --git a/src/grpc/utils.rs b/src/grpc/utils.rs\nindex bb9e511ea..38bd8a1ed 100644\n--- a/src/grpc/utils.rs\n+++ b/src/grpc/utils.rs\n@@ -1,11 +1,19 @@\n-use super::InstanceInfo;\n use ipnetwork::IpNetwork;\n use tonic::Status;\n \n-use super::proto::{DeviceConfig as ProtoDeviceConfig, DeviceConfigResponse};\n-use crate::db::{\n-    models::{device::WireguardNetworkDevice, wireguard::WireguardNetwork},\n-    DbPool, Device, Settings, User,\n+use super::{\n+    proto::{DeviceConfig as ProtoDeviceConfig, DeviceConfigResponse, InstanceConfigResponse},\n+    InstanceInfo,\n+};\n+use crate::{\n+    db::{\n+        models::{device::WireguardNetworkDevice, wireguard::WireguardNetwork},\n+        DbPool, Device, Settings, User,\n+    },\n+    enterprise::{\n+        db::models::enterprise_settings::EnterpriseSettings,\n+        license::{get_cached_license, validate_license},\n+    },\n };\n \n pub(crate) async fn build_device_config_response(\n@@ -93,3 +101,20 @@ pub(crate) async fn build_device_config_response(\n         token: None,\n     })\n }\n+\n+pub(crate) async fn build_instance_config_response(\n+    pool: &DbPool,\n+) -> Result<InstanceConfigResponse, Status> {\n+    debug!(\"Building instance config response\");\n+    let enterprise = validate_license(get_cached_license().as_ref()).is_ok();\n+    let enterprise_settings = EnterpriseSettings::get(pool).await.map_err(|err| {\n+        error!(\"Failed to get enterprise settings while building instance config response: {err}\");\n+        Status::internal(\"unexpected error\")\n+    })?;\n+    debug!(\"Instance config response built\");\n+\n+    Ok(InstanceConfigResponse {\n+        enterprise,\n+        disable_all_traffic: enterprise_settings.disable_all_traffic,\n+    })\n+}\ndiff --git a/src/handlers/app_info.rs b/src/handlers/app_info.rs\nindex c0f60f693..a8bc4294c 100644\n--- a/src/handlers/app_info.rs\n+++ b/src/handlers/app_info.rs\n@@ -2,11 +2,11 @@ use axum::{extract::State, http::StatusCode};\n use serde_json::json;\n \n use super::{ApiResponse, ApiResult, VERSION};\n-use crate::db::Settings;\n-use crate::enterprise::license::get_cached_license;\n use crate::{\n-    appstate::AppState, auth::SessionInfo, db::WireguardNetwork,\n-    enterprise::license::validate_license,\n+    appstate::AppState,\n+    auth::SessionInfo,\n+    db::{Settings, WireguardNetwork},\n+    enterprise::license::{get_cached_license, validate_license},\n };\n \n /// Additional information about core state.\ndiff --git a/src/secret.rs b/src/secret.rs\nindex ff062e195..d0434a8f9 100644\n--- a/src/secret.rs\n+++ b/src/secret.rs\n@@ -1,6 +1,4 @@\n-use std::convert::Infallible;\n-use std::error::Error;\n-use std::str::FromStr;\n+use std::{convert::Infallible, error::Error, str::FromStr};\n \n use secrecy::{ExposeSecret, Secret};\n use serde::{Deserialize, Serialize};\ndiff --git a/web/src/i18n/en/index.ts b/web/src/i18n/en/index.ts\nindex 6217edfb7..c8c7fb13f 100644\n--- a/web/src/i18n/en/index.ts\n+++ b/web/src/i18n/en/index.ts\n@@ -1236,6 +1236,11 @@ const en: BaseTranslation = {\n           helper:\n             \"When this option is enabled, only users in the Admin group can manage devices in user profile (it's disabled for all other users)\",\n         },\n+        disableAllTraffic: {\n+          label: 'Disable the option to route all traffic through VPN',\n+          helper:\n+            'When this option is enabled, users will not be able to route all traffic through the VPN using the defguard client.',\n+        },\n         manualConfig: {\n           label: 'Disable users ability to download manual WireGuard configuration',\n           helper:\ndiff --git a/web/src/i18n/i18n-types.ts b/web/src/i18n/i18n-types.ts\nindex 1046d6e97..b5feb55d1 100644\n--- a/web/src/i18n/i18n-types.ts\n+++ b/web/src/i18n/i18n-types.ts\n@@ -2936,6 +2936,16 @@ type RootTranslation = {\n \t\t\t\t\t */\n \t\t\t\t\thelper: string\n \t\t\t\t}\n+\t\t\t\tdisableAllTraffic: {\n+\t\t\t\t\t/**\n+\t\t\t\t\t * D\u200bi\u200bs\u200ba\u200bb\u200bl\u200be\u200b \u200bt\u200bh\u200be\u200b \u200bo\u200bp\u200bt\u200bi\u200bo\u200bn\u200b \u200bt\u200bo\u200b \u200br\u200bo\u200bu\u200bt\u200be\u200b \u200ba\u200bl\u200bl\u200b \u200bt\u200br\u200ba\u200bf\u200bf\u200bi\u200bc\u200b \u200bt\u200bh\u200br\u200bo\u200bu\u200bg\u200bh\u200b \u200bV\u200bP\u200bN\n+\t\t\t\t\t */\n+\t\t\t\t\tlabel: string\n+\t\t\t\t\t/**\n+\t\t\t\t\t * W\u200bh\u200be\u200bn\u200b \u200bt\u200bh\u200bi\u200bs\u200b \u200bo\u200bp\u200bt\u200bi\u200bo\u200bn\u200b \u200bi\u200bs\u200b \u200be\u200bn\u200ba\u200bb\u200bl\u200be\u200bd\u200b,\u200b \u200bu\u200bs\u200be\u200br\u200bs\u200b \u200bw\u200bi\u200bl\u200bl\u200b \u200bn\u200bo\u200bt\u200b \u200bb\u200be\u200b \u200ba\u200bb\u200bl\u200be\u200b \u200bt\u200bo\u200b \u200br\u200bo\u200bu\u200bt\u200be\u200b \u200ba\u200bl\u200bl\u200b \u200bt\u200br\u200ba\u200bf\u200bf\u200bi\u200bc\u200b \u200bt\u200bh\u200br\u200bo\u200bu\u200bg\u200bh\u200b \u200bt\u200bh\u200be\u200b \u200bV\u200bP\u200bN\u200b \u200bu\u200bs\u200bi\u200bn\u200bg\u200b \u200bt\u200bh\u200be\u200b \u200bd\u200be\u200bf\u200bg\u200bu\u200ba\u200br\u200bd\u200b \u200bc\u200bl\u200bi\u200be\u200bn\u200bt\u200b.\n+\t\t\t\t\t */\n+\t\t\t\t\thelper: string\n+\t\t\t\t}\n \t\t\t\tmanualConfig: {\n \t\t\t\t\t/**\n \t\t\t\t\t * D\u200bi\u200bs\u200ba\u200bb\u200bl\u200be\u200b \u200bu\u200bs\u200be\u200br\u200bs\u200b \u200ba\u200bb\u200bi\u200bl\u200bi\u200bt\u200by\u200b \u200bt\u200bo\u200b \u200bd\u200bo\u200bw\u200bn\u200bl\u200bo\u200ba\u200bd\u200b \u200bm\u200ba\u200bn\u200bu\u200ba\u200bl\u200b \u200bW\u200bi\u200br\u200be\u200bG\u200bu\u200ba\u200br\u200bd\u200b \u200bc\u200bo\u200bn\u200bf\u200bi\u200bg\u200bu\u200br\u200ba\u200bt\u200bi\u200bo\u200bn\n@@ -7176,6 +7186,16 @@ export type TranslationFunctions = {\n \t\t\t\t\t */\n \t\t\t\t\thelper: () => LocalizedString\n \t\t\t\t}\n+\t\t\t\tdisableAllTraffic: {\n+\t\t\t\t\t/**\n+\t\t\t\t\t * Disable the option to route all traffic through VPN\n+\t\t\t\t\t */\n+\t\t\t\t\tlabel: () => LocalizedString\n+\t\t\t\t\t/**\n+\t\t\t\t\t * When this option is enabled, users will not be able to route all traffic through the VPN using the defguard client.\n+\t\t\t\t\t */\n+\t\t\t\t\thelper: () => LocalizedString\n+\t\t\t\t}\n \t\t\t\tmanualConfig: {\n \t\t\t\t\t/**\n \t\t\t\t\t * Disable users ability to download manual WireGuard configuration\ndiff --git a/web/src/i18n/pl/index.ts b/web/src/i18n/pl/index.ts\nindex 723d73afa..8c73d9bce 100644\n--- a/web/src/i18n/pl/index.ts\n+++ b/web/src/i18n/pl/index.ts\n@@ -1223,6 +1223,11 @@ Uwaga, podane tutaj konfiguracje nie posiadaj\u0105 klucza prywatnego. Musisz uzupe\n           helper:\n             'Kiedy ta opcja jest w\u0142\u0105czona, tylko u\u017cytkownicy w grupie \"Admin\" mog\u0105 zarz\u0105dza\u0107 urz\u0105dzeniami w profilu u\u017cytkownika',\n         },\n+        disableAllTraffic: {\n+          label: 'Zablokuj mo\u017cliwo\u015b\u0107 przekierowania ca\u0142ego ruchu przez VPN',\n+          helper:\n+            'Kiedy ta opcja jest w\u0142\u0105czona, u\u017cytkownicy nie b\u0119d\u0105 mogli przekierowa\u0107 ca\u0142ego ruchu przez VPN za pomoc\u0105 klienta Defguard.',\n+        },\n         manualConfig: {\n           label: 'Wy\u0142\u0105cz wy\u015bwietlanie konfiguracji WireGuard',\n           helper:\ndiff --git a/web/src/pages/settings/components/EnterpriseSettings/components/EnterpriseForm.tsx b/web/src/pages/settings/components/EnterpriseSettings/components/EnterpriseForm.tsx\nindex 912fd3d80..fac922a09 100644\n--- a/web/src/pages/settings/components/EnterpriseSettings/components/EnterpriseForm.tsx\n+++ b/web/src/pages/settings/components/EnterpriseSettings/components/EnterpriseForm.tsx\n@@ -75,6 +75,19 @@ export const EnterpriseForm = () => {\n             {parse(LL.settingsPage.enterprise.fields.manualConfig.helper())}\n           </Helper>\n         </div>\n+        <div className=\"checkbox-row\">\n+          <LabeledCheckbox\n+            disabled={isLoading}\n+            label={LL.settingsPage.enterprise.fields.disableAllTraffic.label()}\n+            value={settings.disable_all_traffic}\n+            onChange={() =>\n+              mutate({ disable_all_traffic: !settings.disable_all_traffic })\n+            }\n+          />\n+          <Helper>\n+            {parse(LL.settingsPage.enterprise.fields.disableAllTraffic.helper())}\n+          </Helper>\n+        </div>\n       </Card>\n     </section>\n   );\ndiff --git a/web/src/shared/types.ts b/web/src/shared/types.ts\nindex 06336c7ae..fd02238e0 100644\n--- a/web/src/shared/types.ts\n+++ b/web/src/shared/types.ts\n@@ -871,6 +871,7 @@ export type SettingsLicense = {\n \n export type SettingsEnterprise = {\n   admin_device_management: boolean;\n+  disable_all_traffic: boolean;\n   only_client_activation: boolean;\n };\n \n", "instance_id": "DefGuard__defguard-765", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "\nThe problem statement is mostly clear in terms of the high-level goal: adding a toggle in the \"Enterprise features\" settings tab to enable or disable the \"All traffic\" feature for users, with a specific UI behavior (help message and disabled state) when the feature is turned off. It also mentions a dependency on another issue (#717) related to syncing with the \"Enterprise\" license state, which provides some context about prerequisites. However, there are minor ambiguities and missing details that prevent it from being comprehensive. For instance, the problem statement does not explicitly define what \"All traffic\" means in the context of the application (e.g., routing all network traffic through a VPN, as inferred from code changes). Additionally, it lacks specifics on how the toggle should interact with existing features or other settings, and there are no examples or detailed UI mockups provided. Edge cases, such as what happens to existing user configurations when the feature is disabled, are not addressed. Overall, while the intent is understandable, these gaps leave room for interpretation, warranting a score of 2 (Mostly Clear).\n", "difficulty_explanation": "\nI assign a difficulty score of 0.45, placing this problem in the medium range (0.4-0.6), based on the following analysis of the factors:\n\n1. **Clarity and Complexity of the Problem Description**: As noted in the clarity score, the problem is mostly clear but has minor ambiguities. Understanding the goal requires some inference (e.g., \"All traffic\" likely refers to VPN routing), but it does not pose a significant barrier to implementation. The logic itself is not inherently complex\u2014it's a straightforward feature toggle with associated UI and backend changes.\n\n2. **Scope and Depth of Code Changes**: The code changes span multiple files and layers of the application, including database schema migrations (adding a new column `disable_all_traffic` to `enterprisesettings`), updates to SQL queries (modifying SELECT, INSERT, and UPDATE statements), backend logic in Rust (updating models, GRPC responses, and handlers), and frontend updates (adding a new checkbox in the settings UI with associated translations). While the changes are distributed across several files, they are relatively localized to the enterprise settings module and do not appear to impact the broader system architecture significantly. The amount of code change is moderate, involving both structural updates (database schema) and functional updates (UI and API responses).\n\n3. **Number of Technical Concepts to Understand**: Solving this problem requires familiarity with several concepts, including:\n   - Database migrations and schema design (SQL, PostgreSQL).\n   - Rust programming, particularly with frameworks like `sqlx` for database interactions and `tonic` for GRPC.\n   - Frontend development with TypeScript/React (adding UI components and handling state).\n   - Internationalization (i18n) for multi-language support in the UI.\n   - Basic understanding of VPN or network routing concepts to contextualize \"All traffic.\"\n   These concepts are not overly complex individually, but their combination across backend, frontend, and database layers adds to the cognitive load. However, they are within the realm of standard full-stack development skills.\n\n4. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes suggest a few considerations, such as ensuring the new database field is properly initialized (handled via a default value of `FALSE`) and ensuring the client UI correctly reflects the disabled state. There may be implicit edge cases, such as handling users who have already configured \"All traffic\" before the feature is disabled, or ensuring synchronization with the enterprise license state (as hinted by the dependency on #717). However, the provided code changes do not introduce complex error handling logic, and the feature's impact seems straightforward (a boolean toggle).\n\nOverall, this problem requires understanding multiple parts of the codebase and making coordinated changes across backend, frontend, and database layers, which justifies a medium difficulty. It does not reach the \"hard\" range (0.6-0.8) because the changes are not architecturally significant, nor do they involve complex algorithms, performance optimizations, or intricate domain-specific knowledge beyond standard full-stack development. A score of 0.45 reflects the moderate complexity of integrating a new feature across several components with manageable scope and technical depth.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Proposal: `atuin config` should list all config files and dirs\nWhen writing documentation, it would be nice to tell people that they can run `atuin config` to get the locations of their config file, key file, and other important configuration locations and information.\r\n\r\nThis is in the spirit of [\"Everything that uses configuration files should report where they're located\"](https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ReportConfigFileLocations).\r\n\r\nSome examples from other commands:\r\n<details><summary>brew config</summary>\r\n\r\n```\r\n$ brew config\r\nHOMEBREW_VERSION: 4.2.2-12-g0555270\r\nORIGIN: https://github.com/Homebrew/brew\r\nHEAD: 055527086789d315ac20253966bc4afce373499c\r\nLast commit: 7 days ago\r\nCore tap HEAD: 13fda40c2e56386c3c969fc1bc0e186095228dc7\r\nCore tap last commit: 3 weeks ago\r\nCore tap JSON: 03 Jan 14:57 UTC\r\nCore cask tap HEAD: eb0b3ca130c206fea3f2c94e89393c6608f9a02a\r\nCore cask tap last commit: 3 weeks ago\r\nCore cask tap JSON: 03 Jan 14:57 UTC\r\nHOMEBREW_PREFIX: /opt/homebrew\r\nHOMEBREW_BAT_THEME: ansi\r\nHOMEBREW_CASK_OPTS: []\r\nHOMEBREW_EDITOR: /opt/homebrew/bin/nvim\r\nHOMEBREW_MAKE_JOBS: 10\r\nHOMEBREW_SORBET_RUNTIME: set\r\nHomebrew Ruby: 3.1.4 => /opt/homebrew/Library/Homebrew/vendor/portable-ruby/3.1.4/bin/ruby\r\nCPU: 10-core 64-bit arm_firestorm_icestorm\r\nClang: 15.0.0 build 1500\r\nGit: 2.43.0 => /opt/homebrew/bin/git\r\nCurl: 8.4.0 => /usr/bin/curl\r\nmacOS: 14.2.1-arm64\r\nCLT: 15.1.0.0.1.1700200546\r\nXcode: 15.2\r\nRosetta 2: false\r\n```\r\n\r\n</details>\r\n\r\n<details><summary>redis-cli INFO</summary>\r\n\r\n```\r\n# Server\r\nredis_version:7.2.3\r\nredis_git_sha1:00000000\r\nredis_git_dirty:0\r\nredis_build_id:96f23777753ded6c\r\nredis_mode:standalone\r\nos:Darwin 23.2.0 arm64\r\narch_bits:64\r\nmonotonic_clock:POSIX clock_gettime\r\nmultiplexing_api:kqueue\r\natomicvar_api:c11-builtin\r\ngcc_version:4.2.1\r\nprocess_id:69512\r\nprocess_supervised:no\r\nrun_id:81cb2362298263eb73ca70ef8d63d2be7d75670f\r\ntcp_port:6379\r\nserver_time_usec:1704903236777843\r\nuptime_in_seconds:14\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:10404420\r\nexecutable:/opt/homebrew/opt/redis/bin/redis-server\r\nconfig_file:/opt/homebrew/etc/redis.conf\r\nio_threads_active:0\r\nlistener0:name=tcp,bind=127.0.0.1,bind=::1,port=6379\r\n\r\n# Clients\r\nconnected_clients:1\r\ncluster_connections:0\r\nmaxclients:10000\r\nclient_recent_max_input_buffer:0\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\ntotal_blocking_keys:0\r\ntotal_blocking_keys_on_nokey:0\r\n\r\n# Memory\r\nused_memory:1161184\r\nused_memory_human:1.11M\r\nused_memory_rss:6455296\r\nused_memory_rss_human:6.16M\r\nused_memory_peak:1161184\r\nused_memory_peak_human:1.11M\r\nused_memory_peak_perc:100.00%\r\nused_memory_overhead:1099208\r\nused_memory_startup:1098992\r\nused_memory_dataset:61976\r\nused_memory_dataset_perc:99.65%\r\nallocator_allocated:1124560\r\nallocator_active:6423552\r\nallocator_resident:6423552\r\ntotal_system_memory:34359738368\r\ntotal_system_memory_human:32.00G\r\nused_memory_lua:31744\r\nused_memory_vm_eval:31744\r\nused_memory_lua_human:31.00K\r\nused_memory_scripts_eval:0\r\nnumber_of_cached_scripts:0\r\nnumber_of_functions:0\r\nnumber_of_libraries:0\r\nused_memory_vm_functions:32768\r\nused_memory_vm_total:64512\r\nused_memory_vm_total_human:63.00K\r\nused_memory_functions:216\r\nused_memory_scripts:216\r\nused_memory_scripts_human:216B\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:5.71\r\nallocator_frag_bytes:5298992\r\nallocator_rss_ratio:1.00\r\nallocator_rss_bytes:0\r\nrss_overhead_ratio:1.00\r\nrss_overhead_bytes:31744\r\nmem_fragmentation_ratio:5.74\r\nmem_fragmentation_bytes:5330736\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_total_replication_buffers:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:0\r\nmem_cluster_links:0\r\nmem_aof_buffer:0\r\nmem_allocator:libc\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\nlazyfreed_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nasync_loading:0\r\ncurrent_cow_peak:0\r\ncurrent_cow_size:0\r\ncurrent_cow_size_age:0\r\ncurrent_fork_perc:0.00\r\ncurrent_save_keys_processed:0\r\ncurrent_save_keys_total:0\r\nrdb_changes_since_last_save:0\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1704903222\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:-1\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_saves:0\r\nrdb_last_cow_size:0\r\nrdb_last_load_keys_expired:0\r\nrdb_last_load_keys_loaded:0\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_rewrites:0\r\naof_rewrites_consecutive_failures:0\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:3\r\ntotal_commands_processed:2\r\ninstantaneous_ops_per_sec:0\r\ntotal_net_input_bytes:42\r\ntotal_net_output_bytes:10432\r\ntotal_net_repl_input_bytes:0\r\ntotal_net_repl_output_bytes:0\r\ninstantaneous_input_kbps:0.00\r\ninstantaneous_output_kbps:0.00\r\ninstantaneous_input_repl_kbps:0.00\r\ninstantaneous_output_repl_kbps:0.00\r\nrejected_connections:0\r\nsync_full:0\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:0\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nevicted_clients:0\r\ntotal_eviction_exceeded_time:0\r\ncurrent_eviction_exceeded_time:0\r\nkeyspace_hits:0\r\nkeyspace_misses:0\r\npubsub_channels:0\r\npubsub_patterns:0\r\npubsubshard_channels:0\r\nlatest_fork_usec:0\r\ntotal_forks:0\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntotal_active_defrag_time:0\r\ncurrent_active_defrag_time:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\ntracking_total_prefixes:0\r\nunexpected_error_replies:0\r\ntotal_error_replies:0\r\ndump_payload_sanitizations:0\r\ntotal_reads_processed:5\r\ntotal_writes_processed:2\r\nio_threaded_reads_processed:0\r\nio_threaded_writes_processed:0\r\nreply_buffer_shrinks:0\r\nreply_buffer_expands:0\r\neventloop_cycles:145\r\neventloop_duration_sum:53917\r\neventloop_duration_cmd_sum:325\r\ninstantaneous_eventloop_cycles_per_sec:9\r\ninstantaneous_eventloop_duration_usec:167\r\nacl_access_denied_auth:0\r\nacl_access_denied_cmd:0\r\nacl_access_denied_key:0\r\nacl_access_denied_channel:0\r\n\r\n# Replication\r\nrole:master\r\nconnected_slaves:0\r\nmaster_failover_state:no-failover\r\nmaster_replid:1ea297a9fced698cb421c39779f946e8d1bbf1d6\r\nmaster_replid2:0000000000000000000000000000000000000000\r\nmaster_repl_offset:0\r\nsecond_repl_offset:-1\r\nrepl_backlog_active:0\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:0\r\nrepl_backlog_histlen:0\r\n\r\n# CPU\r\nused_cpu_sys:0.024833\r\nused_cpu_user:0.021988\r\nused_cpu_sys_children:0.000000\r\nused_cpu_user_children:0.000000\r\n\r\n# Modules\r\n\r\n# Errorstats\r\n\r\n# Cluster\r\ncluster_enabled:0\r\n\r\n# Keyspace\r\n```\r\n\r\n</details>\r\n\r\n<details><summary>go env</summary>\r\n\r\n```\r\n$ go env\r\nGO111MODULE=''\r\nGOARCH='arm64'\r\nGOBIN='/Users/llimllib/go/bin'\r\nGOCACHE='/Users/llimllib/Library/Caches/go-build'\r\nGOENV='/Users/llimllib/Library/Application Support/go/env'\r\nGOEXE=''\r\nGOEXPERIMENT=''\r\nGOFLAGS=''\r\nGOHOSTARCH='arm64'\r\nGOHOSTOS='darwin'\r\nGOINSECURE=''\r\nGOMODCACHE='/Users/llimllib/go/pkg/mod'\r\nGONOPROXY=''\r\nGONOSUMDB=''\r\nGOOS='darwin'\r\nGOPATH='/Users/llimllib/go'\r\nGOPRIVATE=''\r\nGOPROXY='https://proxy.golang.org,direct'\r\nGOROOT='/Users/llimllib/.local/share/asdf/installs/golang/1.21.1/go'\r\nGOSUMDB='sum.golang.org'\r\nGOTMPDIR=''\r\nGOTOOLCHAIN='auto'\r\nGOTOOLDIR='/Users/llimllib/.local/share/asdf/installs/golang/1.21.1/go/pkg/tool/darwin_arm64'\r\nGOVCS=''\r\nGOVERSION='go1.21.1'\r\nGCCGO='gccgo'\r\nAR='ar'\r\nCC='clang'\r\nCXX='clang++'\r\nCGO_ENABLED='1'\r\nGOMOD='/dev/null'\r\nGOWORK=''\r\nCGO_CFLAGS='-O2 -g'\r\nCGO_CPPFLAGS=''\r\nCGO_CXXFLAGS='-O2 -g'\r\nCGO_FFLAGS='-O2 -g'\r\nCGO_LDFLAGS='-O2 -g'\r\nPKG_CONFIG='pkg-config'\r\nGOGCCFLAGS='-fPIC -arch arm64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -ffile-prefix-map=/var/folders/cj/3fpctnd52vv37y9gpdgg7c200000gn/T/go-build1348807819=/tmp/go-build -gno-record-gcc-switches -fno-common'\r\n```\r\n\r\n</details>\r\n\r\n<details><summary>pip config list -v</summary>\r\n\r\n```\r\n$ pip config list -v\r\nFor variant 'global', will try loading '/Library/Application Support/pip/pip.conf'\r\nFor variant 'user', will try loading '/Users/llimllib/.pip/pip.conf'\r\nFor variant 'user', will try loading '/Users/llimllib/.config/pip/pip.conf'\r\nFor variant 'site', will try loading '/Users/llimllib/.local/share/asdf/installs/python/3.10.12/pip.conf'\r\n```\r\n\r\n</details>\r\n\r\nIt would be cool if `atuin` would print its entire configuration nicely like redis, but also would be an improvement if it would just tell the user that their config file is in `~/.config/atuin/config.toml`, their key in `~/.local/share/atuin/key`, and any other important file locations.\n", "patch": "diff --git a/atuin/src/command/client.rs b/atuin/src/command/client.rs\nindex 732df7ff3ba..ccd554bfa99 100644\n--- a/atuin/src/command/client.rs\n+++ b/atuin/src/command/client.rs\n@@ -17,6 +17,7 @@ mod doctor;\n mod dotfiles;\n mod history;\n mod import;\n+mod info;\n mod init;\n mod kv;\n mod search;\n@@ -59,6 +60,10 @@ pub enum Cmd {\n     #[command()]\n     Init(init::Cmd),\n \n+    /// Information about dotfiles locations and ENV vars\n+    #[command()]\n+    Info,\n+\n     #[command()]\n     Doctor,\n \n@@ -117,6 +122,11 @@ impl Cmd {\n \n             Self::Init(init) => init.run(&settings).await,\n \n+            Self::Info => {\n+                info::run(&settings);\n+                Ok(())\n+            }\n+\n             Self::Doctor => doctor::run(&settings),\n \n             Self::DefaultConfig => {\ndiff --git a/atuin/src/command/client/info.rs b/atuin/src/command/client/info.rs\nnew file mode 100644\nindex 00000000000..60ba1fe67dd\n--- /dev/null\n+++ b/atuin/src/command/client/info.rs\n@@ -0,0 +1,31 @@\n+use atuin_client::settings::Settings;\r\n+\r\n+use crate::VERSION;\r\n+\r\n+pub fn run(settings: &Settings) {\r\n+    let config = atuin_common::utils::config_dir();\r\n+    let mut config_file = config.clone();\r\n+    config_file.push(\"config.toml\");\r\n+    let mut sever_config = config;\r\n+    sever_config.push(\"server.toml\");\r\n+\r\n+    let config_paths = format!(\r\n+        \"Config files:\\nclient config: {:?}\\nserver config: {:?}\\nclient db path: {:?}\\nkey path: {:?}\\nsession path: {:?}\",\r\n+        config_file.to_string_lossy(),\r\n+        sever_config.to_string_lossy(),\r\n+        settings.db_path,\r\n+        settings.key_path,\r\n+        settings.session_path\r\n+    );\r\n+\r\n+    let env_vars = format!(\r\n+        \"Env Vars:\\nATUIN_CONFIG_DIR = {:?}\",\r\n+        std::env::var(\"ATUIN_CONFIG_DIR\").unwrap_or_else(|_| \"None\".into())\r\n+    );\r\n+\r\n+    let general_info = format!(\"Version info:\\nversion: {VERSION}\");\r\n+\r\n+    let print_out = format!(\"{config_paths}\\n\\n{env_vars}\\n\\n{general_info}\");\r\n+\r\n+    println!(\"{print_out}\");\r\n+}\r\n", "instance_id": "atuinsh__atuin-1841", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in its intent to add a feature to the `atuin` tool that lists configuration file locations and other relevant information when running `atuin config` or a similar command. The goal is well-defined, and the inclusion of examples from other tools (like `brew config`, `redis-cli INFO`, `go env`, and `pip config list`) provides a good reference for the desired output format and scope. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly specify the exact command name to be used (it suggests `atuin config` but the code changes implement `atuin info`), nor does it define the full scope of information to be displayed beyond config files and key paths. Additionally, there are no explicit mentions of edge cases, such as what to display if certain files or environment variables are not set, or how to handle permissions issues when accessing file paths. Despite these minor gaps, the overall intent and requirements are understandable, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem is relatively low, falling into the Easy category (0.2-0.4). The task involves adding a new subcommand (`info`) to the `atuin` client, which requires creating a new file (`info.rs`) and making minor modifications to an existing file (`client.rs`) to integrate the new command. The scope of code changes is small and localized, involving straightforward logic to retrieve and display configuration paths and environment variables using existing settings from the `Settings` struct. The technical concepts required are basic: familiarity with Rust's module system, command-line argument parsing (likely using a library like `clap`, as inferred from the code structure), and simple file path handling using standard library functions. No complex algorithms, design patterns, or deep architectural changes are needed, and the impact on the broader codebase is minimal. Edge cases, such as missing environment variables or inaccessible file paths, are handled minimally in the provided code (e.g., using `unwrap_or_else` for environment variables), and no advanced error handling or performance considerations are required. Overall, this is a straightforward feature addition that a developer with basic Rust experience could implement with ease, justifying a difficulty score of 0.25.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "`json!` unusable with `no_std` and feature `alloc`\nWhen you use an array inside the `json!` macro, the expansion calls `vec!` unqualified. This is a problem in a `no_std` environment, because it requires the user to `use alloc::vec`. Which is weird and no expected from a macro.\r\n\r\nReproducer on rustexplorer: https://www.rustexplorer.com/b#LyoKW2RlcGVuZGVuY2llc10Kc2VyZGVfanNvbiA9IHsgdmVyc2lvbiA9ICIxLjAuMTIwIiwgZGVmYXVsdC1mZWF0dXJlcyA9IGZhbHNlLCBmZWF0dXJlcyA9IFsiYWxsb2MiXSB9CiovCgojIVtub19zdGRdCgpleHRlcm4gY3JhdGUgYWxsb2M7CgpmbiBtYWluKCkgewogICAgc2VyZGVfanNvbjo6anNvbiEoWyIiLCAiIl0pOwp9Cg==\r\n\r\nCode: \r\n```rust\r\n/*\r\n[dependencies]\r\nserde_json = { version = \"1.0.120\", default-features = false, features = [\"alloc\"] }\r\n*/\r\n\r\n#![no_std]\r\n\r\nextern crate alloc;\r\n\r\nfn main() {\r\n    serde_json::json!([\"\", \"\"]);\r\n}\r\n```\r\n\r\nI think this issue has a simple solution by changing `vec!` to `::alloc::vec!`, unless I'm missing something.\n", "patch": "diff --git a/src/lib.rs b/src/lib.rs\nindex 3225e26f0..4ef91095f 100644\n--- a/src/lib.rs\n+++ b/src/lib.rs\n@@ -373,6 +373,12 @@ extern crate alloc;\n #[cfg(feature = \"std\")]\n extern crate std;\n \n+// Not public API. Used from macro-generated code.\n+#[doc(hidden)]\n+pub mod __private {\n+    pub use alloc::vec;\n+}\n+\n #[cfg(feature = \"std\")]\n #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n #[doc(inline)]\ndiff --git a/src/macros.rs b/src/macros.rs\nindex 68e071026..c47bdf929 100644\n--- a/src/macros.rs\n+++ b/src/macros.rs\n@@ -77,12 +77,12 @@ macro_rules! json_internal {\n \n     // Done with trailing comma.\n     (@array [$($elems:expr,)*]) => {\n-        vec![$($elems,)*]\n+        $crate::__private::vec![$($elems,)*]\n     };\n \n     // Done without trailing comma.\n     (@array [$($elems:expr),*]) => {\n-        vec![$($elems),*]\n+        $crate::__private::vec![$($elems),*]\n     };\n \n     // Next element is `null`.\n@@ -254,7 +254,7 @@ macro_rules! json_internal {\n     };\n \n     ([]) => {\n-        $crate::Value::Array(vec![])\n+        $crate::Value::Array($crate::__private::vec![])\n     };\n \n     ([ $($tt:tt)+ ]) => {\n", "instance_id": "serde-rs__json-1166", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: the `json!` macro in `serde_json` is unusable in a `no_std` environment with the `alloc` feature because it calls `vec!` unqualified, requiring users to manually import `alloc::vec`. The goal is to fix this usability issue, and a minimal reproducer is provided via a RustExplorer link, which helps in understanding the problem context. However, the statement lacks explicit mention of the expected behavior or constraints (e.g., compatibility with other features or environments) and does not discuss potential edge cases or side effects of the proposed solution. While the issue is valid and the core problem is clear, these minor missing details prevent it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem falls in the easy range (0.2-0.4) due to the following reasons based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes:** The changes are localized to two files (`lib.rs` and `macros.rs`) and involve a straightforward modification\u2014replacing unqualified `vec!` calls with a fully qualified path via a private module (`$crate::__private::vec!`). The amount of code change is minimal, with only a few lines altered, and there is no impact on the broader system architecture. It does not require understanding complex interactions across the codebase.\n\n2. **Number of Technical Concepts:** The solution requires basic familiarity with Rust's `no_std` environment, the `alloc` crate, and macro hygiene. These are relatively fundamental concepts for a Rust developer working on libraries like `serde_json`. No advanced algorithms, design patterns, or domain-specific knowledge are needed.\n\n3. **Potential Edge Cases and Error Handling:** The problem statement does not mention specific edge cases, and the code changes do not introduce new error handling logic. The fix appears to be a direct substitution without additional complexity in handling edge cases or unexpected behaviors.\n\n4. **Overall Complexity:** The issue is a usability fix rather than a deep architectural or algorithmic challenge. The proposed solution of qualifying the `vec!` macro path is simple and aligns with Rust's conventions for `no_std` compatibility. The primary challenge lies in ensuring the fix does not break other configurations (e.g., with `std` feature enabled), but this is not explicitly discussed in the problem or changes and appears to be handled implicitly by the existing feature flags.\n\nGiven these factors, a difficulty score of 0.25 reflects an easy problem that requires minimal code changes and a basic understanding of Rust's feature system and macro usage. It is slightly above the \"very easy\" range due to the need to understand `no_std` constraints and ensure compatibility, but it remains a straightforward fix for an experienced developer.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "bug: Integration dav-server-opendalfs can not handle encoded path correctly\n### Describe the bug\n\nThe currently implementation of dav-server-opendalfs will internally encode the url passed in by dav-server into %+ hex format and pass it to the dependent opendal Operator, thus accessing the wrong path.\n\nFor example, accessing '%CE%B1%CE%BB%CF%86%CE%AC%CE%B2%CE%B7%C' in dav-server-opendalfs should access decoded '\u03b1\u03bb\u03c6\u03ac\u03b2\u03b7\u03c4\u03bf' in underlying opendal service, however it actually access the encoded path currently.\n\n\n### Steps to Reproduce\n\ncode to reproduce:\n```rust\nuse dav_server::fakels::FakeLs;\nuse dav_server::DavHandler;\nuse dav_server_opendalfs::OpendalFs;\nuse hyper::body::Bytes;\nuse hyper::http;\nuse opendal::layers::LoggingLayer;\nuse opendal::{services, Operator};\nuse std::fs;\nuse tempfile::TempDir;\n\n#[tokio::main]\nasync fn main() {\n    env_logger::builder().parse_filters(\"debug\").init();\n    let tmp_dir = TempDir::with_prefix(\"test\").unwrap();\n    let builder = services::Fs::default().root(tmp_dir.path().to_str().unwrap());\n    let op = Operator::new(builder)\n        .unwrap()\n        .layer(LoggingLayer::default())\n        .finish();\n    let webdavfs = OpendalFs::new(op);\n    let dav_server = DavHandler::builder()\n        .filesystem(webdavfs)\n        .locksystem(FakeLs::new())\n        .build_handler();\n    // http://localhost:8080/test_\u03b1\u03bb\u03c6\u03ac\u03b2\u03b7\u03c4\u03bf/\n    let url_encoded = \"http://localhost:8080/test_%CE%B1%CE%BB%CF%86%CE%AC%CE%B2%CE%B7%C/\";\n    let req = http::request::Request::builder()\n        .method(\"MKCOL\")\n        .uri(url_encoded)\n        .body(http_body_util::Empty::<Bytes>::new())\n        .unwrap();\n    dav_server.handle(req).await;\n    let entries = fs::read_dir(tmp_dir.path())\n        .unwrap()\n        .collect::<Result<Vec<_>, _>>()\n        .unwrap();\n    println!(\"{:?}\", entries);\n    assert!(entries\n        .iter()\n        .any(|entry| entry.file_name() == \"test_\u03b1\u03bb\u03c6\u03ac\u03b2\u03b7\u03c4\u03bf\"));\n}\n```\n\n### Expected Behavior\n\ndav-server-opendalfs should handle encoded path correctly\n\n### Additional Context\n\n_No response_\n\n### Are you willing to submit a PR to fix this bug?\n\n- [x] Yes, I would like to submit a PR.\n", "patch": "diff --git a/integrations/dav-server/src/file.rs b/integrations/dav-server/src/file.rs\nindex d20a32c30e39..7c344552ecea 100644\n--- a/integrations/dav-server/src/file.rs\n+++ b/integrations/dav-server/src/file.rs\n@@ -19,7 +19,6 @@ use std::fmt::{Debug, Formatter};\n use std::io::SeekFrom;\n \n use bytes::{Buf, Bytes, BytesMut};\n-use dav_server::davpath::DavPath;\n use dav_server::fs::{DavFile, OpenOptions};\n use dav_server::fs::{DavMetaData, FsResult};\n use dav_server::fs::{FsError, FsFuture};\n@@ -33,7 +32,7 @@ use super::utils::*;\n /// OpendalFile is a `DavFile` implementation for opendal.\n pub struct OpendalFile {\n     op: Operator,\n-    path: DavPath,\n+    path: String,\n     state: State,\n     buf: BytesMut,\n }\n@@ -60,10 +59,10 @@ enum State {\n \n impl OpendalFile {\n     /// Create a new opendal file.\n-    pub async fn open(op: Operator, path: DavPath, options: OpenOptions) -> FsResult<Self> {\n+    pub async fn open(op: Operator, path: String, options: OpenOptions) -> FsResult<Self> {\n         let state = if options.read {\n             let r = op\n-                .reader(path.as_url_string().as_str())\n+                .reader(&path)\n                 .await\n                 .map_err(convert_error)?\n                 .into_futures_async_read(..)\n@@ -72,7 +71,7 @@ impl OpendalFile {\n             State::Read(r)\n         } else if options.write {\n             let w = op\n-                .writer_with(path.as_url_string().as_str())\n+                .writer_with(&path)\n                 .append(options.append)\n                 .await\n                 .map_err(convert_error)?\n@@ -95,7 +94,7 @@ impl DavFile for OpendalFile {\n     fn metadata(&mut self) -> FsFuture<Box<dyn DavMetaData>> {\n         async move {\n             self.op\n-                .stat(self.path.as_url_string().as_str())\n+                .stat(&self.path)\n                 .await\n                 .map(|opendal_metadata| {\n                     Box::new(OpendalMetaData::new(opendal_metadata)) as Box<dyn DavMetaData>\ndiff --git a/integrations/dav-server/src/fs.rs b/integrations/dav-server/src/fs.rs\nindex 449b562c1186..49dc3a086b09 100644\n--- a/integrations/dav-server/src/fs.rs\n+++ b/integrations/dav-server/src/fs.rs\n@@ -66,6 +66,10 @@ impl OpendalFs {\n     pub fn new(op: Operator) -> Box<OpendalFs> {\n         Box::new(OpendalFs { op })\n     }\n+\n+    fn fs_path(&self, path: &DavPath) -> Result<String, FsError> {\n+        String::from_utf8(path.as_bytes().to_vec()).map_err(|_| FsError::GeneralFailure)\n+    }\n }\n \n impl DavFileSystem for OpendalFs {\n@@ -75,7 +79,8 @@ impl DavFileSystem for OpendalFs {\n         options: dav_server::fs::OpenOptions,\n     ) -> FsFuture<'a, Box<dyn DavFile>> {\n         async move {\n-            let file = OpendalFile::open(self.op.clone(), path.clone(), options).await?;\n+            let path = self.fs_path(path)?;\n+            let file = OpendalFile::open(self.op.clone(), path, options).await?;\n             Ok(Box::new(file) as Box<dyn DavFile>)\n         }\n         .boxed()\n@@ -87,7 +92,7 @@ impl DavFileSystem for OpendalFs {\n         _meta: ReadDirMeta,\n     ) -> FsFuture<'a, FsStream<Box<dyn DavDirEntry>>> {\n         async move {\n-            let path = path.as_url_string();\n+            let path = self.fs_path(path)?;\n             self.op\n                 .lister(path.as_str())\n                 .await\n@@ -99,7 +104,8 @@ impl DavFileSystem for OpendalFs {\n \n     fn metadata<'a>(&'a self, path: &'a DavPath) -> FsFuture<'a, Box<dyn DavMetaData>> {\n         async move {\n-            let opendal_metadata = self.op.stat(path.as_url_string().as_str()).await;\n+            let path = self.fs_path(path)?;\n+            let opendal_metadata = self.op.stat(path.as_str()).await;\n             match opendal_metadata {\n                 Ok(metadata) => {\n                     let webdav_metadata = OpendalMetaData::new(metadata);\n@@ -113,7 +119,7 @@ impl DavFileSystem for OpendalFs {\n \n     fn create_dir<'a>(&'a self, path: &'a DavPath) -> FsFuture<'a, ()> {\n         async move {\n-            let path = path.as_url_string();\n+            let path = self.fs_path(path)?;\n \n             // check if the parent path is exist.\n             // During MKCOL processing, a server MUST make the Request-URI a member of its parent collection, unless the Request-URI is \"/\".  If no such ancestor exists, the method MUST fail.\n@@ -156,10 +162,8 @@ impl DavFileSystem for OpendalFs {\n \n     fn remove_file<'a>(&'a self, path: &'a DavPath) -> FsFuture<'a, ()> {\n         async move {\n-            self.op\n-                .delete(path.as_url_string().as_str())\n-                .await\n-                .map_err(convert_error)\n+            let path = self.fs_path(path)?;\n+            self.op.delete(&path).await.map_err(convert_error)\n         }\n         .boxed()\n     }\n", "instance_id": "apache__opendal-5650", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "The problem statement is mostly clear in describing the bug related to URL path encoding in the `dav-server-opendalfs` integration. It provides a specific example of the issue (encoded path not being decoded correctly) and includes a reproducible code snippet, which is helpful for understanding the problem context. The expected behavior is also stated, albeit briefly. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly discuss potential edge cases (e.g., invalid UTF-8 sequences in paths, or paths with mixed encoded and decoded components) or constraints on the solution (e.g., performance considerations or compatibility with other parts of the system). Additionally, there is no mention of how the solution should handle error cases related to decoding. Despite these minor gaps, the overall intent and issue are understandable, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the scope of code changes is moderate, involving modifications across two files (`file.rs` and `fs.rs`) in the `dav-server` integration. The changes primarily focus on replacing the use of `DavPath` with a decoded `String` representation, which requires understanding the interaction between the `dav-server` library and the `opendal` operator. Second, the technical concepts involved include URL path encoding/decoding, Rust's string handling (e.g., UTF-8 conversion), and familiarity with the `dav-server` and `opendal` APIs. These concepts are not overly complex for an experienced developer but do require a solid grasp of Rust's ownership model and async programming (given the use of `async/await`). Third, while the problem statement does not explicitly mention edge cases, the code changes suggest potential issues like handling invalid UTF-8 data during path conversion, which are addressed minimally with a basic error mapping to `FsError::GeneralFailure`. The overall impact on the system's architecture is limited, as the change is localized to path handling logic without broader systemic effects. Given the moderate scope, the need to understand a few specific concepts, and the potential for unaddressed edge cases, I assign a difficulty score of 0.45, placing it in the medium category (0.4-0.6), as it requires more than simple modifications but is not a deeply complex or architectural challenge.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Make quotes consistent for output value\n**Description**\n\nWhen you select a path (and only an _existing_ path) the output value is single-quoted.\n\n**Example**\n\n```shell\n# Create an example directory\nmkdir /tmp/example\ncd /tmp/example\n\n# Create a few directories\nmkdir a\nmkdir 'b c'\n\n# Select through 'tv'\necho 'a\\nb c\\nd e' | tv\n```\n\n* If we select the option `a` the output value is `a`\n* If we select the option `b c` the output value is `'b c'`\n* If we select the option `d e` the output value is `d e`\n\nAs you can see, the output value is single-quoted only if the selected option contains a space **and if the path actually exists**. Which is a really weird behavior, especially when we're doing something else than selecting directories. This is inconsistent and makes it hard to provide the value to other commands.\n\n**Expected behavior**\n\nValues should either:\n\n* Neither be quoted\n* Always be quoted\n* Quoted only if there is a space (or special character) in the string\n\nBut *not* quoted in some filesystem-related cases and not others like it is currently.\n\n**Environment**\n - OS: Ubuntu 24.10\n - Project version: 0.9.2\n", "patch": "diff --git a/television/app.rs b/television/app.rs\nindex 3c7c2ee..8acbf22 100644\n--- a/television/app.rs\n+++ b/television/app.rs\n@@ -271,6 +271,7 @@ impl App {\n                     {\n                         return Ok(ActionOutcome::Entries(entries));\n                     }\n+\n                     return Ok(ActionOutcome::Input(\n                         self.television.lock().await.current_pattern.clone(),\n                     ));\ndiff --git a/television/channels/alias.rs b/television/channels/alias.rs\nindex a2a4b98..19a8f5e 100644\n--- a/television/channels/alias.rs\n+++ b/television/channels/alias.rs\n@@ -170,7 +170,7 @@ async fn load_aliases(injector: Injector<Alias>) {\n             None\n         })\n         .for_each(|alias| {\n-            let () = injector.push(alias.clone(), |e, cols| {\n+            let () = injector.push(alias, |e, cols| {\n                 cols[0] = (e.name.clone() + &e.value).into();\n             });\n         });\ndiff --git a/television/channels/cable.rs b/television/channels/cable.rs\nindex aa66230..22189f7 100644\n--- a/television/channels/cable.rs\n+++ b/television/channels/cable.rs\n@@ -159,7 +159,7 @@ impl OnAir for Channel {\n             .map(|item| {\n                 let path = item.matched_string;\n                 Entry::new(\n-                    path.clone(),\n+                    path,\n                     match &self.preview_kind {\n                         PreviewKind::Command(ref preview_command) => {\n                             PreviewType::Command(preview_command.clone())\n@@ -179,7 +179,7 @@ impl OnAir for Channel {\n         self.matcher.get_result(index).map(|item| {\n             let path = item.matched_string;\n             Entry::new(\n-                path.clone(),\n+                path,\n                 match &self.preview_kind {\n                     PreviewKind::Command(ref preview_command) => {\n                         PreviewType::Command(preview_command.clone())\ndiff --git a/television/channels/entry.rs b/television/channels/entry.rs\nindex 3cee902..24a0175 100644\n--- a/television/channels/entry.rs\n+++ b/television/channels/entry.rs\n@@ -1,7 +1,6 @@\n use std::{\n     fmt::Display,\n     hash::{Hash, Hasher},\n-    path::PathBuf,\n };\n \n use devicons::FileIcon;\n@@ -143,12 +142,6 @@ impl Entry {\n \n     pub fn stdout_repr(&self) -> String {\n         let mut repr = self.name.clone();\n-        if PathBuf::from(&repr).exists()\n-            && repr.contains(|c| char::is_ascii_whitespace(&c))\n-        {\n-            repr.insert(0, '\\'');\n-            repr.push('\\'');\n-        }\n         if let Some(line_number) = self.line_number {\n             repr.push_str(&format!(\":{line_number}\"));\n         }\n@@ -226,4 +219,32 @@ mod tests {\n         let ranges = vec![(1, 2), (3, 4), (5, 6)];\n         assert_eq!(merge_ranges(&ranges), vec![(1, 2), (3, 4), (5, 6)]);\n     }\n+\n+    #[test]\n+    fn test_leaves_name_intact() {\n+        let entry = Entry {\n+            name: \"test name with spaces\".to_string(),\n+            value: None,\n+            name_match_ranges: None,\n+            value_match_ranges: None,\n+            icon: None,\n+            line_number: None,\n+            preview_type: PreviewType::Basic,\n+        };\n+        assert_eq!(entry.stdout_repr(), \"test name with spaces\");\n+    }\n+    #[test]\n+    fn test_uses_line_number_information() {\n+        let a: usize = 10;\n+        let entry = Entry {\n+            name: \"test_file_name.rs\".to_string(),\n+            value: None,\n+            name_match_ranges: None,\n+            value_match_ranges: None,\n+            icon: None,\n+            line_number: Some(a),\n+            preview_type: PreviewType::Basic,\n+        };\n+        assert_eq!(entry.stdout_repr(), \"test_file_name.rs:10\");\n+    }\n }\ndiff --git a/television/channels/git_repos.rs b/television/channels/git_repos.rs\nindex d3b574d..fec62f0 100644\n--- a/television/channels/git_repos.rs\n+++ b/television/channels/git_repos.rs\n@@ -64,12 +64,9 @@ impl OnAir for Channel {\n             .into_iter()\n             .map(|item| {\n                 let path = item.matched_string;\n-                Entry::new(\n-                    path.clone(),\n-                    PreviewType::Command(PREVIEW_COMMAND.clone()),\n-                )\n-                .with_name_match_ranges(&item.match_indices)\n-                .with_icon(self.icon)\n+                Entry::new(path, PreviewType::Command(PREVIEW_COMMAND.clone()))\n+                    .with_name_match_ranges(&item.match_indices)\n+                    .with_icon(self.icon)\n             })\n             .collect()\n     }\n@@ -77,11 +74,8 @@ impl OnAir for Channel {\n     fn get_result(&self, index: u32) -> Option<Entry> {\n         self.matcher.get_result(index).map(|item| {\n             let path = item.matched_string;\n-            Entry::new(\n-                path.clone(),\n-                PreviewType::Command(PREVIEW_COMMAND.clone()),\n-            )\n-            .with_icon(self.icon)\n+            Entry::new(path, PreviewType::Command(PREVIEW_COMMAND.clone()))\n+                .with_icon(self.icon)\n         })\n     }\n \ndiff --git a/television/channels/remote_control.rs b/television/channels/remote_control.rs\nindex 323ecaf..a6b6767 100644\n--- a/television/channels/remote_control.rs\n+++ b/television/channels/remote_control.rs\n@@ -78,9 +78,9 @@ impl RemoteControl {\n             .as_ref()\n             .and_then(|channels| channels.get(channel_name).cloned())\n         {\n-            Some(prototype) => Ok(TelevisionChannel::Cable(\n-                cable::Channel::from(prototype.clone()),\n-            )),\n+            Some(prototype) => {\n+                Ok(TelevisionChannel::Cable(cable::Channel::from(prototype)))\n+            }\n             None => match UnitChannel::try_from(channel_name) {\n                 Ok(channel) => Ok(channel.into()),\n                 Err(_) => Err(color_eyre::eyre::eyre!(\ndiff --git a/television/channels/stdin.rs b/television/channels/stdin.rs\nindex 6acb760..581c84c 100644\n--- a/television/channels/stdin.rs\n+++ b/television/channels/stdin.rs\n@@ -91,7 +91,7 @@ impl OnAir for Channel {\n \n     fn get_result(&self, index: u32) -> Option<Entry> {\n         self.matcher.get_result(index).map(|item| {\n-            Entry::new(item.matched_string.clone(), self.preview_type.clone())\n+            Entry::new(item.matched_string, self.preview_type.clone())\n         })\n     }\n \ndiff --git a/television/television.rs b/television/television.rs\nindex 9d5a914..625a170 100644\n--- a/television/television.rs\n+++ b/television/television.rs\n@@ -423,9 +423,7 @@ impl Television {\n                                 .iter()\n                                 .map(|e| e.name.clone())\n                                 .collect::<Vec<_>>()\n-                                .join(\" \")\n-                                .to_string()\n-                                .to_string(),\n+                                .join(\" \"),\n                         )\n                         .unwrap();\n                     }\n", "instance_id": "alexpasmantier__television-307", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "The problem statement is mostly clear in describing the issue with inconsistent quoting of output values based on whether a path exists and contains spaces. It provides a concrete example with shell commands and expected outputs, which helps in understanding the current behavior and the inconsistency. The expected behavior is outlined with three possible solutions (no quoting, always quoting, or quoting only with spaces/special characters), which gives a clear goal for the fix. However, there are minor ambiguities: the problem statement does not explicitly specify which of the three proposed solutions is preferred or if the developer has the freedom to choose. Additionally, it lacks detailed discussion of edge cases (e.g., handling of special characters beyond spaces, or behavior with non-ASCII characters) and constraints (e.g., performance considerations for large inputs). These missing details prevent it from being fully comprehensive, hence a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls in the Easy range (0.2-0.4) due to several factors. First, the scope of code changes is moderate but not extensive; the provided diff shows modifications across multiple files (e.g., `entry.rs`, `cable.rs`, `git_repos.rs`), but the changes are mostly straightforward, involving the removal of conditional quoting logic in `Entry::stdout_repr()` and minor adjustments to string handling in other places (e.g., removing `.clone()` calls). The core change is localized to the `Entry` struct's output representation, which simplifies the impact on the broader codebase architecture. Second, the technical concepts required are relatively basic: understanding Rust's string handling, struct methods, and basic file path operations (though the `PathBuf::exists()` check is being removed). No advanced algorithms, design patterns, or domain-specific knowledge are needed. Third, while the problem statement does not explicitly mention edge cases, the code changes suggest that edge case handling (e.g., spaces in names) is simplified by removing conditional logic, reducing complexity in this area. Overall, solving this requires understanding some code logic and making simple modifications, aligning with a difficulty score of 0.30. The task does not involve deep architectural changes or complex error handling, keeping it on the easier side of the spectrum.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "bug: incorrectly calculating the size of script that is loaded from memory\n## \ud83d\udc1b Bug Report\r\nthe script that is loaded from memory lost the last character because its size is not correct and misses a one-character from its length. \r\n\r\n### Possible Solution\r\n<!--- Not obligatory, but suggest a fix/reason for the bug, -->\r\n\r\nhttps://github.com/metacall/core/blob/76f02c051c9bfd84926331f8ada8b9506a12f04d/source/ports/rs_port/src/loaders.rs#L82-L87\r\n\r\n```diff\r\n metacall_load_from_memory( \r\n     c_tag.as_ptr(), \r\n     c_script.as_ptr(), \r\n-    script.len(), \r\n+    script.len() + 1, \r\n     ptr::null_mut(), \r\n)\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\n#### source code\r\n```rust\r\nuse metacall::{loaders, switch};\r\nfn main() {\r\n    let _metacall = switch::initialize().unwrap();\r\n    loaders::from_memory(\"node\", \"console.log('Hello world')\").unwrap();\r\n}\r\n```\r\n\r\n#### behavior\r\n```\r\nException in node_loader_trampoline_load_from_memory while loading: console.log('Hello world' 0x5b3b086100b0-0x5b3b08610080-26-2913836576:1\r\nconsole.log('Hello world'\r\n            ^^^^^^^^^^^^^\r\n\r\nSyntaxError: missing ) after argument list\r\n    at internalCompileFunction (node:internal/vm:73:18)\r\n    at wrapSafe (node:internal/modules/cjs/loader:1274:20)\r\n    at Module._compile (node:internal/modules/cjs/loader:1320:27)\r\n    at node_loader_trampoline_load_from_memory (/gnu/store/ka685gr3ah26nmjfny1kwixmv2nsc2ms-metacall-0.7.8/lib/bootstrap.js:182:5)\r\n```\r\n\n", "patch": "diff --git a/source/ports/rs_port/src/loaders.rs b/source/ports/rs_port/src/loaders.rs\nindex cf0cec127..eb691acbb 100644\n--- a/source/ports/rs_port/src/loaders.rs\n+++ b/source/ports/rs_port/src/loaders.rs\n@@ -82,7 +82,7 @@ pub fn from_memory(tag: impl ToString, script: impl ToString) -> Result<(), Meta\n         metacall_load_from_memory(\n             c_tag.as_ptr(),\n             c_script.as_ptr(),\n-            script.len(),\n+            script.len() + 1,\n             ptr::null_mut(),\n         )\n     } != 0\n", "instance_id": "metacall__core-514", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in identifying the bug: a script loaded from memory is missing its last character due to an incorrect size calculation. The issue is described with a specific error message, steps to reproduce, and a proposed solution in the form of a code diff. However, there are minor ambiguities and missing details. For instance, the problem does not explicitly clarify whether the script length issue applies to all scripts or specific types, nor does it discuss potential edge cases (e.g., empty scripts or scripts with special characters). Additionally, the context of why the length needs to be incremented by 1 (e.g., null termination or another reason) is not explained in the problem statement, which could lead to confusion. Despite these minor gaps, the overall intent and reproduction steps are clear enough to understand the issue and proposed fix, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem is very low, falling in the 0.0-0.2 range (Very Easy). The issue involves a straightforward bug fix in a single line of code within the `loaders.rs` file, changing `script.len()` to `script.len() + 1` in the `metacall_load_from_memory` function call. The scope of the change is minimal, affecting only one function and requiring no deep understanding of the broader codebase or architecture. The technical concepts involved are basic\u2014understanding string length in Rust and passing it to a C-style API. There are no complex algorithms, design patterns, or domain-specific knowledge required. While the problem statement does not explicitly mention edge cases, the simplicity of the fix suggests that edge case handling (e.g., empty strings) is either not relevant or already managed by the underlying API. Error handling modifications are not needed based on the provided diff. Overall, this is a trivial fix that a junior developer with basic Rust knowledge could implement, justifying a difficulty score of 0.15.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Fungible and fungibles adapters should allow account death like burns and mints\nThe fungible and fungibles adapters set the preservation of the burn operation to `Expendable`: [here](https://github.com/paritytech/polkadot-sdk/blob/f3ab3854e1df9e0498599f01ba4f9f152426432a/polkadot/xcm/xcm-builder/src/fungible_adapter.rs#L217) and [here](https://github.com/paritytech/polkadot-sdk/blob/f3ab3854e1df9e0498599f01ba4f9f152426432a/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs#L303).\r\nThis allows accounts to transfer all their funds (and getting reaped because of it) out of their account.\r\nHowever, this only works if they're using the `WithdrawAsset` and `DepositAsset` instructions, which correspond to `burn_from` and `mint_into`.\r\nIf `TransferAsset` is used, as is the case with [limited_reserve_assets_transfer](https://github.com/paritytech/polkadot-sdk/blob/f3ab3854e1df9e0498599f01ba4f9f152426432a/polkadot/xcm/pallet-xcm/src/lib.rs#L1881), then the [`transfer` function will be called with `Preserve`](https://github.com/paritytech/polkadot-sdk/blob/f3ab3854e1df9e0498599f01ba4f9f152426432a/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs#L61).\r\n\r\nThis distinction is arbitrary and we should change the way `TransferAsset` is handled to also allow transferring all the funds of an account. It results in confusing errors for users.\r\nIf needed, we could add a [Hint](https://github.com/paritytech/polkadot-sdk/blob/f3ab3854e1df9e0498599f01ba4f9f152426432a/polkadot/xcm/src/v5/mod.rs#L1145) for changing the default of ALL operations from `Expendable` to `Preserve`.\r\n\n", "patch": "diff --git a/polkadot/xcm/xcm-builder/src/fungible_adapter.rs b/polkadot/xcm/xcm-builder/src/fungible_adapter.rs\nindex 25a705a39eb73..2da772deb0ed7 100644\n--- a/polkadot/xcm/xcm-builder/src/fungible_adapter.rs\n+++ b/polkadot/xcm/xcm-builder/src/fungible_adapter.rs\n@@ -20,11 +20,7 @@ use super::MintLocation;\n use core::{marker::PhantomData, result};\n use frame_support::traits::{\n \ttokens::{\n-\t\tfungible,\n-\t\tFortitude::Polite,\n-\t\tPrecision::Exact,\n-\t\tPreservation::{Expendable, Preserve},\n-\t\tProvenance::Minted,\n+\t\tfungible, Fortitude::Polite, Precision::Exact, Preservation::Expendable, Provenance::Minted,\n \t},\n \tGet,\n };\n@@ -64,7 +60,7 @@ impl<\n \t\t\t.ok_or(MatchError::AccountIdConversionFailed)?;\n \t\tlet dest = AccountIdConverter::convert_location(to)\n \t\t\t.ok_or(MatchError::AccountIdConversionFailed)?;\n-\t\tFungible::transfer(&source, &dest, amount, Preserve)\n+\t\tFungible::transfer(&source, &dest, amount, Expendable)\n \t\t\t.map_err(|error| XcmError::FailedToTransactAsset(error.into()))?;\n \t\tOk(what.clone().into())\n \t}\ndiff --git a/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs b/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs\nindex a259afc6e6825..59b4ccb13d0c5 100644\n--- a/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs\n+++ b/polkadot/xcm/xcm-builder/src/fungibles_adapter.rs\n@@ -19,10 +19,7 @@\n use core::{marker::PhantomData, result};\n use frame_support::traits::{\n \ttokens::{\n-\t\tfungibles,\n-\t\tFortitude::Polite,\n-\t\tPrecision::Exact,\n-\t\tPreservation::{Expendable, Preserve},\n+\t\tfungibles, Fortitude::Polite, Precision::Exact, Preservation::Expendable,\n \t\tProvenance::Minted,\n \t},\n \tContains, Get,\n@@ -58,7 +55,7 @@ impl<\n \t\t\t.ok_or(MatchError::AccountIdConversionFailed)?;\n \t\tlet dest = AccountIdConverter::convert_location(to)\n \t\t\t.ok_or(MatchError::AccountIdConversionFailed)?;\n-\t\tAssets::transfer(asset_id, &source, &dest, amount, Preserve)\n+\t\tAssets::transfer(asset_id, &source, &dest, amount, Expendable)\n \t\t\t.map_err(|e| XcmError::FailedToTransactAsset(e.into()))?;\n \t\tOk(what.clone().into())\n \t}\ndiff --git a/prdoc/pr_7243.prdoc b/prdoc/pr_7243.prdoc\nnew file mode 100644\nindex 0000000000000..c04017c29ce43\n--- /dev/null\n+++ b/prdoc/pr_7243.prdoc\n@@ -0,0 +1,13 @@\n+# Schema: Polkadot SDK PRDoc Schema (prdoc) v1.0.0\n+# See doc at https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/prdoc/schema_user.json\n+\n+title: 'transfer function Preservation is changed to Expendable in fungible and fungibles adapter'\n+\n+doc:\n+  - audience: Runtime Dev\n+    description: |\n+      The Preservation of transfer method of fungible and fungibles adapters is changed from Preserve to Expendable. So the behavior of the TransferAsset will be consistent with the WithdrawAsset function, as in fungible and fungibles adapter.\n+\n+crates: \n+- name: staging-xcm-builder\n+  bump: patch\n\\ No newline at end of file\n", "instance_id": "paritytech__polkadot-sdk-7527", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "\nThe problem statement is mostly clear in describing the issue and the desired outcome. It identifies a specific inconsistency in the behavior of `TransferAsset` compared to `WithdrawAsset` and `DepositAsset` in the context of fungible and fungibles adapters within the Polkadot SDK. The goal of allowing accounts to transfer all funds (and potentially be reaped) using `TransferAsset` is explicitly stated, and links to relevant code sections are provided for context. However, there are minor ambiguities and missing details. For instance, the statement does not fully explain the implications of changing the preservation mode to `Expendable` across all operations or discuss potential risks or side effects of this change. Additionally, while a hint about adding a `Hint` for changing defaults is mentioned, it lacks specificity on how or when this should be implemented. Edge cases or specific scenarios where this change might cause issues are not addressed, which could lead to incomplete understanding for someone unfamiliar with the codebase.\n", "difficulty_explanation": "\nI rate the difficulty of this problem as 0.30, placing it in the \"Easy\" category. Here's the breakdown based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes**: The changes are localized to two files (`fungible_adapter.rs` and `fungibles_adapter.rs`) and involve a straightforward modification\u2014changing the `Preservation` parameter from `Preserve` to `Expendable` in the `transfer` function calls. The diff shows minimal code changes (essentially one line per file), and there is no indication of broader architectural impact or the need to modify multiple modules or interactions across the codebase. Additionally, some import statements are cleaned up, which is trivial.\n\n2. **Number of Technical Concepts**: Solving this problem requires a basic understanding of the Polkadot SDK's XCM (Cross-Consensus Messaging) framework and the specific role of preservation modes (`Preserve` vs. `Expendable`) in asset transfers. Familiarity with Rust and the `frame_support` traits for fungible and fungibles tokens is necessary, but these are not particularly advanced concepts for someone with moderate experience in Rust or blockchain development. No complex algorithms, design patterns, or domain-specific knowledge beyond the immediate context of asset transfers are required.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention specific edge cases or new error handling requirements. The code changes do not introduce new error handling logic; they simply alter the behavior of an existing function call. However, there is an implicit risk of unintended consequences (e.g., accounts being reaped unexpectedly or issues with reserve asset transfers), but these are not addressed in the problem or changes, and the scope of the change does not suggest significant complexity in handling such cases.\n\n4. **Overall Complexity**: The task is relatively simple as it involves a targeted change with a clear intent. It requires understanding the specific behavior of asset transfer operations in the Polkadot SDK, but it does not demand deep architectural knowledge or extensive refactoring. The impact is limited to the behavior of `TransferAsset`, aligning it with other operations, and does not appear to affect performance or system-wide logic.\n\nGiven these factors, the problem is easy to solve for someone with basic to intermediate familiarity with Rust and the Polkadot SDK. It does not involve complex logic, extensive code changes, or significant risk of introducing bugs if implemented as shown. The score of 0.30 reflects a task that is slightly more involved than a trivial fix (e.g., changing a constant) due to the need to understand the context of preservation modes and asset transfers, but it remains straightforward overall.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "bug: Variant extract failed\n# Bug Report\n\n**Cairo version:**\nscarb 2.9.2+nightly-2025-02-01 (3a752f93d 2025-02-01)\ncairo: 2.9.2 (99f052811)\nsierra: 1.6.0\n\nThis code fails:\n\n```\n#[derive(Copy, Drop, Debug)]\nenum Food {\n    CordonBleu,\n    Steak,\n    Sushi,\n}\n\n#[derive(Copy, Drop, Debug)]\nenum Day {\n    Monday,\n    Tuesday,\n    Wednesday,\n}\n\n// We don't have the ingredients to make Sushi.\nfn have_ingredients(food: Food) -> Option<Food> {\n    match food {\n        Food::Sushi => Option::None,\n        _ => Option::Some(food),\n    }\n}\n\n// We have the recipe for everything except Cordon Bleu.\nfn have_recipe(food: Food) -> Option<Food> {\n    match food {\n        Food::CordonBleu => Option::None,\n        _ => Option::Some(food),\n    }\n}\n\n// This can conveniently be rewritten more compactly with `and_then()`:\nfn cookable_v3(food: Food) -> Option<Food> {\n    have_recipe(food).and_then(|| have_ingredients(food))\n}\n\n\nfn eat(food: Food, day: Day) {\n    match cookable_v3(food) {\n        Option::Some(food) => println!(\"Yay! On {:?} we get to eat {:?}.\", day, food),\n        Option::None => println!(\"Oh no. We don't get to eat on {:?}?\", day),\n    }\n}\n\nfn main() {\n    let cordon_bleu= Food::CordonBleu;\n    eat(cordon_bleu, Day::Monday);\n}\n```\n\nThe issue is in `cookable_v3` where we capture `food` from the closure's environment instead of using the `some_food` returned from `and_then`. But it should be valid\n\n```\nthread 'scarb compile and_then-eubo84o80rjps' panicked at /Users/runner/.cargo/git/checkouts/cairo-f086c7e6d4098a68/99f0528/crates/cairo-lang-sierra-generator/src/utils.rs:399:21:\nVariant extract failed: `Impl(ImplGenericFunctionId { impl_id: ImplId(5), function: TraitFunctionId(53) })` is not of variant `GenericFunctionId::Extern`\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nthread 'main' panicked at scarb/src/ops/compile.rs:197:14:\nCompiler thread has panicked.: Any { .. }\n```\n", "patch": "diff --git a/crates/cairo-lang-semantic/src/expr/compute.rs b/crates/cairo-lang-semantic/src/expr/compute.rs\nindex cf508470c9f..35bb6dda1c6 100644\n--- a/crates/cairo-lang-semantic/src/expr/compute.rs\n+++ b/crates/cairo-lang-semantic/src/expr/compute.rs\n@@ -1694,7 +1694,11 @@ fn compute_expr_closure_semantic(\n         if let Some(param_types) = params_tuple_ty {\n             if let Err(err_set) = new_ctx.resolver.inference().conform_ty(closure_type, param_types)\n             {\n-                new_ctx.resolver.inference().consume_error_without_reporting(err_set);\n+                new_ctx.resolver.inference().report_on_pending_error(\n+                    err_set,\n+                    new_ctx.diagnostics,\n+                    syntax.stable_ptr().untyped(),\n+                );\n             }\n         }\n \n", "instance_id": "starkware-libs__cairo-7250", "clarity": 2, "difficulty": 0.75, "clarity_explanation": "The problem statement is mostly clear in describing the bug related to the `and_then` method in the Cairo language, where a closure captures a variable from the environment incorrectly. It provides a reproducible code snippet that triggers the bug, along with the error message and stack trace, which helps in understanding the issue. However, there are minor ambiguities: the problem statement does not explicitly clarify the expected behavior of `and_then` in this context (e.g., how the closure should handle the input from `have_recipe`), and it lacks details on potential edge cases or constraints specific to the Cairo language's type system or closure semantics. Additionally, the connection between the bug report and the provided code change is not immediately obvious without deeper context about the Cairo compiler internals. Overall, while the problem is valid and mostly clear, these missing details prevent it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem is rated as hard (0.75) due to several factors. First, the scope of the code change, while seemingly small (a single file modification in `crates/cairo-lang-semantic/src/expr/compute.rs`), involves the Cairo compiler's semantic analysis and type inference system, which is a critical and complex part of the codebase. Understanding and modifying this requires deep knowledge of the compiler's internals, specifically how closures and type inference are handled. Second, the technical concepts involved are advanced, including type inference, closure semantics, and error reporting mechanisms in a custom programming language (Cairo). Third, the problem likely requires understanding interactions between different compiler components (e.g., semantic analysis and diagnostics), even if the change is localized to one file. Fourth, while edge cases are not explicitly mentioned in the problem statement, modifying type inference and error handling logic inherently involves considering various edge cases (e.g., different closure parameter types, inference failures) to avoid introducing new bugs. Finally, the impact of the change could be significant, as it affects how errors are reported in the compiler, potentially influencing user experience and debugging. This combination of deep technical knowledge, complex concepts, and potential system-wide implications justifies a high difficulty score, though not at the extreme end (e.g., 0.9-1.0), as the change itself is relatively small and focused.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "MINOR: Add validation to the get_resource_config method in GrpcPlacementService\n### What type of enhancement is this?\r\n\r\nRefactor\r\n\r\n### What does the enhancement do?\r\n\r\nAdd validation to the get_resource_configmethod in GrpcPlacementService and fill in the test case. \r\n\r\nTips:\r\nyou can implement the `ValidateExt` trait on `GetResourceConfigRequest`, then invoke ` validate_ext ` function to achieve the validation functionality.\r\n\r\n- you can locate the ValidateExt trait in the file: src\\placement-center\\src\\server\\grpc\\validate.rs\r\n- you need to add validation to the node_list method in this file:  src\\placement-center\\src\\server\\grpc\\service_placement.rs\r\n- you need to fill in the test case in this file: src\\grpc-clients\\tests\\placement_test.rs\r\n\r\nreference:\r\n- https://github.com/robustmq/robustmq/pull/548)https://github.com/robustmq/robustmq/pull/548\r\n\r\n### Implementation challenges\r\n\r\n_No response_\n", "patch": "diff --git a/src/placement-center/src/server/grpc/service_placement.rs b/src/placement-center/src/server/grpc/service_placement.rs\nindex bace2f5f7..b9cddea91 100644\n--- a/src/placement-center/src/server/grpc/service_placement.rs\n+++ b/src/placement-center/src/server/grpc/service_placement.rs\n@@ -238,6 +238,8 @@ impl PlacementCenterService for GrpcPlacementService {\n         request: Request<GetResourceConfigRequest>,\n     ) -> Result<Response<GetResourceConfigReply>, Status> {\n         let req = request.into_inner();\n+        let _ = req.validate_ext()?;\n+\n         let storage = ResourceConfigStorage::new(self.rocksdb_engine_handler.clone());\n         match storage.get(req.cluster_name, req.resources) {\n             Ok(data) => {\ndiff --git a/src/placement-center/src/server/grpc/validate.rs b/src/placement-center/src/server/grpc/validate.rs\nindex a0f5327ff..a8c777b13 100644\n--- a/src/placement-center/src/server/grpc/validate.rs\n+++ b/src/placement-center/src/server/grpc/validate.rs\n@@ -16,8 +16,8 @@ use std::net::{IpAddr, SocketAddr};\n \n use common_base::error::common::CommonError;\n use protocol::placement_center::placement_center_inner::{\n-    ClusterType, DeleteIdempotentDataRequest, RegisterNodeRequest, SetIdempotentDataRequest,\n-    SetResourceConfigRequest, UnRegisterNodeRequest,\n+    ClusterType, DeleteIdempotentDataRequest, GetResourceConfigRequest, RegisterNodeRequest,\n+    SetIdempotentDataRequest, SetResourceConfigRequest, UnRegisterNodeRequest,\n };\n use tonic::Status;\n \n@@ -127,6 +127,18 @@ impl ValidateExt for SetResourceConfigRequest {\n     }\n }\n \n+impl ValidateExt for GetResourceConfigRequest {\n+    fn validate_ext(&self) -> Result<(), Status> {\n+        if self.cluster_name.is_empty() {\n+            return Err(Status::cancelled(\n+                CommonError::ParameterCannotBeNull(\"cluster name\".to_string()).to_string(),\n+            ));\n+        }\n+\n+        Ok(())\n+    }\n+}\n+\n impl ValidateExt for SetIdempotentDataRequest {\n     fn validate_ext(&self) -> Result<(), Status> {\n         ensure_param_not_empty(\"cluster_name\", &self.cluster_name)?;\n", "instance_id": "robustmq__robustmq-634", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in terms of the goal, which is to add validation to the `get_resource_config` method in `GrpcPlacementService` and to fill in a test case. It provides specific file locations for the implementation and references a related pull request for additional context. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define what constitutes valid input for the `GetResourceConfigRequest` beyond the code changes (e.g., it does not mention acceptable values or formats for `cluster_name` or `resources`). Additionally, there is no mention of specific edge cases or error conditions to handle beyond a basic check for an empty `cluster_name`. The \"Implementation Challenges\" section being empty also leaves potential complexities unaddressed. Overall, while the intent and basic requirements are clear, the lack of detailed constraints or edge case specifications prevents it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem is rated as easy (0.25) based on the following analysis of the factors:\n\n1. **Scope and Depth of Code Changes:** The code changes are minimal and localized to two files: `service_placement.rs` for adding a validation call and `validate.rs` for implementing the validation logic for `GetResourceConfigRequest`. The changes involve adding a single line to invoke validation in the service method and a straightforward implementation of the `ValidateExt` trait with a basic check for an empty `cluster_name`. There is no impact on the broader system architecture, and the modifications are isolated to specific functions without requiring deep interaction with other parts of the codebase.\n\n2. **Number of Technical Concepts:** The problem requires understanding of Rust's trait system to implement `ValidateExt`, basic error handling using `Result` and `Status` from the `tonic` crate, and familiarity with the project's error type `CommonError`. These concepts are relatively basic for a Rust developer and do not involve complex algorithms, design patterns, or domain-specific knowledge beyond the project's internal structure. The validation logic itself is simple, checking only for an empty string.\n\n3. **Potential Edge Cases and Error Handling:** The provided code changes handle a single edge case (empty `cluster_name`), and there are no additional complex error conditions or edge cases mentioned in the problem statement or evident from the code. The error handling logic is straightforward, returning a `Status::cancelled` with a descriptive message. No advanced error handling or performance considerations are required.\n\n4. **Overall Complexity:** The task is a simple enhancement that involves adding validation to an existing method and implementing a test case (though the test case code is not provided in the diff). It does not require deep understanding of the codebase beyond the specific files mentioned, and the changes are minor in scope. This aligns with an easy difficulty level, as it involves understanding some code logic and making simple modifications.\n\nIn summary, this problem is straightforward for a developer with basic to intermediate Rust experience, requiring minimal code changes and basic validation logic, thus warranting a difficulty score of 0.25.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "support changing applications settings via serial-settings and load/store in flash\n* On boot the initial settings are loaded from flash, or `Default::default()` if invalid\r\n* Then they are altered from retained, republished, and altered from non-retained pub messages on mqtt as currently done\r\n* serial terminal allows accessing them (get and set) as well\r\n* serial terminal allows comitting them to flash\r\n\r\nImpact/feasibility to be determined.\r\nThis allows full standalone operation without network/broker.\n", "patch": "diff --git a/Cargo.lock b/Cargo.lock\nindex 98903bf22..e256a9aa6 100644\n--- a/Cargo.lock\n+++ b/Cargo.lock\n@@ -1354,8 +1354,8 @@ dependencies = [\n \n [[package]]\n name = \"usbd-serial\"\n-version = \"0.2.0\"\n-source = \"git+https://github.com/rust-embedded-community/usbd-serial?rev=096742c1c480f6f63c1a936a3c23ede7993c624d#096742c1c480f6f63c1a936a3c23ede7993c624d\"\n+version = \"0.2.1\"\n+source = \"git+https://github.com/rust-embedded-community/usbd-serial?rev=ccff77578925942e40e0a2c7b6d397ad164fdedb#ccff77578925942e40e0a2c7b6d397ad164fdedb\"\n dependencies = [\n  \"embedded-hal 0.2.7\",\n  \"embedded-io\",\ndiff --git a/Cargo.toml b/Cargo.toml\nindex 756481687..a69db2786 100644\n--- a/Cargo.toml\n+++ b/Cargo.toml\n@@ -88,7 +88,7 @@ features = [\"stm32h743v\", \"rt\", \"ethernet\", \"xspi\", \"usb_hs\"]\n \n [patch.crates-io.usbd-serial]\n git = \"https://github.com/rust-embedded-community/usbd-serial\"\n-rev = \"096742c1c480f6f63c1a936a3c23ede7993c624d\"\n+rev = \"ccff77578925942e40e0a2c7b6d397ad164fdedb\"\n \n [features]\n nightly = []\ndiff --git a/book/src/setup.md b/book/src/setup.md\nindex ae6cc379f..b5a22edba 100644\n--- a/book/src/setup.md\n+++ b/book/src/setup.md\n@@ -21,14 +21,41 @@ Power Stabilizer through **exactly one** of the following mechanisms.\n > **Note:** Applying power through more than one mechanism may lead to damage.\n > Ensure the two unused methods are not connected or explicitly disabled.\n \n+## USB Configuration\n+\n+The USB port can be used to bootstrap Stabilizer and configure all internal settings. This is useful\n+either when first configuring the MQTT connection or when operating Stabilizer in standalone mode\n+(i.e. without an ethernet connection or an MQTT broker).\n+\n+Connect a USB cable and open up the serial port in a serial terminal of your choice. `pyserial`\n+provides a simple, easy-to-use terminal emulator:\n+```sh\n+python -m serial <port>\n+```\n+\n+Once you have opened the port, you can use the provided menu to update any of Stabilizers runtime\n+settings. All settings configured via the USB interface are only applied when Stabilizer first boots\n+up. Any modifications that occur after boot over the MQTT interface will occur after the initial\n+settings configured via USB.\n+\n+> **Note:** Settings configured via USB do not take immediat effect. Instead, they will apply after\n+> the device is rebooted.\n+\n+> **Note:** Settings configured via USB are only initial settings. Any modifications\n+> that occur after startup (i.e. via MQTT) will take precedent over those configured via USB. MQTT\n+> settings can only be persisted or retained via the MQTT broker.\n+\n+> **Note:** Saving settings via the USB port only saves the initial settings. It does not take into\n+> account the current operational settings that may have been applied via MQTT.\n+\n ## Network and DHCP\n \n Stabilizer supports 10Base-T or 100Base-T with Auto MDI-X.\n-Stabilizer uses DHCP to obtain its network configuration information. Ensure there is a\n-properly configured DHCP server running on the network segment that Stabilizer is\n-connected to.\n-Alternatively, a static IP can be enforced in the firmware build command by specifying\n-the environmental variable `STATIC_IP` analogous to how a specific broker IP is set.\n+\n+Stabilizer uses DHCP to obtain its network configuration information. Ensure there is a properly\n+configured DHCP server running on the network segment that Stabilizer is connected to. If a DHCP\n+server is not available and a static IP is desired, Stabilizer can be configured with a static IP\n+via the USB interface. A configured `ip` of \"0.0.0.0\" will use DHCP.\n \n > **Note:** If Stabilizer is connected directly to an Ubuntu system (for example using a USB-Ethernet dongle) \n you can set the IPv4 settings of this Ethernet connection in the Ubuntu network settings to\n@@ -179,16 +206,9 @@ missing timer deadlines and panicing.\n \n ## Set the MQTT broker\n \n-The MQTT broker can be configured via the USB port on Stabilizer's front. Connect a USB cable and\n-open up the serial port in a serial terminal of your choice. `pyserial` provides a simple,\n-easy-to-use terminal emulator:\n-```sh\n-python -m serial <port>\n-```\n-\n-Once you have opened the port, you can use the provided menu to update the MQTT broker address. The\n-address can be an IP address or a domain name. Once the broker has been updated, power cycle\n-stabilizer to have the new broker address take effect.\n+The MQTT broker address is [configured via the USB port on Stabilizer's front](#usb-configuration).\n+The address can be an IP address or a domain name. Once the broker address has been updated, power\n+cycle stabilizer to have the new broker address take effect.\n \n ## Verify MQTT connection\n \ndiff --git a/serial-settings/src/lib.rs b/serial-settings/src/lib.rs\nindex cb188feaf..6dcf844b5 100644\n--- a/serial-settings/src/lib.rs\n+++ b/serial-settings/src/lib.rs\n@@ -44,7 +44,7 @@\n //! qutoes.\n //!\n //! # Limitations\n-//! Currently, there is a hardcoded limit of 32-bytes on the settings path. This is arbitrary and\n+//! Currently, there is a hardcoded limit of 64-bytes on the settings path. This is arbitrary and\n //! can be changed if needed.\n #![no_std]\n \n@@ -58,19 +58,21 @@ pub use interface::BestEffortInterface;\n \n /// Specifies the API required for objects that are used as settings with the serial terminal\n /// interface.\n-pub trait Settings: for<'a> JsonCoreSlash<'a> + Clone {\n+pub trait Settings<const Y: usize>:\n+    for<'a> JsonCoreSlash<'a, Y> + Clone\n+{\n     /// Reset the settings to their default values.\n     fn reset(&mut self) {}\n }\n \n-pub trait Platform: Sized {\n+pub trait Platform<const Y: usize>: Sized {\n     /// This type specifies the interface to the user, for example, a USB CDC-ACM serial port.\n     type Interface: embedded_io::Read\n         + embedded_io::ReadReady\n         + core::fmt::Write;\n \n     /// Specifies the settings that are used on the device.\n-    type Settings: Settings;\n+    type Settings: Settings<Y>;\n \n     /// `save()` Error type\n     type Error: core::fmt::Debug;\n@@ -91,12 +93,12 @@ pub trait Platform: Sized {\n     fn settings_mut(&mut self) -> &mut Self::Settings;\n }\n \n-struct Context<'a, P: Platform> {\n+struct Context<'a, P: Platform<Y>, const Y: usize> {\n     platform: P,\n     buffer: &'a mut [u8],\n }\n \n-impl<'a, P: Platform> Context<'a, P> {\n+impl<'a, P: Platform<Y>, const Y: usize> Context<'a, P, Y> {\n     fn handle_platform(\n         _menu: &menu::Menu<Self>,\n         item: &menu::Item<Self>,\n@@ -116,7 +118,7 @@ impl<'a, P: Platform> Context<'a, P> {\n         let mut defaults = context.platform.settings().clone();\n         defaults.reset();\n \n-        for path in P::Settings::iter_paths::<heapless::String<32>>(\"/\") {\n+        for path in P::Settings::iter_paths::<heapless::String<64>>(\"/\") {\n             match path {\n                 Err(e) => writeln!(context, \"Failed to get path: {e}\"),\n                 Ok(path) => {\n@@ -297,16 +299,20 @@ impl<'a, P: Platform> Context<'a, P> {\n     }\n }\n \n-impl<'a, P: Platform> core::fmt::Write for Context<'a, P> {\n+impl<'a, P: Platform<Y>, const Y: usize> core::fmt::Write\n+    for Context<'a, P, Y>\n+{\n     fn write_str(&mut self, s: &str) -> core::fmt::Result {\n         self.platform.interface_mut().write_str(s)\n     }\n }\n \n /// The serial settings management object.\n-pub struct Runner<'a, P: Platform>(menu::Runner<'a, Context<'a, P>>);\n+pub struct Runner<'a, P: Platform<Y>, const Y: usize>(\n+    menu::Runner<'a, Context<'a, P, Y>>,\n+);\n \n-impl<'a, P: Platform> Runner<'a, P> {\n+impl<'a, P: Platform<Y>, const Y: usize> Runner<'a, P, Y> {\n     /// Constructor\n     ///\n     /// # Args\ndiff --git a/src/bin/dual-iir.rs b/src/bin/dual-iir.rs\nindex 1cbb16b54..4b96f881f 100644\n--- a/src/bin/dual-iir.rs\n+++ b/src/bin/dual-iir.rs\n@@ -16,7 +16,7 @@\n //! * Derivative kick avoidance\n //!\n //! ## Settings\n-//! Refer to the [Settings] structure for documentation of run-time configurable settings for this\n+//! Refer to the [DualIir] structure for documentation of run-time configurable settings for this\n //! application.\n //!\n //! ## Telemetry\n@@ -30,6 +30,7 @@\n \n use core::mem::MaybeUninit;\n use core::sync::atomic::{fence, Ordering};\n+use serde::{Deserialize, Serialize};\n \n use rtic_monotonics::Monotonic;\n \n@@ -56,6 +57,7 @@ use stabilizer::{\n         telemetry::{Telemetry, TelemetryBuffer},\n         NetworkState, NetworkUsers,\n     },\n+    settings::NetSettings,\n };\n \n const SCALE: f32 = i16::MAX as _;\n@@ -73,8 +75,39 @@ const SAMPLE_TICKS: u32 = 1 << SAMPLE_TICKS_LOG2;\n const SAMPLE_PERIOD: f32 =\n     SAMPLE_TICKS as f32 * hardware::design_parameters::TIMER_PERIOD;\n \n-#[derive(Clone, Copy, Debug, Tree)]\n+#[derive(Clone, Debug, Tree)]\n pub struct Settings {\n+    #[tree(depth(3))]\n+    pub dual_iir: DualIir,\n+\n+    #[tree(depth(1))]\n+    pub net: NetSettings,\n+}\n+\n+impl stabilizer::settings::AppSettings for Settings {\n+    fn new(net: NetSettings) -> Self {\n+        Self {\n+            net,\n+            dual_iir: DualIir::default(),\n+        }\n+    }\n+\n+    fn net(&self) -> &NetSettings {\n+        &self.net\n+    }\n+}\n+\n+impl serial_settings::Settings<4> for Settings {\n+    fn reset(&mut self) {\n+        *self = Self {\n+            dual_iir: DualIir::default(),\n+            net: NetSettings::new(self.net.mac),\n+        }\n+    }\n+}\n+\n+#[derive(Clone, Copy, Debug, Tree, Serialize, Deserialize)]\n+pub struct DualIir {\n     /// Configure the Analog Front End (AFE) gain.\n     ///\n     /// # Path\n@@ -148,7 +181,7 @@ pub struct Settings {\n     signal_generator: [signal_generator::BasicConfig; 2],\n }\n \n-impl Default for Settings {\n+impl Default for DualIir {\n     fn default() -> Self {\n         let mut i = iir::Biquad::IDENTITY;\n         i.set_min(-SCALE);\n@@ -184,16 +217,16 @@ mod app {\n     #[shared]\n     struct Shared {\n         usb: UsbDevice,\n-        network: NetworkUsers<Settings, Telemetry, 3>,\n+        network: NetworkUsers<DualIir, Telemetry, 3>,\n \n-        settings: Settings,\n+        settings: DualIir,\n         telemetry: TelemetryBuffer,\n         signal_generator: [SignalGenerator; 2],\n     }\n \n     #[local]\n     struct Local {\n-        usb_terminal: SerialTerminal,\n+        usb_terminal: SerialTerminal<Settings, 4>,\n         sampling_timer: SamplingTimer,\n         digital_inputs: (DigitalInput0, DigitalInput1),\n         afes: (AFE0, AFE1),\n@@ -217,34 +250,31 @@ mod app {\n             SAMPLE_TICKS,\n         );\n \n-        let settings = stabilizer.usb_serial.settings();\n+        let settings: &Settings = stabilizer.usb_serial.settings();\n         let mut network = NetworkUsers::new(\n             stabilizer.net.stack,\n             stabilizer.net.phy,\n             clock,\n             env!(\"CARGO_BIN_NAME\"),\n-            &settings.broker,\n-            &settings.id,\n+            &settings.net,\n             stabilizer.metadata,\n         );\n \n         let generator = network.configure_streaming(StreamFormat::AdcDacData);\n \n-        let settings = Settings::default();\n-\n         let shared = Shared {\n             usb: stabilizer.usb,\n             network,\n-            settings,\n+            settings: settings.dual_iir,\n             telemetry: TelemetryBuffer::default(),\n             signal_generator: [\n                 SignalGenerator::new(\n-                    settings.signal_generator[0]\n+                    settings.dual_iir.signal_generator[0]\n                         .try_into_config(SAMPLE_PERIOD, DacCode::FULL_SCALE)\n                         .unwrap(),\n                 ),\n                 SignalGenerator::new(\n-                    settings.signal_generator[1]\n+                    settings.dual_iir.signal_generator[1]\n                         .try_into_config(SAMPLE_PERIOD, DacCode::FULL_SCALE)\n                         .unwrap(),\n                 ),\ndiff --git a/src/bin/lockin.rs b/src/bin/lockin.rs\nindex 50eb4fba1..e6566f631 100644\n--- a/src/bin/lockin.rs\n+++ b/src/bin/lockin.rs\n@@ -15,8 +15,8 @@\n //! * Input/output data streamng via UDP\n //!\n //! ## Settings\n-//! Refer to the [Settings] structure for documentation of run-time configurable settings for this\n-//! application.\n+//! Refer to the [Lockin] structure for documentation of run-time configurable settings\n+//! for this application.\n //!\n //! ## Telemetry\n //! Refer to [Telemetry] for information about telemetry reported by this application.\n@@ -38,7 +38,7 @@ use rtic_monotonics::Monotonic;\n use fugit::ExtU32;\n use mutex_trait::prelude::*;\n \n-use idsp::{Accu, Complex, ComplexExt, Filter, Lockin, Lowpass, Repeat, RPLL};\n+use idsp::{Accu, Complex, ComplexExt, Filter, Lowpass, Repeat, RPLL};\n \n use stabilizer::{\n     hardware::{\n@@ -60,6 +60,7 @@ use stabilizer::{\n         telemetry::{Telemetry, TelemetryBuffer},\n         NetworkState, NetworkUsers,\n     },\n+    settings::NetSettings,\n };\n \n // The logarithm of the number of samples in each batch process. This corresponds with 2^3 samples\n@@ -73,6 +74,37 @@ const BATCH_SIZE: usize = 1 << BATCH_SIZE_LOG2;\n const SAMPLE_TICKS_LOG2: u32 = 7;\n const SAMPLE_TICKS: u32 = 1 << SAMPLE_TICKS_LOG2;\n \n+#[derive(Clone, Debug, Tree)]\n+pub struct Settings {\n+    #[tree(depth(2))]\n+    pub lockin: Lockin,\n+\n+    #[tree(depth(1))]\n+    pub net: NetSettings,\n+}\n+\n+impl stabilizer::settings::AppSettings for Settings {\n+    fn new(net: NetSettings) -> Self {\n+        Self {\n+            net,\n+            lockin: Lockin::default(),\n+        }\n+    }\n+\n+    fn net(&self) -> &NetSettings {\n+        &self.net\n+    }\n+}\n+\n+impl serial_settings::Settings<3> for Settings {\n+    fn reset(&mut self) {\n+        *self = Self {\n+            lockin: Lockin::default(),\n+            net: NetSettings::new(self.net.mac),\n+        }\n+    }\n+}\n+\n #[derive(Copy, Clone, Debug, Serialize, Deserialize)]\n enum Conf {\n     /// Output the lockin magnitude.\n@@ -100,7 +132,7 @@ enum LockinMode {\n }\n \n #[derive(Copy, Clone, Debug, Tree)]\n-pub struct Settings {\n+pub struct Lockin {\n     /// Configure the Analog Front End (AFE) gain.\n     ///\n     /// # Path\n@@ -192,7 +224,7 @@ pub struct Settings {\n     stream_target: StreamTarget,\n }\n \n-impl Default for Settings {\n+impl Default for Lockin {\n     fn default() -> Self {\n         Self {\n             afe: [Gain::G1; 2],\n@@ -221,14 +253,14 @@ mod app {\n     #[shared]\n     struct Shared {\n         usb: UsbDevice,\n-        network: NetworkUsers<Settings, Telemetry, 2>,\n-        settings: Settings,\n+        network: NetworkUsers<Lockin, Telemetry, 2>,\n+        settings: Lockin,\n         telemetry: TelemetryBuffer,\n     }\n \n     #[local]\n     struct Local {\n-        usb_terminal: SerialTerminal,\n+        usb_terminal: SerialTerminal<Settings, 3>,\n         sampling_timer: SamplingTimer,\n         digital_inputs: (DigitalInput0, DigitalInput1),\n         timestamper: InputStamper,\n@@ -236,7 +268,7 @@ mod app {\n         adcs: (Adc0Input, Adc1Input),\n         dacs: (Dac0Output, Dac1Output),\n         pll: RPLL,\n-        lockin: Lockin<Repeat<2, Lowpass<2>>>,\n+        lockin: idsp::Lockin<Repeat<2, Lowpass<2>>>,\n         signal_generator: signal_generator::SignalGenerator,\n         generator: FrameGenerator,\n         cpu_temp_sensor: stabilizer::hardware::cpu_temp_sensor::CpuTempSensor,\n@@ -255,14 +287,14 @@ mod app {\n             SAMPLE_TICKS,\n         );\n \n-        let settings = stabilizer.usb_serial.settings();\n+        let settings: &Settings = stabilizer.usb_serial.settings();\n+\n         let mut network = NetworkUsers::new(\n             stabilizer.net.stack,\n             stabilizer.net.phy,\n             clock,\n             env!(\"CARGO_BIN_NAME\"),\n-            &settings.broker,\n-            &settings.id,\n+            &settings.net,\n             stabilizer.metadata,\n         );\n \n@@ -272,7 +304,7 @@ mod app {\n             network,\n             usb: stabilizer.usb,\n             telemetry: TelemetryBuffer::default(),\n-            settings: Settings::default(),\n+            settings: settings.lockin,\n         };\n \n         let signal_config = signal_generator::Config {\n@@ -294,7 +326,7 @@ mod app {\n             timestamper: stabilizer.timestamper,\n \n             pll: RPLL::new(SAMPLE_TICKS_LOG2 + BATCH_SIZE_LOG2),\n-            lockin: Lockin::default(),\n+            lockin: idsp::Lockin::default(),\n             signal_generator: signal_generator::SignalGenerator::new(\n                 signal_config,\n             ),\ndiff --git a/src/hardware/mod.rs b/src/hardware/mod.rs\nindex 21746676c..76c477d8b 100644\n--- a/src/hardware/mod.rs\n+++ b/src/hardware/mod.rs\n@@ -84,8 +84,18 @@ pub type I2c1 = hal::i2c::I2c<hal::stm32::I2C1>;\n pub type I2c1Proxy =\n     shared_bus::I2cProxy<'static, shared_bus::AtomicCheckMutex<I2c1>>;\n \n-pub type SerialTerminal =\n-    serial_settings::Runner<'static, crate::settings::SerialSettingsPlatform>;\n+pub type SerialPort = usbd_serial::SerialPort<\n+    'static,\n+    crate::hardware::UsbBus,\n+    &'static mut setup::SerialBufferStore,\n+    &'static mut setup::SerialBufferStore,\n+>;\n+\n+pub type SerialTerminal<C, const Y: usize> = serial_settings::Runner<\n+    'static,\n+    crate::settings::SerialSettingsPlatform<C, Y>,\n+    Y,\n+>;\n \n pub enum HardwareVersion {\n     Rev1_0,\ndiff --git a/src/hardware/setup.rs b/src/hardware/setup.rs\nindex 006c52d94..1971301bd 100644\n--- a/src/hardware/setup.rs\n+++ b/src/hardware/setup.rs\n@@ -13,6 +13,8 @@ use stm32h7xx_hal::{\n \n use smoltcp_nal::smoltcp;\n \n+use crate::settings::{AppSettings, NetSettings};\n+\n use super::{\n     adc, afe, cpu_temp_sensor::CpuTempSensor, dac, delay, design_parameters,\n     eeprom, input_stamper::InputStamper, metadata::ApplicationMetadata,\n@@ -27,6 +29,26 @@ const NUM_TCP_SOCKETS: usize = 4;\n const NUM_UDP_SOCKETS: usize = 1;\n const NUM_SOCKETS: usize = NUM_UDP_SOCKETS + NUM_TCP_SOCKETS;\n \n+pub struct SerialBufferStore([u8; 1024]);\n+\n+impl Default for SerialBufferStore {\n+    fn default() -> Self {\n+        Self([0u8; 1024])\n+    }\n+}\n+\n+impl core::borrow::Borrow<[u8]> for &mut SerialBufferStore {\n+    fn borrow(&self) -> &[u8] {\n+        &self.0\n+    }\n+}\n+\n+impl core::borrow::BorrowMut<[u8]> for &mut SerialBufferStore {\n+    fn borrow_mut(&mut self) -> &mut [u8] {\n+        &mut self.0\n+    }\n+}\n+\n pub struct NetStorage {\n     pub ip_addrs: [smoltcp::wire::IpCidr; 1],\n \n@@ -107,7 +129,10 @@ pub struct EemGpioDevices {\n }\n \n /// The available hardware interfaces on Stabilizer.\n-pub struct StabilizerDevices {\n+pub struct StabilizerDevices<\n+    C: serial_settings::Settings<Y> + 'static,\n+    const Y: usize,\n+> {\n     pub temperature_sensor: CpuTempSensor,\n     pub afes: (AFE0, AFE1),\n     pub adcs: (adc::Adc0Input, adc::Adc1Input),\n@@ -118,7 +143,7 @@ pub struct StabilizerDevices {\n     pub net: NetworkDevices,\n     pub digital_inputs: (DigitalInput0, DigitalInput1),\n     pub eem_gpio: EemGpioDevices,\n-    pub usb_serial: SerialTerminal,\n+    pub usb_serial: SerialTerminal<C, Y>,\n     pub usb: UsbDevice,\n     pub metadata: &'static ApplicationMetadata,\n }\n@@ -200,13 +225,18 @@ fn load_itcm() {\n /// stabilizer hardware interfaces in a disabled state. `pounder` is an `Option` containing\n /// `Some(devices)` if pounder is detected, where `devices` is a `PounderDevices` structure\n /// containing all of the pounder hardware interfaces in a disabled state.\n-pub fn setup(\n+pub fn setup<C, const Y: usize>(\n     mut core: stm32h7xx_hal::stm32::CorePeripherals,\n     device: stm32h7xx_hal::stm32::Peripherals,\n     clock: SystemTimer,\n     batch_size: usize,\n     sample_ticks: u32,\n-) -> (StabilizerDevices, Option<PounderDevices>) {\n+) -> (StabilizerDevices<C, Y>, Option<PounderDevices>)\n+where\n+    C: serial_settings::Settings<Y>\n+        + for<'d> miniconf::JsonCoreSlash<'d, Y>\n+        + AppSettings,\n+{\n     // Set up RTT logging\n     {\n         // Enable debug during WFE/WFI-induced sleep\n@@ -624,6 +654,17 @@ pub fn setup(\n     ));\n     log::info!(\"EUI48: {}\", mac_addr);\n \n+    let (flash, settings) = {\n+        let mut flash = {\n+            let (_, flash_bank2) = device.FLASH.split();\n+            super::flash::Flash(flash_bank2.unwrap())\n+        };\n+\n+        let mut settings = C::new(NetSettings::new(mac_addr.clone()));\n+        crate::settings::load_from_flash(&mut settings, &mut flash);\n+        (flash, settings)\n+    };\n+\n     let network_devices = {\n         let ethernet_pins = {\n             // Reset the PHY before configuring pins.\n@@ -668,10 +709,14 @@ pub fn setup(\n         unsafe { ethernet::enable_interrupt() };\n \n         // Configure IP address according to DHCP socket availability\n-        let ip_addrs: smoltcp::wire::IpAddress = option_env!(\"STATIC_IP\")\n-            .unwrap_or(\"0.0.0.0\")\n-            .parse()\n-            .unwrap();\n+        let ip_addrs: smoltcp::wire::IpAddress = match settings.net().ip.parse()\n+        {\n+            Ok(addr) => addr,\n+            Err(e) => {\n+                log::warn!(\"Invalid IP address in settings: {e:?}. Defaulting to 0.0.0.0 (DHCP)\");\n+                \"0.0.0.0\".parse().unwrap()\n+            }\n+        };\n \n         let random_seed = {\n             let mut rng =\n@@ -1075,7 +1120,16 @@ pub fn setup(\n             &mut endpoint_memory[..],\n         ));\n \n-        let serial = usbd_serial::SerialPort::new(usb_bus.as_ref().unwrap());\n+        let rx_buffer = cortex_m::singleton!(: SerialBufferStore = SerialBufferStore::default()).unwrap();\n+        let tx_buffer = cortex_m::singleton!(: SerialBufferStore = SerialBufferStore::default()).unwrap();\n+\n+        let serial = {\n+            usbd_serial::SerialPort::new_with_store(\n+                usb_bus.as_ref().unwrap(),\n+                rx_buffer,\n+                tx_buffer,\n+            )\n+        };\n         let usb_device = usb_device::device::UsbDeviceBuilder::new(\n             usb_bus.as_ref().unwrap(),\n             usb_device::device::UsbVidPid(0x1209, 0x392F),\n@@ -1091,25 +1145,18 @@ pub fn setup(\n         (usb_device, serial)\n     };\n \n-    let usb_serial = {\n-        let (_, flash_bank2) = device.FLASH.split();\n-\n+    let usb_terminal = {\n         let input_buffer =\n             cortex_m::singleton!(: [u8; 256] = [0u8; 256]).unwrap();\n         let serialize_buffer =\n             cortex_m::singleton!(: [u8; 512] = [0u8; 512]).unwrap();\n \n-        let mut storage = super::flash::Flash(flash_bank2.unwrap());\n-        let mut settings =\n-            crate::settings::Settings::new(network_devices.mac_address);\n-        settings.reload(&mut storage);\n-\n         serial_settings::Runner::new(\n             crate::settings::SerialSettingsPlatform {\n                 interface: serial_settings::BestEffortInterface::new(\n                     usb_serial,\n                 ),\n-                storage,\n+                storage: flash,\n                 settings,\n                 metadata,\n             },\n@@ -1126,6 +1173,7 @@ pub fn setup(\n         temperature_sensor: CpuTempSensor::new(\n             adc3.create_channel(hal::adc::Temperature::new()),\n         ),\n+        usb_serial: usb_terminal,\n         timestamper: input_stamper,\n         net: network_devices,\n         adc_dac_timer: sampling_timer,\n@@ -1133,7 +1181,6 @@ pub fn setup(\n         digital_inputs,\n         eem_gpio,\n         usb: usb_device,\n-        usb_serial,\n         metadata,\n     };\n \ndiff --git a/src/hardware/signal_generator.rs b/src/hardware/signal_generator.rs\nindex 3a8b4d259..542520456 100644\n--- a/src/hardware/signal_generator.rs\n+++ b/src/hardware/signal_generator.rs\n@@ -20,7 +20,7 @@ pub enum Signal {\n /// Where `<signal>` may be any of [Signal] variants, `frequency` specifies the signal frequency\n /// in Hertz, `symmetry` specifies the normalized signal symmetry which ranges from 0 - 1.0, and\n /// `amplitude` specifies the signal amplitude in Volts.\n-#[derive(Copy, Clone, Debug, Tree)]\n+#[derive(Copy, Clone, Debug, Tree, Serialize, Deserialize)]\n pub struct BasicConfig {\n     /// The signal type that should be generated. See [Signal] variants.\n     pub signal: Signal,\ndiff --git a/src/net/mod.rs b/src/net/mod.rs\nindex 4248049dd..1c6d359c3 100644\n--- a/src/net/mod.rs\n+++ b/src/net/mod.rs\n@@ -17,6 +17,7 @@ use crate::hardware::{\n     metadata::ApplicationMetadata, EthernetPhy, NetworkManager, NetworkStack,\n     SystemTimer,\n };\n+use crate::settings::NetSettings;\n use data_stream::{DataStream, FrameGenerator};\n use network_processor::NetworkProcessor;\n use telemetry::TelemetryClient;\n@@ -87,8 +88,7 @@ where\n     /// * `phy` - The ethernet PHY connecting the network.\n     /// * `clock` - A `SystemTimer` implementing `Clock`.\n     /// * `app` - The name of the application.\n-    /// * `broker` - The domain name of the MQTT broker to use.\n-    /// * `id` - The MQTT client ID base to use.\n+    /// * `net_settings` - The network-specific settings to use for the application.\n     /// * `metadata` - The application metadata\n     ///\n     /// # Returns\n@@ -98,8 +98,7 @@ where\n         phy: EthernetPhy,\n         clock: SystemTimer,\n         app: &str,\n-        broker: &str,\n-        id: &str,\n+        net_settings: &NetSettings,\n         metadata: &'static ApplicationMetadata,\n     ) -> Self {\n         let stack_manager =\n@@ -109,14 +108,14 @@ where\n         let processor =\n             NetworkProcessor::new(stack_manager.acquire_stack(), phy);\n \n-        let prefix = get_device_prefix(app, id);\n+        let prefix = get_device_prefix(app, &net_settings.id);\n \n         let store =\n             cortex_m::singleton!(: MqttStorage = MqttStorage::default())\n                 .unwrap();\n \n         let named_broker = miniconf::minimq::broker::NamedBroker::new(\n-            broker,\n+            &net_settings.broker,\n             stack_manager.acquire_stack(),\n         )\n         .unwrap();\n@@ -129,13 +128,13 @@ where\n                 named_broker,\n                 &mut store.settings,\n             )\n-            .client_id(&get_client_id(id, \"settings\"))\n+            .client_id(&get_client_id(&net_settings.id, \"settings\"))\n             .unwrap(),\n         )\n         .unwrap();\n \n         let named_broker = minimq::broker::NamedBroker::new(\n-            broker,\n+            &net_settings.broker,\n             stack_manager.acquire_stack(),\n         )\n         .unwrap();\n@@ -146,7 +145,7 @@ where\n                 // The telemetry client doesn't receive any messages except MQTT control packets.\n                 // As such, we don't need much of the buffer for RX.\n                 .rx_buffer(minimq::config::BufferConfig::Maximum(100))\n-                .client_id(&get_client_id(id, \"tlm\"))\n+                .client_id(&get_client_id(&net_settings.id, \"tlm\"))\n                 .unwrap(),\n         );\n \ndiff --git a/src/settings.rs b/src/settings.rs\nindex 2c8dcf920..82623d49b 100644\n--- a/src/settings.rs\n+++ b/src/settings.rs\n@@ -6,7 +6,7 @@\n //! 2. Dynamic Run-time Settings\n //!\n //! Static device configuration settings are loaded and used only at device power-up. These include\n-//! things like the MQTT broker address and the MQTT identified. Conversely, the dynamic run-time\n+//! things like the MQTT broker address and the MQTT identifier. Conversely, the dynamic run-time\n //! settings can be changed and take effect immediately during device operation.\n //!\n //! This settings management interface is currently targeted at the static device configuration\n@@ -24,70 +24,85 @@\n //!    storage sharing.\n use crate::hardware::{flash::Flash, metadata::ApplicationMetadata, platform};\n use core::fmt::Write;\n-use miniconf::{TreeDeserialize, TreeKey, TreeSerialize};\n+use miniconf::Tree;\n use postcard::ser_flavors::Flavor;\n use stm32h7xx_hal::flash::LockedFlashBank;\n \n-#[derive(Clone, miniconf::Tree)]\n-pub struct Settings {\n+/// Settings that are used for configuring the network interface to Stabilizer.\n+#[derive(Clone, Debug, Tree)]\n+pub struct NetSettings {\n+    /// The broker domain name (or IP address) to use for MQTT connections.\n     pub broker: heapless::String<255>,\n+\n+    /// The MQTT ID to use upon connection with a broker.\n     pub id: heapless::String<23>,\n+\n+    /// An optional static IP address to use. An unspecified IP address (or malformed address) will\n+    /// use DHCP.\n+    pub ip: heapless::String<15>,\n     #[tree(skip)]\n+    /// The MAC address of Stabilizer, which is used to reinitialize the ID to default settings.\n     pub mac: smoltcp_nal::smoltcp::wire::EthernetAddress,\n }\n \n-impl serial_settings::Settings for Settings {\n-    fn reset(&mut self) {\n-        *self = Self::new(self.mac)\n-    }\n-}\n-\n-impl Settings {\n+impl NetSettings {\n     pub fn new(mac: smoltcp_nal::smoltcp::wire::EthernetAddress) -> Self {\n         let mut id = heapless::String::new();\n         write!(&mut id, \"{mac}\").unwrap();\n \n         Self {\n             broker: \"mqtt\".into(),\n+            ip: \"0.0.0.0\".into(),\n             id,\n             mac,\n         }\n     }\n+}\n \n-    pub fn reload(&mut self, storage: &mut Flash) {\n-        // Loop over flash and read settings\n-        let mut buffer = [0u8; 512];\n-        for path in Settings::iter_paths::<heapless::String<64>>(\"/\") {\n-            let path = path.unwrap();\n-\n-            // Try to fetch the setting from flash.\n-            let item = match sequential_storage::map::fetch_item::<\n-                SettingsItem,\n-                _,\n-            >(\n-                storage,\n-                storage.range(),\n-                &mut buffer,\n-                path.clone(),\n-            ) {\n-                Err(e) => {\n-                    log::warn!(\"Failed to load flash setting `{path}`: {e:?}\");\n-                    continue;\n-                }\n-                Ok(Some(item)) => item,\n-                _ => continue,\n-            };\n+pub trait AppSettings {\n+    /// Construct the settings given known network settings.\n+    fn new(net: NetSettings) -> Self;\n+\n+    /// Get the network settings from the application settings.\n+    fn net(&self) -> &NetSettings;\n+}\n \n-            log::info!(\"Found `{path}` in flash settings\");\n+pub fn load_from_flash<\n+    T: for<'d> miniconf::JsonCoreSlash<'d, Y>,\n+    const Y: usize,\n+>(\n+    structure: &mut T,\n+    storage: &mut Flash,\n+) {\n+    // Loop over flash and read settings\n+    let mut buffer = [0u8; 512];\n+    for path in T::iter_paths::<heapless::String<64>>(\"/\") {\n+        let path = path.unwrap();\n \n-            let mut deserializer = postcard::Deserializer::from_flavor(\n-                postcard::de_flavors::Slice::new(&item.data),\n-            );\n-            if let Err(e) = self\n-                .deserialize_by_key(path.split('/').skip(1), &mut deserializer)\n-            {\n-                log::warn!(\"Failed to load {path} from flash settings: {e:?}\");\n+        // Try to fetch the setting from flash.\n+        let item = match sequential_storage::map::fetch_item::<SettingsItem, _>(\n+            storage,\n+            storage.range(),\n+            &mut buffer,\n+            path.clone(),\n+        ) {\n+            Err(e) => {\n+                log::warn!(\"Failed to fetch `{path}` from flash: {e:?}\");\n+                continue;\n             }\n+            Ok(Some(item)) => item,\n+            _ => continue,\n+        };\n+\n+        log::info!(\"Loading initial `{path}` from flash\");\n+\n+        let mut deserializer = postcard::Deserializer::from_flavor(\n+            postcard::de_flavors::Slice::new(&item.data),\n+        );\n+        if let Err(e) = structure\n+            .deserialize_by_key(path.split('/').skip(1), &mut deserializer)\n+        {\n+            log::warn!(\"Failed to deserialize `{path}` from flash: {e:?}\");\n         }\n     }\n }\n@@ -128,13 +143,13 @@ impl<F> From<postcard::Error> for Error<F> {\n     }\n }\n \n-pub struct SerialSettingsPlatform {\n+pub struct SerialSettingsPlatform<C, const Y: usize> {\n     /// The interface to read/write data to/from serially (via text) to the user.\n-    pub interface: serial_settings::BestEffortInterface<\n-        usbd_serial::SerialPort<'static, crate::hardware::UsbBus>,\n-    >,\n+    pub interface:\n+        serial_settings::BestEffortInterface<crate::hardware::SerialPort>,\n+\n     /// The Settings structure.\n-    pub settings: Settings,\n+    pub settings: C,\n     /// The storage mechanism used to persist settings to between boots.\n     pub storage: Flash,\n \n@@ -142,17 +157,20 @@ pub struct SerialSettingsPlatform {\n     pub metadata: &'static ApplicationMetadata,\n }\n \n-impl serial_settings::Platform for SerialSettingsPlatform {\n-    type Interface = serial_settings::BestEffortInterface<\n-        usbd_serial::SerialPort<'static, crate::hardware::UsbBus>,\n-    >;\n-    type Settings = Settings;\n+impl<C, const Y: usize> serial_settings::Platform<Y>\n+    for SerialSettingsPlatform<C, Y>\n+where\n+    C: serial_settings::Settings<Y>,\n+{\n+    type Interface =\n+        serial_settings::BestEffortInterface<crate::hardware::SerialPort>;\n+    type Settings = C;\n     type Error = Error<\n         <LockedFlashBank as embedded_storage::nor_flash::ErrorType>::Error,\n     >;\n \n     fn save(&mut self, buf: &mut [u8]) -> Result<(), Self::Error> {\n-        for path in Settings::iter_paths::<heapless::String<64>>(\"/\") {\n+        for path in Self::Settings::iter_paths::<heapless::String<64>>(\"/\") {\n             let mut item = SettingsItem {\n                 path: path.unwrap(),\n                 ..Default::default()\n@@ -168,7 +186,7 @@ impl serial_settings::Platform for SerialSettingsPlatform {\n                 .settings\n                 .serialize_by_key(item.path.split('/').skip(1), &mut serializer)\n             {\n-                log::warn!(\"Failed to save {} to flash: {e:?}\", item.path);\n+                log::warn!(\"Failed to save `{}` to flash: {e:?}\", item.path);\n                 continue;\n             }\n \n@@ -189,7 +207,7 @@ impl serial_settings::Platform for SerialSettingsPlatform {\n             .map(|old| old.data != item.data)\n             .unwrap_or(true)\n             {\n-                log::info!(\"Storing setting `{}` in flash\", item.path);\n+                log::info!(\"Storing `{}` to flash\", item.path);\n                 sequential_storage::map::store_item(\n                     &mut self.storage,\n                     range,\n", "instance_id": "quartiq__stabilizer-857", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "\nThe problem statement is mostly clear in outlining the goal of supporting application settings changes via a serial interface and storing/loading them in flash memory. It specifies key behaviors such as loading initial settings from flash on boot, handling settings via MQTT (retained and non-retained), and allowing serial terminal access for getting, setting, and committing settings to flash. The intent of enabling standalone operation without a network or broker is also mentioned. However, there are minor ambiguities and missing details that prevent a perfect score. For instance, the problem statement does not explicitly define the format or structure of the settings data, nor does it mention specific constraints or requirements for flash storage (e.g., size limits, wear leveling). Additionally, edge cases such as handling corrupted flash data or conflicts between MQTT and serial settings updates are not addressed. While the overall objective is understandable, these missing details could lead to implementation uncertainties.\n", "difficulty_explanation": "\nI assign a difficulty score of 0.65, placing this problem in the \"Hard\" category due to several factors:\n\n1. **Scope and Depth of Code Changes**: The code changes provided in the diff are extensive, spanning multiple files and modules in a Rust-based embedded system project. Modifications affect core components such as settings management, serial communication, network configuration, and flash storage. The changes involve restructuring how settings are stored and accessed (e.g., splitting settings into application-specific and network-specific parts), updating USB serial handling, and integrating flash storage logic. These changes impact multiple layers of the system, requiring a good understanding of the interactions between hardware, middleware, and application logic. While the changes do not appear to fundamentally alter the system's architecture, they are significant in scope, touching critical functionality like boot-time initialization and runtime settings updates.\n\n2. **Number of Technical Concepts**: Solving this problem requires familiarity with several advanced concepts in Rust and embedded systems programming. Key areas include:\n   - **Embedded Rust**: Understanding of `no_std` environments, memory management with `cortex_m` singletons, and safe handling of hardware resources.\n   - **Serial Communication**: Knowledge of USB serial protocols and libraries like `usbd-serial` for implementing a terminal interface.\n   - **Flash Storage**: Handling non-volatile storage with libraries like `sequential_storage` for persistent settings, including serialization/deserialization with `postcard`.\n   - **Settings Management**: Use of the `miniconf` crate for hierarchical settings with JSON-like traversal and serialization.\n   - **MQTT and Networking**: Understanding how settings interact with network configurations and MQTT brokers, including handling static IP vs. DHCP.\n   - **Concurrency and Safety**: Managing shared resources in an RTIC (Real-Time Interrupt-driven Concurrency) framework, ensuring thread-safety and avoiding data races.\n   These concepts are moderately to highly complex, especially for someone not already familiar with embedded Rust or the specific libraries used in this codebase.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement hints at edge cases such as invalid flash data (falling back to `Default::default()`), but the code changes reveal additional complexity in error handling. For instance, the code includes logic to handle malformed IP addresses by defaulting to DHCP, logging warnings for failed flash operations, and managing settings precedence between USB and MQTT updates. Implementing robust error handling for flash corruption, serial communication failures, and settings conflicts adds to the difficulty. These edge cases are not trivial, as they require careful design to ensure system stability in a standalone mode without network support.\n\n4. **Overall Complexity**: While the problem does not reach the \"Very Hard\" category (e.g., it does not involve designing a new protocol or deep system-level optimizations), it demands a deep understanding of the existing codebase and careful integration of new functionality. The need to modify multiple interdependent components (settings, serial interface, flash storage, network stack) and ensure correctness across boot and runtime scenarios pushes this into the \"Hard\" range. A developer would need significant experience with Rust, embedded systems, and the specific libraries used to implement this feature without introducing bugs or performance issues.\n\nIn summary, this problem is challenging due to the breadth of code changes, the depth of technical knowledge required, and the need to handle non-trivial edge cases. A score of 0.65 reflects the complexity of integrating serial settings management into an existing embedded system while maintaining robustness and compatibility with existing features like MQTT-based settings updates.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Add `with_value` handler for value like items in agents.\nThe `HandlerContext` provides the following handler for map like items:\r\n\r\n```rust\r\n    pub fn with_entry<'a, Item, K, V, F>(\r\n        &self,\r\n        lane: fn(&Agent) -> &Item,\r\n        key: K,\r\n        f: F,\r\n    ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'a\r\n    where\r\n        Agent: 'static,\r\n        Item: TransformableMapLikeItem<K, V> + 'static,\r\n        K: Send + Clone + Eq + Hash + 'static,\r\n        V: Clone + 'static, // Clone here is spurious, see #607\r\n        F: FnOnce(Option<V>) -> Option<V> + Send + 'a,\r\n```\r\n\r\nThis creates a handler that will transform the value associated with a key in the map like item.\r\n\r\nThis is inflexible as it requires that the value be cloned. It should be altered to borrow the current value instead. An additional combinator called `transform_entry` can be introduced with the existing functionality.\r\n\r\nEquivalent combinators should be added for value like items.\n", "patch": "diff --git a/example_apps/tutorial_app/src/unit_agent.rs b/example_apps/tutorial_app/src/unit_agent.rs\nindex 7501ead6c..55d8fef61 100644\n--- a/example_apps/tutorial_app/src/unit_agent.rs\n+++ b/example_apps/tutorial_app/src/unit_agent.rs\n@@ -153,8 +153,8 @@ fn update_histogram(\n     item: HistoryItem,\n ) -> impl EventHandler<UnitAgent> {\n     let bucket = bucket_of(&item.timestamp);\n-    context.with_entry(UnitAgent::HISTOGRAM, bucket, |maybe| {\n-        let mut counter = maybe.unwrap_or_default();\n+    context.transform_entry(UnitAgent::HISTOGRAM, bucket, |maybe| {\n+        let mut counter = maybe.copied().unwrap_or_default();\n         counter.count += rand::thread_rng().gen_range(0..20);\n         Some(counter)\n     })\ndiff --git a/server/swimos_agent/src/agent_lifecycle/utility/mod.rs b/server/swimos_agent/src/agent_lifecycle/utility/mod.rs\nindex 6f18a3882..aec999a17 100644\n--- a/server/swimos_agent/src/agent_lifecycle/utility/mod.rs\n+++ b/server/swimos_agent/src/agent_lifecycle/utility/mod.rs\n@@ -13,6 +13,7 @@\n // limitations under the License.\n \n use std::any::Any;\n+use std::borrow::Borrow;\n use std::fmt::Debug;\n use std::hash::Hash;\n use std::time::Duration;\n@@ -41,7 +42,7 @@ use crate::event_handler::{\n };\n use crate::event_handler::{GetAgentUri, HandlerAction, SideEffect};\n use crate::item::{\n-    JoinLikeItem, MapLikeItem, MutableMapLikeItem, MutableValueLikeItem, TransformableMapLikeItem,\n+    InspectableMapLikeItem, JoinLikeItem, MapLikeItem, MutableMapLikeItem, MutableValueLikeItem,\n     ValueLikeItem,\n };\n use crate::lanes::command::{CommandLane, DoCommand};\n@@ -157,45 +158,86 @@ impl<Agent: 'static> HandlerContext<Agent> {\n \n     /// Create an event handler that will get the value of a value lane store of the agent.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the value lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the value lane or store.\n     pub fn get_value<Item, T>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n     ) -> impl HandlerAction<Agent, Completion = T> + Send + 'static\n     where\n         Item: ValueLikeItem<T>,\n         T: Clone + Send + 'static,\n     {\n-        Item::get_handler::<Agent>(lane)\n+        Item::get_handler::<Agent>(item)\n     }\n \n-    /// Create an event handler that will set a new value into value lane or store of the agent.\n+    /// Create an event handler that will set a new value into a value lane or store of the agent.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the value lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the value lane or store.\n     /// * `value` - The value to set.\n     pub fn set_value<Item, T>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n         value: T,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'static\n     where\n         Item: MutableValueLikeItem<T>,\n         T: Send + 'static,\n     {\n-        Item::set_handler::<Agent>(lane, value)\n+        Item::set_handler::<Agent>(item, value)\n+    }\n+\n+    /// Create an event handler that will transform the value of a value lane or store of the agent.\n+    ///\n+    /// #Arguments\n+    /// * `item` - Projection to the value lane or store.\n+    /// * `f` - A closure that produces a new value from a reference to the existing value.\n+    pub fn transform_value<'a, Item, T, F>(\n+        &self,\n+        item: fn(&Agent) -> &Item,\n+        f: F,\n+    ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'a\n+    where\n+        Agent: 'static,\n+        Item: ValueLikeItem<T> + MutableValueLikeItem<T> + 'static,\n+        T: 'static,\n+        F: FnOnce(&T) -> T + Send + 'a,\n+    {\n+        Item::with_value_handler::<Item, Agent, F, T, T>(item, f)\n+            .and_then(move |v| Item::set_handler(item, v))\n+    }\n+\n+    /// Create an event handler that will inspect the value of a value lane or store and generate a result from it.\n+    /// This differs from using [`Self::get_value`] in that it does not require a clone to be made of the existing value.\n+    ///\n+    /// #Arguments\n+    /// * `item` - Projection to the value lane or store.\n+    /// * `f` - A closure that produces a value from a reference to the current value of the item.\n+    pub fn with_value<'a, Item, T, F, B, U>(\n+        &self,\n+        item: fn(&Agent) -> &Item,\n+        f: F,\n+    ) -> impl HandlerAction<Agent, Completion = U> + Send + 'a\n+    where\n+        Agent: 'static,\n+        Item: ValueLikeItem<T> + 'static,\n+        T: Borrow<B>,\n+        B: 'static,\n+        F: FnOnce(&B) -> U + Send + 'a,\n+    {\n+        Item::with_value_handler::<Item, Agent, F, B, U>(item, f)\n     }\n \n     /// Create an event handler that will update an entry in a map lane or store of the agent.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane or store.\n     /// * `key - The key to update.\n     /// * `value` - The new value.\n     pub fn update<Item, K, V>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n         key: K,\n         value: V,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'static\n@@ -204,39 +246,66 @@ impl<Agent: 'static> HandlerContext<Agent> {\n         K: Send + Clone + Eq + Hash + 'static,\n         V: Send + 'static,\n     {\n-        Item::update_handler::<Agent>(lane, key, value)\n+        Item::update_handler::<Agent>(item, key, value)\n     }\n \n-    /// Create an event handler that will transform the value in an entry of a map lane or store of the agent.\n+    /// Create an event handler that will inspect an entry in the map and produce a new value from it.\n+    /// This differs from using [`Self::get_entry`] in that it does not require that a clone be made of the existing value.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane or store.\n     /// * `key - The key to update.\n     /// * `f` - A function to apple to the entry in the map.\n-    pub fn with_entry<'a, Item, K, V, F>(\n+    pub fn with_entry<'a, Item, K, V, F, B, U>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n+        key: K,\n+        f: F,\n+    ) -> impl HandlerAction<Agent, Completion = U> + Send + 'a\n+    where\n+        Agent: 'static,\n+        Item: InspectableMapLikeItem<K, V> + 'static,\n+        K: Send + Clone + Eq + Hash + 'static,\n+        V: Borrow<B> + 'static,\n+        B: ?Sized + 'static,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a,\n+    {\n+        Item::with_entry_handler::<Agent, F, B, U>(item, key, f)\n+    }\n+\n+    /// Create an event handler that will transform the value in an entry of a map lane or store of the agent.\n+    /// If the map contains an entry with that key, it will be updated (or removed) based on the result of the calling\n+    /// the closure on it. If the map does not contain an entry with that key, the closure will be called with [`None`]\n+    /// and an entry will be inserted if it returns a value.\n+    ///\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane.\n+    /// * `key - The key to update.\n+    /// * `f` - A closure to apply to the entry in the map to produce the replacement.\n+    pub fn transform_entry<'a, Item, K, V, F>(\n+        &self,\n+        item: fn(&Agent) -> &Item,\n         key: K,\n         f: F,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'a\n     where\n         Agent: 'static,\n-        Item: TransformableMapLikeItem<K, V> + 'static,\n+        Item: MutableMapLikeItem<K, V> + 'static,\n         K: Send + Clone + Eq + Hash + 'static,\n-        V: Clone + 'static,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a,\n+        V: 'static,\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a,\n     {\n-        Item::with_handler::<Agent, F>(lane, key, f)\n+        Item::transform_entry_handler::<Agent, F>(item, key, f)\n     }\n \n     /// Create an event handler that will remove an entry from a map lane or store of the agent.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane or store.\n     /// * `key - The key to remove.\n     pub fn remove<Item, K, V>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n         key: K,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'static\n     where\n@@ -244,33 +313,33 @@ impl<Agent: 'static> HandlerContext<Agent> {\n         K: Send + Clone + Eq + Hash + 'static,\n         V: Send + 'static,\n     {\n-        Item::remove_handler::<Agent>(lane, key)\n+        Item::remove_handler::<Agent>(item, key)\n     }\n \n     /// Create an event handler that will clear a map lane or store of the agent.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane or store.\n     pub fn clear<Item, K, V>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'static\n     where\n         Item: MutableMapLikeItem<K, V>,\n         K: Send + Clone + Eq + Hash + 'static,\n         V: Send + 'static,\n     {\n-        Item::clear_handler::<Agent>(lane)\n+        Item::clear_handler::<Agent>(item)\n     }\n \n     /// Create an event handler that replaces the entire contents of a map lane or store.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map lane or store.\n     /// * `entries` - The new entries for the lane.\n     pub fn replace_map<Item, K, V, I>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n         entries: I,\n     ) -> impl HandlerAction<Agent, Completion = ()> + Send + 'static\n     where\n@@ -283,19 +352,19 @@ impl<Agent: 'static> HandlerContext<Agent> {\n         let context = *self;\n         let insertions = entries\n             .into_iter()\n-            .map(move |(k, v)| context.update(lane, k, v));\n-        self.clear(lane).followed_by(Sequentially::new(insertions))\n+            .map(move |(k, v)| context.update(item, k, v));\n+        self.clear(item).followed_by(Sequentially::new(insertions))\n     }\n \n     /// Create an event handler that will attempt to get an entry from a map-like item of the agent.\n     /// This includes map lanes and stores and join lanes.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map-like item.\n     /// * `key - The key to fetch.\n     pub fn get_entry<Item, K, V>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n         key: K,\n     ) -> impl HandlerAction<Agent, Completion = Option<V>> + Send + 'static\n     where\n@@ -303,24 +372,24 @@ impl<Agent: 'static> HandlerContext<Agent> {\n         K: Send + Clone + Eq + Hash + 'static,\n         V: Send + Clone + 'static,\n     {\n-        Item::get_handler::<Agent>(lane, key)\n+        Item::get_handler::<Agent>(item, key)\n     }\n \n     /// Create an event handler that will attempt to get the entire contents of a map-like item of the\n     /// agent. This includes map lanes and stores and join lanes.\n     ///\n-    /// # Arguments\n-    /// * `lane` - Projection to the map lane.\n+    /// #Arguments\n+    /// * `item` - Projection to the map-like item.\n     pub fn get_map<Item, K, V>(\n         &self,\n-        lane: fn(&Agent) -> &Item,\n+        item: fn(&Agent) -> &Item,\n     ) -> impl HandlerAction<Agent, Completion = HashMap<K, V>> + Send + 'static\n     where\n         Item: MapLikeItem<K, V>,\n         K: Send + Clone + Eq + Hash + 'static,\n         V: Send + Clone + 'static,\n     {\n-        Item::get_map_handler::<Agent>(lane)\n+        Item::get_map_handler::<Agent>(item)\n     }\n \n     /// Create an event handler that will send a command to a command lane of the agent.\ndiff --git a/server/swimos_agent/src/item.rs b/server/swimos_agent/src/item.rs\nindex 40f1cf22a..81a78d287 100644\n--- a/server/swimos_agent/src/item.rs\n+++ b/server/swimos_agent/src/item.rs\n@@ -12,7 +12,7 @@\n // See the License for the specific language governing permissions and\n // limitations under the License.\n \n-use std::collections::HashMap;\n+use std::{borrow::Borrow, collections::HashMap};\n \n use crate::{\n     event_handler::{EventHandler, HandlerAction},\n@@ -51,9 +51,32 @@ pub trait MapLikeItem<K, V> {\n         C: 'static;\n \n     fn get_handler<C: 'static>(projection: fn(&C) -> &Self, key: K) -> Self::GetHandler<C>;\n+\n     fn get_map_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::GetMapHandler<C>;\n }\n \n+pub trait InspectableMapLikeItem<K, V> {\n+    type WithEntryHandler<'a, C, F, B, U>: HandlerAction<C, Completion = U> + Send + 'a\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+\n+    fn with_entry_handler<'a, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        key: K,\n+        f: F,\n+    ) -> Self::WithEntryHandler<'a, C, F, B, U>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+}\n+\n pub trait MutableMapLikeItem<K, V> {\n     type UpdateHandler<C>: EventHandler<C> + Send + 'static\n     where\n@@ -72,24 +95,22 @@ pub trait MutableMapLikeItem<K, V> {\n     ) -> Self::UpdateHandler<C>;\n     fn remove_handler<C: 'static>(projection: fn(&C) -> &Self, key: K) -> Self::RemoveHandler<C>;\n     fn clear_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::ClearHandler<C>;\n-}\n \n-pub trait TransformableMapLikeItem<K, V> {\n-    type WithEntryHandler<'a, C, F>: EventHandler<C> + Send + 'a\n+    type TransformEntryHandler<'a, C, F>: EventHandler<C> + Send + 'a\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a;\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a;\n \n-    fn with_handler<'a, C, F>(\n+    fn transform_entry_handler<'a, C, F>(\n         projection: fn(&C) -> &Self,\n         key: K,\n         f: F,\n-    ) -> Self::WithEntryHandler<'a, C, F>\n+    ) -> Self::TransformEntryHandler<'a, C, F>\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a;\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a;\n }\n \n pub trait ValueLikeItem<T> {\n@@ -97,7 +118,25 @@ pub trait ValueLikeItem<T> {\n     where\n         C: 'static;\n \n+    type WithValueHandler<'a, C, F, B, U>: HandlerAction<C, Completion = U> + Send + 'a\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a;\n+\n     fn get_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::GetHandler<C>;\n+\n+    fn with_value_handler<'a, Item, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        f: F,\n+    ) -> Self::WithValueHandler<'a, C, F, B, U>\n+    where\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a;\n }\n \n pub trait MutableValueLikeItem<T> {\ndiff --git a/server/swimos_agent/src/lanes/join/map/mod.rs b/server/swimos_agent/src/lanes/join/map/mod.rs\nindex 307061ebd..7f590c3e5 100644\n--- a/server/swimos_agent/src/lanes/join/map/mod.rs\n+++ b/server/swimos_agent/src/lanes/join/map/mod.rs\n@@ -18,6 +18,7 @@ use std::{\n     cell::RefCell,\n     collections::{hash_map::Entry, BTreeSet, HashMap, HashSet},\n     hash::Hash,\n+    marker::PhantomData,\n };\n \n use bytes::BytesMut;\n@@ -38,7 +39,7 @@ use crate::{\n     event_handler::{\n         ActionContext, EventHandler, EventHandlerError, HandlerAction, Modification, StepResult,\n     },\n-    item::{AgentItem, MapItem, MapLikeItem},\n+    item::{AgentItem, InspectableMapLikeItem, MapItem, MapLikeItem},\n     lanes::{\n         join_map::default_lifecycle::DefaultJoinMapLifecycle, map::MapLaneEvent, LaneItem, MapLane,\n     },\n@@ -685,6 +686,55 @@ where\n     }\n }\n \n+/// A [`HandlerAction`] that will produce a value by applying a closure to a reference to\n+/// and entry in the lane.\n+pub struct JoinMapLaneWithEntry<C, L, K, V, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a JoinMapLane<L, K, V>,\n+    key: K,\n+    f: Option<F>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, L, K, V, F, B: ?Sized> JoinMapLaneWithEntry<C, L, K, V, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the lane.\n+    /// * `key` - Key of the entry.\n+    /// * `f` - The closure to apply to the entry.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a JoinMapLane<L, K, V>, key: K, f: F) -> Self {\n+        JoinMapLaneWithEntry {\n+            projection,\n+            key,\n+            f: Some(f),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n+impl<'a, C, L, K, V, F, B, U> HandlerAction<C> for JoinMapLaneWithEntry<C, L, K, V, F, B>\n+where\n+    K: Eq + Hash + 'static,\n+    C: 'a,\n+    B: ?Sized + 'static,\n+    V: Borrow<B>,\n+    F: FnOnce(Option<&B>) -> U + Send + 'a,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        if let Some(f) = self.f.take() {\n+            let item = (self.projection)(context);\n+            StepResult::done(item.inner.with_entry(&self.key, f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n+\n impl<L, K, V> MapLikeItem<K, V> for JoinMapLane<L, K, V>\n where\n     L: Send + 'static,\n@@ -708,6 +758,36 @@ where\n     }\n }\n \n+impl<L, K, V> InspectableMapLikeItem<K, V> for JoinMapLane<L, K, V>\n+where\n+    L: Send + 'static,\n+    K: Clone + Eq + Hash + Send + 'static,\n+    V: Send + 'static,\n+{\n+    type WithEntryHandler<'a, C, F, B, U> = JoinMapLaneWithEntry<C, L, K, V, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+\n+    fn with_entry_handler<'a, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        key: K,\n+        f: F,\n+    ) -> Self::WithEntryHandler<'a, C, F, B, U>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a,\n+    {\n+        JoinMapLaneWithEntry::new(projection, key, f)\n+    }\n+}\n+\n /// An [`EventHandler`] that will remove a downlink from the lane.\n pub struct JoinMapRemoveDownlink<L, C, K, V> {\n     projection: fn(&C) -> &JoinMapLane<L, K, V>,\ndiff --git a/server/swimos_agent/src/lanes/join/value/mod.rs b/server/swimos_agent/src/lanes/join/value/mod.rs\nindex 132528608..bd307b4b6 100644\n--- a/server/swimos_agent/src/lanes/join/value/mod.rs\n+++ b/server/swimos_agent/src/lanes/join/value/mod.rs\n@@ -16,6 +16,7 @@ use std::any::{Any, TypeId};\n use std::borrow::Borrow;\n use std::collections::hash_map::Entry;\n use std::hash::Hash;\n+use std::marker::PhantomData;\n use std::{cell::RefCell, collections::HashMap};\n \n use bytes::BytesMut;\n@@ -28,7 +29,7 @@ use uuid::Uuid;\n use crate::agent_model::downlink::OpenEventDownlinkAction;\n use crate::config::SimpleDownlinkConfig;\n use crate::event_handler::{EventHandler, EventHandlerError, Modification};\n-use crate::item::{JoinLikeItem, MapLikeItem};\n+use crate::item::{InspectableMapLikeItem, JoinLikeItem, MapLikeItem};\n use crate::{\n     agent_model::WriteResult,\n     event_handler::{ActionContext, HandlerAction, StepResult},\n@@ -460,6 +461,55 @@ impl<C, K, V> JoinValueAddDownlink<C, K, V> {\n     }\n }\n \n+/// A [`HandlerAction`] that will produce a value by applying a closure to a reference to\n+/// and entry in the lane.\n+pub struct JoinValueLaneWithEntry<C, K, V, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a JoinValueLane<K, V>,\n+    key: K,\n+    f: Option<F>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, K, V, F, B: ?Sized> JoinValueLaneWithEntry<C, K, V, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the lane.\n+    /// * `key` - Key of the entry.\n+    /// * `f` - The closure to apply to the entry.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a JoinValueLane<K, V>, key: K, f: F) -> Self {\n+        JoinValueLaneWithEntry {\n+            projection,\n+            key,\n+            f: Some(f),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n+impl<'a, C, K, V, F, B, U> HandlerAction<C> for JoinValueLaneWithEntry<C, K, V, F, B>\n+where\n+    K: Eq + Hash + 'static,\n+    C: 'a,\n+    B: ?Sized + 'static,\n+    V: Borrow<B>,\n+    F: FnOnce(Option<&B>) -> U + Send + 'a,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        if let Some(f) = self.f.take() {\n+            let item = (self.projection)(context);\n+            StepResult::done(item.inner.with_entry(&self.key, f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n+\n impl<K, V> MapLikeItem<K, V> for JoinValueLane<K, V>\n where\n     K: Clone + Eq + Hash + Send + 'static,\n@@ -482,6 +532,35 @@ where\n     }\n }\n \n+impl<K, V> InspectableMapLikeItem<K, V> for JoinValueLane<K, V>\n+where\n+    K: Clone + Eq + Hash + Send + 'static,\n+    V: Send + 'static,\n+{\n+    type WithEntryHandler<'a, C, F, B, U> = JoinValueLaneWithEntry<C, K, V, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+\n+    fn with_entry_handler<'a, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        key: K,\n+        f: F,\n+    ) -> Self::WithEntryHandler<'a, C, F, B, U>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a,\n+    {\n+        JoinValueLaneWithEntry::new(projection, key, f)\n+    }\n+}\n+\n /// An [`EventHandler`] that will remove a downlink from the lane.\n pub struct JoinValueRemoveDownlink<C, K, V> {\n     projection: fn(&C) -> &JoinValueLane<K, V>,\ndiff --git a/server/swimos_agent/src/lanes/map/mod.rs b/server/swimos_agent/src/lanes/map/mod.rs\nindex 1ed763896..19ccf3ef3 100644\n--- a/server/swimos_agent/src/lanes/map/mod.rs\n+++ b/server/swimos_agent/src/lanes/map/mod.rs\n@@ -34,8 +34,8 @@ use crate::{\n         ActionContext, AndThen, EventHandlerError, HandlerAction, HandlerActionExt, HandlerTrans,\n         Modification, StepResult,\n     },\n-    item::{AgentItem, MapItem, MapLikeItem, MutableMapLikeItem, TransformableMapLikeItem},\n-    map_storage::{MapStoreInner, WithEntryResult},\n+    item::{AgentItem, InspectableMapLikeItem, MapItem, MapLikeItem, MutableMapLikeItem},\n+    map_storage::{MapStoreInner, TransformEntryResult},\n     meta::AgentMetadata,\n };\n \n@@ -104,12 +104,11 @@ where\n     }\n \n     /// Transform the value associated with a key.\n-    pub(crate) fn with_entry<F>(&self, key: K, f: F) -> WithEntryResult\n+    pub fn transform_entry<F>(&self, key: K, f: F) -> TransformEntryResult\n     where\n-        V: Clone,\n-        F: FnOnce(Option<V>) -> Option<V>,\n+        F: FnOnce(Option<&V>) -> Option<V>,\n     {\n-        self.inner.borrow_mut().with_entry(key, f)\n+        self.inner.borrow_mut().transform_entry(key, f)\n     }\n \n     /// Remove and entry from the map.\n@@ -129,7 +128,7 @@ where\n         Q: Hash + Eq,\n         F: FnOnce(Option<&V>) -> R,\n     {\n-        self.inner.borrow().get(key, f)\n+        self.inner.borrow().with_entry(key, f)\n     }\n \n     /// Read the complete state of the map.\n@@ -147,6 +146,20 @@ where\n     }\n }\n \n+impl<K, V> MapLane<K, V>\n+where\n+    K: Eq + Hash,\n+{\n+    pub fn with_entry<F, B, U>(&self, key: &K, f: F) -> U\n+    where\n+        B: ?Sized,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U,\n+    {\n+        self.inner.borrow().with_entry(key, f)\n+    }\n+}\n+\n const INFALLIBLE_SER: &str = \"Serializing lane responses to recon should be infallible.\";\n \n impl<K, V> LaneItem for MapLane<K, V>\n@@ -381,6 +394,56 @@ where\n     }\n }\n \n+impl<C, K, V, F, B, U> HandlerAction<C> for MapLaneWithEntry<C, K, V, F, B>\n+where\n+    K: Eq + Hash,\n+    B: ?Sized,\n+    V: Borrow<B>,\n+    F: FnOnce(Option<&B>) -> U,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        let MapLaneWithEntry {\n+            projection,\n+            key_and_f,\n+            ..\n+        } = self;\n+        if let Some((key, f)) = key_and_f.take() {\n+            let lane = projection(context);\n+            StepResult::done(lane.with_entry(&key, f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n+\n+///  An [event handler](crate::event_handler::EventHandler)`] that will alter an entry in the map.\n+pub struct MapLaneWithEntry<C, K, V, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a MapLane<K, V>,\n+    key_and_f: Option<(K, F)>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, K, V, F, B: ?Sized> MapLaneWithEntry<C, K, V, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the lane.\n+    /// * `key` - Key of the entry.\n+    /// * `f` - The closure to apply to the entry.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a MapLane<K, V>, key: K, f: F) -> Self {\n+        MapLaneWithEntry {\n+            projection,\n+            key_and_f: Some((key, f)),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n ///  An [event handler](crate::event_handler::EventHandler)`] that will request a sync from the lane.\n pub struct MapLaneSync<C, K, V> {\n     projection: for<'a> fn(&'a C) -> &'a MapLane<K, V>,\n@@ -528,26 +591,25 @@ where\n     decode.and_then(ProjTransform::new(projection))\n }\n \n-///  An [event handler](crate::event_handler::EventHandler)`] that will alter an entry in the map.\n-pub struct MapLaneWithEntry<C, K, V, F> {\n+/// An (event handler)[`crate::event_handler::EventHandler`] that will alter an entry in the map.\n+pub struct MapLaneTransformEntry<C, K, V, F> {\n     projection: for<'a> fn(&'a C) -> &'a MapLane<K, V>,\n     key_and_f: Option<(K, F)>,\n }\n \n-impl<C, K, V, F> MapLaneWithEntry<C, K, V, F> {\n+impl<C, K, V, F> MapLaneTransformEntry<C, K, V, F> {\n     pub fn new(projection: for<'a> fn(&'a C) -> &'a MapLane<K, V>, key: K, f: F) -> Self {\n-        MapLaneWithEntry {\n+        MapLaneTransformEntry {\n             projection,\n             key_and_f: Some((key, f)),\n         }\n     }\n }\n \n-impl<C, K, V, F> HandlerAction<C> for MapLaneWithEntry<C, K, V, F>\n+impl<C, K, V, F> HandlerAction<C> for MapLaneTransformEntry<C, K, V, F>\n where\n     K: Clone + Eq + Hash,\n-    V: Clone,\n-    F: FnOnce(Option<V>) -> Option<V>,\n+    F: FnOnce(Option<&V>) -> Option<V>,\n {\n     type Completion = ();\n \n@@ -557,13 +619,13 @@ where\n         _meta: AgentMetadata,\n         context: &C,\n     ) -> StepResult<Self::Completion> {\n-        let MapLaneWithEntry {\n+        let MapLaneTransformEntry {\n             projection,\n             key_and_f,\n         } = self;\n         if let Some((key, f)) = key_and_f.take() {\n             let lane = projection(context);\n-            if matches!(lane.with_entry(key, f), WithEntryResult::NoChange) {\n+            if matches!(lane.transform_entry(key, f), TransformEntryResult::NoChange) {\n                 StepResult::done(())\n             } else {\n                 StepResult::Complete {\n@@ -599,6 +661,35 @@ where\n     }\n }\n \n+impl<K, V> InspectableMapLikeItem<K, V> for MapLane<K, V>\n+where\n+    K: Eq + Hash + Send + 'static,\n+    V: 'static,\n+{\n+    type WithEntryHandler<'a, C, F, B, U> = MapLaneWithEntry<C, K, V, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized +'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+\n+    fn with_entry_handler<'a, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        key: K,\n+        f: F,\n+    ) -> Self::WithEntryHandler<'a, C, F, B, U>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a,\n+    {\n+        MapLaneWithEntry::new(projection, key, f)\n+    }\n+}\n+\n impl<K, V> MutableMapLikeItem<K, V> for MapLane<K, V>\n where\n     K: Clone + Eq + Hash + Send + 'static,\n@@ -631,29 +722,23 @@ where\n     fn clear_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::ClearHandler<C> {\n         MapLaneClear::new(projection)\n     }\n-}\n \n-impl<K, V> TransformableMapLikeItem<K, V> for MapLane<K, V>\n-where\n-    K: Clone + Eq + Hash + Send + 'static,\n-    V: Clone + Send + 'static,\n-{\n-    type WithEntryHandler<'a, C, F> = MapLaneWithEntry<C, K, V, F>\n+    type TransformEntryHandler<'a, C, F> = MapLaneTransformEntry<C, K, V, F>\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a;\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a;\n \n-    fn with_handler<'a, C, F>(\n+    fn transform_entry_handler<'a, C, F>(\n         projection: fn(&C) -> &Self,\n         key: K,\n         f: F,\n-    ) -> Self::WithEntryHandler<'a, C, F>\n+    ) -> Self::TransformEntryHandler<'a, C, F>\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a,\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a,\n     {\n-        MapLaneWithEntry::new(projection, key, f)\n+        MapLaneTransformEntry::new(projection, key, f)\n     }\n }\ndiff --git a/server/swimos_agent/src/lanes/value/mod.rs b/server/swimos_agent/src/lanes/value/mod.rs\nindex 969ad2657..55d845df1 100644\n--- a/server/swimos_agent/src/lanes/value/mod.rs\n+++ b/server/swimos_agent/src/lanes/value/mod.rs\n@@ -17,7 +17,7 @@ pub mod lifecycle;\n #[cfg(test)]\n mod tests;\n \n-use std::{cell::RefCell, collections::VecDeque};\n+use std::{borrow::Borrow, cell::RefCell, collections::VecDeque, marker::PhantomData};\n \n use bytes::BytesMut;\n use static_assertions::assert_impl_all;\n@@ -77,6 +77,23 @@ impl<T> ValueLane<T> {\n         let ValueLane { sync_queue, .. } = self;\n         sync_queue.borrow_mut().push_back(id);\n     }\n+\n+    /// Replace the contents of the lane.\n+    pub fn replace<F>(&self, f: F)\n+    where\n+        F: FnOnce(&T) -> T,\n+    {\n+        self.store.replace(f);\n+    }\n+\n+    pub(crate) fn with<F, B, U>(&self, f: F) -> U\n+    where\n+        B: ?Sized,\n+        T: Borrow<B>,\n+        F: FnOnce(&B) -> U,\n+    {\n+        self.store.with(f)\n+    }\n }\n \n impl<T> AgentItem for ValueLane<T> {\n@@ -257,6 +274,49 @@ impl<C, T> HandlerAction<C> for ValueLaneSync<C, T> {\n     }\n }\n \n+/// An [`HandlerAction`] that will produce a value from a reference to the contents of the lane.\n+pub struct ValueLaneWithValue<C, T, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a ValueLane<T>,\n+    f: Option<F>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, T, F, B: ?Sized> ValueLaneWithValue<C, T, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the lane.\n+    /// * `f` - Closure to apply to the value of the lane.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a ValueLane<T>, f: F) -> Self {\n+        ValueLaneWithValue {\n+            projection,\n+            f: Some(f),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n+impl<C, T, F, B, U> HandlerAction<C> for ValueLaneWithValue<C, T, F, B>\n+where\n+    B: ?Sized,\n+    T: Borrow<B>,\n+    F: FnOnce(&B) -> U,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        if let Some(f) = self.f.take() {\n+            let lane = (self.projection)(context);\n+            StepResult::done(lane.with(f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n+\n impl<C, T> HandlerTrans<T> for ProjTransform<C, ValueLane<T>> {\n     type Out = ValueLaneSet<C, T>;\n \n@@ -286,9 +346,30 @@ where\n     where\n         C: 'static;\n \n+    type WithValueHandler<'a, C, F, B, U> = ValueLaneWithValue<C, T, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a;\n+\n     fn get_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::GetHandler<C> {\n         ValueLaneGet::new(projection)\n     }\n+\n+    fn with_value_handler<'a, Item, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        f: F,\n+    ) -> Self::WithValueHandler<'a, C, F, B, U>\n+    where\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a,\n+    {\n+        ValueLaneWithValue::new(projection, f)\n+    }\n }\n \n impl<T> MutableValueLikeItem<T> for ValueLane<T>\ndiff --git a/server/swimos_agent/src/map_storage/mod.rs b/server/swimos_agent/src/map_storage/mod.rs\nindex 53d923508..411580c84 100644\n--- a/server/swimos_agent/src/map_storage/mod.rs\n+++ b/server/swimos_agent/src/map_storage/mod.rs\n@@ -50,7 +50,7 @@ impl<K, V, Q: Default> MapStoreInner<K, V, Q> {\n     }\n }\n \n-pub enum WithEntryResult {\n+pub enum TransformEntryResult {\n     NoChange,\n     Update,\n     Remove,\n@@ -76,10 +76,9 @@ where\n         queue.push(MapOperation::Update { key, value: () });\n     }\n \n-    pub fn with_entry<F>(&mut self, key: K, f: F) -> WithEntryResult\n+    pub fn transform_entry<F>(&mut self, key: K, f: F) -> TransformEntryResult\n     where\n-        V: Clone,\n-        F: FnOnce(Option<V>) -> Option<V>,\n+        F: FnOnce(Option<&V>) -> Option<V>,\n     {\n         let MapStoreInner {\n             content,\n@@ -87,17 +86,17 @@ where\n             queue,\n         } = self;\n         match content.remove(&key) {\n-            Some(v) => match f(Some(v.clone())) {\n+            Some(v) => match f(Some(&v)) {\n                 Some(v2) => {\n                     content.insert(key.clone(), v2);\n                     *previous = Some(MapLaneEvent::Update(key.clone(), Some(v)));\n                     queue.push(MapOperation::Update { key, value: () });\n-                    WithEntryResult::Update\n+                    TransformEntryResult::Update\n                 }\n                 _ => {\n                     *previous = Some(MapLaneEvent::Remove(key.clone(), v));\n                     queue.push(MapOperation::Remove { key: key.clone() });\n-                    WithEntryResult::Remove\n+                    TransformEntryResult::Remove\n                 }\n             },\n             _ => match f(None) {\n@@ -105,9 +104,9 @@ where\n                     content.insert(key.clone(), v2);\n                     *previous = Some(MapLaneEvent::Update(key.clone(), None));\n                     queue.push(MapOperation::Update { key, value: () });\n-                    WithEntryResult::Update\n+                    TransformEntryResult::Update\n                 }\n-                _ => WithEntryResult::NoChange,\n+                _ => TransformEntryResult::NoChange,\n             },\n         }\n     }\n@@ -135,16 +134,6 @@ where\n         queue.push(MapOperation::Clear);\n     }\n \n-    pub fn get<B, F, R>(&self, key: &B, f: F) -> R\n-    where\n-        K: Borrow<B>,\n-        B: Hash + Eq,\n-        F: FnOnce(Option<&V>) -> R,\n-    {\n-        let MapStoreInner { content, .. } = self;\n-        f(content.get(key))\n-    }\n-\n     pub fn get_map<F, R>(&self, f: F) -> R\n     where\n         F: FnOnce(&HashMap<K, V>) -> R,\n@@ -172,3 +161,21 @@ where\n         queue.pop(content)\n     }\n }\n+\n+impl<K, V, Q> MapStoreInner<K, V, Q>\n+where\n+    K: Eq + Hash,\n+{\n+    pub fn with_entry<B1, B2, F, R>(&self, key: &B1, f: F) -> R\n+    where\n+        B1: ?Sized,\n+        B2: ?Sized,\n+        K: Borrow<B1>,\n+        V: Borrow<B2>,\n+        B1: Hash + Eq,\n+        F: FnOnce(Option<&B2>) -> R,\n+    {\n+        let MapStoreInner { content, .. } = self;\n+        f(content.get(key).map(Borrow::borrow))\n+    }\n+}\ndiff --git a/server/swimos_agent/src/stores/map/mod.rs b/server/swimos_agent/src/stores/map/mod.rs\nindex ac24123ca..52cdea627 100644\n--- a/server/swimos_agent/src/stores/map/mod.rs\n+++ b/server/swimos_agent/src/stores/map/mod.rs\n@@ -14,6 +14,7 @@\n \n use std::borrow::Borrow;\n use std::hash::Hash;\n+use std::marker::PhantomData;\n use std::{cell::RefCell, collections::HashMap};\n \n use bytes::BytesMut;\n@@ -25,8 +26,8 @@ use tokio_util::codec::Encoder;\n use crate::agent_model::WriteResult;\n use crate::event_handler::{ActionContext, HandlerAction, Modification, StepResult};\n use crate::event_queue::EventQueue;\n-use crate::item::{AgentItem, MapItem, MapLikeItem, MutableMapLikeItem, TransformableMapLikeItem};\n-use crate::map_storage::{MapStoreInner, WithEntryResult};\n+use crate::item::{AgentItem, InspectableMapLikeItem, MapItem, MapLikeItem, MutableMapLikeItem};\n+use crate::map_storage::{MapStoreInner, TransformEntryResult};\n use crate::meta::AgentMetadata;\n \n use super::StoreItem;\n@@ -91,12 +92,11 @@ where\n     }\n \n     /// Transform the value associated with a key.\n-    pub fn with_entry<F>(&self, key: K, f: F) -> WithEntryResult\n+    pub fn transform_entry<F>(&self, key: K, f: F) -> TransformEntryResult\n     where\n-        V: Clone,\n-        F: FnOnce(Option<V>) -> Option<V>,\n+        F: FnOnce(Option<&V>) -> Option<V>,\n     {\n-        self.inner.borrow_mut().with_entry(key, f)\n+        self.inner.borrow_mut().transform_entry(key, f)\n     }\n \n     /// Remove an entry from the map.\n@@ -112,11 +112,11 @@ where\n     /// Read a value from the map, if it exists.\n     pub fn get<Q, F, R>(&self, key: &Q, f: F) -> R\n     where\n-        K: Borrow<Q>,\n-        Q: Hash + Eq,\n+        K: Borrow<Q> + Eq + Hash,\n+        Q: Eq + Hash,\n         F: FnOnce(Option<&V>) -> R,\n     {\n-        self.inner.borrow().get(key, f)\n+        self.inner.borrow().with_entry(key, f)\n     }\n \n     /// Read the complete state of the map.\n@@ -128,6 +128,23 @@ where\n     }\n }\n \n+impl<K, V> MapStore<K, V>\n+where\n+    K: Eq + Hash,\n+{\n+    pub fn with_entry<F, B1, B2, U>(&self, key: &B1, f: F) -> U\n+    where\n+        B1: ?Sized,\n+        B2: ?Sized,\n+        K: Borrow<B1>,\n+        B1: Eq + Hash,\n+        V: Borrow<B2>,\n+        F: FnOnce(Option<&B2>) -> U,\n+    {\n+        self.inner.borrow().with_entry(key, f)\n+    }\n+}\n+\n const INFALLIBLE_SER: &str = \"Serializing store responses to recon should be infallible.\";\n \n impl<K, V> StoreItem for MapStore<K, V>\n@@ -363,25 +380,24 @@ where\n }\n \n ///  An [event handler](crate::event_handler::EventHandler)`] that may alter an entry in the map.\n-pub struct MapStoreWithEntry<C, K, V, F> {\n+pub struct MapStoreTransformEntry<C, K, V, F> {\n     projection: for<'a> fn(&'a C) -> &'a MapStore<K, V>,\n     key_and_f: Option<(K, F)>,\n }\n \n-impl<C, K, V, F> MapStoreWithEntry<C, K, V, F> {\n+impl<C, K, V, F> MapStoreTransformEntry<C, K, V, F> {\n     pub fn new(projection: for<'a> fn(&'a C) -> &'a MapStore<K, V>, key: K, f: F) -> Self {\n-        MapStoreWithEntry {\n+        MapStoreTransformEntry {\n             projection,\n             key_and_f: Some((key, f)),\n         }\n     }\n }\n \n-impl<C, K, V, F> HandlerAction<C> for MapStoreWithEntry<C, K, V, F>\n+impl<C, K, V, F> HandlerAction<C> for MapStoreTransformEntry<C, K, V, F>\n where\n     K: Clone + Eq + Hash,\n-    V: Clone,\n-    F: FnOnce(Option<V>) -> Option<V>,\n+    F: FnOnce(Option<&V>) -> Option<V>,\n {\n     type Completion = ();\n \n@@ -391,13 +407,16 @@ where\n         _meta: AgentMetadata,\n         context: &C,\n     ) -> StepResult<Self::Completion> {\n-        let MapStoreWithEntry {\n+        let MapStoreTransformEntry {\n             projection,\n             key_and_f,\n         } = self;\n         if let Some((key, f)) = key_and_f.take() {\n             let store = projection(context);\n-            if matches!(store.with_entry(key, f), WithEntryResult::NoChange) {\n+            if matches!(\n+                store.transform_entry(key, f),\n+                TransformEntryResult::NoChange\n+            ) {\n                 StepResult::done(())\n             } else {\n                 StepResult::Complete {\n@@ -411,6 +430,56 @@ where\n     }\n }\n \n+/// A [handler action][`HandlerAction`] that will produce a value by applying a closure to a reference to\n+/// and entry in the store.\n+pub struct MapStoreWithEntry<C, K, V, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a MapStore<K, V>,\n+    key_and_f: Option<(K, F)>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, K, V, F, B: ?Sized> MapStoreWithEntry<C, K, V, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the store.\n+    /// * `key` - Key of the entry.\n+    /// * `f` - The closure to apply to the entry.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a MapStore<K, V>, key: K, f: F) -> Self {\n+        MapStoreWithEntry {\n+            projection,\n+            key_and_f: Some((key, f)),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n+impl<C, K, V, F, B, U> HandlerAction<C> for MapStoreWithEntry<C, K, V, F, B>\n+where\n+    K: Eq + Hash,\n+    B: ?Sized,\n+    V: Borrow<B>,\n+    F: FnOnce(Option<&B>) -> U,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        let MapStoreWithEntry {\n+            projection,\n+            key_and_f,\n+            ..\n+        } = self;\n+        if let Some((key, f)) = key_and_f.take() {\n+            let store = projection(context);\n+            StepResult::done(store.with_entry(&key, f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n impl<K, V> MapLikeItem<K, V> for MapStore<K, V>\n where\n     K: Clone + Eq + Hash + Send + 'static,\n@@ -433,6 +502,35 @@ where\n     }\n }\n \n+impl<K, V> InspectableMapLikeItem<K, V> for MapStore<K, V>\n+where\n+    K: Eq + Hash + Send + 'static,\n+    V: 'static,\n+{\n+    type WithEntryHandler<'a, C, F, B, U> = MapStoreWithEntry<C, K, V, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized +'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a;\n+\n+    fn with_entry_handler<'a, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        key: K,\n+        f: F,\n+    ) -> Self::WithEntryHandler<'a, C, F, B, U>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        B: ?Sized + 'static,\n+        V: Borrow<B>,\n+        F: FnOnce(Option<&B>) -> U + Send + 'a,\n+    {\n+        MapStoreWithEntry::new(projection, key, f)\n+    }\n+}\n+\n impl<K, V> MutableMapLikeItem<K, V> for MapStore<K, V>\n where\n     K: Clone + Eq + Hash + Send + 'static,\n@@ -465,29 +563,23 @@ where\n     fn clear_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::ClearHandler<C> {\n         MapStoreClear::new(projection)\n     }\n-}\n \n-impl<K, V> TransformableMapLikeItem<K, V> for MapStore<K, V>\n-where\n-    K: Clone + Eq + Hash + Send + 'static,\n-    V: Clone + Send + 'static,\n-{\n-    type WithEntryHandler<'a, C, F> = MapStoreWithEntry<C, K, V, F>\n+    type TransformEntryHandler<'a, C, F> = MapStoreTransformEntry<C, K, V, F>\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a;\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a;\n \n-    fn with_handler<'a, C, F>(\n+    fn transform_entry_handler<'a, C, F>(\n         projection: fn(&C) -> &Self,\n         key: K,\n         f: F,\n-    ) -> Self::WithEntryHandler<'a, C, F>\n+    ) -> Self::TransformEntryHandler<'a, C, F>\n     where\n         Self: 'static,\n         C: 'a,\n-        F: FnOnce(Option<V>) -> Option<V> + Send + 'a,\n+        F: FnOnce(Option<&V>) -> Option<V> + Send + 'a,\n     {\n-        MapStoreWithEntry::new(projection, key, f)\n+        MapStoreTransformEntry::new(projection, key, f)\n     }\n }\ndiff --git a/server/swimos_agent/src/stores/value/mod.rs b/server/swimos_agent/src/stores/value/mod.rs\nindex bf92bd571..36247dbcb 100644\n--- a/server/swimos_agent/src/stores/value/mod.rs\n+++ b/server/swimos_agent/src/stores/value/mod.rs\n@@ -12,7 +12,11 @@\n // See the License for the specific language governing permissions and\n // limitations under the License.\n \n-use std::cell::{Cell, RefCell};\n+use std::{\n+    borrow::Borrow,\n+    cell::{Cell, RefCell},\n+    marker::PhantomData,\n+};\n \n use bytes::BytesMut;\n use static_assertions::assert_impl_all;\n@@ -120,6 +124,31 @@ impl<T> ValueStore<T> {\n             false\n         }\n     }\n+\n+    pub(crate) fn replace<F>(&self, f: F)\n+    where\n+        F: FnOnce(&T) -> T,\n+    {\n+        let ValueStore { inner, dirty, .. } = self;\n+        let mut guard = inner.borrow_mut();\n+        let Inner { content, previous } = &mut *guard;\n+        let new_value = f(content);\n+        let prev = std::mem::replace(content, new_value);\n+        *previous = Some(prev);\n+        dirty.replace(true);\n+    }\n+\n+    pub(crate) fn with<F, B, U>(&self, f: F) -> U\n+    where\n+        B: ?Sized,\n+        T: Borrow<B>,\n+        F: FnOnce(&B) -> U,\n+    {\n+        let ValueStore { inner, .. } = self;\n+        let guard = inner.borrow();\n+        let Inner { content, .. } = &*guard;\n+        f(content.borrow())\n+    }\n }\n \n impl<T> AgentItem for ValueStore<T> {\n@@ -247,6 +276,49 @@ impl<C, T> HandlerAction<C> for ValueStoreSet<C, T> {\n     }\n }\n \n+/// An [`HandlerAction`] that will produce a value from a reference to the contents of the store.\n+pub struct ValueStoreWithValue<C, T, F, B: ?Sized> {\n+    projection: for<'a> fn(&'a C) -> &'a ValueStore<T>,\n+    f: Option<F>,\n+    _type: PhantomData<fn(&B)>,\n+}\n+\n+impl<C, T, F, B: ?Sized> ValueStoreWithValue<C, T, F, B> {\n+    /// #Arguments\n+    /// * `projection` - Projection from the agent context to the store.\n+    /// * `f` - Closure to apply to the value of the store.\n+    pub fn new(projection: for<'a> fn(&'a C) -> &'a ValueStore<T>, f: F) -> Self {\n+        ValueStoreWithValue {\n+            projection,\n+            f: Some(f),\n+            _type: PhantomData,\n+        }\n+    }\n+}\n+\n+impl<C, T, F, B, U> HandlerAction<C> for ValueStoreWithValue<C, T, F, B>\n+where\n+    T: Borrow<B>,\n+    B: ?Sized,\n+    F: FnOnce(&B) -> U,\n+{\n+    type Completion = U;\n+\n+    fn step(\n+        &mut self,\n+        _action_context: &mut ActionContext<C>,\n+        _meta: AgentMetadata,\n+        context: &C,\n+    ) -> StepResult<Self::Completion> {\n+        if let Some(f) = self.f.take() {\n+            let store = (self.projection)(context);\n+            StepResult::done(store.with(f))\n+        } else {\n+            StepResult::after_done()\n+        }\n+    }\n+}\n+\n impl<T> ValueLikeItem<T> for ValueStore<T>\n where\n     T: Clone + Send + 'static,\n@@ -255,9 +327,30 @@ where\n     where\n         C: 'static;\n \n+    type WithValueHandler<'a, C, F, B, U> = ValueStoreWithValue<C, T, F, B>\n+    where\n+        Self: 'static,\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a;\n+\n     fn get_handler<C: 'static>(projection: fn(&C) -> &Self) -> Self::GetHandler<C> {\n         ValueStoreGet::new(projection)\n     }\n+\n+    fn with_value_handler<'a, Item, C, F, B, U>(\n+        projection: fn(&C) -> &Self,\n+        f: F,\n+    ) -> Self::WithValueHandler<'a, C, F, B, U>\n+    where\n+        C: 'a,\n+        T: Borrow<B>,\n+        B: ?Sized + 'static,\n+        F: FnOnce(&B) -> U + Send + 'a,\n+    {\n+        ValueStoreWithValue::new(projection, f)\n+    }\n }\n \n impl<T> MutableValueLikeItem<T> for ValueStore<T>\n", "instance_id": "swimos__swim-rust-620", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in its intent to add a `with_value` handler for value-like items in agents and to modify the existing `with_entry` handler for map-like items to avoid cloning by borrowing instead. It also introduces a new `transform_entry` combinator to retain the original functionality. The goal, input, and output expectations are reasonably defined through the provided code snippet and description. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly discuss edge cases or constraints for the new handlers (e.g., behavior when the value or entry does not exist, or performance implications of borrowing vs. cloning). Additionally, while it mentions \"equivalent combinators\" for value-like items, it lacks specific examples or detailed requirements for their behavior. Overall, the statement is valid and clear but misses some finer points that could affect implementation.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes is significant, spanning multiple files and modules (e.g., `HandlerContext`, various lane and store implementations like `MapLane`, `ValueLane`, `MapStore`, `ValueStore`, and associated traits). This requires a deep understanding of the codebase's architecture, particularly how different components (lanes, stores, and handlers) interact. Second, the problem involves advanced Rust concepts such as lifetime management, borrowing (`Borrow` trait), generics, and trait implementations, which are inherently complex and require careful handling to avoid issues like borrow checker errors or incorrect lifetime annotations. Third, the changes impact core functionality (event handlers and data access patterns), necessitating a thorough understanding of the system's design to ensure consistency and correctness across different item types (map-like and value-like). While edge cases are not explicitly mentioned in the problem statement, the implementation must account for scenarios like missing entries/values, which adds to the complexity. However, it does not reach the \"Very Hard\" category as it does not involve system-level considerations or highly specialized domain knowledge beyond Rust's type system and concurrency patterns. A score of 0.65 reflects the need for deep technical expertise and significant effort to implement and validate the solution across the codebase.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "text(\"...\").wrapping(Wrapping::None) is ignored\n### Is your issue REALLY a bug?\n\n- [X] My issue is indeed a bug!\n- [X] I am not crazy! I will not fill out this form just to ask a question or request a feature. Pinky promise.\n\n### Is there an existing issue for this?\n\n- [X] I have searched the existing issues.\n\n### Is this issue related to iced?\n\n- [X] My hardware is compatible and my graphics drivers are up-to-date.\n\n### What happened?\n\nEven if I specify Wrapping::None, the text is wrapped.\r\nHere is a SSCCE:\r\n```rust\r\nuse iced::{widget::text, Element};\r\n\r\n#[derive(Default)]\r\nstruct State;\r\n\r\n#[derive(Debug)]\r\nenum Message {}\r\n\r\nfn main() -> iced::Result {\r\n    iced::run(\"Text Wrapping Bug\", update, view)\r\n}\r\n\r\nfn update(_state: &mut State, _message: Message) {}\r\n\r\nfn view(_state: &State) -> Element<Message> {\r\n    text(\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\")\r\n    .wrapping(text::Wrapping::None)\r\n    .into()\r\n}\r\n```\r\n<img width=\"513\" alt=\"Screenshot 2024-11-24 at 23 58 55\" src=\"https://github.com/user-attachments/assets/c27206ec-6353-4183-a615-9a628f262c13\">\r\n\n\n### What is the expected behavior?\n\nI expect to see only one line of text as I specify Wrapping::None.\n\n### Version\n\ncrates.io release\n\n### Operating System\n\nmacOS\n\n### Do you have any log output?\n\n_No response_\n", "patch": "diff --git a/graphics/src/text/paragraph.rs b/graphics/src/text/paragraph.rs\nindex 07ddbb821a..48c8e9e65f 100644\n--- a/graphics/src/text/paragraph.rs\n+++ b/graphics/src/text/paragraph.rs\n@@ -80,6 +80,8 @@ impl core::text::Paragraph for Paragraph {\n             Some(text.bounds.height),\n         );\n \n+        buffer.set_wrap(font_system.raw(), text::to_wrap(text.wrapping));\n+\n         buffer.set_text(\n             font_system.raw(),\n             text.content,\n@@ -122,6 +124,8 @@ impl core::text::Paragraph for Paragraph {\n             Some(text.bounds.height),\n         );\n \n+        buffer.set_wrap(font_system.raw(), text::to_wrap(text.wrapping));\n+\n         buffer.set_rich_text(\n             font_system.raw(),\n             text.content.iter().enumerate().map(|(i, span)| {\n", "instance_id": "iced-rs__iced-2723", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "The problem statement is mostly clear, as it describes a specific bug where the `text.wrapping(Wrapping::None)` setting in the `iced` library is ignored, resulting in text wrapping despite the configuration. The goal (to prevent text wrapping) and the expected behavior (single line of text) are explicitly stated. A minimal reproducible example (SSCCE) is provided, along with a screenshot demonstrating the issue, which adds to the clarity. However, there are minor ambiguities: the problem statement does not specify whether this behavior occurs under specific conditions (e.g., certain text lengths, fonts, or container sizes) or if it is consistent across all scenarios. Additionally, edge cases or constraints (e.g., maximum text length, interaction with other text properties) are not mentioned, which could impact the solution's scope. Hence, while the issue is valid and mostly clear, it lacks some minor details that would make it comprehensive.", "difficulty_explanation": "The difficulty of this problem falls in the \"Easy\" range (0.2-0.4) due to several factors. First, the scope of the code change is relatively small and localized to a single file (`paragraph.rs`) and a specific part of the codebase related to text rendering in the `iced` library. The provided diff shows a straightforward modification\u2014adding a call to `buffer.set_wrap()` to respect the `Wrapping::None` setting\u2014which indicates that the fix does not require extensive changes or impact the broader system architecture. Second, the technical concepts involved are relatively simple: understanding the `iced` library's text rendering pipeline and how text wrapping is configured using the provided API. It does not require advanced algorithms, design patterns, or domain-specific knowledge beyond familiarity with GUI rendering basics. Third, the problem does not explicitly mention complex edge cases or error handling requirements, and the code change does not introduce new error handling logic. While there might be implicit edge cases (e.g., very long text strings or specific font configurations), these are not highlighted in the problem statement or diff, keeping the complexity low. Overall, solving this issue requires understanding some code logic and making a simple modification, aligning with an \"Easy\" difficulty score of 0.30.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Issue when compiling 0.14.0 without `std` feature\n```\r\n   Compiling rustybuzz v0.14.0\r\nerror[E0433]: failed to resolve: use of undeclared crate or module `std`\r\n --> /home/jeremy/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rustybuzz-0.14.0/src/hb/buffer.rs:3:5\r\n  |\r\n3 | use std::cmp::min;\r\n  |     ^^^ use of undeclared crate or module `std`\r\n\r\nerror[E0433]: failed to resolve: use of undeclared crate or module `std`\r\n --> /home/jeremy/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rustybuzz-0.14.0/src/hb/ot/layout/GSUB/alternate_set.rs:4:5\r\n  |\r\n4 | use std::convert::TryFrom;\r\n  |     ^^^ use of undeclared crate or module `std`\r\n\r\nerror[E0433]: failed to resolve: use of undeclared crate or module `std`\r\n --> /home/jeremy/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rustybuzz-0.14.0/src/hb/ot_layout_gsubgpos.rs:3:5\r\n  |\r\n3 | use std::cmp::max;\r\n  |     ^^^ use of undeclared crate or module `std`\r\n\r\nFor more information about this error, try `rustc --explain E0433`.\r\nerror: could not compile `rustybuzz` (lib) due to 3 previous errors\r\n```\n", "patch": "diff --git a/src/hb/buffer.rs b/src/hb/buffer.rs\nindex fb103216..8ab4d036 100644\n--- a/src/hb/buffer.rs\n+++ b/src/hb/buffer.rs\n@@ -1,6 +1,6 @@\n use alloc::{string::String, vec::Vec};\n use core::convert::TryFrom;\n-use std::cmp::min;\n+use core::cmp::min;\n \n use ttf_parser::GlyphId;\n \ndiff --git a/src/hb/ot/layout/GSUB/alternate_set.rs b/src/hb/ot/layout/GSUB/alternate_set.rs\nindex ae8d7ef1..42fc3983 100644\n--- a/src/hb/ot/layout/GSUB/alternate_set.rs\n+++ b/src/hb/ot/layout/GSUB/alternate_set.rs\n@@ -1,7 +1,7 @@\n use crate::hb::ot_layout_gsubgpos::Apply;\n use crate::hb::ot_layout_gsubgpos::OT::hb_ot_apply_context_t;\n use crate::hb::ot_map::hb_ot_map_t;\n-use std::convert::TryFrom;\n+use core::convert::TryFrom;\n use ttf_parser::gsub::AlternateSet;\n \n impl Apply for AlternateSet<'_> {\ndiff --git a/src/hb/ot_layout_gsubgpos.rs b/src/hb/ot_layout_gsubgpos.rs\nindex 970d2d70..247110ca 100644\n--- a/src/hb/ot_layout_gsubgpos.rs\n+++ b/src/hb/ot_layout_gsubgpos.rs\n@@ -1,6 +1,6 @@\n //! Matching of glyph patterns.\n \n-use std::cmp::max;\n+use core::cmp::max;\n \n use ttf_parser::opentype_layout::*;\n use ttf_parser::{GlyphId, LazyArray16};\n", "instance_id": "harfbuzz__rustybuzz-106", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in identifying the issue: compilation errors in the `rustybuzz` crate (version 0.14.0) when the `std` feature is disabled, due to references to the `std` crate instead of `core`. The error messages provided in the statement pinpoint the exact locations and nature of the problem (undeclared crate `std`), and the goal is implicitly understood as fixing these compilation errors to support a no-std environment. However, the statement lacks explicit mention of the desired outcome (e.g., ensuring compatibility with no-std builds) and does not provide context about the broader implications or constraints of making these changes. Additionally, there are no examples or test cases to validate the fix, and edge cases or potential side effects of switching from `std` to `core` are not discussed. Despite these minor omissions, the problem is valid and the intent is reasonably clear from the error logs and code changes provided.", "difficulty_explanation": "The difficulty of this problem is very low, falling in the 0.0-0.2 range, as it involves straightforward code modifications to fix a compilation issue. The scope of the changes is limited to three specific files, where references to `std` are replaced with `core` for basic utilities like `min`, `max`, and `TryFrom`. This requires minimal understanding of Rust's standard library versus core library distinction and the implications of no-std environments, which is a basic concept for Rust developers. The changes are isolated, do not impact the broader architecture of the codebase, and involve no complex logic, algorithms, or interactions between modules. There are no significant edge cases or error handling requirements mentioned or implied in the problem statement or code changes, as the fix is purely syntactic. The amount of code change is trivial, consisting of simple find-and-replace operations across a few lines. Overall, this is a very easy task that a junior developer with basic Rust knowledge could handle with minimal effort.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Decouple the `auto-save` and `auto-format` options\nI\u2019d like to suggest that `auto-format` be triggered only by manual saving, rather than being tied to `auto-save`.\n\nReasons:\n1. Code formatting doesn\u2019t need to happen frequently.\n2. When both `auto-save` and `auto-format` are enabled, formatting occurs while writing code, which can be disruptive.\n\nDecoupling these options would improve the user experience and potentially resolve issues like #11237 and #11966.\n", "patch": "diff --git a/helix-term/src/commands/typed.rs b/helix-term/src/commands/typed.rs\nindex 9c48bf72382e..c5c53acd5ce7 100644\n--- a/helix-term/src/commands/typed.rs\n+++ b/helix-term/src/commands/typed.rs\n@@ -678,10 +678,16 @@ pub(super) fn buffers_remaining_impl(editor: &mut Editor) -> anyhow::Result<()>\n     Ok(())\n }\n \n+#[derive(Debug, Clone, Copy)]\n+pub struct WriteAllOptions {\n+    pub force: bool,\n+    pub write_scratch: bool,\n+    pub auto_format: bool,\n+}\n+\n pub fn write_all_impl(\n     cx: &mut compositor::Context,\n-    force: bool,\n-    write_scratch: bool,\n+    options: WriteAllOptions,\n ) -> anyhow::Result<()> {\n     let mut errors: Vec<&'static str> = Vec::new();\n     let config = cx.editor.config();\n@@ -699,7 +705,7 @@ pub fn write_all_impl(\n                 return None;\n             }\n             if doc.path().is_none() {\n-                if write_scratch {\n+                if options.write_scratch {\n                     errors.push(\"cannot write a buffer without a filename\");\n                 }\n                 return None;\n@@ -722,14 +728,14 @@ pub fn write_all_impl(\n         // Save an undo checkpoint for any outstanding changes.\n         doc.append_changes_to_history(view);\n \n-        let fmt = if config.auto_format {\n+        let fmt = if options.auto_format && config.auto_format {\n             doc.auto_format().map(|fmt| {\n                 let callback = make_format_callback(\n                     doc_id,\n                     doc.version(),\n                     target_view,\n                     fmt,\n-                    Some((None, force)),\n+                    Some((None, options.force)),\n                 );\n                 jobs.add(Job::with_callback(callback).wait_before_exiting());\n             })\n@@ -738,11 +744,11 @@ pub fn write_all_impl(\n         };\n \n         if fmt.is_none() {\n-            cx.editor.save::<PathBuf>(doc_id, None, force)?;\n+            cx.editor.save::<PathBuf>(doc_id, None, options.force)?;\n         }\n     }\n \n-    if !errors.is_empty() && !force {\n+    if !errors.is_empty() && !options.force {\n         bail!(\"{:?}\", errors);\n     }\n \n@@ -758,7 +764,14 @@ fn write_all(\n         return Ok(());\n     }\n \n-    write_all_impl(cx, false, true)\n+    write_all_impl(\n+        cx,\n+        WriteAllOptions {\n+            force: false,\n+            write_scratch: true,\n+            auto_format: true,\n+        },\n+    )\n }\n \n fn force_write_all(\n@@ -770,7 +783,14 @@ fn force_write_all(\n         return Ok(());\n     }\n \n-    write_all_impl(cx, true, true)\n+    write_all_impl(\n+        cx,\n+        WriteAllOptions {\n+            force: true,\n+            write_scratch: true,\n+            auto_format: true,\n+        },\n+    )\n }\n \n fn write_all_quit(\n@@ -781,7 +801,14 @@ fn write_all_quit(\n     if event != PromptEvent::Validate {\n         return Ok(());\n     }\n-    write_all_impl(cx, false, true)?;\n+    write_all_impl(\n+        cx,\n+        WriteAllOptions {\n+            force: false,\n+            write_scratch: true,\n+            auto_format: true,\n+        },\n+    )?;\n     quit_all_impl(cx, false)\n }\n \n@@ -793,7 +820,14 @@ fn force_write_all_quit(\n     if event != PromptEvent::Validate {\n         return Ok(());\n     }\n-    let _ = write_all_impl(cx, true, true);\n+    let _ = write_all_impl(\n+        cx,\n+        WriteAllOptions {\n+            force: true,\n+            write_scratch: true,\n+            auto_format: true,\n+        },\n+    );\n     quit_all_impl(cx, true)\n }\n \ndiff --git a/helix-term/src/handlers/auto_save.rs b/helix-term/src/handlers/auto_save.rs\nindex 4e154df808a7..47e2ecfdf13d 100644\n--- a/helix-term/src/handlers/auto_save.rs\n+++ b/helix-term/src/handlers/auto_save.rs\n@@ -87,7 +87,13 @@ fn request_auto_save(editor: &mut Editor) {\n         jobs: &mut Jobs::new(),\n     };\n \n-    if let Err(e) = commands::typed::write_all_impl(context, false, false) {\n+    let options = commands::WriteAllOptions {\n+        force: false,\n+        write_scratch: false,\n+        auto_format: false,\n+    };\n+\n+    if let Err(e) = commands::typed::write_all_impl(context, options) {\n         context.editor.set_error(format!(\"{}\", e));\n     }\n }\ndiff --git a/helix-term/src/ui/editor.rs b/helix-term/src/ui/editor.rs\nindex 6fecd512b5a0..d8500ed4d7ea 100644\n--- a/helix-term/src/ui/editor.rs\n+++ b/helix-term/src/ui/editor.rs\n@@ -1522,7 +1522,12 @@ impl Component for EditorView {\n             }\n             Event::FocusLost => {\n                 if context.editor.config().auto_save.focus_lost {\n-                    if let Err(e) = commands::typed::write_all_impl(context, false, false) {\n+                    let options = commands::WriteAllOptions {\n+                        force: false,\n+                        write_scratch: false,\n+                        auto_format: false,\n+                    };\n+                    if let Err(e) = commands::typed::write_all_impl(context, options) {\n                         context.editor.set_error(format!(\"{}\", e));\n                     }\n                 }\n", "instance_id": "helix-editor__helix-12817", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in its intent to decouple the `auto-save` and `auto-format` options so that formatting is not triggered during auto-save events. The goal is explicitly stated, and the reasons provided (improving user experience and avoiding disruptions) add context to the request. However, there are minor ambiguities and missing details. For instance, the problem statement does not specify how the decoupling should behave in edge cases (e.g., what happens if a user manually saves during an auto-save operation) or whether there are specific user configurations or settings that need to be introduced to control this behavior. Additionally, while it references related issues (#11237 and #11966), it does not provide details on what those issues entail, which could be critical for understanding the full scope of the problem. Overall, the statement is valid and clear in its primary objective but lacks comprehensive details on constraints and edge cases, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls in the Easy range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes:** The code changes are relatively localized, primarily affecting a few files (`typed.rs`, `auto_save.rs`, and `editor.rs`) within the `helix-term` module. The modifications involve refactoring the `write_all_impl` function to accept a new `WriteAllOptions` struct, which encapsulates parameters like `force`, `write_scratch`, and `auto_format`. This change requires updating several call sites to pass the appropriate options, particularly to disable `auto_format` during auto-save operations. While the changes span multiple files, they are straightforward and do not significantly impact the broader system architecture.\n\n2. **Number of Technical Concepts:** The solution requires a basic understanding of Rust's struct and function parameter passing, as well as familiarity with the codebase's existing logic for saving and formatting. No advanced language features, complex algorithms, or design patterns are needed. The primary concept is parameterizing behavior through a configuration struct, which is a common and simple pattern in Rust.\n\n3. **Edge Cases and Error Handling:** The problem statement does not explicitly mention edge cases, and the code changes do not introduce new error handling logic beyond what already exists in the codebase. The modifications maintain the existing error handling structure (e.g., collecting errors in a vector and bailing out if necessary), suggesting that edge cases are either not significant or are already handled by the existing code.\n\n4. **Overall Complexity:** The task involves understanding the interaction between `auto-save` and `auto-format` within the editor's save mechanism, but this interaction is not deeply complex. The changes are mostly mechanical\u2014introducing a new struct and updating function calls\u2014without requiring deep architectural redesign or performance optimization.\n\nGiven these considerations, I assign a difficulty score of 0.35, placing it on the higher end of the Easy range due to the need to modify multiple files and understand the save mechanism's logic, but still well below Medium difficulty as the changes are straightforward and do not involve complex concepts or significant risk of introducing bugs.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "bug: stack overflow on closures with outer params\n# Bug Report\n\n**Cairo version:**\n```\n\u276f scarb --version\nscarb 2.9.2+nightly-2025-02-01 (3a752f93d 2025-02-01)\ncairo: 2.9.2 (99f052811)\nsierra: 1.6.0\n```\nThe following code:\n```\nfn main() {\n    let outer_var = 42;\n    let closure_annotated = |i: u32| -> u32 { i + outer_var };\n    println!(\"closure_annotated: {}\", closure_annotated(1));\n}\n```\n\nfails `scarb cairo-run` with:\n\n```\nthread 'scarb compile closures-665rku3l74rb0' has overflowed its stack\nfatal runtime error: stack overflow\nerror: `scarb metadata` exited with error\n```\n", "patch": "diff --git a/crates/cairo-lang-semantic/src/types.rs b/crates/cairo-lang-semantic/src/types.rs\nindex 392695c053d..71faba8790d 100644\n--- a/crates/cairo-lang-semantic/src/types.rs\n+++ b/crates/cairo-lang-semantic/src/types.rs\n@@ -10,7 +10,7 @@ use cairo_lang_syntax::attribute::consts::MUST_USE_ATTR;\n use cairo_lang_syntax::node::ids::SyntaxStablePtrId;\n use cairo_lang_syntax::node::{TypedStablePtr, TypedSyntaxNode, ast};\n use cairo_lang_utils::{Intern, LookupIntern, OptionFrom, define_short_id, try_extract_matches};\n-use itertools::Itertools;\n+use itertools::{Itertools, chain};\n use num_bigint::BigInt;\n use num_traits::Zero;\n use sha3::{Digest, Keccak256};\n@@ -946,7 +946,7 @@ pub fn priv_type_is_var_free(db: &dyn SemanticGroup, ty: TypeId) -> bool {\n         // a var free ImplType needs to be rewritten if has impl bounds constraints.\n         TypeLongId::ImplType(_) => false,\n         TypeLongId::Closure(closure) => {\n-            closure.param_tys.iter().all(|param| param.is_var_free(db))\n+            chain!(&closure.captured_types, &closure.param_tys).all(|param| param.is_var_free(db))\n                 && closure.ret_ty.is_var_free(db)\n         }\n     }\n", "instance_id": "starkware-libs__cairo-7255", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in describing the bug: it provides a specific version of the Cairo language toolchain, a minimal reproducible code snippet that triggers a stack overflow error, and the exact error output. The goal is implicitly understood as fixing the stack overflow issue related to closures capturing outer variables. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly state the expected behavior or output of the provided code snippet, nor does it discuss potential edge cases or constraints (e.g., other closure patterns that might be affected). Additionally, there is no mention of performance or compatibility requirements for the fix. While the issue is valid and the context is provided, these missing details prevent it from being fully comprehensive, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category (0.6-0.8) due to several factors. First, the scope of the code change is relatively small, confined to a single file (`types.rs`) and a specific function (`priv_type_is_var_free`). The diff shows a minimal change\u2014adding consideration of `captured_types` alongside `param_tys` when checking if a closure type is variable-free. However, the impact of this change is significant as it addresses a stack overflow issue, which suggests a deeper issue in the type system or semantic analysis of the Cairo compiler. Understanding the fix requires knowledge of Rust (the language of the codebase), specifically iterators and the `itertools` crate (e.g., usage of `chain!`), as well as a conceptual grasp of closures, captured variables, and type systems in a compiler context. Additionally, the problem likely involves understanding the internal representation of closures in Cairo (`Closure` struct with `captured_types` and `param_tys`), which points to domain-specific knowledge of the Cairo language semantics. While the code change itself is small, the potential for subtle bugs or regressions in the type system (e.g., incorrect handling of captured variables leading to other semantic errors) adds complexity. Edge cases, though not explicitly mentioned in the problem statement, are implied\u2014different closure patterns, nested closures, or varying captured variable types could be affected by this change, requiring careful consideration. Overall, solving this requires a deep understanding of compiler internals and type system logic, justifying a difficulty score of 0.65, leaning towards the lower end of \"Hard\" due to the localized nature of the code change but still reflecting the conceptual depth required.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "useFilenamingConvention fails for export\n### Environment information\r\n\r\n```bash\r\nCLI:\r\n  Version:                      1.9.3\r\n  Color support:                true\r\n\r\nPlatform:\r\n  CPU Architecture:             aarch64\r\n  OS:                           macos\r\n\r\nEnvironment:\r\n  BIOME_LOG_PATH:               unset\r\n  BIOME_LOG_PREFIX_NAME:        unset\r\n  BIOME_CONFIG_PATH:            unset\r\n  NO_COLOR:                     unset\r\n  TERM:                         \"xterm-256color\"\r\n  JS_RUNTIME_VERSION:           \"v20.13.1\"\r\n  JS_RUNTIME_NAME:              \"node\"\r\n  NODE_PACKAGE_MANAGER:         \"yarn/4.5.0\"\r\n\r\nBiome Configuration:\r\n  Status:                       Loaded successfully\r\n  Formatter disabled:           false\r\n  Linter disabled:              false\r\n  Organize imports disabled:    true\r\n  VCS disabled:                 false\r\n\r\nLinter:\r\n  JavaScript enabled:           true\r\n  JSON enabled:                 true\r\n  CSS enabled:                  true\r\n  GraphQL enabled:              false\r\n  Recommended:                  true\r\n  All:                          false\r\n  Enabled rules:\r\n  performance/noDelete\r\n  suspicious/noCatchAssign\r\n  suspicious/noUnsafeNegation\r\n  complexity/useLiteralKeys\r\n  complexity/noMultipleSpacesInRegularExpressionLiterals\r\n  a11y/useValidLang\r\n  complexity/noUselessEmptyExport\r\n  suspicious/useNamespaceKeyword\r\n  suspicious/useValidTypeof\r\n  a11y/useValidAriaRole\r\n  correctness/noConstantCondition\r\n  a11y/useAriaActivedescendantWithTabindex\r\n  suspicious/noAssignInExpressions\r\n  style/useDefaultParameterLast\r\n  complexity/noEmptyTypeParameters\r\n  correctness/noConstructorReturn\r\n  style/useSelfClosingElements\r\n  suspicious/noDuplicateParameters\r\n  suspicious/noDuplicateSelectorsKeyframeBlock\r\n  correctness/noUnknownProperty\r\n  style/useTemplate\r\n  correctness/noUnusedLabels\r\n  complexity/noUselessTernary\r\n  correctness/noUnreachableSuper\r\n  suspicious/noCompareNegZero\r\n  correctness/noSwitchDeclarations\r\n  a11y/noAutofocus\r\n  correctness/noUnsafeOptionalChaining\r\n  correctness/noConstAssign\r\n  suspicious/noControlCharactersInRegex\r\n  complexity/noUselessTypeConstraint\r\n  style/noVar\r\n  suspicious/noDoubleEquals\r\n  suspicious/noRedundantUseStrict\r\n  style/useLiteralEnumMembers\r\n  suspicious/noGlobalIsNan\r\n  suspicious/noEmptyInterface\r\n  suspicious/noConstEnum\r\n  suspicious/noMisleadingCharacterClass\r\n  correctness/noPrecisionLoss\r\n  a11y/noLabelWithoutControl\r\n  suspicious/noRedeclare\r\n  correctness/noStringCaseMismatch\r\n  correctness/noSetterReturn\r\n  correctness/noInvalidConstructorSuper\r\n  suspicious/noImplicitAnyLet\r\n  suspicious/noFallthroughSwitchClause\r\n  suspicious/noUnsafeDeclarationMerging\r\n  correctness/noUnreachable\r\n  a11y/useKeyWithClickEvents\r\n  suspicious/noDuplicateObjectKeys\r\n  complexity/noUselessThisAlias\r\n  complexity/noThisInStatic\r\n  complexity/useOptionalChain\r\n  correctness/noInnerDeclarations\r\n  suspicious/noDuplicateCase\r\n  a11y/useValidAnchor\r\n  complexity/useRegexLiterals\r\n  correctness/noSelfAssign\r\n  correctness/noInvalidBuiltinInstantiation\r\n  style/noUselessElse\r\n  style/useShorthandFunctionType\r\n  suspicious/noShadowRestrictedNames\r\n  correctness/noInvalidDirectionInLinearGradient\r\n  suspicious/noImportantInKeyframe\r\n  a11y/useMediaCaption\r\n  complexity/noUselessLabel\r\n  complexity/noUselessCatch\r\n  correctness/noUnsafeFinally\r\n  correctness/noNonoctalDecimalEscape\r\n  style/useEnumInitializers\r\n  a11y/useHtmlLang\r\n  suspicious/noDuplicateTestHooks\r\n  complexity/noStaticOnlyClass\r\n  style/useWhile\r\n  complexity/useArrowFunction\r\n  style/noInferrableTypes\r\n  a11y/noNoninteractiveTabindex\r\n  complexity/useSimpleNumberKeys\r\n  correctness/useYield\r\n  a11y/noInteractiveElementToNoninteractiveRole\r\n  style/useNumericLiterals\r\n  correctness/noUnnecessaryContinue\r\n  suspicious/noApproximativeNumericConstant\r\n  suspicious/noImportAssign\r\n  suspicious/noLabelVar\r\n  correctness/noGlobalObjectCalls\r\n  suspicious/useDefaultSwitchClauseLast\r\n  a11y/useAltText\r\n  correctness/noEmptyCharacterClassInRegex\r\n  correctness/noUnknownUnit\r\n  suspicious/noSparseArray\r\n  a11y/useIframeTitle\r\n  complexity/noBannedTypes\r\n  a11y/noSvgWithoutTitle\r\n  correctness/noVoidElementsWithChildren\r\n  style/useAsConstAssertion\r\n  correctness/useJsxKeyInIterable\r\n  style/useExportType\r\n  complexity/noUselessLoneBlockStatements\r\n  style/noArguments\r\n  suspicious/noMisleadingInstantiator\r\n  suspicious/noDebugger\r\n  a11y/useValidAriaValues\r\n  correctness/noUnmatchableAnbSelector\r\n  suspicious/noCommentText\r\n  suspicious/noGlobalAssign\r\n  suspicious/noDuplicateJsxProps\r\n  suspicious/noThenProperty\r\n  a11y/noPositiveTabindex\r\n  correctness/noEmptyPattern\r\n  complexity/noExcessiveNestedTestSuites\r\n  security/noDangerouslySetInnerHtmlWithChildren\r\n  a11y/useKeyWithMouseEvents\r\n  suspicious/noExtraNonNullAssertion\r\n  suspicious/noShorthandPropertyOverrides\r\n  correctness/noRenderReturnValue\r\n  security/noGlobalEval\r\n  style/useConst\r\n  suspicious/useGetterReturn\r\n  a11y/noRedundantRoles\r\n  complexity/useFlatMap\r\n  correctness/useIsNan\r\n  suspicious/noGlobalIsFinite\r\n  suspicious/noSelfCompare\r\n  suspicious/noAsyncPromiseExecutor\r\n  suspicious/noDuplicateFontNames\r\n  security/noDangerouslySetInnerHtml\r\n  style/useNodejsImportProtocol\r\n  a11y/noDistractingElements\r\n  suspicious/noArrayIndexKey\r\n  complexity/noWith\r\n  suspicious/noDuplicateClassMembers\r\n  complexity/noExtraBooleanCast\r\n  performance/noAccumulatingSpread\r\n  a11y/useValidAriaProps\r\n  a11y/noRedundantAlt\r\n  correctness/noChildrenProp\r\n  correctness/noUnknownFunction\r\n  correctness/noInvalidPositionAtImportRule\r\n  suspicious/noConfusingLabels\r\n  suspicious/noPrototypeBuiltins\r\n  suspicious/noConfusingVoidType\r\n  suspicious/noFocusedTests\r\n  a11y/useButtonType\r\n  a11y/noAriaUnsupportedElements\r\n  correctness/noInvalidGridAreas\r\n  style/useFilenamingConvention\r\n  correctness/noFlatMapIdentity\r\n  suspicious/noSuspiciousSemicolonInJsx\r\n  a11y/noBlankTarget\r\n  a11y/useHeadingContent\r\n  correctness/useValidForDirection\r\n  correctness/noVoidTypeReturn\r\n  correctness/noInvalidUseBeforeDeclaration\r\n  a11y/noAriaHiddenOnFocusable\r\n  a11y/useGenericFontNames\r\n  correctness/noUnknownMediaFeatureName\r\n  a11y/useAnchorContent\r\n  complexity/noUselessRename\r\n  style/useNumberNamespace\r\n  complexity/noUselessConstructor\r\n  a11y/noAccessKey\r\n  style/useExponentiationOperator\r\n  style/noUnusedTemplateLiteral\r\n  complexity/noUselessSwitchCase\r\n  style/useSingleVarDeclarator\r\n  suspicious/noExportsInTest\r\n  a11y/noNoninteractiveElementToInteractiveRole\r\n  style/noCommaOperator\r\n  suspicious/noDuplicateAtImportRules\r\n  suspicious/useIsArray\r\n  a11y/noHeaderScope\r\n  complexity/noUselessFragments\r\n  suspicious/noMisrefactoredShorthandAssign\r\n  complexity/noForEach\r\n  suspicious/noClassAssign\r\n  suspicious/noEmptyBlock\r\n  suspicious/noFunctionAssign\r\n\r\nWorkspace:\r\n  Open Documents:               0\r\n```\r\n\r\n\r\n### Rule name\r\n\r\nuseFilenamingConvention\r\n\r\n### Playground link\r\n\r\nBasically a renamed :\r\n\r\n```js\r\nconst _Button = 1;\r\n\r\nexport {_Button as Button};\r\n```\r\nRepro: https://github.com/artola/biome-issue-4254\r\n\r\n### Expected result\r\n\r\nWith this config should not error for a named export `export {_Button as Button};`\r\n\r\n```text\r\n        \"useFilenamingConvention\": {\r\n          \"level\": \"error\",\r\n          \"options\": {\r\n            \"strictCase\": false,\r\n            \"requireAscii\": true,\r\n            \"filenameCases\": [\"kebab-case\", \"export\"]\r\n          }\r\n        },\r\n```\r\n\r\n### Code of Conduct\r\n\r\n- [X] I agree to follow Biome's Code of Conduct\n", "patch": "diff --git a/CHANGELOG.md b/CHANGELOG.md\nindex 8e1af31d6cd5..a5c7d9c850c9 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -131,6 +131,27 @@ our [guidelines for writing a good changelog entry](https://github.com/biomejs/b\n \n   Contributed by @Conaclos\n \n+- [useFilenamingConvention](https://biomejs.dev/linter/rules/use-filenaming-convention) now correctly handles renamed exports ([#4254](https://github.com/biomejs/biome/issues/4254)).\n+\n+  The rule allows the filename to be named as one of the exports of the module.\n+  For instance, the file containing the following export can be named `Button`.\n+\n+  ```js\n+  class Button {}\n+  export { Button }\n+  ```\n+\n+  The rule now correctly handles the renaming of an export.\n+  For example, the file containing the following export can only be named `Button`.\n+  Previously the rule expected the file to be named `A`.\n+\n+  ```js\n+  class A {}\n+  export { A as Button }\n+  ```\n+\n+  Contributed by @Conaclos\n+\n ### Parser\n \n #### Bug Fixes\ndiff --git a/Cargo.lock b/Cargo.lock\nindex f71699e99604..ef2708145843 100644\n--- a/Cargo.lock\n+++ b/Cargo.lock\n@@ -836,6 +836,7 @@ dependencies = [\n  \"biome_rowan\",\n  \"rust-lapper\",\n  \"rustc-hash 1.1.0\",\n+ \"smallvec\",\n ]\n \n [[package]]\ndiff --git a/crates/biome_js_analyze/src/lint/style/use_filenaming_convention.rs b/crates/biome_js_analyze/src/lint/style/use_filenaming_convention.rs\nindex 9bfafd14293b..0dd150df42a5 100644\n--- a/crates/biome_js_analyze/src/lint/style/use_filenaming_convention.rs\n+++ b/crates/biome_js_analyze/src/lint/style/use_filenaming_convention.rs\n@@ -4,7 +4,10 @@ use biome_analyze::{\n };\n use biome_console::markup;\n use biome_deserialize_macros::Deserializable;\n-use biome_rowan::TextRange;\n+use biome_js_syntax::{\n+    binding_ext::AnyJsIdentifierBinding, AnyJsIdentifierUsage, JsExportNamedSpecifier,\n+};\n+use biome_rowan::{AstNode, TextRange};\n use biome_string_case::{Case, Cases};\n use rustc_hash::FxHashSet;\n use serde::{Deserialize, Serialize};\n@@ -210,13 +213,20 @@ impl Rule for UseFilenamingConvention {\n         }\n         if options.filename_cases.0.contains(&FilenameCase::Export) {\n             // If no exported binding has the file name, then reports the filename\n-            let model = ctx.model();\n-            model\n-                .all_bindings()\n-                .map(|binding| binding.tree())\n-                .filter(|binding| model.is_exported(binding))\n-                .filter_map(|exported_binding| exported_binding.name_token().ok())\n-                .all(|exported_name_token| exported_name_token.text_trimmed() != name)\n+            ctx.model()\n+                .all_exported_bindings()\n+                .all(|exported_binding| {\n+                    exported_binding\n+                        .exports()\n+                        .filter_map(|export| match AnyJsIdentifierBinding::try_cast(export) {\n+                            Ok(id) => id.name_token().ok(),\n+                            Err(export) => match JsExportNamedSpecifier::cast(export.parent()?) {\n+                                Some(specifier) => specifier.exported_name().ok()?.value().ok(),\n+                                None => AnyJsIdentifierUsage::cast(export)?.value_token().ok(),\n+                            },\n+                        })\n+                        .all(|exported_name_token| exported_name_token.text_trimmed() != name)\n+                })\n                 .then_some(FileNamingConventionState::Filename)\n         } else {\n             Some(FileNamingConventionState::Filename)\ndiff --git a/crates/biome_js_semantic/Cargo.toml b/crates/biome_js_semantic/Cargo.toml\nindex a7a4ed94c3e8..21f41f0988ef 100644\n--- a/crates/biome_js_semantic/Cargo.toml\n+++ b/crates/biome_js_semantic/Cargo.toml\n@@ -15,6 +15,7 @@ biome_js_syntax = { workspace = true }\n biome_rowan     = { workspace = true }\n rust-lapper     = \"1.1.0\"\n rustc-hash      = { workspace = true }\n+smallvec        = { workspace = true }\n \n [dev-dependencies]\n biome_console     = { path = \"../biome_console\" }\ndiff --git a/crates/biome_js_semantic/src/semantic_model/binding.rs b/crates/biome_js_semantic/src/semantic_model/binding.rs\nindex 4eecd0fe5ab0..54f3b33b87f2 100644\n--- a/crates/biome_js_semantic/src/semantic_model/binding.rs\n+++ b/crates/biome_js_semantic/src/semantic_model/binding.rs\n@@ -6,6 +6,8 @@ use biome_js_syntax::{binding_ext::AnyJsIdentifierBinding, TextRange, TsTypePara\n pub(crate) struct SemanticModelBindingData {\n     pub(crate) range: TextRange,\n     pub(crate) references: Vec<SemanticModelReference>,\n+    // We use a SmallVec because most of the time a binding is expected once.\n+    pub(crate) export_by_start: smallvec::SmallVec<[TextSize; 4]>,\n }\n \n #[derive(Clone, Copy, Debug)]\n@@ -117,6 +119,17 @@ impl Binding {\n         std::iter::successors(first, Reference::find_next_write)\n     }\n \n+    /// Returns all exports of the binding.\n+    /// The node kind is either an identifier binding (tehd eclaration is self exported)\n+    /// or an identifier usage.\n+    pub fn exports(&self) -> impl Iterator<Item = JsSyntaxNode> + '_ {\n+        let binding = self.data.binding(self.id);\n+        binding\n+            .export_by_start\n+            .iter()\n+            .map(|export_start| self.data.binding_node_by_start[export_start].clone())\n+    }\n+\n     pub fn is_imported(&self) -> bool {\n         super::is_imported(self.syntax())\n     }\ndiff --git a/crates/biome_js_semantic/src/semantic_model/builder.rs b/crates/biome_js_semantic/src/semantic_model/builder.rs\nindex 753232abab9f..df2aebde63b5 100644\n--- a/crates/biome_js_semantic/src/semantic_model/builder.rs\n+++ b/crates/biome_js_semantic/src/semantic_model/builder.rs\n@@ -175,7 +175,8 @@ impl SemanticModelBuilder {\n                 let binding_id = BindingId::new(self.bindings.len());\n                 self.bindings.push(SemanticModelBindingData {\n                     range,\n-                    references: vec![],\n+                    references: Vec::new(),\n+                    export_by_start: smallvec::SmallVec::new(),\n                 });\n                 self.bindings_by_start.insert(range.start(), binding_id);\n \n@@ -308,8 +309,15 @@ impl SemanticModelBuilder {\n                         .push(SemanticModelUnresolvedReference { range }),\n                 }\n             }\n-            Export { declaration_at, .. } => {\n+            Export {\n+                declaration_at,\n+                range,\n+            } => {\n                 self.exported.insert(declaration_at);\n+\n+                let binding_id = self.bindings_by_start[&declaration_at];\n+                let binding = &mut self.bindings[binding_id.index()];\n+                binding.export_by_start.push(range.start());\n             }\n         }\n     }\ndiff --git a/crates/biome_js_semantic/src/semantic_model/model.rs b/crates/biome_js_semantic/src/semantic_model/model.rs\nindex 97e34d49bb11..ff0169c9d5bc 100644\n--- a/crates/biome_js_semantic/src/semantic_model/model.rs\n+++ b/crates/biome_js_semantic/src/semantic_model/model.rs\n@@ -251,6 +251,17 @@ impl SemanticModel {\n             })\n     }\n \n+    pub fn all_exported_bindings(&self) -> impl Iterator<Item = Binding> + '_ {\n+        self.data\n+            .exported\n+            .iter()\n+            .filter_map(|declared_at| self.data.bindings_by_start.get(declared_at).copied())\n+            .map(|id| Binding {\n+                data: self.data.clone(),\n+                id,\n+            })\n+    }\n+\n     /// Returns the [Binding] of a reference.\n     /// Can also be called from \"binding\" extension method.\n     ///\n", "instance_id": "biomejs__biome-4260", "clarity": 2, "difficulty": 0.55, "clarity_explanation": "The problem statement is mostly clear in describing the issue with the `useFilenamingConvention` rule failing for renamed exports in the Biome linter. It provides a specific example of the problematic code (`export {_Button as Button};`) and references a GitHub issue for reproduction. The expected behavior is also outlined, stating that the rule should not error for such named exports given the provided configuration. However, there are minor ambiguities: the problem statement does not explicitly detail all possible edge cases (e.g., multiple renamed exports or nested export scenarios) or constraints beyond the provided configuration. Additionally, while the environment information and configuration are comprehensive, they are somewhat overwhelming and not directly tied to the core issue, which could distract from the main problem. Overall, the statement is valid and clear but lacks exhaustive detail on edge cases or broader implications.", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the scope of code changes involves multiple files within the Biome project, including modifications to the semantic model and the specific lint rule implementation (`use_filenaming_convention.rs`), as well as updates to the changelog. This requires understanding the interaction between the semantic analysis of JavaScript syntax and the linting logic, which adds to the complexity. Second, the technical concepts involved include Rust language features (e.g., iterators, type casting with `try_cast`), domain-specific knowledge of JavaScript syntax and export semantics, and familiarity with the Biome project's internal data structures (e.g., `SemanticModelBindingData`, `smallvec` for optimization). The changes also necessitate handling nuanced cases like renamed exports, which introduces moderate complexity in logic modification. Third, while edge cases are not extensively detailed in the problem statement, the code changes suggest a need to account for various export scenarios (e.g., direct exports vs. renamed exports), though no explicit error handling or performance optimization is required beyond correct identification of export names. Finally, the impact on the system's architecture is minimal, as the fix is localized to the lint rule and semantic model without broader refactoring. Given these considerations, the problem requires a solid understanding of multiple concepts and careful implementation across a few modules, justifying a score of 0.55, slightly above the medium threshold but not reaching the hard category due to the absence of deep architectural changes or complex error handling.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "bug: incorrectly calculating the size of script that is loaded from memory\n## \ud83d\udc1b Bug Report\r\nthe script that is loaded from memory lost the last character because its size is not correct and misses a one-character from its length. \r\n\r\n### Possible Solution\r\n<!--- Not obligatory, but suggest a fix/reason for the bug, -->\r\n\r\nhttps://github.com/metacall/core/blob/76f02c051c9bfd84926331f8ada8b9506a12f04d/source/ports/rs_port/src/loaders.rs#L82-L87\r\n\r\n```diff\r\n metacall_load_from_memory( \r\n     c_tag.as_ptr(), \r\n     c_script.as_ptr(), \r\n-    script.len(), \r\n+    script.len() + 1, \r\n     ptr::null_mut(), \r\n)\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\n#### source code\r\n```rust\r\nuse metacall::{loaders, switch};\r\nfn main() {\r\n    let _metacall = switch::initialize().unwrap();\r\n    loaders::from_memory(\"node\", \"console.log('Hello world')\").unwrap();\r\n}\r\n```\r\n\r\n#### behavior\r\n```\r\nException in node_loader_trampoline_load_from_memory while loading: console.log('Hello world' 0x5b3b086100b0-0x5b3b08610080-26-2913836576:1\r\nconsole.log('Hello world'\r\n            ^^^^^^^^^^^^^\r\n\r\nSyntaxError: missing ) after argument list\r\n    at internalCompileFunction (node:internal/vm:73:18)\r\n    at wrapSafe (node:internal/modules/cjs/loader:1274:20)\r\n    at Module._compile (node:internal/modules/cjs/loader:1320:27)\r\n    at node_loader_trampoline_load_from_memory (/gnu/store/ka685gr3ah26nmjfny1kwixmv2nsc2ms-metacall-0.7.8/lib/bootstrap.js:182:5)\r\n```\r\n\n", "patch": "diff --git a/source/ports/rs_port/src/loaders.rs b/source/ports/rs_port/src/loaders.rs\nindex cf0cec127..eb691acbb 100644\n--- a/source/ports/rs_port/src/loaders.rs\n+++ b/source/ports/rs_port/src/loaders.rs\n@@ -82,7 +82,7 @@ pub fn from_memory(tag: impl ToString, script: impl ToString) -> Result<(), Meta\n         metacall_load_from_memory(\n             c_tag.as_ptr(),\n             c_script.as_ptr(),\n-            script.len(),\n+            script.len() + 1,\n             ptr::null_mut(),\n         )\n     } != 0\n", "instance_id": "metacall__core-514", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in identifying the bug: a script loaded from memory is missing the last character due to an incorrect size calculation. The issue is described with a specific error message, steps to reproduce, and a proposed solution in the form of a code diff. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly explain why adding 1 to the length (i.e., `script.len() + 1`) is the correct fix\u2014whether this accounts for a null terminator or some other requirement is left unclear. Additionally, there is no mention of potential edge cases (e.g., empty scripts or scripts with special characters) or constraints on the input script. While the provided reproduction steps and error output are helpful, the lack of deeper context about the underlying system (e.g., how `metacall_load_from_memory` handles memory or string termination) slightly reduces clarity. Overall, the statement is valid and mostly clear but misses some minor details that could aid in fully understanding the issue and solution.", "difficulty_explanation": "The difficulty of this problem is very low, falling in the 0.0-0.2 range. The issue is a straightforward bug fix involving a single line of code change in one file (`loaders.rs`). The modification is minimal\u2014adjusting the length parameter passed to `metacall_load_from_memory` by adding 1 to account for the missing character. The scope of the change is extremely limited, with no impact on the broader codebase architecture or interactions between modules. The technical concepts required are basic: understanding string length in Rust and how it might relate to memory allocation or null termination in a C-style API (given the use of `as_ptr()` and `metacall_load_from_memory`). No advanced algorithms, design patterns, or domain-specific knowledge are needed beyond basic familiarity with Rust and FFI (Foreign Function Interface) concepts. Edge cases and error handling are not mentioned in the problem statement, and the fix does not appear to introduce or require additional error handling logic. While there might be a need to verify the fix across different script inputs, this does not significantly increase the difficulty. Overall, this is a very easy task that requires only a simple modification and minimal understanding of the surrounding code.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "`rm` returns directory not found error for both directories and files.\n### Describe the bug\n\nWhen attempting to remove a directory that does not exist, nushell throws the error `nu::shell::directory_not_found`:\n```nu\n\u276f : rm foo/\nError: nu::shell::directory_not_found\n\n  \u00d7 Directory not found\n   \u256d\u2500[entry #2:1:4]\n 1 \u2502 rm foo/\n   \u00b7    \u2500\u2500\u252c\u2500\n   \u00b7      \u2570\u2500\u2500 directory not found\n   \u2570\u2500\u2500\u2500\u2500\n  help: /Users/mussar/workspace/github.com/0x4D5352/nushell/foo/ does not exist```\n\nThis is expected behavior. However, this same error is raised when attempting to remove a file that does not exist:\n\n```nu\n\u276f : rm foo.txt\nError: nu::shell::directory_not_found\n\n  \u00d7 Directory not found\n   \u256d\u2500[entry #1:1:4]\n 1 \u2502 rm foo.txt\n   \u00b7    \u2500\u2500\u2500\u252c\u2500\u2500\u2500\n   \u00b7       \u2570\u2500\u2500 directory not found\n   \u2570\u2500\u2500\u2500\u2500\n  help: /Users/mussar/workspace/github.com/0x4D5352/nushell/foo.txt does not exist\n```\n\nThis might already be a tracked issue, as the code that returns this error in `rm.rs` is coming from a match statement on `glob_from`, and @cptpiepmatz is already working on updating this function: https://github.com/nushell/nushell/commit/dc52a6fec5be7bec59582e8e676d890aae5628a4\n\n### How to reproduce\n\n1. Just try to `rm` a file that doesn't exist.\n\n### Expected behavior\n\nEither return a generic error, or distinguish between directories and files.\n\n### Configuration\n\n| key                | value                                                                                          |\n| ------------------ | ---------------------------------------------------------------------------------------------- |\n| version            | 0.100.0                                                                                        |\n| major              | 0                                                                                              |\n| minor              | 100                                                                                            |\n| patch              | 0                                                                                              |\n| branch             |                                                                                                |\n| commit_hash        |                                                                                                |\n| build_os           | macos-aarch64                                                                                  |\n| build_target       | aarch64-apple-darwin                                                                           |\n| rust_version       | rustc 1.82.0 (f6e511eec 2024-10-15) (Homebrew)                                                 |\n| cargo_version      | cargo 1.82.0                                                                                   |\n| build_time         | 2024-11-13 20:37:01 -06:00                                                                     |\n| build_rust_channel | release                                                                                        |\n| allocator          | mimalloc                                                                                       |\n| features           | default, sqlite, trash                                                                         |\n| installed_plugins  | formats 0.99.1, gstat 0.99.1, highlight 1.4.1+0.100.0, inc 0.99.1, polars 0.99.1, query 0.99.1 |\n", "patch": "diff --git a/crates/nu-cli/src/commands/history/history_.rs b/crates/nu-cli/src/commands/history/history_.rs\nindex 40d951966e009..00efd547d4462 100644\n--- a/crates/nu-cli/src/commands/history/history_.rs\n+++ b/crates/nu-cli/src/commands/history/history_.rs\n@@ -1,5 +1,5 @@\n use nu_engine::command_prelude::*;\n-use nu_protocol::HistoryFileFormat;\n+use nu_protocol::{shell_error::io::IoError, HistoryFileFormat};\n use reedline::{\n     FileBackedHistory, History as ReedlineHistory, HistoryItem, SearchDirection, SearchQuery,\n     SqliteBackedHistory,\n@@ -93,10 +93,11 @@ impl Command for History {\n                         )\n                     })\n                 })\n-                .ok_or(ShellError::FileNotFound {\n-                    file: history_path.display().to_string(),\n-                    span: head,\n-                })?\n+                .ok_or(IoError::new(\n+                    std::io::ErrorKind::NotFound,\n+                    head,\n+                    history_path,\n+                ))?\n                 .into_pipeline_data(head, signals)),\n             HistoryFileFormat::Sqlite => Ok(history_reader\n                 .and_then(|h| {\n@@ -109,10 +110,11 @@ impl Command for History {\n                         .enumerate()\n                         .map(move |(idx, entry)| create_history_record(idx, entry, long, head))\n                 })\n-                .ok_or(ShellError::FileNotFound {\n-                    file: history_path.display().to_string(),\n-                    span: head,\n-                })?\n+                .ok_or(IoError::new(\n+                    std::io::ErrorKind::NotFound,\n+                    head,\n+                    history_path,\n+                ))?\n                 .into_pipeline_data(head, signals)),\n         }\n     }\ndiff --git a/crates/nu-cli/src/commands/history/history_import.rs b/crates/nu-cli/src/commands/history/history_import.rs\nindex 7666bd7eb7e76..b9764306f8f7c 100644\n--- a/crates/nu-cli/src/commands/history/history_import.rs\n+++ b/crates/nu-cli/src/commands/history/history_import.rs\n@@ -1,7 +1,10 @@\n use std::path::{Path, PathBuf};\n \n use nu_engine::command_prelude::*;\n-use nu_protocol::HistoryFileFormat;\n+use nu_protocol::{\n+    shell_error::{self, io::IoError},\n+    HistoryFileFormat,\n+};\n \n use reedline::{\n     FileBackedHistory, History, HistoryItem, ReedlineError, SearchQuery, SqliteBackedHistory,\n@@ -69,17 +72,16 @@ Note that history item IDs are ignored when importing from file.\"#\n         call: &Call,\n         input: PipelineData,\n     ) -> Result<PipelineData, ShellError> {\n+        let span = call.head;\n         let ok = Ok(Value::nothing(call.head).into_pipeline_data());\n \n         let Some(history) = engine_state.history_config() else {\n             return ok;\n         };\n         let Some(current_history_path) = history.file_path() else {\n-            return Err(ShellError::ConfigDirNotFound {\n-                span: Some(call.head),\n-            });\n+            return Err(ShellError::ConfigDirNotFound { span: span.into() });\n         };\n-        if let Some(bak_path) = backup(&current_history_path)? {\n+        if let Some(bak_path) = backup(&current_history_path, span)? {\n             println!(\"Backed history to {}\", bak_path.display());\n         }\n         match input {\n@@ -216,7 +218,7 @@ fn item_from_record(mut rec: Record, span: Span) -> Result<HistoryItem, ShellErr\n         hostname: get(rec, fields::HOSTNAME, |v| Ok(v.as_str()?.to_owned()))?,\n         cwd: get(rec, fields::CWD, |v| Ok(v.as_str()?.to_owned()))?,\n         exit_status: get(rec, fields::EXIT_STATUS, |v| v.as_int())?,\n-        duration: get(rec, fields::DURATION, duration_from_value)?,\n+        duration: get(rec, fields::DURATION, |v| duration_from_value(v, span))?,\n         more_info: None,\n         // TODO: Currently reedline doesn't let you create session IDs.\n         session_id: None,\n@@ -232,19 +234,21 @@ fn item_from_record(mut rec: Record, span: Span) -> Result<HistoryItem, ShellErr\n     Ok(item)\n }\n \n-fn duration_from_value(v: Value) -> Result<std::time::Duration, ShellError> {\n+fn duration_from_value(v: Value, span: Span) -> Result<std::time::Duration, ShellError> {\n     chrono::Duration::nanoseconds(v.as_duration()?)\n         .to_std()\n-        .map_err(|_| ShellError::IOError {\n-            msg: \"negative duration not supported\".to_string(),\n-        })\n+        .map_err(|_| ShellError::NeedsPositiveValue { span })\n }\n \n-fn find_backup_path(path: &Path) -> Result<PathBuf, ShellError> {\n+fn find_backup_path(path: &Path, span: Span) -> Result<PathBuf, ShellError> {\n     let Ok(mut bak_path) = path.to_path_buf().into_os_string().into_string() else {\n         // This isn't fundamentally problem, but trying to work with OsString is a nightmare.\n-        return Err(ShellError::IOError {\n-            msg: \"History path mush be representable as UTF-8\".to_string(),\n+        return Err(ShellError::GenericError {\n+            error: \"History path not UTF-8\".to_string(),\n+            msg: \"History path must be representable as UTF-8\".to_string(),\n+            span: Some(span),\n+            help: None,\n+            inner: vec![],\n         });\n     };\n     bak_path.push_str(\".bak\");\n@@ -260,24 +264,45 @@ fn find_backup_path(path: &Path) -> Result<PathBuf, ShellError> {\n             return Ok(PathBuf::from(bak_path));\n         }\n     }\n-    Err(ShellError::IOError {\n-        msg: \"Too many existing backup files\".to_string(),\n+    Err(ShellError::GenericError {\n+        error: \"Too many backup files\".to_string(),\n+        msg: \"Found too many existing backup files\".to_string(),\n+        span: Some(span),\n+        help: None,\n+        inner: vec![],\n     })\n }\n \n-fn backup(path: &Path) -> Result<Option<PathBuf>, ShellError> {\n+fn backup(path: &Path, span: Span) -> Result<Option<PathBuf>, ShellError> {\n     match path.metadata() {\n         Ok(md) if md.is_file() => (),\n         Ok(_) => {\n-            return Err(ShellError::IOError {\n-                msg: \"history path exists but is not a file\".to_string(),\n-            })\n+            return Err(IoError::new_with_additional_context(\n+                shell_error::io::ErrorKind::NotAFile,\n+                span,\n+                PathBuf::from(path),\n+                \"history path exists but is not a file\",\n+            )\n+            .into())\n         }\n         Err(e) if e.kind() == std::io::ErrorKind::NotFound => return Ok(None),\n-        Err(e) => return Err(e.into()),\n+        Err(e) => {\n+            return Err(IoError::new_internal(\n+                e.kind(),\n+                \"Could not get metadata\",\n+                nu_protocol::location!(),\n+            )\n+            .into())\n+        }\n     }\n-    let bak_path = find_backup_path(path)?;\n-    std::fs::copy(path, &bak_path)?;\n+    let bak_path = find_backup_path(path, span)?;\n+    std::fs::copy(path, &bak_path).map_err(|err| {\n+        IoError::new_internal(\n+            err.kind(),\n+            \"Could not copy backup\",\n+            nu_protocol::location!(),\n+        )\n+    })?;\n     Ok(Some(bak_path))\n }\n \n@@ -388,7 +413,7 @@ mod tests {\n         for name in existing {\n             std::fs::File::create_new(dir.path().join(name)).unwrap();\n         }\n-        let got = find_backup_path(&dir.path().join(\"history.dat\")).unwrap();\n+        let got = find_backup_path(&dir.path().join(\"history.dat\"), Span::test_data()).unwrap();\n         assert_eq!(got, dir.path().join(want))\n     }\n \n@@ -400,7 +425,7 @@ mod tests {\n         write!(&mut history, \"123\").unwrap();\n         let want_bak_path = dir.path().join(\"history.dat.bak\");\n         assert_eq!(\n-            backup(&dir.path().join(\"history.dat\")),\n+            backup(&dir.path().join(\"history.dat\"), Span::test_data()),\n             Ok(Some(want_bak_path.clone()))\n         );\n         let got_data = String::from_utf8(std::fs::read(want_bak_path).unwrap()).unwrap();\n@@ -410,7 +435,7 @@ mod tests {\n     #[test]\n     fn test_backup_no_file() {\n         let dir = tempfile::tempdir().unwrap();\n-        let bak_path = backup(&dir.path().join(\"history.dat\")).unwrap();\n+        let bak_path = backup(&dir.path().join(\"history.dat\"), Span::test_data()).unwrap();\n         assert!(bak_path.is_none());\n     }\n }\ndiff --git a/crates/nu-cli/src/commands/keybindings_listen.rs b/crates/nu-cli/src/commands/keybindings_listen.rs\nindex 40cda5652d5de..ec7b33f2963d3 100644\n--- a/crates/nu-cli/src/commands/keybindings_listen.rs\n+++ b/crates/nu-cli/src/commands/keybindings_listen.rs\n@@ -2,6 +2,7 @@ use crossterm::{\n     event::Event, event::KeyCode, event::KeyEvent, execute, terminal, QueueableCommand,\n };\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n use std::io::{stdout, Write};\n \n #[derive(Clone)]\n@@ -39,7 +40,13 @@ impl Command for KeybindingsListen {\n         match print_events(engine_state) {\n             Ok(v) => Ok(v.into_pipeline_data()),\n             Err(e) => {\n-                terminal::disable_raw_mode()?;\n+                terminal::disable_raw_mode().map_err(|err| {\n+                    IoError::new_internal(\n+                        err.kind(),\n+                        \"Could not disable raw mode\",\n+                        nu_protocol::location!(),\n+                    )\n+                })?;\n                 Err(ShellError::GenericError {\n                     error: \"Error with input\".into(),\n                     msg: \"\".into(),\n@@ -63,8 +70,20 @@ impl Command for KeybindingsListen {\n pub fn print_events(engine_state: &EngineState) -> Result<Value, ShellError> {\n     let config = engine_state.get_config();\n \n-    stdout().flush()?;\n-    terminal::enable_raw_mode()?;\n+    stdout().flush().map_err(|err| {\n+        IoError::new_internal(\n+            err.kind(),\n+            \"Could not flush stdout\",\n+            nu_protocol::location!(),\n+        )\n+    })?;\n+    terminal::enable_raw_mode().map_err(|err| {\n+        IoError::new_internal(\n+            err.kind(),\n+            \"Could not enable raw mode\",\n+            nu_protocol::location!(),\n+        )\n+    })?;\n \n     if config.use_kitty_protocol {\n         if let Ok(false) = crossterm::terminal::supports_keyboard_enhancement() {\n@@ -94,7 +113,9 @@ pub fn print_events(engine_state: &EngineState) -> Result<Value, ShellError> {\n     let mut stdout = std::io::BufWriter::new(std::io::stderr());\n \n     loop {\n-        let event = crossterm::event::read()?;\n+        let event = crossterm::event::read().map_err(|err| {\n+            IoError::new_internal(err.kind(), \"Could not read event\", nu_protocol::location!())\n+        })?;\n         if event == Event::Key(KeyCode::Esc.into()) {\n             break;\n         }\n@@ -113,9 +134,25 @@ pub fn print_events(engine_state: &EngineState) -> Result<Value, ShellError> {\n \n             _ => \"\".to_string(),\n         };\n-        stdout.queue(crossterm::style::Print(o))?;\n-        stdout.queue(crossterm::style::Print(\"\\r\\n\"))?;\n-        stdout.flush()?;\n+        stdout.queue(crossterm::style::Print(o)).map_err(|err| {\n+            IoError::new_internal(\n+                err.kind(),\n+                \"Could not print output record\",\n+                nu_protocol::location!(),\n+            )\n+        })?;\n+        stdout\n+            .queue(crossterm::style::Print(\"\\r\\n\"))\n+            .map_err(|err| {\n+                IoError::new_internal(\n+                    err.kind(),\n+                    \"Could not print linebreak\",\n+                    nu_protocol::location!(),\n+                )\n+            })?;\n+        stdout.flush().map_err(|err| {\n+            IoError::new_internal(err.kind(), \"Could not flush\", nu_protocol::location!())\n+        })?;\n     }\n \n     if config.use_kitty_protocol {\n@@ -125,7 +162,13 @@ pub fn print_events(engine_state: &EngineState) -> Result<Value, ShellError> {\n         );\n     }\n \n-    terminal::disable_raw_mode()?;\n+    terminal::disable_raw_mode().map_err(|err| {\n+        IoError::new_internal(\n+            err.kind(),\n+            \"Could not disable raw mode\",\n+            nu_protocol::location!(),\n+        )\n+    })?;\n \n     Ok(Value::nothing(Span::unknown()))\n }\ndiff --git a/crates/nu-cli/src/config_files.rs b/crates/nu-cli/src/config_files.rs\nindex 28332fe998bde..bb54a860d6f54 100644\n--- a/crates/nu-cli/src/config_files.rs\n+++ b/crates/nu-cli/src/config_files.rs\n@@ -18,7 +18,7 @@ const OLD_PLUGIN_FILE: &str = \"plugin.nu\";\n \n #[cfg(feature = \"plugin\")]\n pub fn read_plugin_file(engine_state: &mut EngineState, plugin_file: Option<Spanned<String>>) {\n-    use nu_protocol::ShellError;\n+    use nu_protocol::{shell_error::io::IoError, ShellError};\n     use std::path::Path;\n \n     let span = plugin_file.as_ref().map(|s| s.span);\n@@ -78,16 +78,12 @@ pub fn read_plugin_file(engine_state: &mut EngineState, plugin_file: Option<Span\n                 } else {\n                     report_shell_error(\n                         engine_state,\n-                        &ShellError::GenericError {\n-                            error: format!(\n-                                \"Error while opening plugin registry file: {}\",\n-                                plugin_path.display()\n-                            ),\n-                            msg: \"plugin path defined here\".into(),\n-                            span,\n-                            help: None,\n-                            inner: vec![err.into()],\n-                        },\n+                        &ShellError::Io(IoError::new_internal_with_path(\n+                            err.kind(),\n+                            \"Could not open plugin registry file\",\n+                            nu_protocol::location!(),\n+                            plugin_path,\n+                        )),\n                     );\n                     return;\n                 }\n@@ -234,8 +230,8 @@ pub fn eval_config_contents(\n #[cfg(feature = \"plugin\")]\n pub fn migrate_old_plugin_file(engine_state: &EngineState) -> bool {\n     use nu_protocol::{\n-        PluginExample, PluginIdentity, PluginRegistryItem, PluginRegistryItemData, PluginSignature,\n-        ShellError,\n+        shell_error::io::IoError, PluginExample, PluginIdentity, PluginRegistryItem,\n+        PluginRegistryItemData, PluginSignature, ShellError,\n     };\n     use std::collections::BTreeMap;\n \n@@ -324,7 +320,15 @@ pub fn migrate_old_plugin_file(engine_state: &EngineState) -> bool {\n     // Write the new file\n     let new_plugin_file_path = config_dir.join(PLUGIN_FILE);\n     if let Err(err) = std::fs::File::create(&new_plugin_file_path)\n-        .map_err(|e| e.into())\n+        .map_err(|err| {\n+            IoError::new_internal_with_path(\n+                err.kind(),\n+                \"Could not create new plugin file\",\n+                nu_protocol::location!(),\n+                new_plugin_file_path.clone(),\n+            )\n+        })\n+        .map_err(ShellError::from)\n         .and_then(|file| contents.write_to(file, None))\n     {\n         report_shell_error(\ndiff --git a/crates/nu-cli/src/eval_file.rs b/crates/nu-cli/src/eval_file.rs\nindex aa4dbfca78b8c..8b252bf17e347 100644\n--- a/crates/nu-cli/src/eval_file.rs\n+++ b/crates/nu-cli/src/eval_file.rs\n@@ -7,9 +7,11 @@ use nu_protocol::{\n     cli_error::report_compile_error,\n     debugger::WithoutDebug,\n     engine::{EngineState, Stack, StateWorkingSet},\n-    report_parse_error, report_parse_warning, PipelineData, ShellError, Span, Value,\n+    report_parse_error, report_parse_warning,\n+    shell_error::io::IoError,\n+    PipelineData, ShellError, Span, Value,\n };\n-use std::sync::Arc;\n+use std::{path::PathBuf, sync::Arc};\n \n /// Entry point for evaluating a file.\n ///\n@@ -24,11 +26,14 @@ pub fn evaluate_file(\n ) -> Result<(), ShellError> {\n     let cwd = engine_state.cwd_as_string(Some(stack))?;\n \n-    let file_path =\n-        canonicalize_with(&path, cwd).map_err(|err| ShellError::FileNotFoundCustom {\n-            msg: format!(\"Could not access file '{path}': {err}\"),\n-            span: Span::unknown(),\n-        })?;\n+    let file_path = canonicalize_with(&path, cwd).map_err(|err| {\n+        IoError::new_with_additional_context(\n+            err.kind(),\n+            Span::unknown(),\n+            PathBuf::from(&path),\n+            \"Could not access file\",\n+        )\n+    })?;\n \n     let file_path_str = file_path\n         .to_str()\n@@ -40,18 +45,24 @@ pub fn evaluate_file(\n             span: Span::unknown(),\n         })?;\n \n-    let file = std::fs::read(&file_path).map_err(|err| ShellError::FileNotFoundCustom {\n-        msg: format!(\"Could not read file '{file_path_str}': {err}\"),\n-        span: Span::unknown(),\n+    let file = std::fs::read(&file_path).map_err(|err| {\n+        IoError::new_with_additional_context(\n+            err.kind(),\n+            Span::unknown(),\n+            file_path.clone(),\n+            \"Could not read file\",\n+        )\n     })?;\n     engine_state.file = Some(file_path.clone());\n \n-    let parent = file_path\n-        .parent()\n-        .ok_or_else(|| ShellError::FileNotFoundCustom {\n-            msg: format!(\"The file path '{file_path_str}' does not have a parent\"),\n-            span: Span::unknown(),\n-        })?;\n+    let parent = file_path.parent().ok_or_else(|| {\n+        IoError::new_with_additional_context(\n+            std::io::ErrorKind::NotFound,\n+            Span::unknown(),\n+            file_path.clone(),\n+            \"The file path does not have a parent\",\n+        )\n+    })?;\n \n     stack.add_env_var(\n         \"FILE_PWD\".to_string(),\ndiff --git a/crates/nu-cli/src/repl.rs b/crates/nu-cli/src/repl.rs\nindex b8fef7355d66b..72da95d4498b5 100644\n--- a/crates/nu-cli/src/repl.rs\n+++ b/crates/nu-cli/src/repl.rs\n@@ -21,6 +21,7 @@ use nu_color_config::StyleComputer;\n #[allow(deprecated)]\n use nu_engine::env_to_strings;\n use nu_parser::{lex, parse, trim_quotes_str};\n+use nu_protocol::shell_error::io::IoError;\n use nu_protocol::{\n     config::NuCursorShape,\n     engine::{EngineState, Stack, StateWorkingSet},\n@@ -846,21 +847,26 @@ fn do_auto_cd(\n         if !path.exists() {\n             report_shell_error(\n                 engine_state,\n-                &ShellError::DirectoryNotFound {\n-                    dir: path.to_string_lossy().to_string(),\n+                &ShellError::Io(IoError::new_with_additional_context(\n+                    std::io::ErrorKind::NotFound,\n                     span,\n-                },\n+                    PathBuf::from(&path),\n+                    \"Cannot change directory\",\n+                )),\n             );\n         }\n         path.to_string_lossy().to_string()\n     };\n \n-    if let PermissionResult::PermissionDenied(reason) = have_permission(path.clone()) {\n+    if let PermissionResult::PermissionDenied(_) = have_permission(path.clone()) {\n         report_shell_error(\n             engine_state,\n-            &ShellError::IOError {\n-                msg: format!(\"Cannot change directory to {path}: {reason}\"),\n-            },\n+            &ShellError::Io(IoError::new_with_additional_context(\n+                std::io::ErrorKind::PermissionDenied,\n+                span,\n+                PathBuf::from(path),\n+                \"Cannot change directory\",\n+            )),\n         );\n         return;\n     }\ndiff --git a/crates/nu-cmd-extra/src/extra/strings/format/bits.rs b/crates/nu-cmd-extra/src/extra/strings/format/bits.rs\nindex 693c6905e8a4a..b34d429c6cb2c 100644\n--- a/crates/nu-cmd-extra/src/extra/strings/format/bits.rs\n+++ b/crates/nu-cmd-extra/src/extra/strings/format/bits.rs\n@@ -3,7 +3,7 @@ use std::io::{self, Read, Write};\n use nu_cmd_base::input_handler::{operate, CmdArgument};\n use nu_engine::command_prelude::*;\n \n-use nu_protocol::Signals;\n+use nu_protocol::{shell_error::io::IoError, Signals};\n use num_traits::ToPrimitive;\n \n struct Arguments {\n@@ -142,7 +142,11 @@ fn byte_stream_to_bits(stream: ByteStream, head: Span) -> ByteStream {\n             ByteStreamType::String,\n             move |buffer| {\n                 let mut byte = [0];\n-                if reader.read(&mut byte[..]).err_span(head)? > 0 {\n+                if reader\n+                    .read(&mut byte[..])\n+                    .map_err(|err| IoError::new(err.kind(), head, None))?\n+                    > 0\n+                {\n                     // Format the byte as bits\n                     if is_first {\n                         is_first = false;\ndiff --git a/crates/nu-cmd-lang/src/core_commands/do_.rs b/crates/nu-cmd-lang/src/core_commands/do_.rs\nindex 62ddea5324fff..fe788983da10d 100644\n--- a/crates/nu-cmd-lang/src/core_commands/do_.rs\n+++ b/crates/nu-cmd-lang/src/core_commands/do_.rs\n@@ -1,7 +1,9 @@\n use nu_engine::{command_prelude::*, get_eval_block_with_early_return, redirect_env};\n #[cfg(feature = \"os\")]\n use nu_protocol::process::{ChildPipe, ChildProcess};\n-use nu_protocol::{engine::Closure, ByteStream, ByteStreamSource, OutDest};\n+use nu_protocol::{\n+    engine::Closure, shell_error::io::IoError, ByteStream, ByteStreamSource, OutDest,\n+};\n \n use std::{\n     io::{Cursor, Read},\n@@ -143,10 +145,16 @@ impl Command for Do {\n                                     .name(\"stdout consumer\".to_string())\n                                     .spawn(move || {\n                                         let mut buf = Vec::new();\n-                                        stdout.read_to_end(&mut buf)?;\n+                                        stdout.read_to_end(&mut buf).map_err(|err| {\n+                                            IoError::new_internal(\n+                                                err.kind(),\n+                                                \"Could not read stdout to end\",\n+                                                nu_protocol::location!(),\n+                                            )\n+                                        })?;\n                                         Ok::<_, ShellError>(buf)\n                                     })\n-                                    .err_span(head)\n+                                    .map_err(|err| IoError::new(err.kind(), head, None))\n                             })\n                             .transpose()?;\n \n@@ -156,7 +164,9 @@ impl Command for Do {\n                             None => String::new(),\n                             Some(mut stderr) => {\n                                 let mut buf = String::new();\n-                                stderr.read_to_string(&mut buf).err_span(span)?;\n+                                stderr\n+                                    .read_to_string(&mut buf)\n+                                    .map_err(|err| IoError::new(err.kind(), span, None))?;\n                                 buf\n                             }\n                         };\ndiff --git a/crates/nu-cmd-plugin/src/commands/plugin/add.rs b/crates/nu-cmd-plugin/src/commands/plugin/add.rs\nindex c603ddbb8c0a2..301b88fdffcf6 100644\n--- a/crates/nu-cmd-plugin/src/commands/plugin/add.rs\n+++ b/crates/nu-cmd-plugin/src/commands/plugin/add.rs\n@@ -1,8 +1,10 @@\n use crate::util::{get_plugin_dirs, modify_plugin_file};\n use nu_engine::command_prelude::*;\n use nu_plugin_engine::{GetPlugin, PersistentPlugin};\n-use nu_protocol::{PluginGcConfig, PluginIdentity, PluginRegistryItem, RegisteredPlugin};\n-use std::sync::Arc;\n+use nu_protocol::{\n+    shell_error::io::IoError, PluginGcConfig, PluginIdentity, PluginRegistryItem, RegisteredPlugin,\n+};\n+use std::{path::PathBuf, sync::Arc};\n \n #[derive(Clone)]\n pub struct PluginAdd;\n@@ -86,11 +88,14 @@ apparent the next time `nu` is next launched with that plugin registry file.\n         let filename_expanded = nu_path::locate_in_dirs(&filename.item, &cwd, || {\n             get_plugin_dirs(engine_state, stack)\n         })\n-        .err_span(filename.span)?;\n+        .map_err(|err| IoError::new(err.kind(), filename.span, PathBuf::from(filename.item)))?;\n \n         let shell_expanded = shell\n             .as_ref()\n-            .map(|s| nu_path::canonicalize_with(&s.item, &cwd).err_span(s.span))\n+            .map(|s| {\n+                nu_path::canonicalize_with(&s.item, &cwd)\n+                    .map_err(|err| IoError::new(err.kind(), s.span, None))\n+            })\n             .transpose()?;\n \n         // Parse the plugin filename so it can be used to spawn the plugin\ndiff --git a/crates/nu-cmd-plugin/src/util.rs b/crates/nu-cmd-plugin/src/util.rs\nindex 57de225ace01d..053900ef19f3c 100644\n--- a/crates/nu-cmd-plugin/src/util.rs\n+++ b/crates/nu-cmd-plugin/src/util.rs\n@@ -1,6 +1,6 @@\n #[allow(deprecated)]\n use nu_engine::{command_prelude::*, current_dir};\n-use nu_protocol::{engine::StateWorkingSet, PluginRegistryFile};\n+use nu_protocol::{engine::StateWorkingSet, shell_error::io::IoError, PluginRegistryFile};\n use std::{\n     fs::{self, File},\n     path::PathBuf,\n@@ -45,21 +45,16 @@ pub(crate) fn read_plugin_file(\n     // Try to read the plugin file if it exists\n     if fs::metadata(&plugin_registry_file_path).is_ok_and(|m| m.len() > 0) {\n         PluginRegistryFile::read_from(\n-            File::open(&plugin_registry_file_path).map_err(|err| ShellError::IOErrorSpanned {\n-                msg: format!(\n-                    \"failed to read `{}`: {}\",\n-                    plugin_registry_file_path.display(),\n-                    err\n-                ),\n-                span: file_span,\n-            })?,\n+            File::open(&plugin_registry_file_path)\n+                .map_err(|err| IoError::new(err.kind(), file_span, plugin_registry_file_path))?,\n             Some(file_span),\n         )\n     } else if let Some(path) = custom_path {\n-        Err(ShellError::FileNotFound {\n-            file: path.item.clone(),\n-            span: path.span,\n-        })\n+        Err(ShellError::Io(IoError::new(\n+            std::io::ErrorKind::NotFound,\n+            path.span,\n+            PathBuf::from(&path.item),\n+        )))\n     } else {\n         Ok(PluginRegistryFile::default())\n     }\n@@ -80,13 +75,8 @@ pub(crate) fn modify_plugin_file(\n     // Try to read the plugin file if it exists\n     let mut contents = if fs::metadata(&plugin_registry_file_path).is_ok_and(|m| m.len() > 0) {\n         PluginRegistryFile::read_from(\n-            File::open(&plugin_registry_file_path).map_err(|err| ShellError::IOErrorSpanned {\n-                msg: format!(\n-                    \"failed to read `{}`: {}\",\n-                    plugin_registry_file_path.display(),\n-                    err\n-                ),\n-                span: file_span,\n+            File::open(&plugin_registry_file_path).map_err(|err| {\n+                IoError::new(err.kind(), file_span, plugin_registry_file_path.clone())\n             })?,\n             Some(file_span),\n         )?\n@@ -99,14 +89,8 @@ pub(crate) fn modify_plugin_file(\n \n     // Save the modified file on success\n     contents.write_to(\n-        File::create(&plugin_registry_file_path).map_err(|err| ShellError::IOErrorSpanned {\n-            msg: format!(\n-                \"failed to create `{}`: {}\",\n-                plugin_registry_file_path.display(),\n-                err\n-            ),\n-            span: file_span,\n-        })?,\n+        File::create(&plugin_registry_file_path)\n+            .map_err(|err| IoError::new(err.kind(), file_span, plugin_registry_file_path))?,\n         Some(span),\n     )?;\n \ndiff --git a/crates/nu-command/src/bytes/ends_with.rs b/crates/nu-command/src/bytes/ends_with.rs\nindex 774b45aefc534..23167a7901b9b 100644\n--- a/crates/nu-command/src/bytes/ends_with.rs\n+++ b/crates/nu-command/src/bytes/ends_with.rs\n@@ -1,5 +1,6 @@\n use nu_cmd_base::input_handler::{operate, CmdArgument};\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n use std::{\n     collections::VecDeque,\n     io::{self, BufRead},\n@@ -76,7 +77,7 @@ impl Command for BytesEndsWith {\n                     Ok(&[]) => break,\n                     Ok(buf) => buf,\n                     Err(e) if e.kind() == io::ErrorKind::Interrupted => continue,\n-                    Err(e) => return Err(e.into_spanned(span).into()),\n+                    Err(e) => return Err(IoError::new(e.kind(), span, None).into()),\n                 };\n                 let len = buf.len();\n                 if len >= cap {\ndiff --git a/crates/nu-command/src/bytes/starts_with.rs b/crates/nu-command/src/bytes/starts_with.rs\nindex 39db1a80cefe2..9681b4ccbe8da 100644\n--- a/crates/nu-command/src/bytes/starts_with.rs\n+++ b/crates/nu-command/src/bytes/starts_with.rs\n@@ -1,5 +1,6 @@\n use nu_cmd_base::input_handler::{operate, CmdArgument};\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n use std::io::Read;\n \n struct Arguments {\n@@ -71,7 +72,7 @@ impl Command for BytesStartsWith {\n             reader\n                 .take(pattern.len() as u64)\n                 .read_to_end(&mut start)\n-                .err_span(span)?;\n+                .map_err(|err| IoError::new(err.kind(), span, None))?;\n \n             Ok(Value::bool(start == pattern, head).into_pipeline_data())\n         } else {\ndiff --git a/crates/nu-command/src/conversions/into/string.rs b/crates/nu-command/src/conversions/into/string.rs\nindex 460f6d973d041..261afe1dd7e26 100644\n--- a/crates/nu-command/src/conversions/into/string.rs\n+++ b/crates/nu-command/src/conversions/into/string.rs\n@@ -2,7 +2,7 @@ use std::sync::Arc;\n \n use nu_cmd_base::input_handler::{operate, CmdArgument};\n use nu_engine::command_prelude::*;\n-use nu_protocol::{into_code, Config};\n+use nu_protocol::{shell_error::into_code, Config};\n use nu_utils::get_system_locale;\n use num_format::ToFormattedString;\n \ndiff --git a/crates/nu-command/src/database/values/sqlite.rs b/crates/nu-command/src/database/values/sqlite.rs\nindex 620ac953242c4..8959cf5998792 100644\n--- a/crates/nu-command/src/database/values/sqlite.rs\n+++ b/crates/nu-command/src/database/values/sqlite.rs\n@@ -2,7 +2,10 @@ use super::definitions::{\n     db_column::DbColumn, db_constraint::DbConstraint, db_foreignkey::DbForeignKey,\n     db_index::DbIndex, db_table::DbTable,\n };\n-use nu_protocol::{CustomValue, PipelineData, Record, ShellError, Signals, Span, Spanned, Value};\n+use nu_protocol::{\n+    shell_error::io::IoError, CustomValue, PipelineData, Record, ShellError, Signals, Span,\n+    Spanned, Value,\n+};\n use rusqlite::{\n     types::ValueRef, Connection, DatabaseName, Error as SqliteError, OpenFlags, Row, Statement,\n     ToSql,\n@@ -38,24 +41,22 @@ impl SQLiteDatabase {\n     }\n \n     pub fn try_from_path(path: &Path, span: Span, signals: Signals) -> Result<Self, ShellError> {\n-        let mut file = File::open(path).map_err(|e| ShellError::ReadingFile {\n-            msg: e.to_string(),\n-            span,\n-        })?;\n+        let mut file =\n+            File::open(path).map_err(|e| IoError::new(e.kind(), span, PathBuf::from(path)))?;\n \n         let mut buf: [u8; 16] = [0; 16];\n         file.read_exact(&mut buf)\n-            .map_err(|e| ShellError::ReadingFile {\n-                msg: e.to_string(),\n-                span,\n-            })\n+            .map_err(|e| ShellError::Io(IoError::new(e.kind(), span, PathBuf::from(path))))\n             .and_then(|_| {\n                 if buf == SQLITE_MAGIC_BYTES {\n                     Ok(SQLiteDatabase::new(path, signals))\n                 } else {\n-                    Err(ShellError::ReadingFile {\n-                        msg: \"Not a SQLite file\".into(),\n-                        span,\n+                    Err(ShellError::GenericError {\n+                        error: \"Not a SQLite file\".into(),\n+                        msg: format!(\"Could not read '{}' as SQLite file\", path.display()),\n+                        span: Some(span),\n+                        help: None,\n+                        inner: vec![],\n                     })\n                 }\n             })\ndiff --git a/crates/nu-command/src/env/config/config_.rs b/crates/nu-command/src/env/config/config_.rs\nindex 71afd57c5abe0..f60b4be290655 100644\n--- a/crates/nu-command/src/env/config/config_.rs\n+++ b/crates/nu-command/src/env/config/config_.rs\n@@ -60,6 +60,8 @@ pub(super) fn start_editor(\n     call: &Call,\n ) -> Result<PipelineData, ShellError> {\n     // Find the editor executable.\n+\n+    use nu_protocol::shell_error::io::IoError;\n     let (editor_name, editor_args) = get_editor(engine_state, stack, call.head)?;\n     let paths = nu_engine::env::path_str(engine_state, stack, call.head)?;\n     let cwd = engine_state.cwd(Some(stack))?;\n@@ -99,13 +101,22 @@ pub(super) fn start_editor(\n     // Spawn the child process. On Unix, also put the child process to\n     // foreground if we're in an interactive session.\n     #[cfg(windows)]\n-    let child = ForegroundChild::spawn(command)?;\n+    let child = ForegroundChild::spawn(command);\n     #[cfg(unix)]\n     let child = ForegroundChild::spawn(\n         command,\n         engine_state.is_interactive,\n         &engine_state.pipeline_externals_state,\n-    )?;\n+    );\n+\n+    let child = child.map_err(|err| {\n+        IoError::new_with_additional_context(\n+            err.kind(),\n+            call.head,\n+            None,\n+            \"Could not spawn foreground child\",\n+        )\n+    })?;\n \n     // Wrap the output into a `PipelineData::ByteStream`.\n     let child = nu_protocol::process::ChildProcess::new(child, None, false, call.head)?;\ndiff --git a/crates/nu-command/src/env/config/config_reset.rs b/crates/nu-command/src/env/config/config_reset.rs\nindex 03c022c3d7683..5215ac6a1d76d 100644\n--- a/crates/nu-command/src/env/config/config_reset.rs\n+++ b/crates/nu-command/src/env/config/config_reset.rs\n@@ -1,8 +1,9 @@\n use chrono::Local;\n use nu_engine::command_prelude::*;\n \n+use nu_protocol::shell_error::io::IoError;\n use nu_utils::{get_scaffold_config, get_scaffold_env};\n-use std::io::Write;\n+use std::{io::Write, path::PathBuf};\n \n #[derive(Clone)]\n pub struct ConfigReset;\n@@ -58,19 +59,23 @@ impl Command for ConfigReset {\n                     \"oldconfig-{}.nu\",\n                     Local::now().format(\"%F-%H-%M-%S\"),\n                 ));\n-                if std::fs::rename(nu_config.clone(), backup_path).is_err() {\n-                    return Err(ShellError::FileNotFoundCustom {\n-                        msg: \"config.nu could not be backed up\".into(),\n+                if let Err(err) = std::fs::rename(nu_config.clone(), &backup_path) {\n+                    return Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n                         span,\n-                    });\n+                        PathBuf::from(backup_path),\n+                        \"config.nu could not be backed up\",\n+                    )));\n                 }\n             }\n-            if let Ok(mut file) = std::fs::File::create(nu_config) {\n-                if writeln!(&mut file, \"{config_file}\").is_err() {\n-                    return Err(ShellError::FileNotFoundCustom {\n-                        msg: \"config.nu could not be written to\".into(),\n+            if let Ok(mut file) = std::fs::File::create(&nu_config) {\n+                if let Err(err) = writeln!(&mut file, \"{config_file}\") {\n+                    return Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n                         span,\n-                    });\n+                        PathBuf::from(nu_config),\n+                        \"config.nu could not be written to\",\n+                    )));\n                 }\n             }\n         }\n@@ -81,19 +86,23 @@ impl Command for ConfigReset {\n             if !no_backup {\n                 let mut backup_path = config_path.clone();\n                 backup_path.push(format!(\"oldenv-{}.nu\", Local::now().format(\"%F-%H-%M-%S\"),));\n-                if std::fs::rename(env_config.clone(), backup_path).is_err() {\n-                    return Err(ShellError::FileNotFoundCustom {\n-                        msg: \"env.nu could not be backed up\".into(),\n+                if let Err(err) = std::fs::rename(env_config.clone(), &backup_path) {\n+                    return Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n                         span,\n-                    });\n+                        PathBuf::from(backup_path),\n+                        \"env.nu could not be backed up\",\n+                    )));\n                 }\n             }\n-            if let Ok(mut file) = std::fs::File::create(env_config) {\n-                if writeln!(&mut file, \"{config_file}\").is_err() {\n-                    return Err(ShellError::FileNotFoundCustom {\n-                        msg: \"env.nu could not be written to\".into(),\n+            if let Ok(mut file) = std::fs::File::create(&env_config) {\n+                if let Err(err) = writeln!(&mut file, \"{config_file}\") {\n+                    return Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n                         span,\n-                    });\n+                        PathBuf::from(env_config),\n+                        \"env.nu could not be written to\",\n+                    )));\n                 }\n             }\n         }\ndiff --git a/crates/nu-command/src/env/source_env.rs b/crates/nu-command/src/env/source_env.rs\nindex 342c31aed4c11..a16bbe557fafe 100644\n--- a/crates/nu-command/src/env/source_env.rs\n+++ b/crates/nu-command/src/env/source_env.rs\n@@ -2,7 +2,7 @@ use nu_engine::{\n     command_prelude::*, find_in_dirs_env, get_dirs_var_from_call, get_eval_block_with_early_return,\n     redirect_env,\n };\n-use nu_protocol::{engine::CommandType, BlockId};\n+use nu_protocol::{engine::CommandType, shell_error::io::IoError, BlockId};\n use std::path::PathBuf;\n \n /// Source a file for environment variables.\n@@ -65,10 +65,11 @@ impl Command for SourceEnv {\n         )? {\n             PathBuf::from(&path)\n         } else {\n-            return Err(ShellError::FileNotFound {\n-                file: source_filename.item,\n-                span: source_filename.span,\n-            });\n+            return Err(ShellError::Io(IoError::new(\n+                std::io::ErrorKind::NotFound,\n+                source_filename.span,\n+                PathBuf::from(source_filename.item),\n+            )));\n         };\n \n         if let Some(parent) = file_path.parent() {\ndiff --git a/crates/nu-command/src/filesystem/cd.rs b/crates/nu-command/src/filesystem/cd.rs\nindex 2af932bcb48a4..3ba438746d7fd 100644\n--- a/crates/nu-command/src/filesystem/cd.rs\n+++ b/crates/nu-command/src/filesystem/cd.rs\n@@ -1,4 +1,7 @@\n+use std::path::PathBuf;\n+\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::{self, io::IoError};\n use nu_utils::filesystem::{have_permission, PermissionResult};\n \n #[derive(Clone)]\n@@ -77,25 +80,39 @@ impl Command for Cd {\n                     if physical {\n                         if let Ok(path) = nu_path::canonicalize_with(path_no_whitespace, &cwd) {\n                             if !path.is_dir() {\n-                                return Err(ShellError::NotADirectory { span: v.span });\n+                                return Err(shell_error::io::IoError::new(\n+                                    shell_error::io::ErrorKind::NotADirectory,\n+                                    v.span,\n+                                    None,\n+                                )\n+                                .into());\n                             };\n                             path\n                         } else {\n-                            return Err(ShellError::DirectoryNotFound {\n-                                dir: path_no_whitespace.to_string(),\n-                                span: v.span,\n-                            });\n+                            return Err(shell_error::io::IoError::new(\n+                                std::io::ErrorKind::NotFound,\n+                                v.span,\n+                                PathBuf::from(path_no_whitespace),\n+                            )\n+                            .into());\n                         }\n                     } else {\n                         let path = nu_path::expand_path_with(path_no_whitespace, &cwd, true);\n                         if !path.exists() {\n-                            return Err(ShellError::DirectoryNotFound {\n-                                dir: path_no_whitespace.to_string(),\n-                                span: v.span,\n-                            });\n+                            return Err(shell_error::io::IoError::new(\n+                                std::io::ErrorKind::NotFound,\n+                                v.span,\n+                                PathBuf::from(path_no_whitespace),\n+                            )\n+                            .into());\n                         };\n                         if !path.is_dir() {\n-                            return Err(ShellError::NotADirectory { span: v.span });\n+                            return Err(shell_error::io::IoError::new(\n+                                shell_error::io::ErrorKind::NotADirectory,\n+                                v.span,\n+                                path,\n+                            )\n+                            .into());\n                         };\n                         path\n                     }\n@@ -117,13 +134,9 @@ impl Command for Cd {\n                 stack.set_cwd(path)?;\n                 Ok(PipelineData::empty())\n             }\n-            PermissionResult::PermissionDenied(reason) => Err(ShellError::IOError {\n-                msg: format!(\n-                    \"Cannot change directory to {}: {}\",\n-                    path.to_string_lossy(),\n-                    reason\n-                ),\n-            }),\n+            PermissionResult::PermissionDenied(_) => {\n+                Err(IoError::new(std::io::ErrorKind::PermissionDenied, call.head, path).into())\n+            }\n         }\n     }\n \ndiff --git a/crates/nu-command/src/filesystem/ls.rs b/crates/nu-command/src/filesystem/ls.rs\nindex 68f35c5294ecb..19418b1a70b73 100644\n--- a/crates/nu-command/src/filesystem/ls.rs\n+++ b/crates/nu-command/src/filesystem/ls.rs\n@@ -5,7 +5,7 @@ use nu_engine::glob_from;\n use nu_engine::{command_prelude::*, env::current_dir};\n use nu_glob::MatchOptions;\n use nu_path::{expand_path_with, expand_to_real_path};\n-use nu_protocol::{DataSource, NuGlob, PipelineMetadata, Signals};\n+use nu_protocol::{shell_error::io::IoError, DataSource, NuGlob, PipelineMetadata, Signals};\n use pathdiff::diff_paths;\n use rayon::prelude::*;\n #[cfg(unix)]\n@@ -254,10 +254,12 @@ fn ls_for_one_pattern(\n         if let Some(path) = pattern_arg {\n             // it makes no sense to list an empty string.\n             if path.item.as_ref().is_empty() {\n-                return Err(ShellError::FileNotFoundCustom {\n-                    msg: \"empty string('') directory or file does not exist\".to_string(),\n-                    span: path.span,\n-                });\n+                return Err(ShellError::Io(IoError::new_with_additional_context(\n+                    std::io::ErrorKind::NotFound,\n+                    path.span,\n+                    PathBuf::from(path.item.to_string()),\n+                    \"empty string('') directory or file does not exist\",\n+                )));\n             }\n             match path.item {\n                 NuGlob::DoNotExpand(p) => Some(Spanned {\n@@ -283,10 +285,7 @@ fn ls_for_one_pattern(\n                 nu_path::expand_path_with(pat.item.as_ref(), &cwd, pat.item.is_expand());\n             // Avoid checking and pushing \"*\" to the path when directory (do not show contents) flag is true\n             if !directory && tmp_expanded.is_dir() {\n-                if read_dir(&tmp_expanded, p_tag, use_threads)?\n-                    .next()\n-                    .is_none()\n-                {\n+                if read_dir(tmp_expanded, p_tag, use_threads)?.next().is_none() {\n                     return Ok(Value::test_nothing().into_pipeline_data());\n                 }\n                 just_read_dir = !(pat.item.is_expand() && nu_glob::is_glob(pat.item.as_ref()));\n@@ -305,7 +304,7 @@ fn ls_for_one_pattern(\n             // Avoid pushing \"*\" to the default path when directory (do not show contents) flag is true\n             if directory {\n                 (NuGlob::Expand(\".\".to_string()), false)\n-            } else if read_dir(&cwd, p_tag, use_threads)?.next().is_none() {\n+            } else if read_dir(cwd.clone(), p_tag, use_threads)?.next().is_none() {\n                 return Ok(Value::test_nothing().into_pipeline_data());\n             } else {\n                 (NuGlob::Expand(\"*\".to_string()), false)\n@@ -318,7 +317,7 @@ fn ls_for_one_pattern(\n     let path = pattern_arg.into_spanned(p_tag);\n     let (prefix, paths) = if just_read_dir {\n         let expanded = nu_path::expand_path_with(path.item.as_ref(), &cwd, path.item.is_expand());\n-        let paths = read_dir(&expanded, p_tag, use_threads)?;\n+        let paths = read_dir(expanded.clone(), p_tag, use_threads)?;\n         // just need to read the directory, so prefix is path itself.\n         (Some(expanded), paths)\n     } else {\n@@ -350,7 +349,16 @@ fn ls_for_one_pattern(\n     let signals_clone = signals.clone();\n \n     let pool = if use_threads {\n-        let count = std::thread::available_parallelism()?.get();\n+        let count = std::thread::available_parallelism()\n+            .map_err(|err| {\n+                IoError::new_with_additional_context(\n+                    err.kind(),\n+                    call_span,\n+                    None,\n+                    \"Could not get available parallelism\",\n+                )\n+            })?\n+            .get();\n         create_pool(count)?\n     } else {\n         create_pool(1)?\n@@ -910,14 +918,12 @@ mod windows_helper {\n                 &mut find_data,\n             ) {\n                 Ok(_) => Ok(find_data),\n-                Err(e) => Err(ShellError::ReadingFile {\n-                    msg: format!(\n-                        \"Could not read metadata for '{}':\\n  '{}'\",\n-                        filename.to_string_lossy(),\n-                        e\n-                    ),\n+                Err(e) => Err(ShellError::Io(IoError::new_with_additional_context(\n+                    std::io::ErrorKind::Other,\n                     span,\n-                }),\n+                    PathBuf::from(filename),\n+                    format!(\"Could not read metadata: {e}\"),\n+                ))),\n             }\n         }\n     }\n@@ -950,28 +956,17 @@ mod windows_helper {\n \n #[allow(clippy::type_complexity)]\n fn read_dir(\n-    f: &Path,\n+    f: PathBuf,\n     span: Span,\n     use_threads: bool,\n ) -> Result<Box<dyn Iterator<Item = Result<PathBuf, ShellError>> + Send>, ShellError> {\n     let items = f\n         .read_dir()\n-        .map_err(|error| {\n-            if error.kind() == std::io::ErrorKind::PermissionDenied {\n-                return ShellError::GenericError {\n-                    error: \"Permission denied\".into(),\n-                    msg: \"The permissions may not allow access for this user\".into(),\n-                    span: Some(span),\n-                    help: None,\n-                    inner: vec![],\n-                };\n-            }\n-\n-            error.into()\n-        })?\n-        .map(|d| {\n+        .map_err(|err| IoError::new(err.kind(), span, f.clone()))?\n+        .map(move |d| {\n             d.map(|r| r.path())\n-                .map_err(|e| ShellError::IOError { msg: e.to_string() })\n+                .map_err(|err| IoError::new(err.kind(), span, f.clone()))\n+                .map_err(ShellError::from)\n         });\n     if !use_threads {\n         let mut collected = items.collect::<Vec<_>>();\ndiff --git a/crates/nu-command/src/filesystem/mktemp.rs b/crates/nu-command/src/filesystem/mktemp.rs\nindex 9a0c041f15993..5ebd054acb9b7 100644\n--- a/crates/nu-command/src/filesystem/mktemp.rs\n+++ b/crates/nu-command/src/filesystem/mktemp.rs\n@@ -106,14 +106,10 @@ impl Command for Mktemp {\n         };\n \n         let res = match uu_mktemp::mktemp(&options) {\n-            Ok(res) => {\n-                res.into_os_string()\n-                    .into_string()\n-                    .map_err(|e| ShellError::IOErrorSpanned {\n-                        msg: e.to_string_lossy().to_string(),\n-                        span,\n-                    })?\n-            }\n+            Ok(res) => res\n+                .into_os_string()\n+                .into_string()\n+                .map_err(|_| ShellError::NonUtf8 { span })?,\n             Err(e) => {\n                 return Err(ShellError::GenericError {\n                     error: format!(\"{}\", e),\ndiff --git a/crates/nu-command/src/filesystem/open.rs b/crates/nu-command/src/filesystem/open.rs\nindex db00f35d6dc42..a372d7e79e5ba 100644\n--- a/crates/nu-command/src/filesystem/open.rs\n+++ b/crates/nu-command/src/filesystem/open.rs\n@@ -1,7 +1,11 @@\n #[allow(deprecated)]\n use nu_engine::{command_prelude::*, current_dir, get_eval_block};\n-use nu_protocol::{ast, DataSource, NuGlob, PipelineMetadata};\n-use std::path::Path;\n+use nu_protocol::{\n+    ast,\n+    shell_error::{self, io::IoError},\n+    DataSource, NuGlob, PipelineMetadata,\n+};\n+use std::path::{Path, PathBuf};\n \n #[cfg(feature = \"sqlite\")]\n use crate::database::SQLiteDatabase;\n@@ -87,25 +91,10 @@ impl Command for Open {\n \n             for path in nu_engine::glob_from(&path, &cwd, call_span, None)\n                 .map_err(|err| match err {\n-                    ShellError::DirectoryNotFound { span, .. } => ShellError::FileNotFound {\n-                        file: path.item.to_string(),\n-                        span,\n-                    },\n-                    // that particular error in `nu_engine::glob_from` doesn't have a span attached\n-                    // to it, so let's add it\n-                    ShellError::GenericError {\n-                        error,\n-                        msg,\n-                        span: _,\n-                        help,\n-                        inner,\n-                    } if error.as_str() == \"Permission denied\" => ShellError::GenericError {\n-                        error,\n-                        msg,\n-                        span: Some(arg_span),\n-                        help,\n-                        inner,\n-                    },\n+                    ShellError::Io(mut err) => {\n+                        err.span = arg_span;\n+                        err.into()\n+                    }\n                     _ => err,\n                 })?\n                 .1\n@@ -114,24 +103,26 @@ impl Command for Open {\n                 let path = Path::new(&path);\n \n                 if permission_denied(path) {\n+                    let err = IoError::new(\n+                        std::io::ErrorKind::PermissionDenied,\n+                        arg_span,\n+                        PathBuf::from(path),\n+                    );\n+\n                     #[cfg(unix)]\n-                    let error_msg = match path.metadata() {\n-                        Ok(md) => format!(\n-                            \"The permissions of {:o} does not allow access for this user\",\n-                            md.permissions().mode() & 0o0777\n-                        ),\n-                        Err(e) => e.to_string(),\n+                    let err = {\n+                        let mut err = err;\n+                        err.additional_context = Some(match path.metadata() {\n+                            Ok(md) => format!(\n+                                \"The permissions of {:o} does not allow access for this user\",\n+                                md.permissions().mode() & 0o0777\n+                            ),\n+                            Err(e) => e.to_string(),\n+                        });\n+                        err\n                     };\n \n-                    #[cfg(not(unix))]\n-                    let error_msg = String::from(\"Permission denied\");\n-                    return Err(ShellError::GenericError {\n-                        error: \"Permission denied\".into(),\n-                        msg: error_msg,\n-                        span: Some(arg_span),\n-                        help: None,\n-                        inner: vec![],\n-                    });\n+                    return Err(err.into());\n                 } else {\n                     #[cfg(feature = \"sqlite\")]\n                     if !raw {\n@@ -147,18 +138,18 @@ impl Command for Open {\n                         }\n                     }\n \n-                    let file = match std::fs::File::open(path) {\n-                        Ok(file) => file,\n-                        Err(err) => {\n-                            return Err(ShellError::GenericError {\n-                                error: \"Permission denied\".into(),\n-                                msg: err.to_string(),\n-                                span: Some(arg_span),\n-                                help: None,\n-                                inner: vec![],\n-                            });\n-                        }\n-                    };\n+                    if path.is_dir() {\n+                        // At least under windows this check ensures that we don't get a\n+                        // permission denied error on directories\n+                        return Err(ShellError::Io(IoError::new(\n+                            shell_error::io::ErrorKind::IsADirectory,\n+                            arg_span,\n+                            PathBuf::from(path),\n+                        )));\n+                    }\n+\n+                    let file = std::fs::File::open(path)\n+                        .map_err(|err| IoError::new(err.kind(), arg_span, PathBuf::from(path)))?;\n \n                     // No content_type by default - Is added later if no converter is found\n                     let stream = PipelineData::ByteStream(\ndiff --git a/crates/nu-command/src/filesystem/rm.rs b/crates/nu-command/src/filesystem/rm.rs\nindex 9a13442aa38ba..91daf99d8c769 100644\n--- a/crates/nu-command/src/filesystem/rm.rs\n+++ b/crates/nu-command/src/filesystem/rm.rs\n@@ -3,7 +3,11 @@ use super::util::try_interaction;\n use nu_engine::{command_prelude::*, env::current_dir};\n use nu_glob::MatchOptions;\n use nu_path::expand_path_with;\n-use nu_protocol::{report_shell_error, NuGlob};\n+use nu_protocol::{\n+    report_shell_error,\n+    shell_error::{self, io::IoError},\n+    NuGlob,\n+};\n #[cfg(unix)]\n use std::os::unix::prelude::FileTypeExt;\n use std::{\n@@ -299,9 +303,17 @@ fn rm(\n                 }\n             }\n             Err(e) => {\n-                // glob_from may canonicalize path and return `DirectoryNotFound`\n+                // glob_from may canonicalize path and return an error when a directory is not found\n                 // nushell should suppress the error if `--force` is used.\n-                if !(force && matches!(e, ShellError::DirectoryNotFound { .. })) {\n+                if !(force\n+                    && matches!(\n+                        e,\n+                        ShellError::Io(IoError {\n+                            kind: shell_error::io::ErrorKind::Std(std::io::ErrorKind::NotFound),\n+                            ..\n+                        })\n+                    ))\n+                {\n                     return Err(e);\n                 }\n             }\n@@ -413,8 +425,7 @@ fn rm(\n                 };\n \n                 if let Err(e) = result {\n-                    let msg = format!(\"Could not delete {:}: {e:}\", f.to_string_lossy());\n-                    Err(ShellError::RemoveNotPossible { msg, span })\n+                    Err(ShellError::Io(IoError::new(e.kind(), span, f)))\n                 } else if verbose {\n                     let msg = if interactive && !confirmed {\n                         \"not deleted\"\ndiff --git a/crates/nu-command/src/filesystem/save.rs b/crates/nu-command/src/filesystem/save.rs\nindex 67fd1a2271cb5..bd580eec8c5b2 100644\n--- a/crates/nu-command/src/filesystem/save.rs\n+++ b/crates/nu-command/src/filesystem/save.rs\n@@ -4,8 +4,8 @@ use nu_engine::get_eval_block;\n use nu_engine::{command_prelude::*, current_dir};\n use nu_path::expand_path_with;\n use nu_protocol::{\n-    ast, byte_stream::copy_with_signals, process::ChildPipe, ByteStreamSource, DataSource, OutDest,\n-    PipelineMetadata, Signals,\n+    ast, byte_stream::copy_with_signals, process::ChildPipe, shell_error::io::IoError,\n+    ByteStreamSource, DataSource, OutDest, PipelineMetadata, Signals,\n };\n use std::{\n     fs::File,\n@@ -86,6 +86,7 @@ impl Command for Save {\n                 span: arg.span,\n             });\n \n+        let from_io_error = IoError::factory(span, path.item.as_path());\n         match input {\n             PipelineData::ByteStream(stream, metadata) => {\n                 check_saving_to_source_file(metadata.as_ref(), &path, stderr_path.as_ref())?;\n@@ -129,7 +130,7 @@ impl Command for Save {\n                                         io::copy(&mut tee, &mut io::stderr())\n                                     }\n                                 }\n-                                .err_span(span)?;\n+                                .map_err(|err| IoError::new(err.kind(), span, None))?;\n                             }\n                             Ok(())\n                         }\n@@ -153,7 +154,7 @@ impl Command for Save {\n                                         )\n                                     })\n                                     .transpose()\n-                                    .err_span(span)?;\n+                                    .map_err(&from_io_error)?;\n \n                                 let res = match stdout {\n                                     ChildPipe::Pipe(pipe) => {\n@@ -203,15 +204,10 @@ impl Command for Save {\n                 let (mut file, _) = get_files(&path, stderr_path.as_ref(), append, force)?;\n                 for val in ls {\n                     file.write_all(&value_to_bytes(val)?)\n-                        .map_err(|err| ShellError::IOError {\n-                            msg: err.to_string(),\n-                        })?;\n-                    file.write_all(\"\\n\".as_bytes())\n-                        .map_err(|err| ShellError::IOError {\n-                            msg: err.to_string(),\n-                        })?;\n+                        .map_err(&from_io_error)?;\n+                    file.write_all(\"\\n\".as_bytes()).map_err(&from_io_error)?;\n                 }\n-                file.flush()?;\n+                file.flush().map_err(&from_io_error)?;\n \n                 Ok(PipelineData::empty())\n             }\n@@ -232,11 +228,8 @@ impl Command for Save {\n                 // Only open file after successful conversion\n                 let (mut file, _) = get_files(&path, stderr_path.as_ref(), append, force)?;\n \n-                file.write_all(&bytes).map_err(|err| ShellError::IOError {\n-                    msg: err.to_string(),\n-                })?;\n-\n-                file.flush()?;\n+                file.write_all(&bytes).map_err(&from_io_error)?;\n+                file.flush().map_err(&from_io_error)?;\n \n                 Ok(PipelineData::empty())\n             }\n@@ -420,33 +413,27 @@ fn prepare_path(\n }\n \n fn open_file(path: &Path, span: Span, append: bool) -> Result<File, ShellError> {\n-    let file = match (append, path.exists()) {\n-        (true, true) => std::fs::OpenOptions::new().append(true).open(path),\n+    let file: Result<File, nu_protocol::shell_error::io::ErrorKind> = match (append, path.exists())\n+    {\n+        (true, true) => std::fs::OpenOptions::new()\n+            .append(true)\n+            .open(path)\n+            .map_err(|err| err.kind().into()),\n         _ => {\n             // This is a temporary solution until `std::fs::File::create` is fixed on Windows (rust-lang/rust#134893)\n             // A TOCTOU problem exists here, which may cause wrong error message to be shown\n             #[cfg(target_os = \"windows\")]\n             if path.is_dir() {\n-                // It should be `io::ErrorKind::IsADirectory` but it's not available in stable yet (1.83)\n-                Err(io::Error::new(\n-                    io::ErrorKind::Unsupported,\n-                    \"Is a directory (os error 21)\",\n-                ))\n+                Err(nu_protocol::shell_error::io::ErrorKind::IsADirectory)\n             } else {\n-                std::fs::File::create(path)\n+                std::fs::File::create(path).map_err(|err| err.kind().into())\n             }\n             #[cfg(not(target_os = \"windows\"))]\n-            std::fs::File::create(path)\n+            std::fs::File::create(path).map_err(|err| err.kind().into())\n         }\n     };\n \n-    file.map_err(|e| ShellError::GenericError {\n-        error: format!(\"Problem with [{}], Permission denied\", path.display()),\n-        msg: e.to_string(),\n-        span: Some(span),\n-        help: None,\n-        inner: vec![],\n-    })\n+    file.map_err(|err_kind| ShellError::Io(IoError::new(err_kind, span, PathBuf::from(path))))\n }\n \n /// Get output file and optional stderr file\n@@ -493,6 +480,9 @@ fn stream_to_file(\n     span: Span,\n     progress: bool,\n ) -> Result<(), ShellError> {\n+    // TODO: maybe we can get a path in here\n+    let from_io_error = IoError::factory(span, None);\n+\n     // https://github.com/nushell/nushell/pull/9377 contains the reason for not using `BufWriter`\n     if progress {\n         let mut bytes_processed = 0;\n@@ -512,7 +502,7 @@ fn stream_to_file(\n             match reader.fill_buf() {\n                 Ok(&[]) => break Ok(()),\n                 Ok(buf) => {\n-                    file.write_all(buf).err_span(span)?;\n+                    file.write_all(buf).map_err(&from_io_error)?;\n                     let len = buf.len();\n                     reader.consume(len);\n                     bytes_processed += len as u64;\n@@ -530,9 +520,9 @@ fn stream_to_file(\n         if let Err(err) = res {\n             let _ = file.flush();\n             bar.abandoned_msg(\"# Error while saving #\".to_owned());\n-            Err(err.into_spanned(span).into())\n+            Err(from_io_error(err).into())\n         } else {\n-            file.flush().err_span(span)?;\n+            file.flush().map_err(&from_io_error)?;\n             Ok(())\n         }\n     } else {\ndiff --git a/crates/nu-command/src/filesystem/ucp.rs b/crates/nu-command/src/filesystem/ucp.rs\nindex 40315d9e782c4..a65cbece664f1 100644\n--- a/crates/nu-command/src/filesystem/ucp.rs\n+++ b/crates/nu-command/src/filesystem/ucp.rs\n@@ -1,6 +1,6 @@\n #[allow(deprecated)]\n use nu_engine::{command_prelude::*, current_dir};\n-use nu_protocol::NuGlob;\n+use nu_protocol::{shell_error::io::IoError, NuGlob};\n use std::path::PathBuf;\n use uu_cp::{BackupMode, CopyMode, UpdateMode};\n \n@@ -197,10 +197,11 @@ impl Command for UCp {\n                     .map(|f| f.1)?\n                     .collect();\n             if exp_files.is_empty() {\n-                return Err(ShellError::FileNotFound {\n-                    file: p.item.to_string(),\n-                    span: p.span,\n-                });\n+                return Err(ShellError::Io(IoError::new(\n+                    std::io::ErrorKind::NotFound,\n+                    p.span,\n+                    PathBuf::from(p.item.to_string()),\n+                )));\n             };\n             let mut app_vals: Vec<PathBuf> = Vec::new();\n             for v in exp_files {\ndiff --git a/crates/nu-command/src/filesystem/umv.rs b/crates/nu-command/src/filesystem/umv.rs\nindex cdf0c05b1f824..c76ab9f376ab5 100644\n--- a/crates/nu-command/src/filesystem/umv.rs\n+++ b/crates/nu-command/src/filesystem/umv.rs\n@@ -1,7 +1,7 @@\n #[allow(deprecated)]\n use nu_engine::{command_prelude::*, current_dir};\n use nu_path::expand_path_with;\n-use nu_protocol::NuGlob;\n+use nu_protocol::{shell_error::io::IoError, NuGlob};\n use std::{ffi::OsString, path::PathBuf};\n use uu_mv::{BackupMode, UpdateMode};\n \n@@ -138,10 +138,11 @@ impl Command for UMv {\n                     .map(|f| f.1)?\n                     .collect();\n             if exp_files.is_empty() {\n-                return Err(ShellError::FileNotFound {\n-                    file: p.item.to_string(),\n-                    span: p.span,\n-                });\n+                return Err(ShellError::Io(IoError::new(\n+                    std::io::ErrorKind::NotFound,\n+                    p.span,\n+                    PathBuf::from(p.item.to_string()),\n+                )));\n             };\n             let mut app_vals: Vec<PathBuf> = Vec::new();\n             for v in exp_files {\ndiff --git a/crates/nu-command/src/filesystem/utouch.rs b/crates/nu-command/src/filesystem/utouch.rs\nindex 9fbf9805de586..d887a5c4118b4 100644\n--- a/crates/nu-command/src/filesystem/utouch.rs\n+++ b/crates/nu-command/src/filesystem/utouch.rs\n@@ -3,8 +3,8 @@ use filetime::FileTime;\n use nu_engine::command_prelude::*;\n use nu_glob::{glob, is_glob};\n use nu_path::expand_path_with;\n-use nu_protocol::NuGlob;\n-use std::{io::ErrorKind, path::PathBuf};\n+use nu_protocol::{shell_error::io::IoError, NuGlob};\n+use std::path::PathBuf;\n use uu_touch::{error::TouchError, ChangeTimes, InputFile, Options, Source};\n \n #[derive(Clone)]\n@@ -225,20 +225,12 @@ impl Command for UTouch {\n                 },\n                 TouchError::ReferenceFileInaccessible(reference_path, io_err) => {\n                     let span = reference_span.expect(\"touch should've been given a reference file\");\n-                    if io_err.kind() == ErrorKind::NotFound {\n-                        ShellError::FileNotFound {\n-                            span,\n-                            file: reference_path.display().to_string(),\n-                        }\n-                    } else {\n-                        ShellError::GenericError {\n-                            error: io_err.to_string(),\n-                            msg: format!(\"Failed to read metadata of {}\", reference_path.display()),\n-                            span: Some(span),\n-                            help: None,\n-                            inner: Vec::new(),\n-                        }\n-                    }\n+                    ShellError::Io(IoError::new_with_additional_context(\n+                        io_err.kind(),\n+                        span,\n+                        reference_path,\n+                        \"failed to read metadata\",\n+                    ))\n                 }\n                 _ => ShellError::GenericError {\n                     error: err.to_string(),\ndiff --git a/crates/nu-command/src/filesystem/watch.rs b/crates/nu-command/src/filesystem/watch.rs\nindex dd21304173179..3028181a21465 100644\n--- a/crates/nu-command/src/filesystem/watch.rs\n+++ b/crates/nu-command/src/filesystem/watch.rs\n@@ -9,6 +9,7 @@ use nu_engine::{command_prelude::*, ClosureEval};\n use nu_protocol::{\n     engine::{Closure, StateWorkingSet},\n     format_shell_error,\n+    shell_error::io::IoError,\n };\n use std::{\n     path::PathBuf,\n@@ -83,11 +84,12 @@ impl Command for Watch {\n \n         let path = match nu_path::canonicalize_with(path_no_whitespace, cwd) {\n             Ok(p) => p,\n-            Err(_) => {\n-                return Err(ShellError::DirectoryNotFound {\n-                    dir: path_no_whitespace.to_string(),\n-                    span: path_arg.span,\n-                })\n+            Err(err) => {\n+                return Err(ShellError::Io(IoError::new(\n+                    err.kind(),\n+                    path_arg.span,\n+                    PathBuf::from(path_no_whitespace),\n+                )))\n             }\n         };\n \n@@ -151,14 +153,22 @@ impl Command for Watch {\n         let mut debouncer = match new_debouncer(debounce_duration, None, tx) {\n             Ok(d) => d,\n             Err(e) => {\n-                return Err(ShellError::IOError {\n-                    msg: format!(\"Failed to create watcher: {e}\"),\n-                })\n+                return Err(ShellError::GenericError {\n+                    error: \"Failed to create watcher\".to_string(),\n+                    msg: e.to_string(),\n+                    span: Some(call.head),\n+                    help: None,\n+                    inner: vec![],\n+                });\n             }\n         };\n         if let Err(e) = debouncer.watcher().watch(&path, recursive_mode) {\n-            return Err(ShellError::IOError {\n-                msg: format!(\"Failed to create watcher: {e}\"),\n+            return Err(ShellError::GenericError {\n+                error: \"Failed to create watcher\".to_string(),\n+                msg: e.to_string(),\n+                span: Some(call.head),\n+                help: None,\n+                inner: vec![],\n             });\n         }\n         // need to cache to make sure that rename event works.\n@@ -249,13 +259,21 @@ impl Command for Watch {\n                     }\n                 }\n                 Ok(Err(_)) => {\n-                    return Err(ShellError::IOError {\n+                    return Err(ShellError::GenericError {\n+                        error: \"Receiving events failed\".to_string(),\n                         msg: \"Unexpected errors when receiving events\".into(),\n-                    })\n+                        span: None,\n+                        help: None,\n+                        inner: vec![],\n+                    });\n                 }\n                 Err(RecvTimeoutError::Disconnected) => {\n-                    return Err(ShellError::IOError {\n+                    return Err(ShellError::GenericError {\n+                        error: \"Disconnected\".to_string(),\n                         msg: \"Unexpected disconnect from file watcher\".into(),\n+                        span: None,\n+                        help: None,\n+                        inner: vec![],\n                     });\n                 }\n                 Err(RecvTimeoutError::Timeout) => {}\ndiff --git a/crates/nu-command/src/filters/chunks.rs b/crates/nu-command/src/filters/chunks.rs\nindex 93757c36e83e4..5149713644248 100644\n--- a/crates/nu-command/src/filters/chunks.rs\n+++ b/crates/nu-command/src/filters/chunks.rs\n@@ -1,5 +1,5 @@\n use nu_engine::command_prelude::*;\n-use nu_protocol::ListStream;\n+use nu_protocol::{shell_error::io::IoError, ListStream};\n use std::{\n     io::{BufRead, Cursor, ErrorKind},\n     num::NonZeroUsize,\n@@ -119,6 +119,7 @@ pub fn chunks(\n     chunk_size: NonZeroUsize,\n     span: Span,\n ) -> Result<PipelineData, ShellError> {\n+    let from_io_error = IoError::factory(span, None);\n     match input {\n         PipelineData::Value(Value::List { vals, .. }, metadata) => {\n             let chunks = ChunksIter::new(vals, chunk_size, span);\n@@ -136,7 +137,7 @@ pub fn chunks(\n             };\n             let value_stream = chunk_read.map(move |chunk| match chunk {\n                 Ok(chunk) => Value::binary(chunk, span),\n-                Err(e) => Value::error(e.into(), span),\n+                Err(e) => Value::error(from_io_error(e).into(), span),\n             });\n             let pipeline_data_with_metadata = value_stream.into_pipeline_data_with_metadata(\n                 span,\n@@ -155,7 +156,7 @@ pub fn chunks(\n                     };\n                     let value_stream = chunk_read.map(move |chunk| match chunk {\n                         Ok(chunk) => Value::binary(chunk, span),\n-                        Err(e) => Value::error(e.into(), span),\n+                        Err(e) => Value::error(from_io_error(e).into(), span),\n                     });\n                     value_stream.into_pipeline_data_with_metadata(\n                         span,\ndiff --git a/crates/nu-command/src/filters/empty.rs b/crates/nu-command/src/filters/empty.rs\nindex f4dd428b777d1..92a540fa4656d 100644\n--- a/crates/nu-command/src/filters/empty.rs\n+++ b/crates/nu-command/src/filters/empty.rs\n@@ -1,4 +1,5 @@\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n use std::io::Read;\n \n pub fn empty(\n@@ -41,7 +42,12 @@ pub fn empty(\n                 let span = stream.span();\n                 match stream.reader() {\n                     Some(reader) => {\n-                        let is_empty = reader.bytes().next().transpose().err_span(span)?.is_none();\n+                        let is_empty = reader\n+                            .bytes()\n+                            .next()\n+                            .transpose()\n+                            .map_err(|err| IoError::new(err.kind(), span, None))?\n+                            .is_none();\n                         if negate {\n                             Ok(Value::bool(!is_empty, head).into_pipeline_data())\n                         } else {\ndiff --git a/crates/nu-command/src/filters/first.rs b/crates/nu-command/src/filters/first.rs\nindex 5695f823c7c9a..a1f15c64ce90b 100644\n--- a/crates/nu-command/src/filters/first.rs\n+++ b/crates/nu-command/src/filters/first.rs\n@@ -1,5 +1,5 @@\n use nu_engine::command_prelude::*;\n-use nu_protocol::Signals;\n+use nu_protocol::{shell_error::io::IoError, Signals};\n use std::io::Read;\n \n #[derive(Clone)]\n@@ -180,7 +180,11 @@ fn first_helper(\n                     if return_single_element {\n                         // Take a single byte\n                         let mut byte = [0u8];\n-                        if reader.read(&mut byte).err_span(span)? > 0 {\n+                        if reader\n+                            .read(&mut byte)\n+                            .map_err(|err| IoError::new(err.kind(), span, None))?\n+                            > 0\n+                        {\n                             Ok(Value::int(byte[0] as i64, head).into_pipeline_data())\n                         } else {\n                             Err(ShellError::AccessEmptyContent { span: head })\ndiff --git a/crates/nu-command/src/filters/interleave.rs b/crates/nu-command/src/filters/interleave.rs\nindex f31a3411aed4d..4f2b457af3f4a 100644\n--- a/crates/nu-command/src/filters/interleave.rs\n+++ b/crates/nu-command/src/filters/interleave.rs\n@@ -1,5 +1,5 @@\n use nu_engine::{command_prelude::*, ClosureEvalOnce};\n-use nu_protocol::engine::Closure;\n+use nu_protocol::{engine::Closure, shell_error::io::IoError};\n use std::{sync::mpsc, thread};\n \n #[derive(Clone)]\n@@ -137,10 +137,7 @@ interleave\n                             }\n                         })\n                         .map(|_| ())\n-                        .map_err(|err| ShellError::IOErrorSpanned {\n-                            msg: err.to_string(),\n-                            span: head,\n-                        })\n+                        .map_err(|err| IoError::new(err.kind(), head, None).into())\n                 })\n             })?;\n \ndiff --git a/crates/nu-command/src/filters/last.rs b/crates/nu-command/src/filters/last.rs\nindex 127833dcd43c3..77b57880f62af 100644\n--- a/crates/nu-command/src/filters/last.rs\n+++ b/crates/nu-command/src/filters/last.rs\n@@ -1,4 +1,5 @@\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n use std::{collections::VecDeque, io::Read};\n \n #[derive(Clone)]\n@@ -165,7 +166,7 @@ impl Command for Last {\n                         let mut buf = VecDeque::with_capacity(rows + TAKE as usize);\n                         loop {\n                             let taken = std::io::copy(&mut (&mut reader).take(TAKE), &mut buf)\n-                                .err_span(span)?;\n+                                .map_err(|err| IoError::new(err.kind(), span, None))?;\n                             if buf.len() > rows {\n                                 buf.drain(..(buf.len() - rows));\n                             }\ndiff --git a/crates/nu-command/src/filters/tee.rs b/crates/nu-command/src/filters/tee.rs\nindex e6439398947c8..c6b61a2fb5ef1 100644\n--- a/crates/nu-command/src/filters/tee.rs\n+++ b/crates/nu-command/src/filters/tee.rs\n@@ -2,8 +2,8 @@ use nu_engine::{command_prelude::*, get_eval_block_with_early_return};\n #[cfg(feature = \"os\")]\n use nu_protocol::process::ChildPipe;\n use nu_protocol::{\n-    byte_stream::copy_with_signals, engine::Closure, report_shell_error, ByteStream,\n-    ByteStreamSource, OutDest, PipelineMetadata, Signals,\n+    byte_stream::copy_with_signals, engine::Closure, report_shell_error, shell_error::io::IoError,\n+    ByteStream, ByteStreamSource, OutDest, PipelineMetadata, Signals,\n };\n use std::{\n     io::{self, Read, Write},\n@@ -82,6 +82,7 @@ use it in your pipeline.\"#\n         input: PipelineData,\n     ) -> Result<PipelineData, ShellError> {\n         let head = call.head;\n+        let from_io_error = IoError::factory(head, None);\n         let use_stderr = call.has_flag(engine_state, stack, \"stderr\")?;\n \n         let closure: Spanned<Closure> = call.req(engine_state, stack, 0)?;\n@@ -263,7 +264,7 @@ use it in your pipeline.\"#\n                     let input = rx.into_pipeline_data_with_metadata(span, signals, metadata_clone);\n                     eval_block(input)\n                 })\n-                .err_span(call.head)?\n+                .map_err(&from_io_error)?\n                 .map(move |result| result.unwrap_or_else(|err| Value::error(err, closure_span)))\n                 .into_pipeline_data_with_metadata(\n                     span,\n@@ -278,7 +279,7 @@ use it in your pipeline.\"#\n                 tee_once(engine_state_arc, move || {\n                     eval_block(value_clone.into_pipeline_data_with_metadata(metadata_clone))\n                 })\n-                .err_span(call.head)?;\n+                .map_err(&from_io_error)?;\n                 Ok(value.into_pipeline_data_with_metadata(metadata))\n             }\n         }\n@@ -439,7 +440,9 @@ fn spawn_tee(\n             );\n             eval_block(PipelineData::ByteStream(stream, info.metadata))\n         })\n-        .err_span(info.span)?;\n+        .map_err(|err| {\n+            IoError::new_with_additional_context(err.kind(), info.span, None, \"Could not spawn tee\")\n+        })?;\n \n     Ok(TeeThread { sender, thread })\n }\n@@ -478,7 +481,15 @@ fn copy_on_thread(\n             copy_with_signals(src, dest, span, &signals)?;\n             Ok(())\n         })\n-        .map_err(|e| e.into_spanned(span).into())\n+        .map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                span,\n+                None,\n+                \"Could not spawn stderr copier\",\n+            )\n+            .into()\n+        })\n }\n \n #[cfg(feature = \"os\")]\n@@ -521,7 +532,12 @@ fn tee_forwards_errors_back_immediately() {\n     use std::time::Duration;\n     let slow_input = (0..100).inspect(|_| std::thread::sleep(Duration::from_millis(1)));\n     let iter = tee(slow_input, |_| {\n-        Err(ShellError::IOError { msg: \"test\".into() })\n+        Err(ShellError::Io(IoError::new_with_additional_context(\n+            std::io::ErrorKind::Other,\n+            Span::test_data(),\n+            None,\n+            \"test\",\n+        )))\n     })\n     .expect(\"io error\");\n     for result in iter {\n@@ -548,7 +564,12 @@ fn tee_waits_for_the_other_thread() {\n     let iter = tee(0..100, move |_| {\n         std::thread::sleep(Duration::from_millis(10));\n         waited_clone.store(true, Ordering::Relaxed);\n-        Err(ShellError::IOError { msg: \"test\".into() })\n+        Err(ShellError::Io(IoError::new_with_additional_context(\n+            std::io::ErrorKind::Other,\n+            Span::test_data(),\n+            None,\n+            \"test\",\n+        )))\n     })\n     .expect(\"io error\");\n     let last = iter.last();\ndiff --git a/crates/nu-command/src/formats/from/json.rs b/crates/nu-command/src/formats/from/json.rs\nindex 36a05ea4e1bd1..17a632d949cf0 100644\n--- a/crates/nu-command/src/formats/from/json.rs\n+++ b/crates/nu-command/src/formats/from/json.rs\n@@ -1,7 +1,7 @@\n use std::io::{BufRead, Cursor};\n \n use nu_engine::command_prelude::*;\n-use nu_protocol::{ListStream, Signals};\n+use nu_protocol::{shell_error::io::IoError, ListStream, Signals};\n \n #[derive(Clone)]\n pub struct FromJson;\n@@ -134,7 +134,7 @@ fn read_json_lines(\n         .lines()\n         .filter(|line| line.as_ref().is_ok_and(|line| !line.trim().is_empty()) || line.is_err())\n         .map(move |line| {\n-            let line = line.err_span(span)?;\n+            let line = line.map_err(|err| IoError::new(err.kind(), span, None))?;\n             if strict {\n                 convert_string_to_value_strict(&line, span)\n             } else {\ndiff --git a/crates/nu-command/src/formats/to/delimited.rs b/crates/nu-command/src/formats/to/delimited.rs\nindex ac04739a3ddca..4054935098232 100644\n--- a/crates/nu-command/src/formats/to/delimited.rs\n+++ b/crates/nu-command/src/formats/to/delimited.rs\n@@ -1,16 +1,14 @@\n use csv::WriterBuilder;\n use nu_cmd_base::formats::to::delimited::merge_descriptors;\n use nu_protocol::{\n-    ByteStream, ByteStreamType, Config, PipelineData, ShellError, Signals, Span, Spanned, Value,\n+    shell_error::io::IoError, ByteStream, ByteStreamType, Config, PipelineData, ShellError,\n+    Signals, Span, Spanned, Value,\n };\n use std::{iter, sync::Arc};\n \n fn make_csv_error(error: csv::Error, format_name: &str, head: Span) -> ShellError {\n     if let csv::ErrorKind::Io(error) = error.kind() {\n-        ShellError::IOErrorSpanned {\n-            msg: error.to_string(),\n-            span: head,\n-        }\n+        IoError::new(error.kind(), head, None).into()\n     } else {\n         ShellError::GenericError {\n             error: format!(\"Failed to generate {format_name} data\"),\ndiff --git a/crates/nu-command/src/formats/to/msgpack.rs b/crates/nu-command/src/formats/to/msgpack.rs\nindex f7c4c7df3dce2..ae1d11e542952 100644\n--- a/crates/nu-command/src/formats/to/msgpack.rs\n+++ b/crates/nu-command/src/formats/to/msgpack.rs\n@@ -5,7 +5,7 @@ use std::io;\n \n use byteorder::{BigEndian, WriteBytesExt};\n use nu_engine::command_prelude::*;\n-use nu_protocol::{ast::PathMember, Signals, Spanned};\n+use nu_protocol::{ast::PathMember, shell_error::io::IoError, Signals, Spanned};\n use rmp::encode as mp;\n \n /// Max recursion depth\n@@ -138,7 +138,7 @@ impl From<WriteError> for ShellError {\n                 help: None,\n                 inner: vec![],\n             },\n-            WriteError::Io(err, span) => err.into_spanned(span).into(),\n+            WriteError::Io(err, span) => ShellError::Io(IoError::new(err.kind(), span, None)),\n             WriteError::Shell(err) => *err,\n         }\n     }\ndiff --git a/crates/nu-command/src/formats/to/msgpackz.rs b/crates/nu-command/src/formats/to/msgpackz.rs\nindex e4166b15d3db9..c6d667280f968 100644\n--- a/crates/nu-command/src/formats/to/msgpackz.rs\n+++ b/crates/nu-command/src/formats/to/msgpackz.rs\n@@ -1,6 +1,7 @@\n use std::io::Write;\n \n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n use super::msgpack::write_value;\n \n@@ -80,7 +81,8 @@ impl Command for ToMsgpackz {\n         );\n \n         write_value(&mut out, &value, 0)?;\n-        out.flush().err_span(call.head)?;\n+        out.flush()\n+            .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n         drop(out);\n \n         Ok(Value::binary(out_buf, call.head).into_pipeline_data())\ndiff --git a/crates/nu-command/src/formats/to/text.rs b/crates/nu-command/src/formats/to/text.rs\nindex 2fc3046e4e429..2736fe24e5ed1 100644\n--- a/crates/nu-command/src/formats/to/text.rs\n+++ b/crates/nu-command/src/formats/to/text.rs\n@@ -1,6 +1,8 @@\n use chrono_humanize::HumanTime;\n use nu_engine::command_prelude::*;\n-use nu_protocol::{format_duration, ByteStream, Config, PipelineMetadata};\n+use nu_protocol::{\n+    format_duration, shell_error::io::IoError, ByteStream, Config, PipelineMetadata,\n+};\n use std::io::Write;\n \n const LINE_ENDING: &str = if cfg!(target_os = \"windows\") {\n@@ -72,6 +74,7 @@ impl Command for ToText {\n             }\n             PipelineData::ListStream(stream, meta) => {\n                 let span = stream.span();\n+                let from_io_error = IoError::factory(head, None);\n                 let stream = if no_newline {\n                     let mut first = true;\n                     let mut iter = stream.into_inner();\n@@ -87,7 +90,7 @@ impl Command for ToText {\n                             if first {\n                                 first = false;\n                             } else {\n-                                write!(buf, \"{LINE_ENDING}\").err_span(head)?;\n+                                write!(buf, \"{LINE_ENDING}\").map_err(&from_io_error)?;\n                             }\n                             // TODO: write directly into `buf` instead of creating an intermediate\n                             // string.\n@@ -98,7 +101,7 @@ impl Command for ToText {\n                                 &config,\n                                 serialize_types,\n                             );\n-                            write!(buf, \"{str}\").err_span(head)?;\n+                            write!(buf, \"{str}\").map_err(&from_io_error)?;\n                             Ok(true)\n                         },\n                     )\ndiff --git a/crates/nu-command/src/misc/source.rs b/crates/nu-command/src/misc/source.rs\nindex c1be441bb00b9..de692c557ca34 100644\n--- a/crates/nu-command/src/misc/source.rs\n+++ b/crates/nu-command/src/misc/source.rs\n@@ -1,6 +1,6 @@\n use nu_engine::{command_prelude::*, get_eval_block_with_early_return};\n use nu_path::canonicalize_with;\n-use nu_protocol::{engine::CommandType, BlockId};\n+use nu_protocol::{engine::CommandType, shell_error::io::IoError, BlockId};\n \n /// Source a file for environment variables.\n #[derive(Clone)]\n@@ -55,11 +55,8 @@ impl Command for Source {\n         let cwd = engine_state.cwd_as_string(Some(stack))?;\n         let pb = std::path::PathBuf::from(block_id_name);\n         let parent = pb.parent().unwrap_or(std::path::Path::new(\"\"));\n-        let file_path =\n-            canonicalize_with(pb.as_path(), cwd).map_err(|err| ShellError::FileNotFoundCustom {\n-                msg: format!(\"Could not access file '{}': {err}\", pb.as_path().display()),\n-                span: Span::unknown(),\n-            })?;\n+        let file_path = canonicalize_with(pb.as_path(), cwd)\n+            .map_err(|err| IoError::new(err.kind(), call.head, pb.clone()))?;\n \n         // Note: We intentionally left out PROCESS_PATH since it's supposed to\n         // to work like argv[0] in C, which is the name of the program being executed.\ndiff --git a/crates/nu-command/src/network/http/client.rs b/crates/nu-command/src/network/http/client.rs\nindex a5cad69b2ca4e..28a8bc82073a9 100644\n--- a/crates/nu-command/src/network/http/client.rs\n+++ b/crates/nu-command/src/network/http/client.rs\n@@ -6,10 +6,11 @@ use base64::{\n };\n use multipart_rs::MultipartWriter;\n use nu_engine::command_prelude::*;\n-use nu_protocol::{ByteStream, LabeledError, Signals};\n+use nu_protocol::{shell_error::io::IoError, ByteStream, LabeledError, Signals};\n use serde_json::Value as JsonValue;\n use std::{\n     collections::HashMap,\n+    error::Error as StdError,\n     io::Cursor,\n     path::PathBuf,\n     str::FromStr,\n@@ -184,6 +185,7 @@ pub fn request_add_authorization_header(\n     request\n }\n \n+#[derive(Debug)]\n #[allow(clippy::large_enum_variant)]\n pub enum ShellErrorOrRequestError {\n     ShellError(ShellError),\n@@ -372,10 +374,10 @@ fn send_multipart_request(\n         Value::Record { val, .. } => {\n             let mut builder = MultipartWriter::new();\n \n-            let err = |e| {\n-                ShellErrorOrRequestError::ShellError(ShellError::IOError {\n-                    msg: format!(\"failed to build multipart data: {}\", e),\n-                })\n+            let err = |e: std::io::Error| {\n+                ShellErrorOrRequestError::ShellError(\n+                    IoError::new_with_additional_context(e.kind(), span, None, e).into(),\n+                )\n             };\n \n             for (col, val) in val.into_owned() {\n@@ -464,6 +466,14 @@ fn send_cancellable_request(\n             let ret = request_fn();\n             let _ = tx.send(ret); // may fail if the user has cancelled the operation\n         })\n+        .map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                span,\n+                None,\n+                \"Could not spawn HTTP requester\",\n+            )\n+        })\n         .map_err(ShellError::from)?;\n \n     // ...and poll the channel for responses\n@@ -519,6 +529,14 @@ fn send_cancellable_request_bytes(\n             // may fail if the user has cancelled the operation\n             let _ = tx.send(ret);\n         })\n+        .map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                span,\n+                None,\n+                \"Could not spawn HTTP requester\",\n+            )\n+        })\n         .map_err(ShellError::from)?;\n \n     // ...and poll the channel for responses\n@@ -618,27 +636,56 @@ pub fn request_add_custom_headers(\n \n fn handle_response_error(span: Span, requested_url: &str, response_err: Error) -> ShellError {\n     match response_err {\n-        Error::Status(301, _) => ShellError::NetworkFailure { msg: format!(\"Resource moved permanently (301): {requested_url:?}\"), span },\n-        Error::Status(400, _) => {\n-            ShellError::NetworkFailure { msg: format!(\"Bad request (400) to {requested_url:?}\"), span }\n-        }\n-        Error::Status(403, _) => {\n-            ShellError::NetworkFailure { msg: format!(\"Access forbidden (403) to {requested_url:?}\"), span }\n-        }\n-        Error::Status(404, _) => ShellError::NetworkFailure { msg: format!(\"Requested file not found (404): {requested_url:?}\"), span },\n-        Error::Status(408, _) => {\n-            ShellError::NetworkFailure { msg: format!(\"Request timeout (408): {requested_url:?}\"), span }\n-        }\n-        Error::Status(_, _) => ShellError::NetworkFailure { msg: format!(\n+        Error::Status(301, _) => ShellError::NetworkFailure {\n+            msg: format!(\"Resource moved permanently (301): {requested_url:?}\"),\n+            span,\n+        },\n+        Error::Status(400, _) => ShellError::NetworkFailure {\n+            msg: format!(\"Bad request (400) to {requested_url:?}\"),\n+            span,\n+        },\n+        Error::Status(403, _) => ShellError::NetworkFailure {\n+            msg: format!(\"Access forbidden (403) to {requested_url:?}\"),\n+            span,\n+        },\n+        Error::Status(404, _) => ShellError::NetworkFailure {\n+            msg: format!(\"Requested file not found (404): {requested_url:?}\"),\n+            span,\n+        },\n+        Error::Status(408, _) => ShellError::NetworkFailure {\n+            msg: format!(\"Request timeout (408): {requested_url:?}\"),\n+            span,\n+        },\n+        Error::Status(_, _) => ShellError::NetworkFailure {\n+            msg: format!(\n                 \"Cannot make request to {:?}. Error is {:?}\",\n                 requested_url,\n                 response_err.to_string()\n-            ), span },\n-\n-        Error::Transport(t) => match t {\n-            t if t.kind() == ErrorKind::ConnectionFailed => ShellError::NetworkFailure { msg: format!(\"Cannot make request to {requested_url}, there was an error establishing a connection.\",), span },\n-            t => ShellError::NetworkFailure { msg: t.to_string(), span },\n+            ),\n+            span,\n         },\n+\n+        Error::Transport(t) => {\n+            let generic_network_failure = || ShellError::NetworkFailure {\n+                msg: t.to_string(),\n+                span,\n+            };\n+            match t.kind() {\n+                ErrorKind::ConnectionFailed => ShellError::NetworkFailure { msg: format!(\"Cannot make request to {requested_url}, there was an error establishing a connection.\",), span },\n+                ErrorKind::Io => 'io: {\n+                    let Some(source) = t.source() else {\n+                        break 'io generic_network_failure();\n+                    };\n+\n+                    let Some(io_error) = source.downcast_ref::<std::io::Error>() else {\n+                        break 'io generic_network_failure();\n+                    };\n+\n+                    ShellError::Io(IoError::new(io_error.kind(), span, None))\n+                }\n+                _ => generic_network_failure()\n+            }\n+        }\n     }\n }\n \ndiff --git a/crates/nu-command/src/network/port.rs b/crates/nu-command/src/network/port.rs\nindex eb77ab1d32f23..fe3c987b855de 100644\n--- a/crates/nu-command/src/network/port.rs\n+++ b/crates/nu-command/src/network/port.rs\n@@ -1,4 +1,5 @@\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n use std::net::{Ipv4Addr, SocketAddr, SocketAddrV4, TcpListener};\n \n@@ -61,12 +62,14 @@ fn get_free_port(\n     stack: &mut Stack,\n     call: &Call,\n ) -> Result<PipelineData, ShellError> {\n+    let from_io_error = IoError::factory(call.head, None);\n+\n     let start_port: Option<Spanned<usize>> = call.opt(engine_state, stack, 0)?;\n     let end_port: Option<Spanned<usize>> = call.opt(engine_state, stack, 1)?;\n \n     let listener = if start_port.is_none() && end_port.is_none() {\n         // get free port from system.\n-        TcpListener::bind(\"127.0.0.1:0\")?\n+        TcpListener::bind(\"127.0.0.1:0\").map_err(&from_io_error)?\n     } else {\n         let (start_port, start_span) = match start_port {\n             Some(p) => (p.item, Some(p.span)),\n@@ -118,20 +121,25 @@ fn get_free_port(\n             });\n         }\n \n-        // try given port one by one.\n-        match (start_port..=end_port)\n-            .map(|port| SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::LOCALHOST, port)))\n-            .find_map(|addr| TcpListener::bind(addr).ok())\n-        {\n-            Some(listener) => listener,\n-            None => {\n-                return Err(ShellError::IOError {\n-                    msg: \"Every port has been tried, but no valid one was found\".to_string(),\n-                })\n+        'search: {\n+            let mut last_err = None;\n+            for port in start_port..=end_port {\n+                let addr = SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::LOCALHOST, port));\n+                match TcpListener::bind(addr) {\n+                    Ok(listener) => break 'search Ok(listener),\n+                    Err(err) => last_err = Some(err),\n+                }\n             }\n-        }\n+\n+            Err(IoError::new_with_additional_context(\n+                last_err.expect(\"range not empty, validated before\").kind(),\n+                range_span,\n+                None,\n+                \"Every port has been tried, but no valid one was found\",\n+            ))\n+        }?\n     };\n \n-    let free_port = listener.local_addr()?.port();\n+    let free_port = listener.local_addr().map_err(&from_io_error)?.port();\n     Ok(Value::int(free_port as i64, call.head).into_pipeline_data())\n }\ndiff --git a/crates/nu-command/src/path/exists.rs b/crates/nu-command/src/path/exists.rs\nindex 3e40bef28a69d..0c482a5fe5dbe 100644\n--- a/crates/nu-command/src/path/exists.rs\n+++ b/crates/nu-command/src/path/exists.rs\n@@ -2,7 +2,7 @@ use super::PathSubcommandArguments;\n #[allow(deprecated)]\n use nu_engine::{command_prelude::*, current_dir, current_dir_const};\n use nu_path::expand_path_with;\n-use nu_protocol::engine::StateWorkingSet;\n+use nu_protocol::{engine::StateWorkingSet, shell_error::io::IoError};\n use std::path::{Path, PathBuf};\n \n struct Arguments {\n@@ -140,7 +140,7 @@ fn exists(path: &Path, span: Span, args: &Arguments) -> Value {\n         // symlink_metadata returns true if the file/folder exists\n         // whether it is a symbolic link or not. Sorry, but returns Err\n         // in every other scenario including the NotFound\n-        std::fs::symlink_metadata(path).map_or_else(\n+        std::fs::symlink_metadata(&path).map_or_else(\n             |e| match e.kind() {\n                 std::io::ErrorKind::NotFound => Ok(false),\n                 _ => Err(e),\n@@ -153,15 +153,7 @@ fn exists(path: &Path, span: Span, args: &Arguments) -> Value {\n     Value::bool(\n         match exists {\n             Ok(exists) => exists,\n-            Err(err) => {\n-                return Value::error(\n-                    ShellError::IOErrorSpanned {\n-                        msg: err.to_string(),\n-                        span,\n-                    },\n-                    span,\n-                )\n-            }\n+            Err(err) => return Value::error(IoError::new(err.kind(), span, path).into(), span),\n         },\n         span,\n     )\ndiff --git a/crates/nu-command/src/path/self_.rs b/crates/nu-command/src/path/self_.rs\nindex 242fbea7a8706..49c1de8624a51 100644\n--- a/crates/nu-command/src/path/self_.rs\n+++ b/crates/nu-command/src/path/self_.rs\n@@ -1,6 +1,6 @@\n use nu_engine::command_prelude::*;\n use nu_path::expand_path_with;\n-use nu_protocol::engine::StateWorkingSet;\n+use nu_protocol::{engine::StateWorkingSet, shell_error::io::IoError};\n \n #[derive(Clone)]\n pub struct SubCommand;\n@@ -54,23 +54,25 @@ impl Command for SubCommand {\n     ) -> Result<PipelineData, ShellError> {\n         let path: Option<String> = call.opt_const(working_set, 0)?;\n         let cwd = working_set.permanent_state.cwd(None)?;\n-        let current_file =\n-            working_set\n-                .files\n-                .top()\n-                .ok_or_else(|| ShellError::FileNotFoundCustom {\n-                    msg: \"Couldn't find current file\".into(),\n-                    span: call.head,\n-                })?;\n+        let current_file = working_set.files.top().ok_or_else(|| {\n+            IoError::new_with_additional_context(\n+                std::io::ErrorKind::NotFound,\n+                call.head,\n+                None,\n+                \"Couldn't find current file\",\n+            )\n+        })?;\n \n         let out = if let Some(path) = path {\n             let dir = expand_path_with(\n-                current_file\n-                    .parent()\n-                    .ok_or_else(|| ShellError::FileNotFoundCustom {\n-                        msg: \"Couldn't find current file's parent.\".into(),\n-                        span: call.head,\n-                    })?,\n+                current_file.parent().ok_or_else(|| {\n+                    IoError::new_with_additional_context(\n+                        std::io::ErrorKind::NotFound,\n+                        call.head,\n+                        current_file.to_owned(),\n+                        \"Couldn't find current file's parent.\",\n+                    )\n+                })?,\n                 &cwd,\n                 true,\n             );\ndiff --git a/crates/nu-command/src/path/type.rs b/crates/nu-command/src/path/type.rs\nindex 81cdaf8cfe4a6..6abed1319acc4 100644\n--- a/crates/nu-command/src/path/type.rs\n+++ b/crates/nu-command/src/path/type.rs\n@@ -1,7 +1,7 @@\n use super::PathSubcommandArguments;\n use nu_engine::command_prelude::*;\n use nu_path::AbsolutePathBuf;\n-use nu_protocol::engine::StateWorkingSet;\n+use nu_protocol::{engine::StateWorkingSet, shell_error::io::IoError};\n use std::{io, path::Path};\n \n struct Arguments {\n@@ -108,7 +108,7 @@ fn path_type(path: &Path, span: Span, args: &Arguments) -> Value {\n     match path.symlink_metadata() {\n         Ok(metadata) => Value::string(get_file_type(&metadata), span),\n         Err(err) if err.kind() == io::ErrorKind::NotFound => Value::nothing(span),\n-        Err(err) => Value::error(err.into_spanned(span).into(), span),\n+        Err(err) => Value::error(IoError::new(err.kind(), span, None).into(), span),\n     }\n }\n \ndiff --git a/crates/nu-command/src/platform/clear.rs b/crates/nu-command/src/platform/clear.rs\nindex 21e3a3054c127..38bb659df61ce 100644\n--- a/crates/nu-command/src/platform/clear.rs\n+++ b/crates/nu-command/src/platform/clear.rs\n@@ -4,6 +4,7 @@ use crossterm::{\n     QueueableCommand,\n };\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n use std::io::Write;\n \n@@ -41,19 +42,27 @@ impl Command for Clear {\n         call: &Call,\n         _input: PipelineData,\n     ) -> Result<PipelineData, ShellError> {\n+        let from_io_error = IoError::factory(call.head, None);\n         match call.has_flag(engine_state, stack, \"keep-scrollback\")? {\n             true => {\n                 std::io::stdout()\n-                    .queue(MoveTo(0, 0))?\n-                    .queue(ClearCommand(ClearType::All))?\n-                    .flush()?;\n+                    .queue(MoveTo(0, 0))\n+                    .map_err(&from_io_error)?\n+                    .queue(ClearCommand(ClearType::All))\n+                    .map_err(&from_io_error)?\n+                    .flush()\n+                    .map_err(&from_io_error)?;\n             }\n             _ => {\n                 std::io::stdout()\n-                    .queue(MoveTo(0, 0))?\n-                    .queue(ClearCommand(ClearType::All))?\n-                    .queue(ClearCommand(ClearType::Purge))?\n-                    .flush()?;\n+                    .queue(MoveTo(0, 0))\n+                    .map_err(&from_io_error)?\n+                    .queue(ClearCommand(ClearType::All))\n+                    .map_err(&from_io_error)?\n+                    .queue(ClearCommand(ClearType::Purge))\n+                    .map_err(&from_io_error)?\n+                    .flush()\n+                    .map_err(&from_io_error)?;\n             }\n         };\n \ndiff --git a/crates/nu-command/src/platform/dir_info.rs b/crates/nu-command/src/platform/dir_info.rs\nindex 9b8ea1929e51e..d96e43403b37b 100644\n--- a/crates/nu-command/src/platform/dir_info.rs\n+++ b/crates/nu-command/src/platform/dir_info.rs\n@@ -1,6 +1,6 @@\n use filesize::file_real_size_fast;\n use nu_glob::Pattern;\n-use nu_protocol::{record, ShellError, Signals, Span, Value};\n+use nu_protocol::{record, shell_error::io::IoError, ShellError, Signals, Span, Value};\n use std::path::PathBuf;\n \n #[derive(Debug, Clone)]\n@@ -77,7 +77,7 @@ impl FileInfo {\n                     long,\n                 })\n             }\n-            Err(e) => Err(e.into()),\n+            Err(e) => Err(IoError::new(e.kind(), tag, path).into()),\n         }\n     }\n }\n@@ -91,6 +91,7 @@ impl DirInfo {\n         signals: &Signals,\n     ) -> Result<Self, ShellError> {\n         let path = path.into();\n+        let from_io_error = IoError::factory(span, path.as_path());\n \n         let mut s = Self {\n             dirs: Vec::new(),\n@@ -99,7 +100,7 @@ impl DirInfo {\n             size: 0,\n             blocks: 0,\n             tag: params.tag,\n-            path,\n+            path: path.clone(),\n             long: params.long,\n         };\n \n@@ -108,7 +109,7 @@ impl DirInfo {\n                 s.size = d.len(); // dir entry size\n                 s.blocks = file_real_size_fast(&s.path, &d).ok().unwrap_or(0);\n             }\n-            Err(e) => s = s.add_error(e.into()),\n+            Err(e) => s = s.add_error(from_io_error(e).into()),\n         };\n \n         match std::fs::read_dir(&s.path) {\n@@ -122,13 +123,13 @@ impl DirInfo {\n                                 s = s.add_dir(i.path(), depth, params, span, signals)?\n                             }\n                             Ok(_t) => s = s.add_file(i.path(), params),\n-                            Err(e) => s = s.add_error(e.into()),\n+                            Err(e) => s = s.add_error(from_io_error(e).into()),\n                         },\n-                        Err(e) => s = s.add_error(e.into()),\n+                        Err(e) => s = s.add_error(from_io_error(e).into()),\n                     }\n                 }\n             }\n-            Err(e) => s = s.add_error(e.into()),\n+            Err(e) => s = s.add_error(from_io_error(e).into()),\n         }\n         Ok(s)\n     }\ndiff --git a/crates/nu-command/src/platform/input/input_.rs b/crates/nu-command/src/platform/input/input_.rs\nindex f792db992e025..5e088098d223e 100644\n--- a/crates/nu-command/src/platform/input/input_.rs\n+++ b/crates/nu-command/src/platform/input/input_.rs\n@@ -7,6 +7,7 @@ use crossterm::{\n };\n use itertools::Itertools;\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n use std::{io::Write, time::Duration};\n \n@@ -69,6 +70,8 @@ impl Command for Input {\n             span: call.head,\n         });\n \n+        let from_io_error = IoError::factory(call.head, None);\n+\n         if numchar.item < 1 {\n             return Err(ShellError::UnsupportedInput {\n                 msg: \"Number of characters to read has to be positive\".to_string(),\n@@ -89,11 +92,11 @@ impl Command for Input {\n \n         let mut buf = String::new();\n \n-        crossterm::terminal::enable_raw_mode()?;\n+        crossterm::terminal::enable_raw_mode().map_err(&from_io_error)?;\n         // clear terminal events\n-        while crossterm::event::poll(Duration::from_secs(0))? {\n+        while crossterm::event::poll(Duration::from_secs(0)).map_err(&from_io_error)? {\n             // If there's an event, read it to remove it from the queue\n-            let _ = crossterm::event::read()?;\n+            let _ = crossterm::event::read().map_err(&from_io_error)?;\n         }\n \n         loop {\n@@ -110,10 +113,14 @@ impl Command for Input {\n                                     || k.modifiers == KeyModifiers::CONTROL\n                                 {\n                                     if k.modifiers == KeyModifiers::CONTROL && c == 'c' {\n-                                        crossterm::terminal::disable_raw_mode()?;\n-                                        return Err(ShellError::IOError {\n-                                            msg: \"SIGINT\".to_string(),\n-                                        });\n+                                        crossterm::terminal::disable_raw_mode()\n+                                            .map_err(&from_io_error)?;\n+                                        return Err(IoError::new(\n+                                            std::io::ErrorKind::Interrupted,\n+                                            call.head,\n+                                            None,\n+                                        )\n+                                        .into());\n                                     }\n                                     continue;\n                                 }\n@@ -138,8 +145,8 @@ impl Command for Input {\n                 },\n                 Ok(_) => continue,\n                 Err(event_error) => {\n-                    crossterm::terminal::disable_raw_mode()?;\n-                    return Err(event_error.into());\n+                    crossterm::terminal::disable_raw_mode().map_err(&from_io_error)?;\n+                    return Err(from_io_error(event_error).into());\n                 }\n             }\n             if !suppress_output {\n@@ -148,16 +155,18 @@ impl Command for Input {\n                     std::io::stdout(),\n                     terminal::Clear(ClearType::CurrentLine),\n                     cursor::MoveToColumn(0),\n-                )?;\n+                )\n+                .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n                 if let Some(prompt) = &prompt {\n-                    execute!(std::io::stdout(), Print(prompt.to_string()))?;\n+                    execute!(std::io::stdout(), Print(prompt.to_string()))\n+                        .map_err(&from_io_error)?;\n                 }\n-                execute!(std::io::stdout(), Print(buf.to_string()))?;\n+                execute!(std::io::stdout(), Print(buf.to_string())).map_err(&from_io_error)?;\n             }\n         }\n-        crossterm::terminal::disable_raw_mode()?;\n+        crossterm::terminal::disable_raw_mode().map_err(&from_io_error)?;\n         if !suppress_output {\n-            std::io::stdout().write_all(b\"\\n\")?;\n+            std::io::stdout().write_all(b\"\\n\").map_err(&from_io_error)?;\n         }\n         match default_val {\n             Some(val) if buf.is_empty() => Ok(Value::string(val, call.head).into_pipeline_data()),\ndiff --git a/crates/nu-command/src/platform/input/input_listen.rs b/crates/nu-command/src/platform/input/input_listen.rs\nindex 69e96e19667ca..56241d6689608 100644\n--- a/crates/nu-command/src/platform/input/input_listen.rs\n+++ b/crates/nu-command/src/platform/input/input_listen.rs\n@@ -5,6 +5,7 @@ use crossterm::event::{\n use crossterm::{execute, terminal};\n use nu_engine::command_prelude::*;\n \n+use nu_protocol::shell_error::io::IoError;\n use num_traits::AsPrimitive;\n use std::io::stdout;\n \n@@ -83,7 +84,7 @@ There are 4 `key_type` variants:\n         let add_raw = call.has_flag(engine_state, stack, \"raw\")?;\n         let config = engine_state.get_config();\n \n-        terminal::enable_raw_mode()?;\n+        terminal::enable_raw_mode().map_err(|err| IoError::new(err.kind(), head, None))?;\n \n         if config.use_kitty_protocol {\n             if let Ok(false) = crossterm::terminal::supports_keyboard_enhancement() {\n@@ -111,7 +112,7 @@ There are 4 `key_type` variants:\n             );\n         }\n \n-        let console_state = event_type_filter.enable_events()?;\n+        let console_state = event_type_filter.enable_events(head)?;\n         loop {\n             let event = crossterm::event::read().map_err(|_| ShellError::GenericError {\n                 error: \"Error with user input\".into(),\n@@ -122,7 +123,7 @@ There are 4 `key_type` variants:\n             })?;\n             let event = parse_event(head, &event, &event_type_filter, add_raw);\n             if let Some(event) = event {\n-                terminal::disable_raw_mode()?;\n+                terminal::disable_raw_mode().map_err(|err| IoError::new(err.kind(), head, None))?;\n                 if config.use_kitty_protocol {\n                     let _ = execute!(\n                         std::io::stdout(),\n@@ -226,17 +227,20 @@ impl EventTypeFilter {\n     /// Enable capturing of all events allowed by this filter.\n     /// Call [`DeferredConsoleRestore::restore`] when done capturing events to restore\n     /// console state\n-    fn enable_events(&self) -> Result<DeferredConsoleRestore, ShellError> {\n+    fn enable_events(&self, span: Span) -> Result<DeferredConsoleRestore, ShellError> {\n         if self.listen_mouse {\n-            crossterm::execute!(stdout(), EnableMouseCapture)?;\n+            crossterm::execute!(stdout(), EnableMouseCapture)\n+                .map_err(|err| IoError::new(err.kind(), span, None))?;\n         }\n \n         if self.listen_paste {\n-            crossterm::execute!(stdout(), EnableBracketedPaste)?;\n+            crossterm::execute!(stdout(), EnableBracketedPaste)\n+                .map_err(|err| IoError::new(err.kind(), span, None))?;\n         }\n \n         if self.listen_focus {\n-            crossterm::execute!(stdout(), crossterm::event::EnableFocusChange)?;\n+            crossterm::execute!(stdout(), crossterm::event::EnableFocusChange)\n+                .map_err(|err| IoError::new(err.kind(), span, None))?;\n         }\n \n         Ok(DeferredConsoleRestore {\ndiff --git a/crates/nu-command/src/platform/input/list.rs b/crates/nu-command/src/platform/input/list.rs\nindex 7d9761f29647c..91a31aebd8a70 100644\n--- a/crates/nu-command/src/platform/input/list.rs\n+++ b/crates/nu-command/src/platform/input/list.rs\n@@ -1,5 +1,6 @@\n use dialoguer::{console::Term, FuzzySelect, MultiSelect, Select};\n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n use std::fmt::{Display, Formatter};\n \n@@ -141,8 +142,13 @@ impl Command for InputList {\n                 .items(&options)\n                 .report(false)\n                 .interact_on_opt(&Term::stderr())\n-                .map_err(|err| ShellError::IOError {\n-                    msg: format!(\"{}: {}\", INTERACT_ERROR, err),\n+                .map_err(|dialoguer::Error::IO(err)| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        call.head,\n+                        None,\n+                        INTERACT_ERROR,\n+                    )\n                 })?,\n             )\n         } else if fuzzy {\n@@ -158,8 +164,13 @@ impl Command for InputList {\n                 .default(0)\n                 .report(false)\n                 .interact_on_opt(&Term::stderr())\n-                .map_err(|err| ShellError::IOError {\n-                    msg: format!(\"{}: {}\", INTERACT_ERROR, err),\n+                .map_err(|dialoguer::Error::IO(err)| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        call.head,\n+                        None,\n+                        INTERACT_ERROR,\n+                    )\n                 })?,\n             )\n         } else {\n@@ -174,8 +185,13 @@ impl Command for InputList {\n                 .default(0)\n                 .report(false)\n                 .interact_on_opt(&Term::stderr())\n-                .map_err(|err| ShellError::IOError {\n-                    msg: format!(\"{}: {}\", INTERACT_ERROR, err),\n+                .map_err(|dialoguer::Error::IO(err)| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        call.head,\n+                        None,\n+                        INTERACT_ERROR,\n+                    )\n                 })?,\n             )\n         };\ndiff --git a/crates/nu-command/src/platform/term/term_query.rs b/crates/nu-command/src/platform/term/term_query.rs\nindex 2cb11f1dc3544..167f660c22704 100644\n--- a/crates/nu-command/src/platform/term/term_query.rs\n+++ b/crates/nu-command/src/platform/term/term_query.rs\n@@ -4,6 +4,7 @@ use std::{\n };\n \n use nu_engine::command_prelude::*;\n+use nu_protocol::shell_error::io::IoError;\n \n const CTRL_C: u8 = 3;\n \n@@ -98,15 +99,19 @@ The `prefix` is not included in the output.\"\n         let prefix = prefix.unwrap_or_default();\n         let terminator: Option<Vec<u8>> = call.get_flag(engine_state, stack, \"terminator\")?;\n \n-        crossterm::terminal::enable_raw_mode()?;\n+        crossterm::terminal::enable_raw_mode()\n+            .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n         scopeguard::defer! {\n             let _ = crossterm::terminal::disable_raw_mode();\n         }\n \n         // clear terminal events\n-        while crossterm::event::poll(Duration::from_secs(0))? {\n+        while crossterm::event::poll(Duration::from_secs(0))\n+            .map_err(|err| IoError::new(err.kind(), call.head, None))?\n+        {\n             // If there's an event, read it to remove it from the queue\n-            let _ = crossterm::event::read()?;\n+            let _ = crossterm::event::read()\n+                .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n         }\n \n         let mut b = [0u8; 1];\n@@ -115,13 +120,19 @@ The `prefix` is not included in the output.\"\n \n         {\n             let mut stdout = std::io::stdout().lock();\n-            stdout.write_all(&query)?;\n-            stdout.flush()?;\n+            stdout\n+                .write_all(&query)\n+                .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n+            stdout\n+                .flush()\n+                .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n         }\n \n         // Validate and skip prefix\n         for bc in prefix {\n-            stdin.read_exact(&mut b)?;\n+            stdin\n+                .read_exact(&mut b)\n+                .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n             if b[0] != bc {\n                 return Err(ShellError::GenericError {\n                     error: \"Input did not begin with expected sequence\".into(),\n@@ -138,7 +149,9 @@ The `prefix` is not included in the output.\"\n \n         if let Some(terminator) = terminator {\n             loop {\n-                stdin.read_exact(&mut b)?;\n+                stdin\n+                    .read_exact(&mut b)\n+                    .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n \n                 if b[0] == CTRL_C {\n                     return Err(ShellError::InterruptedByUser {\n@@ -158,7 +171,9 @@ The `prefix` is not included in the output.\"\n             }\n         } else {\n             loop {\n-                stdin.read_exact(&mut b)?;\n+                stdin\n+                    .read_exact(&mut b)\n+                    .map_err(|err| IoError::new(err.kind(), call.head, None))?;\n \n                 if b[0] == CTRL_C {\n                     break;\ndiff --git a/crates/nu-command/src/strings/str_/join.rs b/crates/nu-command/src/strings/str_/join.rs\nindex e40ffb9417e39..e500da8343efa 100644\n--- a/crates/nu-command/src/strings/str_/join.rs\n+++ b/crates/nu-command/src/strings/str_/join.rs\n@@ -1,5 +1,5 @@\n use nu_engine::command_prelude::*;\n-use nu_protocol::Signals;\n+use nu_protocol::{shell_error::io::IoError, Signals};\n \n use std::io::Write;\n \n@@ -94,13 +94,15 @@ fn run(\n         Signals::empty(),\n         ByteStreamType::String,\n         move |buffer| {\n+            let from_io_error = IoError::factory(span, None);\n+\n             // Write each input to the buffer\n             if let Some(value) = iter.next() {\n                 // Write the separator if this is not the first\n                 if first {\n                     first = false;\n                 } else if let Some(separator) = &separator {\n-                    write!(buffer, \"{}\", separator)?;\n+                    write!(buffer, \"{}\", separator).map_err(&from_io_error)?;\n                 }\n \n                 match value {\n@@ -109,8 +111,9 @@ fn run(\n                     }\n                     // Hmm, not sure what we actually want.\n                     // `to_expanded_string` formats dates as human readable which feels funny.\n-                    Value::Date { val, .. } => write!(buffer, \"{val:?}\")?,\n-                    value => write!(buffer, \"{}\", value.to_expanded_string(\"\\n\", &config))?,\n+                    Value::Date { val, .. } => write!(buffer, \"{val:?}\").map_err(&from_io_error)?,\n+                    value => write!(buffer, \"{}\", value.to_expanded_string(\"\\n\", &config))\n+                        .map_err(&from_io_error)?,\n                 }\n                 Ok(true)\n             } else {\ndiff --git a/crates/nu-command/src/system/nu_check.rs b/crates/nu-command/src/system/nu_check.rs\nindex ff3047a4905ad..ca0d09965a0d2 100644\n--- a/crates/nu-command/src/system/nu_check.rs\n+++ b/crates/nu-command/src/system/nu_check.rs\n@@ -1,7 +1,10 @@\n use nu_engine::{command_prelude::*, find_in_dirs_env, get_dirs_var_from_call};\n use nu_parser::{parse, parse_module_block, parse_module_file_or_dir, unescape_unquote_string};\n-use nu_protocol::engine::{FileStack, StateWorkingSet};\n-use std::path::Path;\n+use nu_protocol::{\n+    engine::{FileStack, StateWorkingSet},\n+    shell_error::io::IoError,\n+};\n+use std::path::{Path, PathBuf};\n \n #[derive(Clone)]\n pub struct NuCheck;\n@@ -89,17 +92,15 @@ impl Command for NuCheck {\n                         stack,\n                         get_dirs_var_from_call(stack, call),\n                     ) {\n-                        Ok(path) => {\n-                            if let Some(path) = path {\n-                                path\n-                            } else {\n-                                return Err(ShellError::FileNotFound {\n-                                    file: path_str.item,\n-                                    span: path_span,\n-                                });\n-                            }\n+                        Ok(Some(path)) => path,\n+                        Ok(None) => {\n+                            return Err(ShellError::Io(IoError::new(\n+                                std::io::ErrorKind::NotFound,\n+                                path_span,\n+                                PathBuf::from(path_str.item),\n+                            )))\n                         }\n-                        Err(error) => return Err(error),\n+                        Err(err) => return Err(err),\n                     };\n \n                     let result = if as_module || path.is_dir() {\n@@ -258,13 +259,13 @@ fn parse_file_script(\n ) -> Result<PipelineData, ShellError> {\n     let filename = check_path(working_set, path_span, call_head)?;\n \n-    if let Ok(contents) = std::fs::read(path) {\n-        parse_script(working_set, Some(&filename), &contents, is_debug, call_head)\n-    } else {\n-        Err(ShellError::IOErrorSpanned {\n-            msg: \"Could not read path\".to_string(),\n-            span: path_span,\n-        })\n+    match std::fs::read(path) {\n+        Ok(contents) => parse_script(working_set, Some(&filename), &contents, is_debug, call_head),\n+        Err(err) => Err(ShellError::Io(IoError::new(\n+            err.kind(),\n+            path_span,\n+            PathBuf::from(path),\n+        ))),\n     }\n }\n \ndiff --git a/crates/nu-command/src/system/registry_query.rs b/crates/nu-command/src/system/registry_query.rs\nindex 3365a7d44009f..cadb3aac29ebd 100644\n--- a/crates/nu-command/src/system/registry_query.rs\n+++ b/crates/nu-command/src/system/registry_query.rs\n@@ -1,5 +1,6 @@\n use nu_engine::command_prelude::*;\n \n+use nu_protocol::shell_error::io::IoError;\n use windows::{core::PCWSTR, Win32::System::Environment::ExpandEnvironmentStringsW};\n use winreg::{enums::*, types::FromRegValue, RegKey};\n \n@@ -90,7 +91,9 @@ fn registry_query(\n     let registry_value: Option<Spanned<String>> = call.opt(engine_state, stack, 1)?;\n \n     let reg_hive = get_reg_hive(engine_state, stack, call)?;\n-    let reg_key = reg_hive.open_subkey(registry_key.item)?;\n+    let reg_key = reg_hive\n+        .open_subkey(registry_key.item)\n+        .map_err(|err| IoError::new(err.kind(), *registry_key_span, None))?;\n \n     if registry_value.is_none() {\n         let mut reg_values = vec![];\ndiff --git a/crates/nu-command/src/system/run_external.rs b/crates/nu-command/src/system/run_external.rs\nindex b917577ba9e53..70e423387a939 100644\n--- a/crates/nu-command/src/system/run_external.rs\n+++ b/crates/nu-command/src/system/run_external.rs\n@@ -2,7 +2,8 @@ use nu_cmd_base::hook::eval_hook;\n use nu_engine::{command_prelude::*, env_to_strings};\n use nu_path::{dots::expand_ndots_safe, expand_tilde, AbsolutePath};\n use nu_protocol::{\n-    did_you_mean, process::ChildProcess, ByteStream, NuGlob, OutDest, Signals, UseAnsiColoring,\n+    did_you_mean, process::ChildProcess, shell_error::io::IoError, ByteStream, NuGlob, OutDest,\n+    Signals, UseAnsiColoring,\n };\n use nu_system::ForegroundChild;\n use nu_utils::IgnoreCaseExt;\n@@ -169,7 +170,9 @@ impl Command for External {\n \n             // canonicalize the path to the script so that tests pass\n             let canon_path = if let Ok(cwd) = engine_state.cwd_as_string(None) {\n-                canonicalize_with(&expanded_name, cwd)?\n+                canonicalize_with(&expanded_name, cwd).map_err(|err| {\n+                    IoError::new(err.kind(), call.head, PathBuf::from(&expanded_name))\n+                })?\n             } else {\n                 // If we can't get the current working directory, just provide the expanded name\n                 expanded_name\n@@ -191,13 +194,22 @@ impl Command for External {\n         let stdout = stack.stdout();\n         let stderr = stack.stderr();\n         let merged_stream = if matches!(stdout, OutDest::Pipe) && matches!(stderr, OutDest::Pipe) {\n-            let (reader, writer) = os_pipe::pipe()?;\n-            command.stdout(writer.try_clone()?);\n+            let (reader, writer) =\n+                os_pipe::pipe().map_err(|err| IoError::new(err.kind(), call.head, None))?;\n+            command.stdout(\n+                writer\n+                    .try_clone()\n+                    .map_err(|err| IoError::new(err.kind(), call.head, None))?,\n+            );\n             command.stderr(writer);\n             Some(reader)\n         } else {\n-            command.stdout(Stdio::try_from(stdout)?);\n-            command.stderr(Stdio::try_from(stderr)?);\n+            command.stdout(\n+                Stdio::try_from(stdout).map_err(|err| IoError::new(err.kind(), call.head, None))?,\n+            );\n+            command.stderr(\n+                Stdio::try_from(stderr).map_err(|err| IoError::new(err.kind(), call.head, None))?,\n+            );\n             None\n         };\n \n@@ -231,13 +243,22 @@ impl Command for External {\n         // Spawn the child process. On Unix, also put the child process to\n         // foreground if we're in an interactive session.\n         #[cfg(windows)]\n-        let mut child = ForegroundChild::spawn(command)?;\n+        let child = ForegroundChild::spawn(command);\n         #[cfg(unix)]\n-        let mut child = ForegroundChild::spawn(\n+        let child = ForegroundChild::spawn(\n             command,\n             engine_state.is_interactive,\n             &engine_state.pipeline_externals_state,\n-        )?;\n+        );\n+\n+        let mut child = child.map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                None,\n+                \"Could not spawn foreground child\",\n+            )\n+        })?;\n \n         // If we need to copy data into the child process, do it now.\n         if let Some(data) = data_to_copy_into_stdin {\n@@ -249,7 +270,14 @@ impl Command for External {\n                 .spawn(move || {\n                     let _ = write_pipeline_data(engine_state, stack, data, stdin);\n                 })\n-                .err_span(call.head)?;\n+                .map_err(|err| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        call.head,\n+                        None,\n+                        \"Could not spawn external stdin worker\",\n+                    )\n+                })?;\n         }\n \n         // Wrap the output into a `PipelineData::ByteStream`.\n@@ -414,7 +442,14 @@ fn write_pipeline_data(\n     if let PipelineData::ByteStream(stream, ..) = data {\n         stream.write_to(writer)?;\n     } else if let PipelineData::Value(Value::Binary { val, .. }, ..) = data {\n-        writer.write_all(&val)?;\n+        writer.write_all(&val).map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                None,\n+                \"Could not write pipeline data\",\n+            )\n+        })?;\n     } else {\n         stack.start_collect_value();\n \n@@ -428,7 +463,14 @@ fn write_pipeline_data(\n         // Write the output.\n         for value in output {\n             let bytes = value.coerce_into_binary()?;\n-            writer.write_all(&bytes)?;\n+            writer.write_all(&bytes).map_err(|err| {\n+                IoError::new_with_additional_context(\n+                    err.kind(),\n+                    Span::unknown(),\n+                    None,\n+                    \"Could not write pipeline data\",\n+                )\n+            })?;\n         }\n     }\n     Ok(())\ndiff --git a/crates/nu-command/src/viewers/table.rs b/crates/nu-command/src/viewers/table.rs\nindex bac035f94a7c2..147555558ec77 100644\n--- a/crates/nu-command/src/viewers/table.rs\n+++ b/crates/nu-command/src/viewers/table.rs\n@@ -13,7 +13,8 @@ use nu_engine::{command_prelude::*, env_to_string};\n use nu_path::form::Absolute;\n use nu_pretty_hex::HexConfig;\n use nu_protocol::{\n-    ByteStream, Config, DataSource, ListStream, PipelineMetadata, Signals, TableMode, ValueIterator,\n+    shell_error::io::IoError, ByteStream, Config, DataSource, ListStream, PipelineMetadata,\n+    Signals, TableMode, ValueIterator,\n };\n use nu_table::{\n     common::configure_table, CollapsedTable, ExpandedTable, JustTable, NuRecordsValue, NuTable,\n@@ -518,7 +519,7 @@ fn pretty_hex_stream(stream: ByteStream, span: Span) -> ByteStream {\n                 (&mut reader)\n                     .take(cfg.width as u64)\n                     .read_to_end(&mut read_buf)\n-                    .err_span(span)?;\n+                    .map_err(|err| IoError::new(err.kind(), span, None))?;\n \n                 if !read_buf.is_empty() {\n                     nu_pretty_hex::hex_write(&mut write_buf, &read_buf, cfg, Some(true))\ndiff --git a/crates/nu-engine/src/command_prelude.rs b/crates/nu-engine/src/command_prelude.rs\nindex 0c5c250a27182..9b9ed40477294 100644\n--- a/crates/nu-engine/src/command_prelude.rs\n+++ b/crates/nu-engine/src/command_prelude.rs\n@@ -2,7 +2,9 @@ pub use crate::CallExt;\n pub use nu_protocol::{\n     ast::CellPath,\n     engine::{Call, Command, EngineState, Stack, StateWorkingSet},\n-    record, ByteStream, ByteStreamType, Category, ErrSpan, Example, IntoInterruptiblePipelineData,\n+    record,\n+    shell_error::io::IoError,\n+    ByteStream, ByteStreamType, Category, ErrSpan, Example, IntoInterruptiblePipelineData,\n     IntoPipelineData, IntoSpanned, IntoValue, PipelineData, Record, ShellError, Signature, Span,\n     Spanned, SyntaxShape, Type, Value,\n };\ndiff --git a/crates/nu-engine/src/env.rs b/crates/nu-engine/src/env.rs\nindex 345d81d6f78cb..0242d0b6b0683 100644\n--- a/crates/nu-engine/src/env.rs\n+++ b/crates/nu-engine/src/env.rs\n@@ -3,6 +3,7 @@ use nu_path::canonicalize_with;\n use nu_protocol::{\n     ast::Expr,\n     engine::{Call, EngineState, Stack, StateWorkingSet},\n+    shell_error::io::IoError,\n     ShellError, Span, Type, Value, VarId,\n };\n use std::{\n@@ -218,9 +219,12 @@ pub fn current_dir(engine_state: &EngineState, stack: &Stack) -> Result<PathBuf,\n     // We're using `canonicalize_with` instead of `fs::canonicalize()` because\n     // we still need to simplify Windows paths. \".\" is safe because `cwd` should\n     // be an absolute path already.\n-    canonicalize_with(&cwd, \".\").map_err(|_| ShellError::DirectoryNotFound {\n-        dir: cwd.to_string_lossy().to_string(),\n-        span: Span::unknown(),\n+    canonicalize_with(&cwd, \".\").map_err(|err| {\n+        ShellError::Io(IoError::new(\n+            err.kind(),\n+            Span::unknown(),\n+            PathBuf::from(cwd),\n+        ))\n     })\n }\n \n@@ -234,9 +238,12 @@ pub fn current_dir_const(working_set: &StateWorkingSet) -> Result<PathBuf, Shell\n     // We're using `canonicalize_with` instead of `fs::canonicalize()` because\n     // we still need to simplify Windows paths. \".\" is safe because `cwd` should\n     // be an absolute path already.\n-    canonicalize_with(&cwd, \".\").map_err(|_| ShellError::DirectoryNotFound {\n-        dir: cwd.to_string_lossy().to_string(),\n-        span: Span::unknown(),\n+    canonicalize_with(&cwd, \".\").map_err(|err| {\n+        ShellError::Io(IoError::new(\n+            err.kind(),\n+            Span::unknown(),\n+            PathBuf::from(cwd),\n+        ))\n     })\n }\n \ndiff --git a/crates/nu-engine/src/eval_ir.rs b/crates/nu-engine/src/eval_ir.rs\nindex 20672484faad1..035f6a394d79a 100644\n--- a/crates/nu-engine/src/eval_ir.rs\n+++ b/crates/nu-engine/src/eval_ir.rs\n@@ -8,9 +8,10 @@ use nu_protocol::{\n         Argument, Closure, EngineState, ErrorHandler, Matcher, Redirection, Stack, StateWorkingSet,\n     },\n     ir::{Call, DataSlice, Instruction, IrAstRef, IrBlock, Literal, RedirectMode},\n-    DataSource, DeclId, ErrSpan, Flag, IntoPipelineData, IntoSpanned, ListStream, OutDest,\n-    PipelineData, PipelineMetadata, PositionalArg, Range, Record, RegId, ShellError, Signals,\n-    Signature, Span, Spanned, Type, Value, VarId, ENV_VARIABLE_ID,\n+    shell_error::io::IoError,\n+    DataSource, DeclId, Flag, IntoPipelineData, IntoSpanned, ListStream, OutDest, PipelineData,\n+    PipelineMetadata, PositionalArg, Range, Record, RegId, ShellError, Signals, Signature, Span,\n+    Spanned, Type, Value, VarId, ENV_VARIABLE_ID,\n };\n use nu_utils::IgnoreCaseExt;\n \n@@ -1489,8 +1490,8 @@ fn open_file(ctx: &EvalContext<'_>, path: &Value, append: bool) -> Result<Arc<Fi\n     }\n     let file = options\n         .create(true)\n-        .open(path_expanded)\n-        .err_span(path.span())?;\n+        .open(&path_expanded)\n+        .map_err(|err| IoError::new(err.kind(), path.span(), path_expanded))?;\n     Ok(Arc::new(file))\n }\n \ndiff --git a/crates/nu-engine/src/glob_from.rs b/crates/nu-engine/src/glob_from.rs\nindex 3765ab7c7b025..1120499b43ed8 100644\n--- a/crates/nu-engine/src/glob_from.rs\n+++ b/crates/nu-engine/src/glob_from.rs\n@@ -1,9 +1,8 @@\n use nu_glob::MatchOptions;\n use nu_path::{canonicalize_with, expand_path_with};\n-use nu_protocol::{NuGlob, ShellError, Span, Spanned};\n+use nu_protocol::{shell_error::io::IoError, NuGlob, ShellError, Span, Spanned};\n use std::{\n     fs,\n-    io::ErrorKind,\n     path::{Component, Path, PathBuf},\n };\n \n@@ -28,6 +27,7 @@ pub fn glob_from(\n     ShellError,\n > {\n     let no_glob_for_pattern = matches!(pattern.item, NuGlob::DoNotExpand(_));\n+    let pattern_span = pattern.span;\n     let (prefix, pattern) = if nu_glob::is_glob(pattern.item.as_ref()) {\n         // Pattern contains glob, split it\n         let mut p = PathBuf::new();\n@@ -80,22 +80,7 @@ pub fn glob_from(\n                 }\n                 Ok(p) => p,\n                 Err(err) => {\n-                    return match err.kind() {\n-                        ErrorKind::PermissionDenied => Err(ShellError::GenericError {\n-                            error: \"Permission denied\".into(),\n-                            msg: err.to_string(),\n-                            span: None,\n-                            help: None,\n-                            inner: vec![],\n-                        }),\n-                        // Previously, all these errors were treated as \"directory not found.\"\n-                        // Now, permission denied errors are handled separately.\n-                        // TODO: Refine handling of I/O errors for more precise responses.\n-                        _ => Err(ShellError::DirectoryNotFound {\n-                            dir: path.to_string_lossy().to_string(),\n-                            span: pattern.span,\n-                        }),\n-                    };\n+                    return Err(IoError::new(err.kind(), pattern_span, path).into());\n                 }\n             };\n             (path.parent().map(|parent| parent.to_path_buf()), path)\ndiff --git a/crates/nu-explore/src/nu_common/command.rs b/crates/nu-explore/src/nu_common/command.rs\nindex ef0157ac6756e..a41e7cf45b0a7 100644\n--- a/crates/nu-explore/src/nu_common/command.rs\n+++ b/crates/nu-explore/src/nu_common/command.rs\n@@ -14,16 +14,24 @@ pub fn run_command_with_value(\n     stack: &mut Stack,\n ) -> Result<PipelineData, ShellError> {\n     if is_ignored_command(command) {\n-        return Err(ShellError::IOError {\n-            msg: String::from(\"the command is ignored\"),\n+        return Err(ShellError::GenericError {\n+            error: \"Command ignored\".to_string(),\n+            msg: \"the command is ignored\".to_string(),\n+            span: None,\n+            help: None,\n+            inner: vec![],\n         });\n     }\n \n     let pipeline = PipelineData::Value(input.clone(), None);\n     let pipeline = run_nu_command(engine_state, stack, command, pipeline)?;\n     if let PipelineData::Value(Value::Error { error, .. }, ..) = pipeline {\n-        Err(ShellError::IOError {\n+        Err(ShellError::GenericError {\n+            error: \"Error from pipeline\".to_string(),\n             msg: error.to_string(),\n+            span: None,\n+            help: None,\n+            inner: vec![*error],\n         })\n     } else {\n         Ok(pipeline)\n@@ -69,8 +77,12 @@ fn eval_source2(\n         );\n \n         if let Some(err) = working_set.parse_errors.first() {\n-            return Err(ShellError::IOError {\n+            return Err(ShellError::GenericError {\n+                error: \"Parse error\".to_string(),\n                 msg: err.to_string(),\n+                span: None,\n+                help: None,\n+                inner: vec![],\n             });\n         }\n \n@@ -79,8 +91,12 @@ fn eval_source2(\n \n     // We need to merge different info other wise things like PIPEs etc will not work.\n     if let Err(err) = engine_state.merge_delta(delta) {\n-        return Err(ShellError::IOError {\n+        return Err(ShellError::GenericError {\n+            error: \"Merge error\".to_string(),\n             msg: err.to_string(),\n+            span: None,\n+            help: None,\n+            inner: vec![err],\n         });\n     }\n \ndiff --git a/crates/nu-plugin-core/src/communication_mode/mod.rs b/crates/nu-plugin-core/src/communication_mode/mod.rs\nindex 576cfe866cce8..19d89363bd8d6 100644\n--- a/crates/nu-plugin-core/src/communication_mode/mod.rs\n+++ b/crates/nu-plugin-core/src/communication_mode/mod.rs\n@@ -2,7 +2,8 @@ use std::ffi::OsStr;\n use std::io::{Stdin, Stdout};\n use std::process::{Child, ChildStdin, ChildStdout, Command, Stdio};\n \n-use nu_protocol::ShellError;\n+use nu_protocol::shell_error::io::IoError;\n+use nu_protocol::{ShellError, Span};\n \n #[cfg(feature = \"local-socket\")]\n mod local_socket;\n@@ -84,8 +85,15 @@ impl CommunicationMode {\n \n                 let listener = interpret_local_socket_name(name)\n                     .and_then(|name| ListenerOptions::new().name(name).create_sync())\n-                    .map_err(|err| ShellError::IOError {\n-                        msg: format!(\"failed to open socket for plugin: {err}\"),\n+                    .map_err(|err| {\n+                        IoError::new_internal(\n+                            err.kind(),\n+                            format!(\n+                                \"Could not interpret local socket name {:?}\",\n+                                name.to_string_lossy()\n+                            ),\n+                            nu_protocol::location!(),\n+                        )\n                     })?;\n                 Ok(PreparedServerCommunication::LocalSocket { listener })\n             }\n@@ -107,8 +115,15 @@ impl CommunicationMode {\n \n                     interpret_local_socket_name(name)\n                         .and_then(|name| ls::Stream::connect(name))\n-                        .map_err(|err| ShellError::IOError {\n-                            msg: format!(\"failed to connect to socket: {err}\"),\n+                        .map_err(|err| {\n+                            ShellError::Io(IoError::new_internal(\n+                                err.kind(),\n+                                format!(\n+                                    \"Could not interpret local socket name {:?}\",\n+                                    name.to_string_lossy()\n+                                ),\n+                                nu_protocol::location!(),\n+                            ))\n                         })\n                 };\n                 // Reverse order from the server: read in, write out\n@@ -171,7 +186,16 @@ impl PreparedServerCommunication {\n                 // output) and one for write (the plugin input)\n                 //\n                 // Be non-blocking on Accept only, so we can timeout.\n-                listener.set_nonblocking(ListenerNonblockingMode::Accept)?;\n+                listener\n+                    .set_nonblocking(ListenerNonblockingMode::Accept)\n+                    .map_err(|err| {\n+                        IoError::new_with_additional_context(\n+                            err.kind(),\n+                            Span::unknown(),\n+                            None,\n+                            \"Could not set non-blocking mode accept for listener\",\n+                        )\n+                    })?;\n                 let mut get_socket = || {\n                     let mut result = None;\n                     while let Ok(None) = child.try_wait() {\n@@ -179,7 +203,14 @@ impl PreparedServerCommunication {\n                             Ok(stream) => {\n                                 // Success! Ensure the stream is in nonblocking mode though, for\n                                 // good measure. Had an issue without this on macOS.\n-                                stream.set_nonblocking(false)?;\n+                                stream.set_nonblocking(false).map_err(|err| {\n+                                    IoError::new_with_additional_context(\n+                                        err.kind(),\n+                                        Span::unknown(),\n+                                        None,\n+                                        \"Could not disable non-blocking mode for listener\",\n+                                    )\n+                                })?;\n                                 result = Some(stream);\n                                 break;\n                             }\n@@ -187,7 +218,11 @@ impl PreparedServerCommunication {\n                                 if !is_would_block_err(&err) {\n                                     // `WouldBlock` is ok, just means it's not ready yet, but some other\n                                     // kind of error should be reported\n-                                    return Err(err.into());\n+                                    return Err(ShellError::Io(IoError::new(\n+                                        err.kind(),\n+                                        Span::unknown(),\n+                                        None,\n+                                    )));\n                                 }\n                             }\n                         }\ndiff --git a/crates/nu-plugin-core/src/interface/mod.rs b/crates/nu-plugin-core/src/interface/mod.rs\nindex de04bd638763c..01f91b7c1c8d8 100644\n--- a/crates/nu-plugin-core/src/interface/mod.rs\n+++ b/crates/nu-plugin-core/src/interface/mod.rs\n@@ -2,8 +2,8 @@\n \n use nu_plugin_protocol::{ByteStreamInfo, ListStreamInfo, PipelineDataHeader, StreamMessage};\n use nu_protocol::{\n-    engine::Sequence, ByteStream, IntoSpanned, ListStream, PipelineData, Reader, ShellError,\n-    Signals,\n+    engine::Sequence, shell_error::io::IoError, ByteStream, ListStream, PipelineData, Reader,\n+    ShellError, Signals, Span,\n };\n use std::{\n     io::{Read, Write},\n@@ -80,8 +80,12 @@ where\n     }\n \n     fn flush(&self) -> Result<(), ShellError> {\n-        self.0.lock().flush().map_err(|err| ShellError::IOError {\n-            msg: err.to_string(),\n+        self.0.lock().flush().map_err(|err| {\n+            ShellError::Io(IoError::new_internal(\n+                err.kind(),\n+                \"PluginWrite could not flush\",\n+                nu_protocol::location!(),\n+            ))\n         })\n     }\n \n@@ -106,8 +110,12 @@ where\n         let mut lock = self.0.lock().map_err(|_| ShellError::NushellFailed {\n             msg: \"writer mutex poisoned\".into(),\n         })?;\n-        lock.flush().map_err(|err| ShellError::IOError {\n-            msg: err.to_string(),\n+        lock.flush().map_err(|err| {\n+            ShellError::Io(IoError::new_internal(\n+                err.kind(),\n+                \"PluginWrite could not flush\",\n+                nu_protocol::location!(),\n+            ))\n         })\n     }\n }\n@@ -332,7 +340,7 @@ where\n                 writer.write_all(std::iter::from_fn(move || match reader.read(buf) {\n                     Ok(0) => None,\n                     Ok(len) => Some(Ok(buf[..len].to_vec())),\n-                    Err(err) => Some(Err(ShellError::from(err.into_spanned(span)))),\n+                    Err(err) => Some(Err(ShellError::from(IoError::new(err.kind(), span, None)))),\n                 }))?;\n                 Ok(())\n             }\n@@ -357,6 +365,14 @@ where\n                             log::warn!(\"Error while writing pipeline in background: {err}\");\n                         }\n                         result\n+                    })\n+                    .map_err(|err| {\n+                        IoError::new_with_additional_context(\n+                            err.kind(),\n+                            Span::unknown(),\n+                            None,\n+                            \"Could not spawn plugin stream background writer\",\n+                        )\n                     })?,\n             )),\n         }\ndiff --git a/crates/nu-plugin-core/src/serializers/json.rs b/crates/nu-plugin-core/src/serializers/json.rs\nindex 7dc868b806e9d..8dfadac2d023a 100644\n--- a/crates/nu-plugin-core/src/serializers/json.rs\n+++ b/crates/nu-plugin-core/src/serializers/json.rs\n@@ -1,5 +1,5 @@\n use nu_plugin_protocol::{PluginInput, PluginOutput};\n-use nu_protocol::ShellError;\n+use nu_protocol::{location, shell_error::io::IoError, ShellError};\n use serde::Deserialize;\n \n use crate::{Encoder, PluginEncoder};\n@@ -26,8 +26,12 @@ impl Encoder<PluginInput> for JsonSerializer {\n         writer: &mut impl std::io::Write,\n     ) -> Result<(), nu_protocol::ShellError> {\n         serde_json::to_writer(&mut *writer, plugin_input).map_err(json_encode_err)?;\n-        writer.write_all(b\"\\n\").map_err(|err| ShellError::IOError {\n-            msg: err.to_string(),\n+        writer.write_all(b\"\\n\").map_err(|err| {\n+            ShellError::Io(IoError::new_internal(\n+                err.kind(),\n+                \"Failed to write final line break\",\n+                location!(),\n+            ))\n         })\n     }\n \n@@ -49,8 +53,12 @@ impl Encoder<PluginOutput> for JsonSerializer {\n         writer: &mut impl std::io::Write,\n     ) -> Result<(), ShellError> {\n         serde_json::to_writer(&mut *writer, plugin_output).map_err(json_encode_err)?;\n-        writer.write_all(b\"\\n\").map_err(|err| ShellError::IOError {\n-            msg: err.to_string(),\n+        writer.write_all(b\"\\n\").map_err(|err| {\n+            ShellError::Io(IoError::new_internal(\n+                err.kind(),\n+                \"JsonSerializer could not encode linebreak\",\n+                nu_protocol::location!(),\n+            ))\n         })\n     }\n \n@@ -68,9 +76,11 @@ impl Encoder<PluginOutput> for JsonSerializer {\n /// Handle a `serde_json` encode error.\n fn json_encode_err(err: serde_json::Error) -> ShellError {\n     if err.is_io() {\n-        ShellError::IOError {\n-            msg: err.to_string(),\n-        }\n+        ShellError::Io(IoError::new_internal(\n+            err.io_error_kind().expect(\"is io\"),\n+            \"Could not encode with json\",\n+            nu_protocol::location!(),\n+        ))\n     } else {\n         ShellError::PluginFailedToEncode {\n             msg: err.to_string(),\n@@ -83,9 +93,11 @@ fn json_decode_err<T>(err: serde_json::Error) -> Result<Option<T>, ShellError> {\n     if err.is_eof() {\n         Ok(None)\n     } else if err.is_io() {\n-        Err(ShellError::IOError {\n-            msg: err.to_string(),\n-        })\n+        Err(ShellError::Io(IoError::new_internal(\n+            err.io_error_kind().expect(\"is io\"),\n+            \"Could not decode with json\",\n+            nu_protocol::location!(),\n+        )))\n     } else {\n         Err(ShellError::PluginFailedToDecode {\n             msg: err.to_string(),\ndiff --git a/crates/nu-plugin-core/src/serializers/msgpack.rs b/crates/nu-plugin-core/src/serializers/msgpack.rs\nindex bf136fd79069c..372511631c915 100644\n--- a/crates/nu-plugin-core/src/serializers/msgpack.rs\n+++ b/crates/nu-plugin-core/src/serializers/msgpack.rs\n@@ -1,7 +1,7 @@\n use std::io::ErrorKind;\n \n use nu_plugin_protocol::{PluginInput, PluginOutput};\n-use nu_protocol::ShellError;\n+use nu_protocol::{shell_error::io::IoError, ShellError};\n use serde::Deserialize;\n \n use crate::{Encoder, PluginEncoder};\n@@ -64,9 +64,12 @@ fn rmp_encode_err(err: rmp_serde::encode::Error) -> ShellError {\n     match err {\n         rmp_serde::encode::Error::InvalidValueWrite(_) => {\n             // I/O error\n-            ShellError::IOError {\n-                msg: err.to_string(),\n-            }\n+            ShellError::Io(IoError::new_internal(\n+                // TODO: get a better kind here\n+                std::io::ErrorKind::Other,\n+                \"Could not encode with rmp\",\n+                nu_protocol::location!(),\n+            ))\n         }\n         _ => {\n             // Something else\n@@ -87,9 +90,12 @@ fn rmp_decode_err<T>(err: rmp_serde::decode::Error) -> Result<Option<T>, ShellEr\n                 Ok(None)\n             } else {\n                 // I/O error\n-                Err(ShellError::IOError {\n-                    msg: err.to_string(),\n-                })\n+                Err(ShellError::Io(IoError::new_internal(\n+                    // TODO: get a better kind here\n+                    std::io::ErrorKind::Other,\n+                    \"Could not decode with rmp\",\n+                    nu_protocol::location!(),\n+                )))\n             }\n         }\n         _ => {\ndiff --git a/crates/nu-plugin-engine/src/interface/mod.rs b/crates/nu-plugin-engine/src/interface/mod.rs\nindex 93d75d0ec9fa5..9eebe6aaed244 100644\n--- a/crates/nu-plugin-engine/src/interface/mod.rs\n+++ b/crates/nu-plugin-engine/src/interface/mod.rs\n@@ -381,8 +381,13 @@ impl PluginInterfaceManager {\n                 // don't block\n                 this.state.writer.write(&PluginInput::EngineCallResponse(\n                     engine_call_id,\n-                    EngineCallResponse::Error(ShellError::IOError {\n-                        msg: \"Can't make engine call because the original caller hung up\".into(),\n+                    EngineCallResponse::Error(ShellError::GenericError {\n+                        error: \"Caller hung up\".to_string(),\n+                        msg: \"Can't make engine call because the original caller hung up\"\n+                            .to_string(),\n+                        span: None,\n+                        help: None,\n+                        inner: vec![],\n                     }),\n                 ))?;\n                 this.state.writer.flush()\ndiff --git a/crates/nu-plugin-engine/src/persistent.rs b/crates/nu-plugin-engine/src/persistent.rs\nindex e664b37f87140..8d444a4d1c365 100644\n--- a/crates/nu-plugin-engine/src/persistent.rs\n+++ b/crates/nu-plugin-engine/src/persistent.rs\n@@ -7,8 +7,9 @@ use super::{PluginInterface, PluginSource};\n use nu_plugin_core::CommunicationMode;\n use nu_protocol::{\n     engine::{EngineState, Stack},\n+    shell_error::io::IoError,\n     HandlerGuard, Handlers, PluginGcConfig, PluginIdentity, PluginMetadata, RegisteredPlugin,\n-    ShellError,\n+    ShellError, Span,\n };\n use std::{\n     collections::HashMap,\n@@ -184,7 +185,14 @@ impl PersistentPlugin {\n         })?;\n \n         // Start the plugin garbage collector\n-        let gc = PluginGc::new(mutable.gc_config.clone(), &self)?;\n+        let gc = PluginGc::new(mutable.gc_config.clone(), &self).map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                None,\n+                \"Could not start plugin gc\",\n+            )\n+        })?;\n \n         let pid = child.id();\n         let interface = make_plugin_interface(\ndiff --git a/crates/nu-plugin/src/plugin/interface/mod.rs b/crates/nu-plugin/src/plugin/interface/mod.rs\nindex be7b2e0dfc028..c3052448b1250 100644\n--- a/crates/nu-plugin/src/plugin/interface/mod.rs\n+++ b/crates/nu-plugin/src/plugin/interface/mod.rs\n@@ -1046,8 +1046,12 @@ impl ForegroundGuard {\n             {\n                 use nix::unistd::{setpgid, Pid};\n                 // This should always succeed, frankly, but handle the error just in case\n-                setpgid(Pid::from_raw(0), Pid::from_raw(0)).map_err(|err| ShellError::IOError {\n-                    msg: err.to_string(),\n+                setpgid(Pid::from_raw(0), Pid::from_raw(0)).map_err(|err| {\n+                    nu_protocol::shell_error::io::IoError::new_internal(\n+                        std::io::Error::from(err).kind(),\n+                        \"Could not set pgid\",\n+                        nu_protocol::location!(),\n+                    )\n                 })?;\n             }\n             interface.leave_foreground()?;\ndiff --git a/crates/nu-plugin/src/plugin/mod.rs b/crates/nu-plugin/src/plugin/mod.rs\nindex c5af681f5eae0..d01a0e260038c 100644\n--- a/crates/nu-plugin/src/plugin/mod.rs\n+++ b/crates/nu-plugin/src/plugin/mod.rs\n@@ -387,7 +387,7 @@ pub enum ServePluginError {\n impl From<ShellError> for ServePluginError {\n     fn from(error: ShellError) -> Self {\n         match error {\n-            ShellError::IOError { .. } => ServePluginError::IOError(error),\n+            ShellError::Io(_) => ServePluginError::IOError(error),\n             ShellError::PluginFailedToLoad { .. } => ServePluginError::Incompatible(error),\n             _ => ServePluginError::UnreportedError(error),\n         }\ndiff --git a/crates/nu-protocol/src/engine/engine_state.rs b/crates/nu-protocol/src/engine/engine_state.rs\nindex 8270e4111a787..dbded4eb6322c 100644\n--- a/crates/nu-protocol/src/engine/engine_state.rs\n+++ b/crates/nu-protocol/src/engine/engine_state.rs\n@@ -7,6 +7,7 @@ use crate::{\n         Variable, Visibility, DEFAULT_OVERLAY_NAME,\n     },\n     eval_const::create_nu_constant,\n+    shell_error::io::IoError,\n     BlockId, Category, Config, DeclId, FileId, GetSpan, Handlers, HistoryConfig, Module, ModuleId,\n     OverlayId, ShellError, SignalAction, Signals, Signature, Span, SpanId, Type, Value, VarId,\n     VirtualPathId,\n@@ -322,8 +323,14 @@ impl EngineState {\n         }\n \n         let cwd = self.cwd(Some(stack))?;\n-        // TODO: better error\n-        std::env::set_current_dir(cwd)?;\n+        std::env::set_current_dir(cwd).map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                None,\n+                \"Could not set current dir\",\n+            )\n+        })?;\n \n         if let Some(config) = stack.config.take() {\n             // If config was updated in the stack, replace it.\n@@ -514,13 +521,12 @@ impl EngineState {\n                 if err.kind() == std::io::ErrorKind::NotFound {\n                     Ok(PluginRegistryFile::default())\n                 } else {\n-                    Err(ShellError::GenericError {\n-                        error: \"Failed to open plugin file\".into(),\n-                        msg: \"\".into(),\n-                        span: None,\n-                        help: None,\n-                        inner: vec![err.into()],\n-                    })\n+                    Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n+                        Span::unknown(),\n+                        PathBuf::from(plugin_path),\n+                        \"Failed to open plugin file\",\n+                    )))\n                 }\n             }\n         }?;\n@@ -531,14 +537,14 @@ impl EngineState {\n         }\n \n         // Write it to the same path\n-        let plugin_file =\n-            File::create(plugin_path.as_path()).map_err(|err| ShellError::GenericError {\n-                error: \"Failed to write plugin file\".into(),\n-                msg: \"\".into(),\n-                span: None,\n-                help: None,\n-                inner: vec![err.into()],\n-            })?;\n+        let plugin_file = File::create(plugin_path.as_path()).map_err(|err| {\n+            IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                PathBuf::from(plugin_path),\n+                \"Failed to write plugin file\",\n+            )\n+        })?;\n \n         contents.write_to(plugin_file, None)\n     }\ndiff --git a/crates/nu-protocol/src/errors/labeled_error.rs b/crates/nu-protocol/src/errors/labeled_error.rs\nindex cdd990463b88e..7104a1a8b1a1b 100644\n--- a/crates/nu-protocol/src/errors/labeled_error.rs\n+++ b/crates/nu-protocol/src/errors/labeled_error.rs\n@@ -143,8 +143,16 @@ impl LabeledError {\n     /// [`ShellError`] implements `miette::Diagnostic`:\n     ///\n     /// ```rust\n-    /// # use nu_protocol::{ShellError, LabeledError};\n-    /// let error = LabeledError::from_diagnostic(&ShellError::IOError { msg: \"error\".into() });\n+    /// # use nu_protocol::{ShellError, LabeledError, shell_error::io::IoError, Span};\n+    /// #\n+    /// let error = LabeledError::from_diagnostic(\n+    ///     &ShellError::Io(IoError::new_with_additional_context(\n+    ///         std::io::ErrorKind::Other,\n+    ///         Span::test_data(),\n+    ///         None,\n+    ///         \"some error\"\n+    ///     ))\n+    /// );\n     /// assert!(error.to_string().contains(\"I/O error\"));\n     /// ```\n     pub fn from_diagnostic(diag: &(impl miette::Diagnostic + ?Sized)) -> LabeledError {\ndiff --git a/crates/nu-protocol/src/errors/mod.rs b/crates/nu-protocol/src/errors/mod.rs\nindex 2e264066a9e73..5f385a21ee0c6 100644\n--- a/crates/nu-protocol/src/errors/mod.rs\n+++ b/crates/nu-protocol/src/errors/mod.rs\n@@ -4,7 +4,7 @@ mod config_error;\n mod labeled_error;\n mod parse_error;\n mod parse_warning;\n-mod shell_error;\n+pub mod shell_error;\n \n pub use cli_error::{\n     format_shell_error, report_parse_error, report_parse_warning, report_shell_error,\n@@ -15,4 +15,4 @@ pub use config_error::ConfigError;\n pub use labeled_error::{ErrorLabel, LabeledError};\n pub use parse_error::{DidYouMean, ParseError};\n pub use parse_warning::ParseWarning;\n-pub use shell_error::*;\n+pub use shell_error::ShellError;\ndiff --git a/crates/nu-protocol/src/errors/shell_error/bridge.rs b/crates/nu-protocol/src/errors/shell_error/bridge.rs\nnew file mode 100644\nindex 0000000000000..eff8ba17e4a14\n--- /dev/null\n+++ b/crates/nu-protocol/src/errors/shell_error/bridge.rs\n@@ -0,0 +1,47 @@\n+use super::ShellError;\n+use serde::{Deserialize, Serialize};\n+use thiserror::Error;\n+\n+/// A bridge for transferring a [`ShellError`] between Nushell or similar processes.\n+///\n+/// This newtype encapsulates a [`ShellError`] to facilitate its transfer between Nushell processes\n+/// or processes with similar behavior.\n+/// By defining this type, we eliminate ambiguity about what is being transferred and avoid the\n+/// need to implement [`From<io::Error>`](From) and [`Into<io::Error>`](Into) directly on\n+/// `ShellError`.\n+#[derive(Debug, Clone, PartialEq, Error, Serialize, Deserialize)]\n+#[error(\"{0}\")]\n+pub struct ShellErrorBridge(pub ShellError);\n+\n+impl TryFrom<std::io::Error> for ShellErrorBridge {\n+    type Error = std::io::Error;\n+\n+    fn try_from(value: std::io::Error) -> Result<Self, Self::Error> {\n+        let kind = value.kind();\n+        value\n+            .downcast()\n+            .inspect(|_| debug_assert_eq!(kind, std::io::ErrorKind::Other))\n+    }\n+}\n+\n+impl From<ShellErrorBridge> for std::io::Error {\n+    fn from(value: ShellErrorBridge) -> Self {\n+        std::io::Error::other(value)\n+    }\n+}\n+\n+#[test]\n+fn test_bridge_io_error_roundtrip() {\n+    let shell_error = ShellError::GenericError {\n+        error: \"some error\".into(),\n+        msg: \"some message\".into(),\n+        span: None,\n+        help: None,\n+        inner: vec![],\n+    };\n+\n+    let bridge = ShellErrorBridge(shell_error);\n+    let io_error = std::io::Error::from(bridge.clone());\n+    let bridge_again = ShellErrorBridge::try_from(io_error).unwrap();\n+    assert_eq!(bridge.0, bridge_again.0);\n+}\ndiff --git a/crates/nu-protocol/src/errors/shell_error/io.rs b/crates/nu-protocol/src/errors/shell_error/io.rs\nnew file mode 100644\nindex 0000000000000..87eaabc74d2d8\n--- /dev/null\n+++ b/crates/nu-protocol/src/errors/shell_error/io.rs\n@@ -0,0 +1,418 @@\n+use miette::{Diagnostic, LabeledSpan, SourceSpan};\n+use std::{\n+    fmt::Display,\n+    path::{Path, PathBuf},\n+};\n+use thiserror::Error;\n+\n+use crate::Span;\n+\n+use super::{location::Location, ShellError};\n+\n+/// Represents an I/O error in the [`ShellError::Io`] variant.\n+///\n+/// This is the central I/O error for the [`ShellError::Io`] variant.\n+/// It represents all I/O errors by encapsulating [`ErrorKind`], an extension of\n+/// [`std::io::ErrorKind`].\n+/// The `span` indicates where the error occurred in user-provided code.\n+/// If the error is not tied to user-provided code, the `location` refers to the precise point in\n+/// the Rust code where the error originated.\n+/// The optional `path` provides the file or directory involved in the error.\n+/// If [`ErrorKind`] alone doesn't provide enough detail, additional context can be added to clarify\n+/// the issue.\n+///\n+/// For handling user input errors (e.g., commands), prefer using [`new`](Self::new).\n+/// Alternatively, use the [`factory`](Self::factory) method to simplify error creation in repeated\n+/// contexts.\n+/// For internal errors, use [`new_internal`](Self::new_internal) to include the location in Rust\n+/// code where the error originated.\n+///\n+/// # Examples\n+///\n+/// ## User Input Error\n+/// ```rust\n+/// # use nu_protocol::shell_error::io::{IoError, ErrorKind};\n+/// # use nu_protocol::Span;\n+/// use std::path::PathBuf;\n+///\n+/// # let span = Span::test_data();\n+/// let path = PathBuf::from(\"/some/missing/file\");\n+/// let error = IoError::new(\n+///     std::io::ErrorKind::NotFound,\n+///     span,\n+///     path\n+/// );\n+/// println!(\"Error: {:?}\", error);\n+/// ```\n+///\n+/// ## Internal Error\n+/// ```rust\n+/// # use nu_protocol::shell_error::io::{IoError, ErrorKind};\n+//  #\n+/// let error = IoError::new_internal(\n+///     std::io::ErrorKind::UnexpectedEof,\n+///     \"Failed to read data from buffer\",\n+///     nu_protocol::location!()\n+/// );\n+/// println!(\"Error: {:?}\", error);\n+/// ```\n+///\n+/// ## Using the Factory Method\n+/// ```rust\n+/// # use nu_protocol::shell_error::io::{IoError, ErrorKind};\n+/// # use nu_protocol::{Span, ShellError};\n+/// use std::path::PathBuf;\n+///\n+/// # fn should_return_err() -> Result<(), ShellError> {\n+/// # let span = Span::new(50, 60);\n+/// let path = PathBuf::from(\"/some/file\");\n+/// let from_io_error = IoError::factory(span, Some(path.as_path()));\n+///\n+/// let content = std::fs::read_to_string(&path).map_err(from_io_error)?;\n+/// # Ok(())\n+/// # }\n+/// #\n+/// # assert!(should_return_err().is_err());\n+/// ```\n+///\n+/// # ShellErrorBridge\n+///\n+/// The [`ShellErrorBridge`](super::bridge::ShellErrorBridge) struct is used to contain a\n+/// [`ShellError`] inside a [`std::io::Error`].\n+/// This allows seamless transfer of `ShellError` instances where `std::io::Error` is expected.\n+/// When a `ShellError` needs to be packed into an I/O context, use this bridge.\n+/// Similarly, when handling an I/O error that is expected to contain a `ShellError`,\n+/// use the bridge to unpack it.\n+///\n+/// This approach ensures clarity about where such container transfers occur.\n+/// All other I/O errors should be handled using the provided constructors for `IoError`.\n+/// This way, the code explicitly indicates when and where a `ShellError` transfer might happen.\n+#[derive(Debug, Clone, Error, PartialEq)]\n+#[non_exhaustive]\n+#[error(\"I/O error\")]\n+pub struct IoError {\n+    /// The type of the underlying I/O error.\n+    ///\n+    /// [`std::io::ErrorKind`] provides detailed context about the type of I/O error that occurred\n+    /// and is part of [`std::io::Error`].\n+    /// If a kind cannot be represented by it, consider adding a new variant to [`ErrorKind`].\n+    ///\n+    /// Only in very rare cases should [`std::io::ErrorKind::Other`] be used, make sure you provide\n+    /// `additional_context` to get useful errors in these cases.\n+    pub kind: ErrorKind,\n+\n+    /// The source location of the error.\n+    pub span: Span,\n+\n+    /// The path related to the I/O error, if applicable.\n+    ///\n+    /// Many I/O errors involve a file or directory path, but operating system error messages\n+    /// often don't include the specific path.\n+    /// Setting this to [`Some`] allows users to see which path caused the error.\n+    pub path: Option<PathBuf>,\n+\n+    /// Additional details to provide more context about the error.\n+    ///\n+    /// Only set this field if it adds meaningful context.\n+    /// If [`ErrorKind`] already contains all the necessary information, leave this as [`None`].\n+    pub additional_context: Option<String>,\n+\n+    /// The precise location in the Rust code where the error originated.\n+    ///\n+    /// This field is particularly useful for debugging errors that stem from the Rust\n+    /// implementation rather than user-provided Nushell code.\n+    /// The original [`Location`] is converted to a string to more easily report the error\n+    /// attributing the location.\n+    ///\n+    /// This value is only used if `span` is [`Span::unknown()`] as most of the time we want to\n+    /// refer to user code than the Rust code.\n+    pub location: Option<String>,\n+}\n+\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, Diagnostic)]\n+pub enum ErrorKind {\n+    Std(std::io::ErrorKind),\n+    // TODO: in Rust 1.83 this can be std::io::ErrorKind::NotADirectory\n+    NotADirectory,\n+    NotAFile,\n+    // TODO: in Rust 1.83 this can be std::io::ErrorKind::IsADirectory\n+    IsADirectory,\n+}\n+\n+impl IoError {\n+    /// Creates a new [`IoError`] with the given kind, span, and optional path.\n+    ///\n+    /// This constructor should be used in all cases where the combination of the error kind, span,\n+    /// and path provides enough information to describe the error clearly.\n+    /// For example, errors like \"File not found\" or \"Permission denied\" are typically\n+    /// self-explanatory when paired with the file path and the location in user-provided\n+    /// Nushell code (`span`).\n+    ///\n+    /// # Constraints\n+    /// If `span` is unknown, use:\n+    /// - `new_internal` if no path is available.\n+    /// - `new_internal_with_path` if a path is available.\n+    pub fn new(kind: impl Into<ErrorKind>, span: Span, path: impl Into<Option<PathBuf>>) -> Self {\n+        let path = path.into();\n+\n+        if span == Span::unknown() {\n+            debug_assert!(\n+                path.is_some(),\n+                \"for unknown spans with paths, use `new_internal_with_path`\"\n+            );\n+            debug_assert!(\n+                path.is_none(),\n+                \"for unknown spans without paths, use `new_internal`\"\n+            );\n+        }\n+\n+        Self {\n+            kind: kind.into(),\n+            span,\n+            path,\n+            additional_context: None,\n+            location: None,\n+        }\n+    }\n+\n+    /// Creates a new [`IoError`] with additional context.\n+    ///\n+    /// Use this constructor when the error kind, span, and path are not sufficient to fully\n+    /// explain the error, and additional context can provide meaningful details.\n+    /// Avoid redundant context (e.g., \"Permission denied\" for an error kind of\n+    /// [`ErrorKind::PermissionDenied`](std::io::ErrorKind::PermissionDenied)).\n+    ///\n+    /// # Constraints\n+    /// If `span` is unknown, use:\n+    /// - `new_internal` if no path is available.\n+    /// - `new_internal_with_path` if a path is available.\n+    pub fn new_with_additional_context(\n+        kind: impl Into<ErrorKind>,\n+        span: Span,\n+        path: impl Into<Option<PathBuf>>,\n+        additional_context: impl ToString,\n+    ) -> Self {\n+        let path = path.into();\n+\n+        if span == Span::unknown() {\n+            debug_assert!(\n+                path.is_some(),\n+                \"for unknown spans with paths, use `new_internal_with_path`\"\n+            );\n+            debug_assert!(\n+                path.is_none(),\n+                \"for unknown spans without paths, use `new_internal`\"\n+            );\n+        }\n+\n+        Self {\n+            kind: kind.into(),\n+            span,\n+            path,\n+            additional_context: Some(additional_context.to_string()),\n+            location: None,\n+        }\n+    }\n+\n+    /// Creates a new [`IoError`] for internal I/O errors without a user-provided span or path.\n+    ///\n+    /// This constructor is intended for internal errors in the Rust implementation that still need\n+    /// to be reported to the end user.\n+    /// Since these errors are not tied to user-provided Nushell code, they generally have no\n+    /// meaningful span or path.\n+    ///\n+    /// Instead, these errors provide:\n+    /// - `additional_context`:\n+    ///   Details about what went wrong internally.\n+    /// - `location`:\n+    ///   The location in the Rust code where the error occurred, allowing us to trace and debug\n+    ///   the issue.\n+    ///   Use the [`nu_protocol::location!`](crate::location) macro to generate the location\n+    ///   information.\n+    ///\n+    /// # Examples\n+    /// ```rust\n+    /// use nu_protocol::shell_error::io::IoError;\n+    ///\n+    /// let error = IoError::new_internal(\n+    ///     std::io::ErrorKind::UnexpectedEof,\n+    ///     \"Failed to read from buffer\",\n+    ///     nu_protocol::location!(),\n+    /// );\n+    /// ```\n+    pub fn new_internal(\n+        kind: impl Into<ErrorKind>,\n+        additional_context: impl ToString,\n+        location: Location,\n+    ) -> Self {\n+        Self {\n+            kind: kind.into(),\n+            span: Span::unknown(),\n+            path: None,\n+            additional_context: Some(additional_context.to_string()),\n+            location: Some(location.to_string()),\n+        }\n+    }\n+\n+    /// Creates a new `IoError` for internal I/O errors with a specific path.\n+    ///\n+    /// This constructor is similar to [`new_internal`] but also includes a file or directory\n+    /// path relevant to the error. Use this function in rare cases where an internal error\n+    /// involves a specific path, and the combination of path and additional context is helpful.\n+    ///\n+    /// # Examples\n+    /// ```rust\n+    /// use std::path::PathBuf;\n+    /// use nu_protocol::shell_error::io::IoError;\n+    ///\n+    /// let error = IoError::new_internal_with_path(\n+    ///     std::io::ErrorKind::NotFound,\n+    ///     \"Could not find special file\",\n+    ///     nu_protocol::location!(),\n+    ///     PathBuf::from(\"/some/file\"),\n+    /// );\n+    /// ```\n+    pub fn new_internal_with_path(\n+        kind: impl Into<ErrorKind>,\n+        additional_context: impl ToString,\n+        location: Location,\n+        path: PathBuf,\n+    ) -> Self {\n+        Self {\n+            kind: kind.into(),\n+            span: Span::unknown(),\n+            path: path.into(),\n+            additional_context: Some(additional_context.to_string()),\n+            location: Some(location.to_string()),\n+        }\n+    }\n+\n+    /// Creates a factory closure for constructing [`IoError`] instances from [`std::io::Error`] values.\n+    ///\n+    /// This method is particularly useful when you need to handle multiple I/O errors which all\n+    /// take the same span and path.\n+    /// Instead of calling `.map_err(|err| IoError::new(err.kind(), span, path))` every time, you\n+    /// can create the factory closure once and pass that into `.map_err`.\n+    pub fn factory<'p, P>(span: Span, path: P) -> impl Fn(std::io::Error) -> Self + use<'p, P>\n+    where\n+        P: Into<Option<&'p Path>>,\n+    {\n+        let path = path.into();\n+        move |err: std::io::Error| IoError::new(err.kind(), span, path.map(PathBuf::from))\n+    }\n+}\n+\n+impl Display for ErrorKind {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        match self {\n+            ErrorKind::Std(error_kind) => {\n+                let msg = error_kind.to_string();\n+                let (first, rest) = msg.split_at(1);\n+                write!(f, \"{}{}\", first.to_uppercase(), rest)\n+            }\n+            ErrorKind::NotADirectory => write!(f, \"Not a directory\"),\n+            ErrorKind::NotAFile => write!(f, \"Not a file\"),\n+            ErrorKind::IsADirectory => write!(f, \"Is a directory\"),\n+        }\n+    }\n+}\n+\n+impl std::error::Error for ErrorKind {}\n+\n+impl Diagnostic for IoError {\n+    fn code<'a>(&'a self) -> Option<Box<dyn std::fmt::Display + 'a>> {\n+        let mut code = String::from(\"nu::shell::io::\");\n+        match self.kind {\n+            ErrorKind::Std(error_kind) => match error_kind {\n+                std::io::ErrorKind::NotFound => code.push_str(\"not_found\"),\n+                std::io::ErrorKind::PermissionDenied => code.push_str(\"permission_denied\"),\n+                std::io::ErrorKind::ConnectionRefused => code.push_str(\"connection_refused\"),\n+                std::io::ErrorKind::ConnectionReset => code.push_str(\"connection_reset\"),\n+                std::io::ErrorKind::ConnectionAborted => code.push_str(\"connection_aborted\"),\n+                std::io::ErrorKind::NotConnected => code.push_str(\"not_connected\"),\n+                std::io::ErrorKind::AddrInUse => code.push_str(\"addr_in_use\"),\n+                std::io::ErrorKind::AddrNotAvailable => code.push_str(\"addr_not_available\"),\n+                std::io::ErrorKind::BrokenPipe => code.push_str(\"broken_pipe\"),\n+                std::io::ErrorKind::AlreadyExists => code.push_str(\"already_exists\"),\n+                std::io::ErrorKind::WouldBlock => code.push_str(\"would_block\"),\n+                std::io::ErrorKind::InvalidInput => code.push_str(\"invalid_input\"),\n+                std::io::ErrorKind::InvalidData => code.push_str(\"invalid_data\"),\n+                std::io::ErrorKind::TimedOut => code.push_str(\"timed_out\"),\n+                std::io::ErrorKind::WriteZero => code.push_str(\"write_zero\"),\n+                std::io::ErrorKind::Interrupted => code.push_str(\"interrupted\"),\n+                std::io::ErrorKind::Unsupported => code.push_str(\"unsupported\"),\n+                std::io::ErrorKind::UnexpectedEof => code.push_str(\"unexpected_eof\"),\n+                std::io::ErrorKind::OutOfMemory => code.push_str(\"out_of_memory\"),\n+                std::io::ErrorKind::Other => code.push_str(\"other\"),\n+                kind => code.push_str(&kind.to_string().to_lowercase().replace(\" \", \"_\")),\n+            },\n+            ErrorKind::NotADirectory => code.push_str(\"not_a_directory\"),\n+            ErrorKind::NotAFile => code.push_str(\"not_a_file\"),\n+            ErrorKind::IsADirectory => code.push_str(\"is_a_directory\"),\n+        }\n+\n+        Some(Box::new(code))\n+    }\n+\n+    fn help<'a>(&'a self) -> Option<Box<dyn std::fmt::Display + 'a>> {\n+        self.path\n+            .as_ref()\n+            .map(|path| format!(\"The error occurred at '{}'\", path.display()))\n+            .map(|s| Box::new(s) as Box<dyn std::fmt::Display>)\n+    }\n+\n+    fn labels(&self) -> Option<Box<dyn Iterator<Item = miette::LabeledSpan> + '_>> {\n+        let span_is_unknown = self.span == Span::unknown();\n+        let span = match (span_is_unknown, self.location.as_ref()) {\n+            (true, None) => return None,\n+            (false, _) => SourceSpan::from(self.span),\n+            (true, Some(location)) => SourceSpan::new(0.into(), location.len()),\n+        };\n+\n+        let label = match self.additional_context.as_ref() {\n+            Some(ctx) => format!(\"{ctx}\\n{}\", self.kind),\n+            None => self.kind.to_string(),\n+        };\n+        let label = LabeledSpan::new_with_span(Some(label), span);\n+        Some(Box::new(std::iter::once(label)))\n+    }\n+\n+    fn diagnostic_source(&self) -> Option<&dyn Diagnostic> {\n+        Some(&self.kind as &dyn Diagnostic)\n+    }\n+\n+    fn source_code(&self) -> Option<&dyn miette::SourceCode> {\n+        let span_is_unknown = self.span == Span::unknown();\n+        match (span_is_unknown, self.location.as_ref()) {\n+            (true, None) | (false, _) => None,\n+            (true, Some(location)) => Some(location as &dyn miette::SourceCode),\n+        }\n+    }\n+}\n+\n+impl From<IoError> for ShellError {\n+    fn from(value: IoError) -> Self {\n+        ShellError::Io(value)\n+    }\n+}\n+\n+impl From<IoError> for std::io::Error {\n+    fn from(value: IoError) -> Self {\n+        Self::new(value.kind.into(), value)\n+    }\n+}\n+\n+impl From<std::io::ErrorKind> for ErrorKind {\n+    fn from(value: std::io::ErrorKind) -> Self {\n+        ErrorKind::Std(value)\n+    }\n+}\n+\n+impl From<ErrorKind> for std::io::ErrorKind {\n+    fn from(value: ErrorKind) -> Self {\n+        match value {\n+            ErrorKind::Std(error_kind) => error_kind,\n+            _ => std::io::ErrorKind::Other,\n+        }\n+    }\n+}\ndiff --git a/crates/nu-protocol/src/errors/shell_error/location.rs b/crates/nu-protocol/src/errors/shell_error/location.rs\nnew file mode 100644\nindex 0000000000000..340f9ada61679\n--- /dev/null\n+++ b/crates/nu-protocol/src/errors/shell_error/location.rs\n@@ -0,0 +1,56 @@\n+use thiserror::Error;\n+\n+/// Represents a specific location in the Rust code.\n+///\n+/// This data structure is used to provide detailed information about where in the Rust code\n+/// an error occurred.\n+/// While most errors in [`ShellError`](super::ShellError) are related to user-provided Nushell\n+/// code, some originate from the underlying Rust implementation.\n+/// With this type, we can pinpoint the exact location of such errors, improving debugging\n+/// and error reporting.\n+#[derive(Debug, Clone, PartialEq, Eq, Error)]\n+#[error(\"{file}:{line}:{column}\")]\n+pub struct Location {\n+    file: &'static str,\n+    line: u32,\n+    column: u32,\n+}\n+\n+impl Location {\n+    /// Internal constructor for [`Location`].\n+    ///\n+    /// This function is not intended to be called directly.\n+    /// Instead, use the [`location!`] macro to create instances.\n+    #[doc(hidden)]\n+    #[deprecated(\n+        note = \"This function is not meant to be called directly. Use `nu_protocol::location` instead.\"\n+    )]\n+    pub fn new(file: &'static str, line: u32, column: u32) -> Self {\n+        Location { file, line, column }\n+    }\n+}\n+\n+/// Macro to create a new [`Location`] for the exact position in your code.\n+///\n+/// This macro captures the current file, line, and column during compilation,\n+/// providing an easy way to associate errors with specific locations in the Rust code.\n+///\n+/// # Note\n+/// This macro relies on the [`file!`], [`line!`], and [`column!`] macros to fetch the\n+/// compilation context.\n+#[macro_export]\n+macro_rules! location {\n+    () => {{\n+        #[allow(deprecated)]\n+        $crate::shell_error::location::Location::new(file!(), line!(), column!())\n+    }};\n+}\n+\n+#[test]\n+fn test_location_macro() {\n+    let location = crate::location!();\n+    let line = line!() - 1; // Adjust for the macro call being on the previous line.\n+    let file = file!();\n+    assert_eq!(location.line, line);\n+    assert_eq!(location.file, file);\n+}\ndiff --git a/crates/nu-protocol/src/errors/shell_error.rs b/crates/nu-protocol/src/errors/shell_error/mod.rs\nsimilarity index 87%\nrename from crates/nu-protocol/src/errors/shell_error.rs\nrename to crates/nu-protocol/src/errors/shell_error/mod.rs\nindex 208f2178f6340..6f651836ca78d 100644\n--- a/crates/nu-protocol/src/errors/shell_error.rs\n+++ b/crates/nu-protocol/src/errors/shell_error/mod.rs\n@@ -4,9 +4,13 @@ use crate::{\n };\n use miette::Diagnostic;\n use serde::{Deserialize, Serialize};\n-use std::{io, num::NonZeroI32};\n+use std::num::NonZeroI32;\n use thiserror::Error;\n \n+pub mod bridge;\n+pub mod io;\n+pub mod location;\n+\n /// The fundamental error type for the evaluation engine. These cases represent different kinds of errors\n /// the evaluator might face, along with helpful spans to label. An error renderer will take this error value\n /// and pass it into an error viewer to display to the user.\n@@ -808,32 +812,6 @@ pub enum ShellError {\n         span: Span,\n     },\n \n-    /// Failed to find a file during a nushell operation.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Does the file in the error message exist? Is it readable and accessible? Is the casing right?\n-    #[error(\"File not found\")]\n-    #[diagnostic(code(nu::shell::file_not_found), help(\"{file} does not exist\"))]\n-    FileNotFound {\n-        file: String,\n-        #[label(\"file not found\")]\n-        span: Span,\n-    },\n-\n-    /// Failed to find a file during a nushell operation.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Does the file in the error message exist? Is it readable and accessible? Is the casing right?\n-    #[error(\"File not found\")]\n-    #[diagnostic(code(nu::shell::file_not_found))]\n-    FileNotFoundCustom {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n     /// The registered plugin data for a plugin is invalid.\n     ///\n     /// ## Resolution\n@@ -924,148 +902,14 @@ pub enum ShellError {\n         span: Span,\n     },\n \n-    /// I/O operation interrupted.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// This is a generic error. Refer to the specific error message for further details.\n-    #[error(\"I/O interrupted\")]\n-    #[diagnostic(code(nu::shell::io_interrupted))]\n-    IOInterrupted {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n     /// An I/O operation failed.\n     ///\n     /// ## Resolution\n     ///\n-    /// This is a generic error. Refer to the specific error message for further details.\n-    #[error(\"I/O error\")]\n-    #[diagnostic(code(nu::shell::io_error), help(\"{msg}\"))]\n-    IOError { msg: String },\n-\n-    /// An I/O operation failed.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// This is a generic error. Refer to the specific error message for further details.\n-    #[error(\"I/O error\")]\n-    #[diagnostic(code(nu::shell::io_error))]\n-    IOErrorSpanned {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n-    /// Tried to `cd` to a path that isn't a directory.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Make sure the path is a directory. It currently exists, but is of some other type, like a file.\n-    #[error(\"Cannot change to directory\")]\n-    #[diagnostic(code(nu::shell::cannot_cd_to_directory))]\n-    NotADirectory {\n-        #[label(\"is not a directory\")]\n-        span: Span,\n-    },\n-\n-    /// Attempted to perform an operation on a directory that doesn't exist.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Make sure the directory in the error message actually exists before trying again.\n-    #[error(\"Directory not found\")]\n-    #[diagnostic(code(nu::shell::directory_not_found), help(\"{dir} does not exist\"))]\n-    DirectoryNotFound {\n-        dir: String,\n-        #[label(\"directory not found\")]\n-        span: Span,\n-    },\n-\n-    /// The requested move operation cannot be completed. This is typically because both paths exist,\n-    /// but are of different types. For example, you might be trying to overwrite an existing file with\n-    /// a directory.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Make sure the destination path does not exist before moving a directory.\n-    #[error(\"Move not possible\")]\n-    #[diagnostic(code(nu::shell::move_not_possible))]\n-    MoveNotPossible {\n-        source_message: String,\n-        #[label(\"{source_message}\")]\n-        source_span: Span,\n-        destination_message: String,\n-        #[label(\"{destination_message}\")]\n-        destination_span: Span,\n-    },\n-\n-    /// Failed to create either a file or directory.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// This is a fairly generic error. Refer to the specific error message for further details.\n-    #[error(\"Create not possible\")]\n-    #[diagnostic(code(nu::shell::create_not_possible))]\n-    CreateNotPossible {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n-    /// Changing the access time (\"atime\") of this file is not possible.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// This can be for various reasons, such as your platform or permission flags. Refer to the specific error message for more details.\n-    #[error(\"Not possible to change the access time\")]\n-    #[diagnostic(code(nu::shell::change_access_time_not_possible))]\n-    ChangeAccessTimeNotPossible {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n-    /// Changing the modification time (\"mtime\") of this file is not possible.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// This can be for various reasons, such as your platform or permission flags. Refer to the specific error message for more details.\n-    #[error(\"Not possible to change the modified time\")]\n-    #[diagnostic(code(nu::shell::change_modified_time_not_possible))]\n-    ChangeModifiedTimeNotPossible {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n-    /// Unable to remove this item.\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// Removal can fail for a number of reasons, such as permissions problems. Refer to the specific error message for more details.\n-    #[error(\"Remove not possible\")]\n-    #[diagnostic(code(nu::shell::remove_not_possible))]\n-    RemoveNotPossible {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n-\n-    /// Error while trying to read a file\n-    ///\n-    /// ## Resolution\n-    ///\n-    /// The error will show the result from a file operation\n-    #[error(\"Error trying to read file\")]\n-    #[diagnostic(code(nu::shell::error_reading_file))]\n-    ReadingFile {\n-        msg: String,\n-        #[label(\"{msg}\")]\n-        span: Span,\n-    },\n+    /// This is the main I/O error, for further details check the error kind and additional context.\n+    #[error(transparent)]\n+    #[diagnostic(transparent)]\n+    Io(io::IoError),\n \n     /// A name was not found. Did you mean a different name?\n     ///\n@@ -1531,75 +1375,26 @@ impl ShellError {\n     }\n }\n \n-impl From<io::Error> for ShellError {\n-    fn from(error: io::Error) -> ShellError {\n-        if error.kind() == io::ErrorKind::Other {\n-            match error.into_inner() {\n-                Some(err) => match err.downcast() {\n-                    Ok(err) => *err,\n-                    Err(err) => Self::IOError {\n-                        msg: err.to_string(),\n-                    },\n-                },\n-                None => Self::IOError {\n-                    msg: \"unknown error\".into(),\n-                },\n-            }\n-        } else {\n-            Self::IOError {\n-                msg: error.to_string(),\n-            }\n-        }\n-    }\n-}\n-\n-impl From<Spanned<io::Error>> for ShellError {\n-    fn from(error: Spanned<io::Error>) -> Self {\n-        let Spanned { item: error, span } = error;\n-        match error.kind() {\n-            io::ErrorKind::Other => match error.into_inner() {\n-                Some(err) => match err.downcast() {\n-                    Ok(err) => *err,\n-                    Err(err) => Self::IOErrorSpanned {\n-                        msg: err.to_string(),\n-                        span,\n-                    },\n-                },\n-                None => Self::IOErrorSpanned {\n-                    msg: \"unknown error\".into(),\n-                    span,\n-                },\n-            },\n-            io::ErrorKind::TimedOut => Self::NetworkFailure {\n-                msg: error.to_string(),\n-                span,\n-            },\n-            _ => Self::IOErrorSpanned {\n-                msg: error.to_string(),\n-                span,\n-            },\n-        }\n-    }\n-}\n-\n-impl From<ShellError> for io::Error {\n-    fn from(error: ShellError) -> Self {\n-        io::Error::new(io::ErrorKind::Other, error)\n-    }\n-}\n-\n impl From<Box<dyn std::error::Error>> for ShellError {\n     fn from(error: Box<dyn std::error::Error>) -> ShellError {\n-        ShellError::IOError {\n+        ShellError::GenericError {\n+            error: format!(\"{error:?}\"),\n             msg: error.to_string(),\n+            span: None,\n+            help: None,\n+            inner: vec![],\n         }\n     }\n }\n \n impl From<Box<dyn std::error::Error + Send + Sync>> for ShellError {\n     fn from(error: Box<dyn std::error::Error + Send + Sync>) -> ShellError {\n-        ShellError::IOError {\n-            msg: format!(\"{error:?}\"),\n+        ShellError::GenericError {\n+            error: format!(\"{error:?}\"),\n+            msg: error.to_string(),\n+            span: None,\n+            help: None,\n+            inner: vec![],\n         }\n     }\n }\n@@ -1682,3 +1477,26 @@ fn shell_error_serialize_roundtrip() {\n         deserialized.help().map(|c| c.to_string())\n     );\n }\n+\n+#[cfg(test)]\n+mod test {\n+    use super::*;\n+\n+    impl From<std::io::Error> for ShellError {\n+        fn from(_: std::io::Error) -> ShellError {\n+            unimplemented!(\"This implementation is defined in the test module to ensure no other implementation exists.\")\n+        }\n+    }\n+\n+    impl From<Spanned<std::io::Error>> for ShellError {\n+        fn from(_: Spanned<std::io::Error>) -> Self {\n+            unimplemented!(\"This implementation is defined in the test module to ensure no other implementation exists.\")\n+        }\n+    }\n+\n+    impl From<ShellError> for std::io::Error {\n+        fn from(_: ShellError) -> Self {\n+            unimplemented!(\"This implementation is defined in the test module to ensure no other implementation exists.\")\n+        }\n+    }\n+}\ndiff --git a/crates/nu-protocol/src/eval_const.rs b/crates/nu-protocol/src/eval_const.rs\nindex 25f5d8404abb2..86ce4d7385e76 100644\n--- a/crates/nu-protocol/src/eval_const.rs\n+++ b/crates/nu-protocol/src/eval_const.rs\n@@ -143,8 +143,12 @@ pub(crate) fn create_nu_constant(engine_state: &EngineState, span: Span) -> Valu\n             Value::string(canon_home_path.to_string_lossy(), span)\n         } else {\n             Value::error(\n-                ShellError::IOError {\n+                ShellError::GenericError {\n+                    error: \"setting $nu.home-path failed\".into(),\n                     msg: \"Could not get home path\".into(),\n+                    span: Some(span),\n+                    help: None,\n+                    inner: vec![],\n                 },\n                 span,\n             )\n@@ -159,8 +163,12 @@ pub(crate) fn create_nu_constant(engine_state: &EngineState, span: Span) -> Valu\n             Value::string(canon_data_path.to_string_lossy(), span)\n         } else {\n             Value::error(\n-                ShellError::IOError {\n+                ShellError::GenericError {\n+                    error: \"setting $nu.data-dir failed\".into(),\n                     msg: \"Could not get data path\".into(),\n+                    span: Some(span),\n+                    help: None,\n+                    inner: vec![],\n                 },\n                 span,\n             )\n@@ -175,8 +183,12 @@ pub(crate) fn create_nu_constant(engine_state: &EngineState, span: Span) -> Valu\n             Value::string(canon_cache_path.to_string_lossy(), span)\n         } else {\n             Value::error(\n-                ShellError::IOError {\n+                ShellError::GenericError {\n+                    error: \"setting $nu.cache-dir failed\".into(),\n                     msg: \"Could not get cache path\".into(),\n+                    span: Some(span),\n+                    help: None,\n+                    inner: vec![],\n                 },\n                 span,\n             )\n@@ -248,8 +260,12 @@ pub(crate) fn create_nu_constant(engine_state: &EngineState, span: Span) -> Valu\n             Value::string(current_exe.to_string_lossy(), span)\n         } else {\n             Value::error(\n-                ShellError::IOError {\n-                    msg: \"Could not get current executable path\".to_string(),\n+                ShellError::GenericError {\n+                    error: \"setting $nu.current-exe failed\".into(),\n+                    msg: \"Could not get current executable path\".into(),\n+                    span: Some(span),\n+                    help: None,\n+                    inner: vec![],\n                 },\n                 span,\n             )\ndiff --git a/crates/nu-protocol/src/pipeline/byte_stream.rs b/crates/nu-protocol/src/pipeline/byte_stream.rs\nindex b5cbbff237ad2..e06a651088613 100644\n--- a/crates/nu-protocol/src/pipeline/byte_stream.rs\n+++ b/crates/nu-protocol/src/pipeline/byte_stream.rs\n@@ -1,7 +1,13 @@\n //! Module managing the streaming of raw bytes between pipeline elements\n+//!\n+//! This module also handles conversions the [`ShellError`] <-> [`io::Error`](std::io::Error),\n+//! so remember the usage of [`ShellErrorBridge`] where applicable.\n #[cfg(feature = \"os\")]\n use crate::process::{ChildPipe, ChildProcess};\n-use crate::{ErrSpan, IntRange, IntoSpanned, PipelineData, ShellError, Signals, Span, Type, Value};\n+use crate::{\n+    shell_error::{bridge::ShellErrorBridge, io::IoError},\n+    IntRange, PipelineData, ShellError, Signals, Span, Type, Value,\n+};\n use serde::{Deserialize, Serialize};\n use std::ops::Bound;\n #[cfg(unix)]\n@@ -225,7 +231,8 @@ impl ByteStream {\n         let known_size = self.known_size.map(|len| len.saturating_sub(n));\n         if let Some(mut reader) = self.reader() {\n             // Copy the number of skipped bytes into the sink before proceeding\n-            io::copy(&mut (&mut reader).take(n), &mut io::sink()).err_span(span)?;\n+            io::copy(&mut (&mut reader).take(n), &mut io::sink())\n+                .map_err(|err| IoError::new(err.kind(), span, None))?;\n             Ok(\n                 ByteStream::read(reader, span, Signals::empty(), ByteStreamType::Binary)\n                     .with_known_size(known_size),\n@@ -346,7 +353,7 @@ impl ByteStream {\n     /// binary.\n     #[cfg(feature = \"os\")]\n     pub fn stdin(span: Span) -> Result<Self, ShellError> {\n-        let stdin = os_pipe::dup_stdin().err_span(span)?;\n+        let stdin = os_pipe::dup_stdin().map_err(|err| IoError::new(err.kind(), span, None))?;\n         let source = ByteStreamSource::File(convert_file(stdin));\n         Ok(Self::new(\n             source,\n@@ -573,15 +580,16 @@ impl ByteStream {\n     /// Any trailing new lines are kept in the returned [`Vec`].\n     pub fn into_bytes(self) -> Result<Vec<u8>, ShellError> {\n         // todo!() ctrlc\n+        let from_io_error = IoError::factory(self.span, None);\n         match self.stream {\n             ByteStreamSource::Read(mut read) => {\n                 let mut buf = Vec::new();\n-                read.read_to_end(&mut buf).err_span(self.span)?;\n+                read.read_to_end(&mut buf).map_err(&from_io_error)?;\n                 Ok(buf)\n             }\n             ByteStreamSource::File(mut file) => {\n                 let mut buf = Vec::new();\n-                file.read_to_end(&mut buf).err_span(self.span)?;\n+                file.read_to_end(&mut buf).map_err(&from_io_error)?;\n                 Ok(buf)\n             }\n             #[cfg(feature = \"os\")]\n@@ -759,7 +767,12 @@ where\n         while let Some(cursor) = self.cursor.as_mut() {\n             let read = cursor.read(buf)?;\n             if read == 0 {\n-                self.cursor = self.iter.next().transpose()?.map(Cursor::new);\n+                self.cursor = self\n+                    .iter\n+                    .next()\n+                    .transpose()\n+                    .map_err(ShellErrorBridge)?\n+                    .map(Cursor::new);\n             } else {\n                 return Ok(read);\n             }\n@@ -782,7 +795,7 @@ impl Reader {\n \n impl Read for Reader {\n     fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n-        self.signals.check(self.span)?;\n+        self.signals.check(self.span).map_err(ShellErrorBridge)?;\n         self.reader.read(buf)\n     }\n }\n@@ -826,7 +839,7 @@ impl Iterator for Lines {\n                     trim_end_newline(&mut string);\n                     Some(Ok(string))\n                 }\n-                Err(e) => Some(Err(e.into_spanned(self.span).into())),\n+                Err(e) => Some(Err(IoError::new(e.kind(), self.span, None).into())),\n             }\n         }\n     }\n@@ -1022,7 +1035,15 @@ impl Iterator for SplitRead {\n         if self.signals.interrupted() {\n             return None;\n         }\n-        self.internal.next().map(|r| r.map_err(|e| e.into()))\n+        self.internal.next().map(|r| {\n+            r.map_err(|err| {\n+                ShellError::Io(IoError::new_internal(\n+                    err.kind(),\n+                    \"Could not get next value for SplitRead\",\n+                    crate::location!(),\n+                ))\n+            })\n+        })\n     }\n }\n \n@@ -1057,12 +1078,17 @@ impl Chunks {\n     }\n \n     fn next_string(&mut self) -> Result<Option<String>, (Vec<u8>, ShellError)> {\n+        let from_io_error = |err: std::io::Error| match ShellErrorBridge::try_from(err) {\n+            Ok(err) => err.0,\n+            Err(err) => IoError::new(err.kind(), self.span, None).into(),\n+        };\n+\n         // Get some data from the reader\n         let buf = self\n             .reader\n             .fill_buf()\n-            .err_span(self.span)\n-            .map_err(|err| (vec![], ShellError::from(err)))?;\n+            .map_err(from_io_error)\n+            .map_err(|err| (vec![], err))?;\n \n         // If empty, this is EOF\n         if buf.is_empty() {\n@@ -1076,9 +1102,9 @@ impl Chunks {\n         if buf.len() < 4 {\n             consumed += buf.len();\n             self.reader.consume(buf.len());\n-            match self.reader.fill_buf().err_span(self.span) {\n+            match self.reader.fill_buf() {\n                 Ok(more_bytes) => buf.extend_from_slice(more_bytes),\n-                Err(err) => return Err((buf, err.into())),\n+                Err(err) => return Err((buf, from_io_error(err))),\n             }\n         }\n \n@@ -1133,11 +1159,15 @@ impl Iterator for Chunks {\n             match self.type_ {\n                 // Binary should always be binary\n                 ByteStreamType::Binary => {\n-                    let buf = match self.reader.fill_buf().err_span(self.span) {\n+                    let buf = match self.reader.fill_buf() {\n                         Ok(buf) => buf,\n                         Err(err) => {\n                             self.error = true;\n-                            return Some(Err(err.into()));\n+                            return Some(Err(ShellError::Io(IoError::new(\n+                                err.kind(),\n+                                self.span,\n+                                None,\n+                            ))));\n                         }\n                     };\n                     if !buf.is_empty() {\n@@ -1206,15 +1236,19 @@ pub fn copy_with_signals(\n     span: Span,\n     signals: &Signals,\n ) -> Result<u64, ShellError> {\n+    let from_io_error = IoError::factory(span, None);\n     if signals.is_empty() {\n         match io::copy(&mut reader, &mut writer) {\n             Ok(n) => {\n-                writer.flush().err_span(span)?;\n+                writer.flush().map_err(&from_io_error)?;\n                 Ok(n)\n             }\n             Err(err) => {\n                 let _ = writer.flush();\n-                Err(err.into_spanned(span).into())\n+                match ShellErrorBridge::try_from(err) {\n+                    Ok(ShellErrorBridge(shell_error)) => Err(shell_error),\n+                    Err(err) => Err(from_io_error(err).into()),\n+                }\n             }\n         }\n     } else {\n@@ -1224,7 +1258,7 @@ pub fn copy_with_signals(\n         // }\n         match generic_copy(&mut reader, &mut writer, span, signals) {\n             Ok(len) => {\n-                writer.flush().err_span(span)?;\n+                writer.flush().map_err(&from_io_error)?;\n                 Ok(len)\n             }\n             Err(err) => {\n@@ -1242,6 +1276,7 @@ fn generic_copy(\n     span: Span,\n     signals: &Signals,\n ) -> Result<u64, ShellError> {\n+    let from_io_error = IoError::factory(span, None);\n     let buf = &mut [0; DEFAULT_BUF_SIZE];\n     let mut len = 0;\n     loop {\n@@ -1250,10 +1285,13 @@ fn generic_copy(\n             Ok(0) => break,\n             Ok(n) => n,\n             Err(e) if e.kind() == ErrorKind::Interrupted => continue,\n-            Err(e) => return Err(e.into_spanned(span).into()),\n+            Err(e) => match ShellErrorBridge::try_from(e) {\n+                Ok(ShellErrorBridge(e)) => return Err(e),\n+                Err(e) => return Err(from_io_error(e).into()),\n+            },\n         };\n         len += n;\n-        writer.write_all(&buf[..n]).err_span(span)?;\n+        writer.write_all(&buf[..n]).map_err(&from_io_error)?;\n     }\n     Ok(len as u64)\n }\n@@ -1278,7 +1316,7 @@ where\n             self.buffer.set_position(0);\n             self.buffer.get_mut().clear();\n             // Ask the generator to generate data\n-            if !(self.generator)(self.buffer.get_mut())? {\n+            if !(self.generator)(self.buffer.get_mut()).map_err(ShellErrorBridge)? {\n                 // End of stream\n                 break;\n             }\ndiff --git a/crates/nu-protocol/src/pipeline/pipeline_data.rs b/crates/nu-protocol/src/pipeline/pipeline_data.rs\nindex b9d523b3da1db..b4a1e9ca01eec 100644\n--- a/crates/nu-protocol/src/pipeline/pipeline_data.rs\n+++ b/crates/nu-protocol/src/pipeline/pipeline_data.rs\n@@ -1,6 +1,7 @@\n use crate::{\n     ast::{Call, PathMember},\n     engine::{EngineState, Stack},\n+    shell_error::io::IoError,\n     ByteStream, ByteStreamType, Config, ListStream, OutDest, PipelineMetadata, Range, ShellError,\n     Signals, Span, Type, Value,\n };\n@@ -219,17 +220,47 @@ impl PipelineData {\n             PipelineData::Empty => Ok(()),\n             PipelineData::Value(value, ..) => {\n                 let bytes = value_to_bytes(value)?;\n-                dest.write_all(&bytes)?;\n-                dest.flush()?;\n+                dest.write_all(&bytes).map_err(|err| {\n+                    IoError::new_internal(\n+                        err.kind(),\n+                        \"Could not write PipelineData to dest\",\n+                        crate::location!(),\n+                    )\n+                })?;\n+                dest.flush().map_err(|err| {\n+                    IoError::new_internal(\n+                        err.kind(),\n+                        \"Could not flush PipelineData to dest\",\n+                        crate::location!(),\n+                    )\n+                })?;\n                 Ok(())\n             }\n             PipelineData::ListStream(stream, ..) => {\n                 for value in stream {\n                     let bytes = value_to_bytes(value)?;\n-                    dest.write_all(&bytes)?;\n-                    dest.write_all(b\"\\n\")?;\n+                    dest.write_all(&bytes).map_err(|err| {\n+                        IoError::new_internal(\n+                            err.kind(),\n+                            \"Could not write PipelineData to dest\",\n+                            crate::location!(),\n+                        )\n+                    })?;\n+                    dest.write_all(b\"\\n\").map_err(|err| {\n+                        IoError::new_internal(\n+                            err.kind(),\n+                            \"Could not write linebreak after PipelineData to dest\",\n+                            crate::location!(),\n+                        )\n+                    })?;\n                 }\n-                dest.flush()?;\n+                dest.flush().map_err(|err| {\n+                    IoError::new_internal(\n+                        err.kind(),\n+                        \"Could not flush PipelineData to dest\",\n+                        crate::location!(),\n+                    )\n+                })?;\n                 Ok(())\n             }\n             PipelineData::ByteStream(stream, ..) => stream.write_to(dest),\n@@ -633,9 +664,23 @@ impl PipelineData {\n     ) -> Result<(), ShellError> {\n         if let PipelineData::Value(Value::Binary { val: bytes, .. }, _) = self {\n             if to_stderr {\n-                stderr_write_all_and_flush(bytes)?;\n+                stderr_write_all_and_flush(bytes).map_err(|err| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        Span::unknown(),\n+                        None,\n+                        \"Writing to stderr failed\",\n+                    )\n+                })?\n             } else {\n-                stdout_write_all_and_flush(bytes)?;\n+                stdout_write_all_and_flush(bytes).map_err(|err| {\n+                    IoError::new_with_additional_context(\n+                        err.kind(),\n+                        Span::unknown(),\n+                        None,\n+                        \"Writing to stdout failed\",\n+                    )\n+                })?\n             }\n             Ok(())\n         } else {\n@@ -666,9 +711,23 @@ impl PipelineData {\n                 }\n \n                 if to_stderr {\n-                    stderr_write_all_and_flush(out)?\n+                    stderr_write_all_and_flush(out).map_err(|err| {\n+                        IoError::new_with_additional_context(\n+                            err.kind(),\n+                            Span::unknown(),\n+                            None,\n+                            \"Writing to stderr failed\",\n+                        )\n+                    })?\n                 } else {\n-                    stdout_write_all_and_flush(out)?\n+                    stdout_write_all_and_flush(out).map_err(|err| {\n+                        IoError::new_with_additional_context(\n+                            err.kind(),\n+                            Span::unknown(),\n+                            None,\n+                            \"Writing to stdout failed\",\n+                        )\n+                    })?\n                 }\n             }\n \ndiff --git a/crates/nu-protocol/src/process/child.rs b/crates/nu-protocol/src/process/child.rs\nindex 8c4fb55c0db36..1c0ef513edd27 100644\n--- a/crates/nu-protocol/src/process/child.rs\n+++ b/crates/nu-protocol/src/process/child.rs\n@@ -1,4 +1,4 @@\n-use crate::{byte_stream::convert_file, ErrSpan, IntoSpanned, ShellError, Span};\n+use crate::{byte_stream::convert_file, shell_error::io::IoError, ShellError, Span};\n use nu_system::{ExitStatus, ForegroundChild};\n use os_pipe::PipeReader;\n use std::{\n@@ -74,13 +74,18 @@ impl ExitStatusFuture {\n                         Ok(status)\n                     }\n                     Ok(Ok(status)) => Ok(status),\n-                    Ok(Err(err)) => Err(ShellError::IOErrorSpanned {\n-                        msg: format!(\"failed to get exit code: {err:?}\"),\n+                    Ok(Err(err)) => Err(ShellError::Io(IoError::new_with_additional_context(\n+                        err.kind(),\n                         span,\n-                    }),\n-                    Err(RecvError) => Err(ShellError::IOErrorSpanned {\n+                        None,\n+                        \"failed to get exit code\",\n+                    ))),\n+                    Err(err @ RecvError) => Err(ShellError::GenericError {\n+                        error: err.to_string(),\n                         msg: \"failed to get exit code\".into(),\n-                        span,\n+                        span: span.into(),\n+                        help: None,\n+                        inner: vec![],\n                     }),\n                 };\n \n@@ -98,13 +103,19 @@ impl ExitStatusFuture {\n             ExitStatusFuture::Running(receiver) => {\n                 let code = match receiver.try_recv() {\n                     Ok(Ok(status)) => Ok(Some(status)),\n-                    Ok(Err(err)) => Err(ShellError::IOErrorSpanned {\n-                        msg: format!(\"failed to get exit code: {err:?}\"),\n-                        span,\n+                    Ok(Err(err)) => Err(ShellError::GenericError {\n+                        error: err.to_string(),\n+                        msg: \"failed to get exit code\".to_string(),\n+                        span: span.into(),\n+                        help: None,\n+                        inner: vec![],\n                     }),\n-                    Err(TryRecvError::Disconnected) => Err(ShellError::IOErrorSpanned {\n+                    Err(TryRecvError::Disconnected) => Err(ShellError::GenericError {\n+                        error: \"receiver disconnected\".to_string(),\n                         msg: \"failed to get exit code\".into(),\n-                        span,\n+                        span: span.into(),\n+                        help: None,\n+                        inner: vec![],\n                     }),\n                     Err(TryRecvError::Empty) => Ok(None),\n                 };\n@@ -180,7 +191,14 @@ impl ChildProcess {\n         thread::Builder::new()\n             .name(\"exit status waiter\".into())\n             .spawn(move || exit_status_sender.send(child.wait()))\n-            .err_span(span)?;\n+            .map_err(|err| {\n+                IoError::new_with_additional_context(\n+                    err.kind(),\n+                    span,\n+                    None,\n+                    \"Could now spawn exit status waiter\",\n+                )\n+            })?;\n \n         Ok(Self::from_raw(stdout, stderr, Some(exit_status), span))\n     }\n@@ -214,14 +232,17 @@ impl ChildProcess {\n     pub fn into_bytes(mut self) -> Result<Vec<u8>, ShellError> {\n         if self.stderr.is_some() {\n             debug_assert!(false, \"stderr should not exist\");\n-            return Err(ShellError::IOErrorSpanned {\n-                msg: \"internal error\".into(),\n-                span: self.span,\n+            return Err(ShellError::GenericError {\n+                error: \"internal error\".into(),\n+                msg: \"stderr should not exist\".into(),\n+                span: self.span.into(),\n+                help: None,\n+                inner: vec![],\n             });\n         }\n \n         let bytes = if let Some(stdout) = self.stdout {\n-            collect_bytes(stdout).err_span(self.span)?\n+            collect_bytes(stdout).map_err(|err| IoError::new(err.kind(), self.span, None))?\n         } else {\n             Vec::new()\n         };\n@@ -236,6 +257,7 @@ impl ChildProcess {\n     }\n \n     pub fn wait(mut self) -> Result<(), ShellError> {\n+        let from_io_error = IoError::factory(self.span, None);\n         if let Some(stdout) = self.stdout.take() {\n             let stderr = self\n                 .stderr\n@@ -246,7 +268,7 @@ impl ChildProcess {\n                         .spawn(move || consume_pipe(stderr))\n                 })\n                 .transpose()\n-                .err_span(self.span)?;\n+                .map_err(&from_io_error)?;\n \n             let res = consume_pipe(stdout);\n \n@@ -254,7 +276,7 @@ impl ChildProcess {\n                 handle\n                     .join()\n                     .map_err(|e| match e.downcast::<io::Error>() {\n-                        Ok(io) => ShellError::from((*io).into_spanned(self.span)),\n+                        Ok(io) => from_io_error(*io).into(),\n                         Err(err) => ShellError::GenericError {\n                             error: \"Unknown error\".into(),\n                             msg: format!(\"{err:?}\"),\n@@ -263,12 +285,12 @@ impl ChildProcess {\n                             inner: Vec::new(),\n                         },\n                     })?\n-                    .err_span(self.span)?;\n+                    .map_err(&from_io_error)?;\n             }\n \n-            res.err_span(self.span)?;\n+            res.map_err(&from_io_error)?;\n         } else if let Some(stderr) = self.stderr.take() {\n-            consume_pipe(stderr).err_span(self.span)?;\n+            consume_pipe(stderr).map_err(&from_io_error)?;\n         }\n \n         check_ok(\n@@ -283,19 +305,20 @@ impl ChildProcess {\n     }\n \n     pub fn wait_with_output(mut self) -> Result<ProcessOutput, ShellError> {\n+        let from_io_error = IoError::factory(self.span, None);\n         let (stdout, stderr) = if let Some(stdout) = self.stdout {\n             let stderr = self\n                 .stderr\n                 .map(|stderr| thread::Builder::new().spawn(move || collect_bytes(stderr)))\n                 .transpose()\n-                .err_span(self.span)?;\n+                .map_err(&from_io_error)?;\n \n-            let stdout = collect_bytes(stdout).err_span(self.span)?;\n+            let stdout = collect_bytes(stdout).map_err(&from_io_error)?;\n \n             let stderr = stderr\n                 .map(|handle| {\n                     handle.join().map_err(|e| match e.downcast::<io::Error>() {\n-                        Ok(io) => ShellError::from((*io).into_spanned(self.span)),\n+                        Ok(io) => from_io_error(*io).into(),\n                         Err(err) => ShellError::GenericError {\n                             error: \"Unknown error\".into(),\n                             msg: format!(\"{err:?}\"),\n@@ -307,7 +330,7 @@ impl ChildProcess {\n                 })\n                 .transpose()?\n                 .transpose()\n-                .err_span(self.span)?;\n+                .map_err(&from_io_error)?;\n \n             (Some(stdout), stderr)\n         } else {\n@@ -315,7 +338,7 @@ impl ChildProcess {\n                 .stderr\n                 .map(collect_bytes)\n                 .transpose()\n-                .err_span(self.span)?;\n+                .map_err(&from_io_error)?;\n \n             (None, stderr)\n         };\ndiff --git a/crates/nu-protocol/src/span.rs b/crates/nu-protocol/src/span.rs\nindex 9fe42c253016b..dd465b5a63ebb 100644\n--- a/crates/nu-protocol/src/span.rs\n+++ b/crates/nu-protocol/src/span.rs\n@@ -115,10 +115,17 @@ impl Span {\n         Self { start: 0, end: 0 }\n     }\n \n+    /// Span for testing purposes.\n+    ///\n+    /// The provided span does not point into any known source but is unequal to [`Span::unknown()`].\n+    ///\n     /// Note: Only use this for test data, *not* live data, as it will point into unknown source\n-    /// when used in errors.\n+    /// when used in errors\n     pub const fn test_data() -> Self {\n-        Self::unknown()\n+        Self {\n+            start: usize::MAX / 2,\n+            end: usize::MAX / 2,\n+        }\n     }\n \n     pub fn offset(&self, offset: usize) -> Self {\n@@ -215,26 +222,14 @@ impl From<Span> for SourceSpan {\n     }\n }\n \n-/// An extension trait for `Result`, which adds a span to the error type.\n+/// An extension trait for [`Result`], which adds a span to the error type.\n+///\n+/// This trait might be removed later, since the old [`Spanned<std::io::Error>`] to [`ShellError`]\n+/// conversion was replaced by [`IoError`](io_error::IoError).\n pub trait ErrSpan {\n     type Result;\n \n-    /// Add the given span to the error type `E`, turning it into a `Spanned<E>`.\n-    ///\n-    /// Some auto-conversion methods to `ShellError` from other error types are available on spanned\n-    /// errors, to give users better information about where an error came from. For example, it is\n-    /// preferred when working with `std::io::Error`:\n-    ///\n-    /// ```no_run\n-    /// use nu_protocol::{ErrSpan, ShellError, Span};\n-    /// use std::io::Read;\n-    ///\n-    /// fn read_from(mut reader: impl Read, span: Span) -> Result<Vec<u8>, ShellError> {\n-    ///     let mut vec = vec![];\n-    ///     reader.read_to_end(&mut vec).err_span(span)?;\n-    ///     Ok(vec)\n-    /// }\n-    /// ```\n+    /// Adds the given span to the error type, turning it into a [`Spanned<E>`].\n     fn err_span(self, span: Span) -> Self::Result;\n }\n \ndiff --git a/crates/nu_plugin_polars/src/dataframe/command/core/open.rs b/crates/nu_plugin_polars/src/dataframe/command/core/open.rs\nindex 97a44d8f4f869..b218530e64857 100644\n--- a/crates/nu_plugin_polars/src/dataframe/command/core/open.rs\n+++ b/crates/nu_plugin_polars/src/dataframe/command/core/open.rs\n@@ -11,8 +11,8 @@ use url::Url;\n \n use nu_plugin::PluginCommand;\n use nu_protocol::{\n-    Category, Example, LabeledError, PipelineData, ShellError, Signature, Span, Spanned,\n-    SyntaxShape, Type, Value,\n+    shell_error::io::IoError, Category, Example, LabeledError, PipelineData, ShellError, Signature,\n+    Span, Spanned, SyntaxShape, Type, Value,\n };\n \n use std::{fmt::Debug, fs::File, io::BufReader, num::NonZeroUsize, path::PathBuf, sync::Arc};\n@@ -221,10 +221,12 @@ fn command(\n                 blamed,\n             )),\n         },\n-        None => Err(ShellError::FileNotFoundCustom {\n-            msg: \"File without extension\".into(),\n-            span: spanned_file.span,\n-        }),\n+        None => Err(ShellError::Io(IoError::new_with_additional_context(\n+            std::io::ErrorKind::NotFound,\n+            spanned_file.span,\n+            PathBuf::from(spanned_file.item),\n+            \"File without extension\",\n+        ))),\n     }\n     .map(|value| PipelineData::Value(value, None))\n }\ndiff --git a/crates/nu_plugin_polars/src/dataframe/command/core/save/mod.rs b/crates/nu_plugin_polars/src/dataframe/command/core/save/mod.rs\nindex 8619ec9d424fe..775baca9905b8 100644\n--- a/crates/nu_plugin_polars/src/dataframe/command/core/save/mod.rs\n+++ b/crates/nu_plugin_polars/src/dataframe/command/core/save/mod.rs\n@@ -14,8 +14,8 @@ use crate::{\n use nu_path::expand_path_with;\n use nu_plugin::{EngineInterface, EvaluatedCall, PluginCommand};\n use nu_protocol::{\n-    Category, Example, LabeledError, PipelineData, ShellError, Signature, Span, Spanned,\n-    SyntaxShape, Type,\n+    shell_error::io::IoError, Category, Example, LabeledError, PipelineData, ShellError, Signature,\n+    Span, Spanned, SyntaxShape, Type,\n };\n use polars::error::PolarsError;\n \n@@ -204,10 +204,12 @@ fn command(\n                 blamed,\n             )),\n         },\n-        None => Err(ShellError::FileNotFoundCustom {\n-            msg: \"File without extension\".into(),\n-            span: spanned_file.span,\n-        }),\n+        None => Err(ShellError::Io(IoError::new_with_additional_context(\n+            std::io::ErrorKind::NotFound,\n+            spanned_file.span,\n+            spanned_file.item,\n+            \"File without extension\",\n+        ))),\n     }?;\n \n     Ok(PipelineData::empty())\ndiff --git a/src/ide.rs b/src/ide.rs\nindex 85023745fa9ad..6ce7e69c6fd83 100644\n--- a/src/ide.rs\n+++ b/src/ide.rs\n@@ -3,7 +3,9 @@ use nu_cli::NuCompleter;\n use nu_parser::{flatten_block, parse, FlatShape};\n use nu_protocol::{\n     engine::{EngineState, Stack, StateWorkingSet},\n-    report_shell_error, DeclId, ShellError, Span, Value, VarId,\n+    report_shell_error,\n+    shell_error::io::IoError,\n+    DeclId, ShellError, Span, Value, VarId,\n };\n use reedline::Completer;\n use serde_json::{json, Value as JsonValue};\n@@ -54,15 +56,16 @@ fn read_in_file<'a>(\n     file_path: &str,\n ) -> (Vec<u8>, StateWorkingSet<'a>) {\n     let file = std::fs::read(file_path)\n-        .into_diagnostic()\n-        .unwrap_or_else(|e| {\n-            report_shell_error(\n-                engine_state,\n-                &ShellError::FileNotFoundCustom {\n-                    msg: format!(\"Could not read file '{}': {:?}\", file_path, e.to_string()),\n-                    span: Span::unknown(),\n-                },\n-            );\n+        .map_err(|err| {\n+            ShellError::Io(IoError::new_with_additional_context(\n+                err.kind(),\n+                Span::unknown(),\n+                PathBuf::from(file_path),\n+                \"Could not read file\",\n+            ))\n+        })\n+        .unwrap_or_else(|err| {\n+            report_shell_error(engine_state, &err);\n             std::process::exit(1);\n         });\n \ndiff --git a/src/main.rs b/src/main.rs\nindex 0e7c656fc7878..6beae6de774ed 100644\n--- a/src/main.rs\n+++ b/src/main.rs\n@@ -428,7 +428,13 @@ fn main() -> Result<()> {\n         for plugin_filename in plugins {\n             // Make sure the plugin filenames are canonicalized\n             let filename = canonicalize_with(&plugin_filename.item, &init_cwd)\n-                .err_span(plugin_filename.span)\n+                .map_err(|err| {\n+                    nu_protocol::shell_error::io::IoError::new(\n+                        err.kind(),\n+                        plugin_filename.span,\n+                        PathBuf::from(&plugin_filename.item),\n+                    )\n+                })\n                 .map_err(ShellError::from)?;\n \n             let identity = PluginIdentity::new(&filename, None)\n", "instance_id": "nushell__nushell-14927", "clarity": 2, "difficulty": 0.75, "clarity_explanation": "The problem statement is mostly clear in describing the bug: the `rm` command in nushell returns a `directory_not_found` error for both non-existent directories and files, which is misleading. The goal is to either return a generic error or distinguish between files and directories. The issue is well-documented with reproducible steps, expected behavior, and configuration details. However, there are minor ambiguities, such as the lack of explicit mention of specific edge cases (e.g., symbolic links, permissions issues) and no clear specification on the preferred solution (generic error vs. distinct errors). Additionally, while the problem statement references related work on `glob_from`, it does not clarify how this bug fix should align with or depend on that work. Overall, the statement provides a solid foundation but misses some finer details that could aid in implementation.", "difficulty_explanation": "The difficulty of this problem is rated as hard (0.75) due to several factors. First, while the core issue is localized to error handling in the `rm` command, the provided code changes span multiple files and modules across the nushell codebase (e.g., `history_`, `keybindings_listen`, `config_files`, `eval_file`, etc.), indicating a broader refactoring effort to standardize I/O error handling. This requires understanding and modifying error propagation across various components, which increases the scope and depth of changes. Second, the technical concepts involved include Rust's error handling mechanisms, I/O operations, and nushell's custom error types (`ShellError`, `IoError`), as well as interactions with system-level operations (file metadata, permissions, etc.), necessitating a deep understanding of both the language and the codebase architecture. Third, the changes impact how errors are reported and handled globally, which could affect the system's behavior in subtle ways, requiring careful consideration of edge cases (e.g., non-UTF-8 paths, permission issues, interrupted operations) and potential regressions. While not at the highest difficulty level (e.g., implementing a new complex feature from scratch), this task demands significant expertise in Rust and nushell's internals, along with meticulous attention to detail to ensure consistency across the codebase. Therefore, a score of 0.75 reflects the challenging nature of this refactoring task.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "[Mono HTTP Server] Implement Git HTTP Protocol Authentication\nThe current mono Git HTTP server does not support authentication, so we have disabled HTTP push operations via a configuration. see issue #585 \r\nIn practice, when GitHub login is used, mono should send a GitHub token to the client for authentication during API calls such as info/refs. This would allow secure HTTP operations while enabling push functionality when authenticated via GitHub.\n", "patch": "diff --git a/Cargo.toml b/Cargo.toml\nindex 3af0eebe..58d3c982 100644\n--- a/Cargo.toml\n+++ b/Cargo.toml\n@@ -71,7 +71,7 @@ bstr = \"1.10.0\"\n colored = \"2.1.0\"\n idgenerator = \"2.0.0\"\n num_cpus = \"1.16.0\"\n-config = \"0.14.0\"\n+config = \"0.14.1\"\n shadow-rs = \"0.35.1\"\n reqwest = \"0.12.8\"\n lazy_static = \"1.5.0\"\n@@ -85,6 +85,8 @@ home = \"0.5.9\"\n ring = \"0.17.8\"\n cedar-policy = \"4.2.1\"\n secp256k1 = \"0.30.0\"\n+oauth2 = \"4.4.2\"\n+base64 = \"0.22.1\"\n \n [profile.release]\n debug = true\n\\ No newline at end of file\ndiff --git a/ceres/Cargo.toml b/ceres/Cargo.toml\nindex 471fd5b1..7ffc71a8 100644\n--- a/ceres/Cargo.toml\n+++ b/ceres/Cargo.toml\n@@ -31,4 +31,4 @@ async-trait = { workspace = true }\n rand = { workspace = true }\n sea-orm = { workspace = true }\n ring = { workspace = true }\n-hex ={ workspace = true}\n+hex = { workspace = true }\ndiff --git a/ceres/src/protocol/smart.rs b/ceres/src/protocol/smart.rs\nindex 4063ef19..a8ff3f26 100644\n--- a/ceres/src/protocol/smart.rs\n+++ b/ceres/src/protocol/smart.rs\n@@ -217,10 +217,10 @@ impl SmartProtocol {\n             .await?;\n \n         // do not block main thread here.\n-        let ph_clone = pack_handler.clone();\n+        let handler_clone = pack_handler.clone();\n         let unpack_result = tokio::task::spawn_blocking(move || {\n             let handle = tokio::runtime::Handle::current();\n-            handle.block_on(async { ph_clone.handle_receiver(receiver).await })\n+            handle.block_on(async { handler_clone.handle_receiver(receiver).await })\n         })\n         .await\n         .unwrap();\ndiff --git a/common/src/config.rs b/common/src/config.rs\nindex 0dc70931..d5d541f3 100644\n--- a/common/src/config.rs\n+++ b/common/src/config.rs\n@@ -210,6 +210,7 @@ impl Default for StorageConfig {\n pub struct MonoConfig {\n     pub import_dir: PathBuf,\n     pub disable_http_push: bool,\n+    pub enable_http_auth: bool,\n     pub admin: String,\n     pub root_dirs: Vec<String>,\n }\n@@ -219,6 +220,7 @@ impl Default for MonoConfig {\n         Self {\n             import_dir: PathBuf::from(\"/third-part\"),\n             disable_http_push: false,\n+            enable_http_auth: false,\n             admin: String::from(\"admin\"),\n             root_dirs: vec![\n                 \"third-part\".to_string(),\ndiff --git a/docker/config.toml b/docker/config.toml\nindex ce582638..6e65a3be 100644\n--- a/docker/config.toml\n+++ b/docker/config.toml\n@@ -56,6 +56,9 @@ import_dir = \"/third-part\"\n # The current mono Git HTTP server does not support authentication, so we provided a disabled operations here\n disable_http_push = false\n \n+# Support http authtication, login in with github and generate token before push\n+enable_http_auth = false\n+\n # Set System Admin in directory init, replace the admin's github username here\n admin = \"admin\"\n \n@@ -96,8 +99,8 @@ split_size = 20971520 # Default size is 20MB (20971520 bytes)\n github_client_id = \"\"\n github_client_secret = \"\"\n \n-# Used redirect to ui after login\n+# Used for redirect to ui after login, for example: https://console.gitmono.com\n ui_domain = \"https://console.gitmono.com\"\n \n-# Set .gitmono.com on Production\n+# Set your own domain here, for example: .gitmono.com\n cookie_domain = \".gitmono.com\"\n\\ No newline at end of file\ndiff --git a/jupiter/Cargo.toml b/jupiter/Cargo.toml\nindex 4d82aecd..b4f9a2fd 100644\n--- a/jupiter/Cargo.toml\n+++ b/jupiter/Cargo.toml\n@@ -32,6 +32,7 @@ serde_json = { workspace = true }\n idgenerator = { workspace = true }\n serde = { workspace = true }\n tokio = { workspace = true, features = [\"macros\"] }\n+uuid = { workspace = true }\n \n [dev-dependencies]\n tokio = { workspace = true, features = [\"macros\"] }\ndiff --git a/jupiter/callisto/src/access_token.rs b/jupiter/callisto/src/access_token.rs\nnew file mode 100644\nindex 00000000..ce7c2677\n--- /dev/null\n+++ b/jupiter/callisto/src/access_token.rs\n@@ -0,0 +1,19 @@\n+//! `SeaORM` Entity, @generated by sea-orm-codegen 1.1.0\n+\n+use sea_orm::entity::prelude::*;\n+\n+#[derive(Clone, Debug, PartialEq, DeriveEntityModel, Eq)]\n+#[sea_orm(table_name = \"access_token\")]\n+pub struct Model {\n+    #[sea_orm(primary_key, auto_increment = false)]\n+    pub id: i64,\n+    pub user_id: i64,\n+    #[sea_orm(column_type = \"Text\")]\n+    pub token: String,\n+    pub created_at: DateTime,\n+}\n+\n+#[derive(Copy, Clone, Debug, EnumIter, DeriveRelation)]\n+pub enum Relation {}\n+\n+impl ActiveModelBehavior for ActiveModel {}\ndiff --git a/jupiter/callisto/src/lib.rs b/jupiter/callisto/src/lib.rs\nindex 3884c3c7..462b8a34 100644\n--- a/jupiter/callisto/src/lib.rs\n+++ b/jupiter/callisto/src/lib.rs\n@@ -1,7 +1,8 @@\n-//! `SeaORM` Entity, @generated by sea-orm-codegen 1.0.0\n+//! `SeaORM` Entity, @generated by sea-orm-codegen 1.1.0\n \n pub mod prelude;\n \n+pub mod access_token;\n pub mod db_enums;\n pub mod git_blob;\n pub mod git_commit;\ndiff --git a/jupiter/callisto/src/prelude.rs b/jupiter/callisto/src/prelude.rs\nindex 4f479117..c937787d 100644\n--- a/jupiter/callisto/src/prelude.rs\n+++ b/jupiter/callisto/src/prelude.rs\n@@ -1,5 +1,6 @@\n //! `SeaORM` Entity, @generated by sea-orm-codegen 1.0.0\n \n+pub use crate::access_token::Entity as AccessToken;\n pub use crate::git_blob::Entity as GitBlob;\n pub use crate::git_commit::Entity as GitCommit;\n pub use crate::git_issue::Entity as GitIssue;\ndiff --git a/jupiter/src/storage/user_storage.rs b/jupiter/src/storage/user_storage.rs\nindex a0fddaee..4287eca6 100644\n--- a/jupiter/src/storage/user_storage.rs\n+++ b/jupiter/src/storage/user_storage.rs\n@@ -4,8 +4,9 @@ use sea_orm::{\n     ActiveModelTrait, ColumnTrait, DatabaseConnection, EntityTrait, IntoActiveModel, ModelTrait,\n     QueryFilter,\n };\n+use uuid::Uuid;\n \n-use callisto::{ssh_keys, user};\n+use callisto::{access_token, ssh_keys, user};\n use common::{errors::MegaError, utils::generate_id};\n \n #[derive(Clone)]\n@@ -36,6 +37,14 @@ impl UserStorage {\n         Ok(res)\n     }\n \n+    pub async fn find_user_by_name(&self, name: &str) -> Result<Option<user::Model>, MegaError> {\n+        let res = user::Entity::find()\n+            .filter(user::Column::Name.eq(name))\n+            .one(self.get_connection())\n+            .await?;\n+        Ok(res)\n+    }\n+\n     pub async fn save_user(&self, user: user::Model) -> Result<(), MegaError> {\n         let a_model = user.into_active_model();\n         a_model.insert(self.get_connection()).await.unwrap();\n@@ -92,4 +101,60 @@ impl UserStorage {\n             .await?;\n         Ok(res)\n     }\n+\n+    pub async fn generate_token(&self, user_id: i64) -> Result<String, MegaError> {\n+        let token_str = Uuid::new_v4().to_string();\n+        let model = access_token::Model {\n+            id: generate_id(),\n+            user_id,\n+            token: token_str.clone(),\n+            created_at: chrono::Utc::now().naive_utc(),\n+        };\n+        let a_model = model.into_active_model();\n+        a_model.insert(self.get_connection()).await.unwrap();\n+        Ok(token_str.to_owned())\n+    }\n+\n+    pub async fn delete_token(&self, user_id: i64, id: i64) -> Result<(), MegaError> {\n+        let res = access_token::Entity::find()\n+            .filter(access_token::Column::Id.eq(id))\n+            .filter(access_token::Column::UserId.eq(user_id))\n+            .one(self.get_connection())\n+            .await?;\n+        if let Some(model) = res {\n+            model.delete(self.get_connection()).await?;\n+        }\n+        Ok(())\n+    }\n+\n+    pub async fn list_token(&self, user_id: i64) -> Result<Vec<access_token::Model>, MegaError> {\n+        let res = access_token::Entity::find()\n+            .filter(access_token::Column::UserId.eq(user_id))\n+            .all(self.get_connection())\n+            .await?;\n+        Ok(res)\n+    }\n+\n+    pub async fn check_token(&self, user_id: i64, token: &str) -> Result<bool, MegaError> {\n+        let res = access_token::Entity::find()\n+            .filter(access_token::Column::UserId.eq(user_id))\n+            .filter(access_token::Column::Token.eq(token))\n+            .one(self.get_connection())\n+            .await?;\n+        match res {\n+            Some(_) => Ok(true),\n+            None => Ok(false),\n+        }\n+    }\n+}\n+\n+#[cfg(test)]\n+mod test {\n+    use uuid::Uuid;\n+\n+    #[test]\n+    fn token_format() {\n+        let uuid = Uuid::new_v4().to_string();\n+        println!(\"{:?}\", uuid);\n+    }\n }\ndiff --git a/mega/config.toml b/mega/config.toml\nindex 3adfdc10..c41b0438 100644\n--- a/mega/config.toml\n+++ b/mega/config.toml\n@@ -56,6 +56,9 @@ import_dir = \"/third-part\"\n # The current mono Git HTTP server does not support authentication, so we provided a disabled operations here\n disable_http_push = false\n \n+# Support http authtication, login in with github and generate token before push\n+enable_http_auth = false\n+\n # Set System Admin in directory init, replace the admin's github username here\n admin = \"admin\"\n \ndiff --git a/mono/Cargo.toml b/mono/Cargo.toml\nindex 4f5dfa12..35141795 100644\n--- a/mono/Cargo.toml\n+++ b/mono/Cargo.toml\n@@ -53,7 +53,8 @@ ed25519-dalek = { workspace = true, features = [\"pkcs8\"] }\n lazy_static = { workspace = true }\n ctrlc = { workspace = true }\n shadow-rs = { workspace = true }\n-oauth2 = \"4.4.2\"\n+oauth2 = { workspace = true }\n+base64 = { workspace = true }\n async-session = \"3.0.0\"\n http = \"1.1.0\"\n cedar-policy = { workspace = true }\n@@ -62,3 +63,9 @@ cedar-policy = { workspace = true }\n \n [build-dependencies]\n shadow-rs = { workspace = true }\n+\n+# [target.'cfg(not(target_env = \"msvc\"))'.dependencies]\n+# tikv-jemallocator = \"0.6\"\n+\n+# [target.'cfg(not(target_env = \"msvc\"))'.dependencies]\n+# jemallocator = {version = \"0.5.4\", features = [\"debug\", \"profiling\"]}\n\\ No newline at end of file\ndiff --git a/mono/config.toml b/mono/config.toml\nindex 69134d01..316dc5fb 100644\n--- a/mono/config.toml\n+++ b/mono/config.toml\n@@ -56,6 +56,9 @@ import_dir = \"/third-part\"\n # The current mono Git HTTP server does not support authentication, so we provided a disabled operations here\n disable_http_push = false\n \n+# Support http authtication, login in with github and generate token before push\n+enable_http_auth = false\n+\n # Set System Admin in directory init, replace the admin's github username here\n admin = \"admin\"\n \n@@ -96,8 +99,8 @@ split_size = 20971520 # Default size is 20MB (20971520 bytes)\n github_client_id = \"\"\n github_client_secret = \"\"\n \n-# Used redirect to ui after login\n+# Used for redirect to ui after login, for example: https://console.gitmono.com\n ui_domain = \"http://localhost:3000\"\n \n-# Set .gitmono.com on Production\n+# Set your own domain here, for example: .gitmono.com\n cookie_domain = \"localhost\"\n\\ No newline at end of file\ndiff --git a/mono/src/api/user/model.rs b/mono/src/api/user/model.rs\nindex d44f29b4..15d3f7ad 100644\n--- a/mono/src/api/user/model.rs\n+++ b/mono/src/api/user/model.rs\n@@ -1,4 +1,4 @@\n-use callisto::ssh_keys;\n+use callisto::{access_token, ssh_keys};\n use chrono::NaiveDateTime;\n use serde::{Deserialize, Serialize};\n \n@@ -29,6 +29,25 @@ impl From<ssh_keys::Model> for ListSSHKey {\n     }\n }\n \n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct ListToken {\n+    pub id: i64,\n+    pub token: String,\n+    pub created_at: NaiveDateTime,\n+}\n+\n+impl From<access_token::Model> for ListToken {\n+    fn from(value: access_token::Model) -> Self {\n+        let mut mask_token =  value.token;\n+        mask_token.replace_range(7..32, \"-******-\");\n+        Self {\n+            id: value.id,\n+            token: mask_token,\n+            created_at: value.created_at,\n+        }\n+    }\n+}\n+\n #[derive(Debug, Serialize, Deserialize)]\n pub struct RepoPermissions {\n     pub admin: Vec<String>,\ndiff --git a/mono/src/api/user/user_router.rs b/mono/src/api/user/user_router.rs\nindex c40e2c11..ebb610a4 100644\n--- a/mono/src/api/user/user_router.rs\n+++ b/mono/src/api/user/user_router.rs\n@@ -13,6 +13,7 @@ use crate::api::user::model::AddSSHKey;\n use crate::api::user::model::ListSSHKey;\n use crate::api::MonoApiServiceState;\n use crate::api::{error::ApiError, oauth::model::LoginUser, util};\n+use crate::api::user::model::ListToken;\n \n pub fn routers() -> Router<MonoApiServiceState> {\n     Router::new()\n@@ -20,6 +21,9 @@ pub fn routers() -> Router<MonoApiServiceState> {\n         .route(\"/user/ssh\", get(list_key))\n         .route(\"/user/ssh\", post(add_key))\n         .route(\"/user/ssh/:key_id/delete\", post(remove_key))\n+        .route(\"/user/token/generate\", post(generate_token))\n+        .route(\"/user/token/list\", get(list_token))\n+        .route(\"/user/token/:key_id/delete\", post(remove_token))\n         .route(\"/repo-permissions\", get(repo_permissions))\n }\n \n@@ -96,12 +100,70 @@ async fn list_key(\n     Ok(Json(res))\n }\n \n+async fn generate_token(\n+    user: LoginUser,\n+    state: State<MonoApiServiceState>,\n+) -> Result<Json<CommonResult<String>>, ApiError> {\n+    let res = state\n+        .context\n+        .services\n+        .user_storage\n+        .generate_token(user.user_id)\n+        .await;\n+    let res = match res {\n+        Ok(data) => CommonResult::success(Some(data)),\n+        Err(err) => CommonResult::failed(&err.to_string()),\n+    };\n+    Ok(Json(res))\n+}\n+\n+\n+async fn remove_token(\n+    user: LoginUser,\n+    state: State<MonoApiServiceState>,\n+    Path(key_id): Path<i64>,\n+) -> Result<Json<CommonResult<String>>, ApiError> {\n+    let res = state\n+        .context\n+        .services\n+        .user_storage\n+        .delete_token(user.user_id, key_id)\n+        .await;\n+    let res = match res {\n+        Ok(_) => CommonResult::success(None),\n+        Err(err) => CommonResult::failed(&err.to_string()),\n+    };\n+    Ok(Json(res))\n+}\n+\n+\n+async fn list_token(\n+    user: LoginUser,\n+    state: State<MonoApiServiceState>,\n+) -> Result<Json<CommonResult<Vec<ListToken>>>, ApiError> {\n+    let res = state\n+        .context\n+        .services\n+        .user_storage\n+        .list_token(user.user_id)\n+        .await;\n+    let res = match res {\n+        Ok(data) => {\n+            let res = data.into_iter().map(|x| x.into()).collect();\n+            CommonResult::success(Some(res))\n+        },\n+        Err(err) => CommonResult::failed(&err.to_string()),\n+    };\n+    Ok(Json(res))\n+}\n+\n async fn repo_permissions(\n     Query(query): Query<HashMap<String, String>>,\n     state: State<MonoApiServiceState>,\n ) -> Result<Json<CommonResult<String>>, ApiError> {\n     let path = std::path::PathBuf::from(query.get(\"path\").unwrap());\n     let _ = util::get_entitystore(path, state).await;\n+    // TODO\n     Ok(Json(CommonResult::success(Some(String::new()))))\n }\n \ndiff --git a/mono/src/git_protocol/AUTHENTICATION.MD b/mono/src/git_protocol/AUTHENTICATION.MD\nnew file mode 100644\nindex 00000000..724f3856\n--- /dev/null\n+++ b/mono/src/git_protocol/AUTHENTICATION.MD\n@@ -0,0 +1,101 @@\n+## Git HTTP Request Authentication Process\n+\n+When Git initiates an HTTP request, the authentication process primarily involves how credentials are passed to verify the user\u2019s identity, ensuring access to remote Git repositories. Below is an overview of the authentication process when Git communicates over HTTP/HTTPS.\n+\n+### 1. Authentication Methods\n+\n+Git supports several common HTTP/HTTPS authentication methods:\n+\n+\t\u2022\tBasic Authentication: Username and password/token are sent in the Authorization header encoded in Base64.\n+\t\u2022\tPersonal Access Token (PAT): Typically used as a replacement for username and password, especially on services like GitHub, GitLab, etc.\n+\t\u2022\tOAuth: Allows for authentication using OAuth tokens, provided the service provider supports it.\n+\n+Usually, Git uses the Authorization header to carry authentication information, but with HTTPS encryption, the credentials are secure during transmission.\n+\n+### 2. Authentication Process\n+\n+(1) Initial Request: No Authentication Information\n+\n+When the Git client first sends an HTTP request to a remote repository, it typically does not immediately include the Authorization header. It sends a standard request to ask the server if the repository is available.\n+\n+Example request (without authentication):\n+\n+```http\n+GET /path/to/repo.git/info/refs?service=git-upload-pack HTTP/1.1\n+Host: git.gitmono.com\n+User-Agent: git/2.46.0\n+```\n+\n+(2) Server Response: Requires Authentication\n+\n+If the remote repository requires authentication to access, the server will respond with a 401 Unauthorized, including a WWW-Authenticate header, indicating that the client needs to authenticate.\n+\n+Example response:\n+\n+```http\n+HTTP/1.1 401 Unauthorized\n+WWW-Authenticate: Basic realm=\"Mega\"\n+```\n+\n+This informs the Git client that it needs to use Basic Authentication or another supported authentication method.\n+\n+(3) Client Sends Authentication Information\n+\n+The Git client will respond to the server\u2019s 401 Unauthorized by looking for locally stored credentials (like username and password or Personal Access Token) or prompting the user for credential input. It will then resend the request, this time including the Authorization header with the authentication information.\n+\n+In Basic Authentication, Git will combine the username and password/token into a username:password format, encode it in Base64, and place it in the Authorization header.\n+\n+Example request:\n+\n+```http\n+GET /path/to/repo.git/info/refs?service=git-upload-pack HTTP/1.1\n+Host: git.gitmono.com\n+User-Agent: git/2.46.0\n+Authorization: Basic dXNlcm5hbWU6dG9rZW4=\n+```\n+\n+Here, dXNlcm5hbWU6dG9rZW4= is the Base64 encoded username:token.\n+\n+(4) Server Validates Authentication Information\n+\n+The server will check the credentials in the Authorization header it received:\n+\n+\t\u2022\tIf authentication is successful, the server will return 200 OK and continue with the Git operation (like pull, push, etc.).\n+\t\u2022\tIf authentication fails, the server will return 401 Unauthorized and may prompt the user to re-enter their credentials.\n+\n+(5) Request Ends\n+\n+Once the credential verification is successful, the Git client can interact with the remote repository. Credentials are typically cached for the session to avoid requiring re-authentication with each request.\n+\n+### 3. Credential Storage and Management\n+\n+(1) Credential Storage\n+\n+To avoid having to manually enter usernames and passwords each time, Git provides various credential storage methods:\n+\n+\t\u2022\tCredential Helper: Git\u2019s credential.helper allows users to save and cache credentials for future requests automatically.\n+\t\u2022\tcredential.helper=cache: Caches credentials for a period.\n+\t\u2022\tcredential.helper=osxkeychain: Uses the system\u2019s keychain service to store credentials on macOS.\n+\t\u2022\tcredential.helper=store: Saves credentials in plain text in the user\u2019s directory (not recommended).\n+\n+git config --global credential.helper cache\n+\n+### 4. How to Debug Authentication Requests\n+\n+The following environment variables can be used to debug the Git HTTP request authentication process:\n+\n+\t\u2022\tGIT_CURL_VERBOSE=1: Used for debugging Git HTTP requests, including HTTPS requests and authentication processes.\n+\t\u2022\tAlthough the Authorization header will be hidden for security reasons, you can check the response status codes (like 401 Unauthorized) to determine if authentication is successful.\n+\t\u2022\tGIT_TRACE=1: Used for debugging Git\u2019s internal operations, including credential lookup and handling.\n+\n+Example Debug Command:\n+\n+```bash\n+GIT_CURL_VERBOSE=1 GIT_TRACE=1 git push\n+```\n+\n+### 5. Common Issues\n+\n+\t\u2022\tCredentials Not Saved: If you find that Git prompts for a username and password every time, check whether credential.helper is configured correctly.\n+\t\u2022\tAuthorization Header Not Displayed: For security reasons, the Git client does not display the full Authorization header in debug output, but it will send the correct header.\n+\t\u2022\tToken Expiration: If using a Personal Access Token (PAT), ensure that the token has not expired and has sufficient permissions for the requested Git operations.\ndiff --git a/mono/src/git_protocol/http.rs b/mono/src/git_protocol/http.rs\nindex 1cd092e6..36b4f365 100644\n--- a/mono/src/git_protocol/http.rs\n+++ b/mono/src/git_protocol/http.rs\n@@ -3,8 +3,12 @@ use std::convert::Infallible;\n use anyhow::Result;\n use axum::body::Body;\n use axum::http::{HeaderValue, Request, Response};\n+use base64::engine::general_purpose;\n+use base64::prelude::*;\n use bytes::{Bytes, BytesMut};\n use futures::{stream, TryStreamExt};\n+use http::HeaderMap;\n+use jupiter::context::Context;\n use tokio::io::AsyncReadExt;\n use tokio_stream::StreamExt;\n \n@@ -19,9 +23,15 @@ use common::model::InfoRefsParams;\n // where $servicename MUST be the service name the client wishes to contact to complete the operation.\n // The request MUST NOT contain additional query parameters.\n pub async fn git_info_refs(\n+    req: Request<Body>,\n     params: InfoRefsParams,\n     mut pack_protocol: SmartProtocol,\n ) -> Result<Response<Body>, ProtocolError> {\n+    if pack_protocol.context.config.monorepo.enable_http_auth\n+        && !http_auth(req.headers(), &pack_protocol.context).await\n+    {\n+        return auth_failed();\n+    }\n     let service_name = params.service.unwrap();\n     pack_protocol.service_type = Some(service_name.parse::<ServiceType>().unwrap());\n \n@@ -37,6 +47,47 @@ pub async fn git_info_refs(\n     Ok(response)\n }\n \n+async fn http_auth(header: &HeaderMap<HeaderValue>, context: &Context) -> bool {\n+    let stg = context.services.user_storage.clone();\n+    for (k, v) in header {\n+        if k == http::header::AUTHORIZATION {\n+            let decoded = general_purpose::STANDARD\n+                .decode(\n+                    v.to_str()\n+                        .unwrap()\n+                        .strip_prefix(\"Basic \")\n+                        .unwrap()\n+                        .as_bytes(),\n+                )\n+                .unwrap();\n+            let credentials = String::from_utf8(decoded).unwrap_or_default();\n+            let mut parts = credentials.splitn(2, ':');\n+            let username = parts.next().unwrap_or(\"\");\n+            let password = parts.next().unwrap_or(\"\");\n+            tracing::debug!(\"{}, {}\", username, password);\n+            match stg.find_user_by_name(username).await.unwrap() {\n+                Some(user) => {\n+                    return stg.check_token(user.id, password).await.unwrap();\n+                }\n+                None => return false,\n+            }\n+        }\n+    }\n+    false\n+}\n+\n+fn auth_failed() -> Result<Response<Body>, ProtocolError> {\n+    let resp = Response::builder()\n+        .status(401)\n+        .header(\n+            http::header::WWW_AUTHENTICATE,\n+            HeaderValue::from_static(\"Basic realm=Mega\"),\n+        )\n+        .body(Body::empty())\n+        .unwrap();\n+    Ok(resp)\n+}\n+\n /// # Handles a Git upload pack request and prepares the response.\n ///\n /// The function takes a `req` parameter representing the HTTP request received and a `pack_protocol`\n@@ -125,6 +176,11 @@ pub async fn git_receive_pack(\n     req: Request<Body>,\n     mut pack_protocol: SmartProtocol,\n ) -> Result<Response<Body>, ProtocolError> {\n+    if pack_protocol.context.config.monorepo.enable_http_auth\n+        && !http_auth(req.headers(), &pack_protocol.context).await\n+    {\n+        return auth_failed();\n+    }\n     // Convert the request body into a data stream.\n     let mut data_stream = req.into_body().into_data_stream();\n     let mut report_status = Bytes::new();\ndiff --git a/mono/src/server/https_server.rs b/mono/src/server/https_server.rs\nindex fd1e1f13..d391ed6a 100644\n--- a/mono/src/server/https_server.rs\n+++ b/mono/src/server/https_server.rs\n@@ -133,7 +133,6 @@ pub async fn start_http(context: Context, options: HttpOptions) {\n ///   - POST       end of `Regex::new(r\"/git-upload-pack$\")`\n ///   - POST       end of `Regex::new(r\"/git-receive-pack$\")`\n pub async fn app(context: Context, host: String, port: u16, common: CommonOptions) -> Router {\n-\n     let state = AppState {\n         host,\n         port,\n@@ -183,6 +182,7 @@ pub async fn get_method_router(\n     state: State<AppState>,\n     Query(params): Query<InfoRefsParams>,\n     uri: Uri,\n+    req: Request<Body>,\n ) -> Result<Response<Body>, ProtocolError> {\n     if INFO_REFS_REGEX.is_match(uri.path()) {\n         let pack_protocol = SmartProtocol::new(\n@@ -190,7 +190,7 @@ pub async fn get_method_router(\n             state.context.clone(),\n             TransportProtocol::Http,\n         );\n-        crate::git_protocol::http::git_info_refs(params, pack_protocol).await\n+        crate::git_protocol::http::git_info_refs(req, params, pack_protocol).await\n     } else {\n         Err(ProtocolError::NotFound(\n             \"Operation not supported\".to_owned(),\ndiff --git a/moon/src/app/(dashboard)/application-layout.tsx b/moon/src/app/(dashboard)/application-layout.tsx\nindex fc98b0b3..9e36a20b 100644\n--- a/moon/src/app/(dashboard)/application-layout.tsx\n+++ b/moon/src/app/(dashboard)/application-layout.tsx\n@@ -31,6 +31,7 @@ import {\n   PlusIcon,\n   ShieldCheckIcon,\n   UserCircleIcon,\n+  KeyIcon,\n } from '@heroicons/react/16/solid'\n import {\n   Cog6ToothIcon,\n@@ -51,6 +52,10 @@ function AccountDropdownMenu({ anchor }: { anchor: 'top start' | 'bottom end' })\n         <UserCircleIcon />\n         <DropdownLabel>My account</DropdownLabel>\n       </DropdownItem>\n+      <DropdownItem href=\"/user/token\">\n+        <KeyIcon />\n+        <DropdownLabel>Tokens</DropdownLabel>\n+      </DropdownItem>\n       <DropdownDivider />\n       <DropdownItem href=\"#\">\n         <ShieldCheckIcon />\ndiff --git a/moon/src/app/(dashboard)/user/token/page.tsx b/moon/src/app/(dashboard)/user/token/page.tsx\nnew file mode 100644\nindex 00000000..c42e90a7\n--- /dev/null\n+++ b/moon/src/app/(dashboard)/user/token/page.tsx\n@@ -0,0 +1,132 @@\n+'use client'\n+\n+import { Divider } from '@/components/catalyst/divider'\n+import { Heading } from '@/components/catalyst/heading'\n+import { useEffect, useState } from 'react'\n+import { Flex, Button, message, List, Modal } from \"antd\";\n+import {\n+    KeyIcon,\n+} from '@heroicons/react/20/solid'\n+import { format } from 'date-fns'\n+import copy from 'copy-to-clipboard';\n+\n+\n+interface TokenItem {\n+    id: number,\n+    token: string,\n+    created_at: string,\n+}\n+\n+export default function KeysPage() {\n+    const [keyList, setKeyList] = useState([]);\n+    const [messageApi, contextHolder] = message.useMessage();\n+    const [isModalOpen, setIsModalOpen] = useState(false);\n+    const [token, setToken] = useState(\"\");\n+\n+    const error = () => {\n+        messageApi.open({\n+            type: 'error',\n+            content: 'Delete failed!',\n+        });\n+    };\n+    const success = () => {\n+        messageApi.open({\n+            type: 'success',\n+            content: 'Delete success!',\n+        });\n+    };\n+\n+    const generateToken = async () => {\n+        try {\n+            const res = await fetch(`/api/user/token`, {\n+                method: 'POST',\n+            });\n+            const response = await res.json();\n+            const token = response.data.data;\n+            setToken(token);\n+        } catch (error) {\n+            console.error('Error fetching data:', error);\n+        }\n+    };\n+\n+    const showModal = () => {\n+        setIsModalOpen(true);\n+        generateToken();\n+    };\n+\n+    const handleOk = () => {\n+        setIsModalOpen(false);\n+        copy(token)\n+        fetchToken()\n+    };\n+\n+    const handleCancel = () => {\n+        setIsModalOpen(false);\n+    };\n+\n+    const fetchToken = async () => {\n+        try {\n+            const res = await fetch(`/api/user/token`);\n+            const response = await res.json();\n+            const keyList = response.data.data;\n+            setKeyList(keyList);\n+        } catch (error) {\n+            console.error('Error fetching data:', error);\n+        }\n+    };\n+\n+    useEffect(() => {\n+        fetchToken();\n+    }, []);\n+\n+    const delete_ssh_key = async (id) => {\n+        const res = await fetch(`/api/user/token/${id}/delete`, {\n+            method: 'POST',\n+        });\n+        if (res.ok) {\n+            success();\n+            fetchToken();\n+        } else {\n+            error();\n+        }\n+    }\n+\n+    return (\n+        <>\n+            {contextHolder}\n+            <Heading>Access Tokens</Heading>\n+            <Flex justify={'flex-end'} >\n+                <Button style={{ backgroundColor: '#428646' }} onClick={showModal} >Generate Token</Button>\n+            </Flex>\n+            <Modal title=\"Generated Token, Only show once, Please Copy it before close\" open={isModalOpen} onOk={handleOk} onCancel={handleCancel}>\n+                <p>{token}</p>\n+            </Modal>\n+            <Divider className=\"my-10 mt-6\" />\n+            This is a list of access token associated with your account. Remove any keys that you do not recognize.\n+            <br />\n+            <List\n+                size=\"large\"\n+                bordered\n+                dataSource={keyList as TokenItem[]}\n+                renderItem={(item) =>\n+                    <List.Item>\n+                        <List.Item.Meta\n+                            avatar={\n+                                <KeyIcon className=\"size-6\" />\n+                            }\n+                            title={\n+                                <>\n+                                    {item.token}\n+                                </>\n+                            }\n+                            description={`Generated on ${format(new Date(item.created_at), \"MMM dd,yyyy\")}`}\n+                        />\n+                        <Button danger onClick={() => delete_ssh_key(item.id)} >Delete</Button>\n+                    </List.Item>}\n+            />\n+        </>\n+\n+    )\n+}\n+\n+\ndiff --git a/moon/src/app/api/user/token/[id]/delete/route.ts b/moon/src/app/api/user/token/[id]/delete/route.ts\nnew file mode 100644\nindex 00000000..d8acad72\n--- /dev/null\n+++ b/moon/src/app/api/user/token/[id]/delete/route.ts\n@@ -0,0 +1,26 @@\n+import { verifySession } from '@/app/lib/dal'\n+import { NextResponse } from 'next/server'\n+\n+const endpoint = process.env.MEGA_INTERNAL_HOST;\n+\n+export async function POST(request: Request, { params }: { params: { id: string } }) {\n+    const session = await verifySession()\n+    if (!session) return Response.json({})\n+\n+    const cookieHeader = request.headers.get('cookie') || '';\n+\n+    const res = await fetch(`${endpoint}/api/v1/user/token/${params.id}/delete`, {\n+        headers: {\n+            'Cookie': cookieHeader,\n+        },\n+        method: 'POST'\n+    })\n+    if (!res.ok) {\n+        return new NextResponse(\n+            JSON.stringify({ error: res.statusText }),\n+            { status: res.status }\n+        );\n+    }\n+    const data = await res.json()\n+    return Response.json({ data })\n+}\n\\ No newline at end of file\ndiff --git a/moon/src/app/api/user/token/route.ts b/moon/src/app/api/user/token/route.ts\nnew file mode 100644\nindex 00000000..aa324822\n--- /dev/null\n+++ b/moon/src/app/api/user/token/route.ts\n@@ -0,0 +1,51 @@\n+import { verifySession } from '@/app/lib/dal'\n+import { NextResponse, type NextRequest } from 'next/server'\n+export const revalidate = 0\n+export const dynamic = 'force-dynamic' // defaults to auto\n+\n+const endpoint = process.env.MEGA_INTERNAL_HOST;\n+\n+export async function POST(request: NextRequest) {\n+    const session = await verifySession()\n+    if (!session) return Response.json({})\n+\n+    const cookieHeader = request.headers.get('cookie') || '';\n+\n+    const res = await fetch(`${endpoint}/api/v1/user/token/generate`, {\n+        headers: {\n+            'Cookie': cookieHeader,\n+            'Content-Type': 'application/json',\n+        },\n+        method: 'POST',\n+    })\n+    if (!res.ok) {\n+        return new NextResponse(\n+            JSON.stringify({ error: res.statusText }),\n+            { status: res.status }\n+        );\n+    }\n+    const data = await res.json()\n+    return Response.json({ data })\n+}\n+\n+\n+export async function GET(request: NextRequest) { \n+    const session = await verifySession()\n+    if (!session) return Response.json({})\n+\n+    const cookieHeader = request.headers.get('cookie') || '';\n+\n+    const res = await fetch(`${endpoint}/api/v1/user/token/list`, {\n+        headers: {\n+            'Cookie': cookieHeader,\n+        },\n+    })\n+    if (!res.ok) {\n+        return new NextResponse(\n+            JSON.stringify({ error: res.statusText }),\n+            { status: res.status }\n+        );\n+    }\n+    const data = await res.json()\n+    return Response.json({ data })\n+}\n\\ No newline at end of file\ndiff --git a/moon/src/middleware.ts b/moon/src/middleware.ts\nindex 5385caea..6b85b84d 100644\n--- a/moon/src/middleware.ts\n+++ b/moon/src/middleware.ts\n@@ -2,7 +2,7 @@ import { NextRequest, NextResponse } from 'next/server'\n import { cookies } from 'next/headers'\n \n // 1. Specify protected and public routes\n-const protectedRoutes = ['/user/keys/add', '/user/keys']\n+const protectedRoutes = ['/user/keys/add', '/user/keys', 'user/token']\n const publicRoutes = ['/login', '/']\n \n export default async function middleware(req: NextRequest) {\ndiff --git a/saturn/mega_policies.cedar b/saturn/mega_policies.cedar\nindex da06f2c7..bb69a2c6 100644\n--- a/saturn/mega_policies.cedar\n+++ b/saturn/mega_policies.cedar\n@@ -51,7 +51,6 @@ permit (\n )\n when { principal in resource.admins };\n \n-\n // root admin can do anything\n permit (principal, action, resource)\n-when { principal == User::\"genedna\" };\n\\ No newline at end of file\n+when { principal == User::\"genedna\" || principal == User::\"benjamin-747\" };\n\\ No newline at end of file\n", "instance_id": "web3infra-foundation__mega-656", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "\nThe problem statement is mostly clear in its intent to implement Git HTTP Protocol Authentication for a mono HTTP server, specifically to enable secure HTTP operations and push functionality using GitHub tokens. It references a related issue (#585) and provides a high-level goal of sending a GitHub token to the client for authentication during API calls like `info/refs`. However, there are minor ambiguities and missing details that prevent it from being comprehensive. For instance, the problem statement does not explicitly define the expected input/output formats for the authentication process, nor does it specify how the GitHub token should be obtained, stored, or validated beyond a general mention of GitHub login. Additionally, there are no examples or detailed constraints provided (e.g., token expiration, rate limiting, or specific security requirements). While the code changes provide context, the problem statement itself lacks specifics on edge cases or error handling requirements, which are critical for authentication systems. Thus, it earns a score of 2 (Mostly Clear) due to its valid and generally understandable goal but with minor details missing.\n", "difficulty_explanation": "\nI assign a difficulty score of 0.65, placing this problem in the \"Hard\" range (0.6-0.8), due to the following factors:\n\n1. **Scope and Depth of Code Changes**: The code changes span multiple files and modules across the codebase, including configuration updates (`config.toml`), backend logic in Rust (`mono/src/git_protocol/http.rs`, `jupiter/src/storage/user_storage.rs`), database schema additions (`jupiter/callisto/src/access_token.rs`), API endpoints (`mono/src/api/user/user_router.rs`), and even frontend UI components (`moon/src/app/(dashboard)/user/token/page.tsx`). This indicates a broad impact on the system, requiring modifications in authentication logic, token management, and user interface. While the changes do not appear to fundamentally alter the system's architecture, they involve integrating a new authentication flow across backend and frontend, which adds to the complexity. The amount of code change is moderate but distributed, necessitating a good understanding of the interactions between components.\n\n2. **Number of Technical Concepts**: Solving this problem requires familiarity with several technical concepts and tools. These include Rust programming (async/await with Tokio, SeaORM for database operations), HTTP protocol handling (Basic Authentication, headers like `Authorization` and `WWW-Authenticate`), OAuth2 and token-based authentication, Base64 encoding/decoding, database schema design for token storage, and frontend development with React/Next.js (including API integration and UI updates). Additionally, domain-specific knowledge of Git HTTP protocols (`git-upload-pack`, `git-receive-pack`, `info/refs`) is necessary to correctly implement the authentication checks at the right points in the request flow. While none of these concepts are extraordinarily advanced individually, the combination and integration across layers increase the cognitive load.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes and the nature of authentication systems imply several that must be handled. These include invalid or expired tokens, missing or malformed `Authorization` headers, concurrent token generation/deletion, and ensuring token security (e.g., masking tokens in UI as seen in the code). The code introduces error handling for authentication failures (returning 401 Unauthorized) and token validation, but additional considerations like rate limiting, token revocation on user logout, or handling compromised tokens are not addressed and would need to be considered for a robust solution. These edge cases add moderate complexity to the implementation.\n\n4. **Overall Complexity and Impact**: The task requires a deep understanding of the existing codebase to integrate authentication without breaking existing functionality (e.g., ensuring non-authenticated requests are handled appropriately when authentication is disabled). The implementation impacts critical security aspects of the system, as authentication is a core component of secure operations. While it does not involve advanced algorithms or system-level redesigns (which would push it into the \"Very Hard\" range), the cross-module changes, security implications, and need for careful error handling make it a challenging problem that requires experience and attention to detail.\n\nIn summary, this problem is rated at 0.65 due to its broad scope across multiple components, the need to understand and integrate several technical concepts, and the moderate complexity of edge cases and security considerations. It is a hard problem that demands a solid grasp of the codebase and authentication principles but does not reach the level of very hard challenges involving novel algorithms or deep system redesigns.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Async UDFs on subqueries produces runtime error\nA query like this:\r\n\r\n```sql\r\nselect new_udf(out.seconds) from (\r\nselect timestamp_struct as out\r\nfrom (\r\n    select\r\n        header.ts as timestamp_struct\r\n    from nested2\r\n));\r\n```\r\n\r\nwith any async UDF, for example\r\n\r\n```rust\r\nuse arroyo_udf_plugin::udf;\r\n\r\n#[udf]\r\nasync fn new_udf(x: i64) -> i64 {\r\n    x\r\n}\r\n```\r\n\r\nProduces a runtime error:\r\n\r\n```\r\n2024-11-01T23:04:54.758632Z  INFO arroyo_controller::states: state transition job_id=\"job_q5WOEkQvWV\" from=\"Scheduling\" to=\"Running\" duration_ms=167\r\n2024-11-01T23:04:56.711565Z  INFO arroyo_api::jobs: Subscribed to output\r\n2024-11-01T23:05:00.698013Z ERROR arroyo_server_common: panicked at crates/arroyo-worker/src/arrow/async_udf.rs:299:22:\r\ncalled `Result::unwrap()` on an `Err` value: Execution(\"get indexed field seconds not found in struct\") panic.file=\"crates/arroyo-worker/src/arrow/async_udf.rs\" panic.line=299 panic.column=22\r\n```\n", "patch": "diff --git a/crates/arroyo-planner/src/extension/mod.rs b/crates/arroyo-planner/src/extension/mod.rs\nindex 161a9de21..8213d0bae 100644\n--- a/crates/arroyo-planner/src/extension/mod.rs\n+++ b/crates/arroyo-planner/src/extension/mod.rs\n@@ -15,15 +15,9 @@ use datafusion::logical_expr::{\n };\n use datafusion_proto::physical_plan::to_proto::serialize_physical_expr;\n use datafusion_proto::physical_plan::DefaultPhysicalExtensionCodec;\n-use datafusion_proto::protobuf::ProjectionNode;\n use prost::Message;\n use watermark_node::WatermarkNode;\n \n-use crate::builder::{NamedNode, Planner};\n-use crate::schemas::{add_timestamp_field, has_timestamp_field};\n-use crate::{fields_with_qualifiers, schema_from_df_fields, DFField, ASYNC_RESULT_FIELD};\n-use join::JoinExtension;\n-\n use self::debezium::{DebeziumUnrollingExtension, ToDebeziumExtension};\n use self::updating_aggregate::UpdatingAggregateExtension;\n use self::{\n@@ -31,6 +25,10 @@ use self::{\n     remote_table::RemoteTableExtension, sink::SinkExtension, table_source::TableSourceExtension,\n     window_fn::WindowFunctionExtension,\n };\n+use crate::builder::{NamedNode, Planner};\n+use crate::schemas::{add_timestamp_field, has_timestamp_field};\n+use crate::{fields_with_qualifiers, schema_from_df_fields, DFField, ASYNC_RESULT_FIELD};\n+use join::JoinExtension;\n \n pub(crate) mod aggregate;\n pub(crate) mod debezium;\n@@ -207,12 +205,6 @@ impl ArroyoExtension for AsyncUDFExtension {\n             })\n             .collect::<Result<Vec<_>>>()?;\n \n-        ProjectionNode {\n-            input: None,\n-            expr: vec![],\n-            optional_alias: None,\n-        };\n-\n         let config = AsyncUdfOperator {\n             name: self.name.clone(),\n             udf: Some(self.udf.clone().into()),\ndiff --git a/crates/arroyo-planner/src/rewriters.rs b/crates/arroyo-planner/src/rewriters.rs\nindex fd3b47cf6..a938292f3 100644\n--- a/crates/arroyo-planner/src/rewriters.rs\n+++ b/crates/arroyo-planner/src/rewriters.rs\n@@ -536,9 +536,25 @@ impl<'a> TreeNodeRewriter for AsyncUdfRewriter<'a> {\n \n         let udf = self.provider.dylib_udfs.get(&name).unwrap().clone();\n \n+        let input = if matches!(*projection.input, LogicalPlan::Projection(..)) {\n+            // if our input is a projection, we need to plan it separately -- this happens\n+            // for subqueries\n+\n+            Arc::new(LogicalPlan::Extension(Extension {\n+                node: Arc::new(RemoteTableExtension {\n+                    input: (*projection.input).clone(),\n+                    name: TableReference::bare(\"subquery_projection\"),\n+                    schema: projection.input.schema().clone(),\n+                    materialize: false,\n+                }),\n+            }))\n+        } else {\n+            projection.input\n+        };\n+\n         Ok(Transformed::yes(LogicalPlan::Extension(Extension {\n             node: Arc::new(AsyncUDFExtension {\n-                input: projection.input,\n+                input,\n                 name,\n                 udf,\n                 arg_exprs: args,\n", "instance_id": "ArroyoSystems__arroyo-780", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in describing the issue: a runtime error occurs when using async UDFs with subqueries in a SQL query. It provides a specific SQL query example, a sample async UDF in Rust, and the exact runtime error message, which helps in understanding the context and reproducing the issue. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define the expected behavior or output when the issue is resolved, nor does it mention specific constraints or edge cases to consider (e.g., types of subqueries or UDFs affected). Additionally, there is no mention of the broader context of the system or the desired fix strategy, which could impact how one approaches the solution. Despite these minor gaps, the statement is valid and provides enough information to start investigating the issue, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" range (0.6-0.8) due to several factors. First, the scope of code changes, while limited to two files (`arroyo-planner/src/extension/mod.rs` and `arroyo-planner/src/rewriters.rs`), involves non-trivial modifications to the logical planning and rewriting logic for async UDFs in a data processing system, likely built on top of DataFusion. The changes address how subqueries are handled as inputs to async UDF extensions, which requires understanding the interaction between projections, subqueries, and custom extensions in the query planner\u2014a moderately complex architectural component. Second, the number of technical concepts involved is significant: familiarity with Rust, async programming, DataFusion's logical and physical plan structures, and custom UDF extensions are necessary. Additionally, the error message points to a specific issue with field indexing in structs during async UDF execution, suggesting a need to debug and understand schema handling in nested queries. Third, while the problem statement does not explicitly mention edge cases, the nature of subqueries and async UDFs implies potential complexities in handling various query structures, schema mismatches, or nested projections, which may require careful error handling or additional validation logic. Overall, solving this requires a deep understanding of the query planner's internals and moderate refactoring, but it does not appear to impact the broader system architecture or involve extremely advanced concepts, justifying a score of 0.65.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "rumqttc: filters are not validated before subscribing\n# Expected Behavior\r\n\r\nFilters should be validated before subscribing and invalid filters should be rejected\r\n\r\n# Current Behavior\r\n\r\nNo validation is performed\r\n\r\n## Context\r\n\r\nFor publish, we check [valid_topic](https://github.com/bytebeamio/rumqtt/blob/742d8bacc20dbab70374ebc6df711276feecc887/rumqttc/src/client.rs#L84) before sending it to broker, we should do same for subscribe.\r\n\r\n[valid_filter](https://github.com/bytebeamio/rumqtt/blob/742d8bacc20dbab70374ebc6df711276feecc887/rumqttc/src/mqttbytes/topic.rs#L22) is defined, but never used. ( same for v5! )\r\n\r\nit should be used before [sending the request](https://github.com/bytebeamio/rumqtt/blob/742d8bacc20dbab70374ebc6df711276feecc887/rumqttc/src/client.rs#L155), similar to how we do in publish. \r\n\r\nnote: might be required to validate at different place or at same place but with iter, as there might be multiple filters! \n", "patch": "diff --git a/rumqttc/CHANGELOG.md b/rumqttc/CHANGELOG.md\nindex 88bc2d319..8f46b1347 100644\n--- a/rumqttc/CHANGELOG.md\n+++ b/rumqttc/CHANGELOG.md\n@@ -23,6 +23,7 @@ and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0\n \n ### Fixed\n \n+* Validate filters while creating subscription requests.\n * Make v4::Connect::write return correct value\n \n ### Security\ndiff --git a/rumqttc/src/client.rs b/rumqttc/src/client.rs\nindex 863b73191..15cd5f5ad 100644\n--- a/rumqttc/src/client.rs\n+++ b/rumqttc/src/client.rs\n@@ -3,7 +3,7 @@\n use std::time::Duration;\n \n use crate::mqttbytes::{v4::*, QoS};\n-use crate::{valid_topic, ConnectionError, Event, EventLoop, MqttOptions, Request};\n+use crate::{valid_filter, valid_topic, ConnectionError, Event, EventLoop, MqttOptions, Request};\n \n use bytes::Bytes;\n use flume::{SendError, Sender, TrySendError};\n@@ -150,16 +150,24 @@ impl AsyncClient {\n \n     /// Sends a MQTT Subscribe to the `EventLoop`\n     pub async fn subscribe<S: Into<String>>(&self, topic: S, qos: QoS) -> Result<(), ClientError> {\n-        let subscribe = Subscribe::new(topic.into(), qos);\n+        let topic = topic.into();\n+        let subscribe = Subscribe::new(&topic, qos);\n         let request = Request::Subscribe(subscribe);\n+        if !valid_filter(&topic) {\n+            return Err(ClientError::Request(request));\n+        }\n         self.request_tx.send_async(request).await?;\n         Ok(())\n     }\n \n     /// Attempts to send a MQTT Subscribe to the `EventLoop`\n     pub fn try_subscribe<S: Into<String>>(&self, topic: S, qos: QoS) -> Result<(), ClientError> {\n-        let subscribe = Subscribe::new(topic.into(), qos);\n+        let topic = topic.into();\n+        let subscribe = Subscribe::new(&topic, qos);\n         let request = Request::Subscribe(subscribe);\n+        if !valid_filter(&topic) {\n+            return Err(ClientError::TryRequest(request));\n+        }\n         self.request_tx.try_send(request)?;\n         Ok(())\n     }\n@@ -169,8 +177,13 @@ impl AsyncClient {\n     where\n         T: IntoIterator<Item = SubscribeFilter>,\n     {\n-        let subscribe = Subscribe::new_many(topics);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::Request(request));\n+        }\n         self.request_tx.send_async(request).await?;\n         Ok(())\n     }\n@@ -180,8 +193,13 @@ impl AsyncClient {\n     where\n         T: IntoIterator<Item = SubscribeFilter>,\n     {\n-        let subscribe = Subscribe::new_many(topics);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::TryRequest(request));\n+        }\n         self.request_tx.try_send(request)?;\n         Ok(())\n     }\n@@ -323,8 +341,12 @@ impl Client {\n \n     /// Sends a MQTT Subscribe to the `EventLoop`\n     pub fn subscribe<S: Into<String>>(&self, topic: S, qos: QoS) -> Result<(), ClientError> {\n-        let subscribe = Subscribe::new(topic.into(), qos);\n+        let topic = topic.into();\n+        let subscribe = Subscribe::new(&topic, qos);\n         let request = Request::Subscribe(subscribe);\n+        if !valid_filter(&topic) {\n+            return Err(ClientError::Request(request));\n+        }\n         self.client.request_tx.send(request)?;\n         Ok(())\n     }\n@@ -340,8 +362,13 @@ impl Client {\n     where\n         T: IntoIterator<Item = SubscribeFilter>,\n     {\n-        let subscribe = Subscribe::new_many(topics);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::Request(request));\n+        }\n         self.client.request_tx.send(request)?;\n         Ok(())\n     }\ndiff --git a/rumqttc/src/mqttbytes/v4/mod.rs b/rumqttc/src/mqttbytes/v4/mod.rs\nindex ed438dd0f..3621945de 100644\n--- a/rumqttc/src/mqttbytes/v4/mod.rs\n+++ b/rumqttc/src/mqttbytes/v4/mod.rs\n@@ -15,6 +15,7 @@ mod subscribe;\n mod unsuback;\n mod unsubscribe;\n \n+pub use codec::*;\n pub use connack::*;\n pub use connect::*;\n pub use disconnect::*;\n@@ -28,7 +29,6 @@ pub use suback::*;\n pub use subscribe::*;\n pub use unsuback::*;\n pub use unsubscribe::*;\n-pub use codec::*;\n \n /// Encapsulates all MQTT packet types\n #[derive(Debug, Clone, PartialEq, Eq)]\n@@ -116,7 +116,7 @@ impl Packet {\n             return Err(Error::OutgoingPacketTooLarge {\n                 pkt_size: self.size(),\n                 max: max_size,\n-            })\n+            });\n         }\n \n         match self {\ndiff --git a/rumqttc/src/proxy.rs b/rumqttc/src/proxy.rs\nindex e7f84cd37..94c7aabd3 100644\n--- a/rumqttc/src/proxy.rs\n+++ b/rumqttc/src/proxy.rs\n@@ -49,7 +49,8 @@ impl Proxy {\n     ) -> Result<Box<dyn AsyncReadWrite>, ProxyError> {\n         let proxy_addr = format!(\"{}:{}\", self.addr, self.port);\n \n-        let tcp: Box<dyn AsyncReadWrite> = Box::new(socket_connect(proxy_addr, network_options).await?);\n+        let tcp: Box<dyn AsyncReadWrite> =\n+            Box::new(socket_connect(proxy_addr, network_options).await?);\n         let mut tcp = match self.ty {\n             ProxyType::Http => tcp,\n             #[cfg(any(feature = \"use-rustls\", feature = \"use-native-tls\"))]\ndiff --git a/rumqttc/src/v5/client.rs b/rumqttc/src/v5/client.rs\nindex 910da504f..f8629b8c5 100644\n--- a/rumqttc/src/v5/client.rs\n+++ b/rumqttc/src/v5/client.rs\n@@ -6,7 +6,7 @@ use super::mqttbytes::v5::{\n     Filter, PubAck, PubRec, Publish, PublishProperties, Subscribe, SubscribeProperties,\n     Unsubscribe, UnsubscribeProperties,\n };\n-use super::mqttbytes::QoS;\n+use super::mqttbytes::{valid_filter, QoS};\n use super::{ConnectionError, Event, EventLoop, MqttOptions, Request};\n use crate::valid_topic;\n \n@@ -256,8 +256,12 @@ impl AsyncClient {\n         properties: Option<SubscribeProperties>,\n     ) -> Result<(), ClientError> {\n         let filter = Filter::new(topic, qos);\n+        let is_filter_valid = valid_filter(&filter.path);\n         let subscribe = Subscribe::new(filter, properties);\n         let request: Request = Request::Subscribe(subscribe);\n+        if !is_filter_valid {\n+            return Err(ClientError::Request(request));\n+        }\n         self.request_tx.send_async(request).await?;\n         Ok(())\n     }\n@@ -283,8 +287,12 @@ impl AsyncClient {\n         properties: Option<SubscribeProperties>,\n     ) -> Result<(), ClientError> {\n         let filter = Filter::new(topic, qos);\n+        let is_filter_valid = valid_filter(&filter.path);\n         let subscribe = Subscribe::new(filter, properties);\n         let request = Request::Subscribe(subscribe);\n+        if !is_filter_valid {\n+            return Err(ClientError::TryRequest(request));\n+        }\n         self.request_tx.try_send(request)?;\n         Ok(())\n     }\n@@ -311,8 +319,14 @@ impl AsyncClient {\n     where\n         T: IntoIterator<Item = Filter>,\n     {\n-        let subscribe = Subscribe::new_many(topics, properties);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter, properties);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::Request(request));\n+        }\n+\n         self.request_tx.send_async(request).await?;\n         Ok(())\n     }\n@@ -344,8 +358,13 @@ impl AsyncClient {\n     where\n         T: IntoIterator<Item = Filter>,\n     {\n-        let subscribe = Subscribe::new_many(topics, properties);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter, properties);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::TryRequest(request));\n+        }\n         self.request_tx.try_send(request)?;\n         Ok(())\n     }\n@@ -589,8 +608,12 @@ impl Client {\n         properties: Option<SubscribeProperties>,\n     ) -> Result<(), ClientError> {\n         let filter = Filter::new(topic, qos);\n+        let is_filter_valid = valid_filter(&filter.path);\n         let subscribe = Subscribe::new(filter, properties);\n         let request = Request::Subscribe(subscribe);\n+        if !is_filter_valid {\n+            return Err(ClientError::Request(request));\n+        }\n         self.client.request_tx.send(request)?;\n         Ok(())\n     }\n@@ -632,8 +655,13 @@ impl Client {\n     where\n         T: IntoIterator<Item = Filter>,\n     {\n-        let subscribe = Subscribe::new_many(topics, properties);\n+        let mut topics_iter = topics.into_iter();\n+        let is_valid_filters = topics_iter.all(|filter| valid_filter(&filter.path));\n+        let subscribe = Subscribe::new_many(topics_iter, properties);\n         let request = Request::Subscribe(subscribe);\n+        if !is_valid_filters {\n+            return Err(ClientError::Request(request));\n+        }\n         self.client.request_tx.send(request)?;\n         Ok(())\n     }\n", "instance_id": "bytebeamio__rumqtt-828", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "The problem statement is mostly clear in describing the expected behavior: filters should be validated before subscribing, similar to how topics are validated before publishing in the `rumqttc` library. It provides context by referencing specific functions (`valid_filter`, `valid_topic`) and relevant code locations in the repository, which helps in understanding the issue. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define what constitutes an \"invalid filter\" or provide examples of valid and invalid filters. Additionally, while it mentions the need to handle multiple filters (using an iterator), it lacks specificity on how validation failures should be reported or handled beyond rejecting the request. Edge cases, such as empty filter lists or malformed input, are not addressed. Overall, the statement is valid and clear enough to guide implementation but leaves some minor details to interpretation.", "difficulty_explanation": "The difficulty of this problem falls in the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes:** The changes are relatively localized, primarily affecting the `client.rs` files for both v4 and v5 MQTT implementations. The modifications involve adding validation logic using the existing `valid_filter` function before sending subscription requests. While the changes span multiple methods (e.g., `subscribe`, `try_subscribe`, `subscribe_many`) in both synchronous and asynchronous clients, they are repetitive and follow a consistent pattern. The overall amount of code change is moderate, and there is no significant impact on the system's architecture.\n\n2. **Number of Technical Concepts:** Solving this problem requires understanding basic Rust concepts such as iterators (for handling multiple filters), error handling (returning appropriate error types like `ClientError`), and familiarity with the library's internal structure (e.g., `Request` and `Subscribe` types). The `valid_filter` function is already implemented and simply needs to be integrated, so no complex algorithm or design pattern is required. The concepts involved are straightforward for someone with moderate Rust experience.\n\n3. **Edge Cases and Error Handling:** The problem statement hints at handling multiple filters but does not explicitly mention specific edge cases (e.g., empty filter lists, malformed strings). The code changes introduce basic error handling by rejecting invalid filters with a `ClientError`, but the complexity of these error conditions is low. The developer must ensure that validation is applied consistently across all subscription methods, but this does not significantly increase the difficulty.\n\n4. **Overall Complexity:** The task involves understanding the existing codebase to locate where subscription requests are made and applying a pre-existing validation function. While it requires attention to detail to cover all relevant methods and handle iterator-based validation for multiple filters, the logic is not inherently complex. The changes are more about consistency and correctness than deep architectural or algorithmic challenges.\n\nA score of 0.35 reflects that this is an easy problem requiring some code logic understanding and simple modifications across a few files, but it does not demand advanced technical knowledge or complex refactoring. It is suitable for a developer with intermediate Rust skills and some familiarity with the library's structure.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Ignore files without using .gitignore (.brootignore? .ignore?)\nI'd like a way to tell broot to ignore certain folders with a large number of useless files (`~/.cache, ~/rust, ~/crates.io-index`) without making a git repo around them (or hiding them). Is there a way to do this already? If not, I suggest a .brootignore file, which is parsed the same as a .gitignore file, except it's not required to be in a git repo.\n", "patch": "diff --git a/src/git/ignore.rs b/src/git/ignore.rs\nindex 98ded5d3..ee71ce85 100644\n--- a/src/git/ignore.rs\n+++ b/src/git/ignore.rs\n@@ -168,7 +168,7 @@ impl GitIgnorer {\n                     chain.push(self.files.alloc(gif));\n                 }\n             }\n-            for filename in [\".gitignore\", \".git/info/exclude\"] {\n+            for filename in [\".gitignore\", \".git/info/exclude\", \".ignore\"] {\n                 let file = dir.join(filename);\n                 if let Ok(gif) = GitIgnoreFile::new(&file, dir) {\n                     //debug!(\"pushing GIF {:#?}\", &gif);\n@@ -203,9 +203,11 @@ impl GitIgnorer {\n             parent_chain.clone()\n         };\n         if chain.in_repo {\n-            let ignore_file = dir.join(\".gitignore\");\n-            if let Ok(gif) = GitIgnoreFile::new(&ignore_file, dir) {\n-                chain.push(self.files.alloc(gif));\n+            for filename in [\".gitignore\", \".ignore\"] {\n+                let ignore_file = dir.join(filename);\n+                if let Ok(gif) = GitIgnoreFile::new(&ignore_file, dir) {\n+                    chain.push(self.files.alloc(gif));\n+                }\n             }\n         }\n         chain\n", "instance_id": "Canop__broot-931", "clarity": 2, "difficulty": 0.3, "clarity_explanation": "The problem statement is mostly clear in expressing the goal: to allow broot to ignore certain folders without relying on a git repository or .gitignore files. The suggestion of a \".brootignore\" or \".ignore\" file is understandable, and the intent to mimic .gitignore parsing logic is implied. However, there are minor ambiguities and missing details. For instance, the problem does not explicitly define the expected format or precedence rules for the new ignore file (e.g., does it override .gitignore or complement it?). Additionally, there are no examples of input/output behavior or specific constraints on how the ignore mechanism should work. Edge cases, such as handling conflicts between different ignore files or performance implications of parsing additional files, are not mentioned. Despite these gaps, the overall intent is clear enough to proceed with implementation.", "difficulty_explanation": "The difficulty of this problem falls into the \"Easy\" range (0.2-0.4) due to the following factors:\n\n1. **Scope and Depth of Code Changes:** The provided diff shows modifications to a single file (`src/git/ignore.rs`) and involves minimal changes\u2014essentially adding support for a new ignore file (\".ignore\") alongside existing .gitignore logic. The changes are localized to a specific module and do not appear to impact the broader architecture of the system. The amount of code change is small, with only a few lines modified to include the new filename in the list of files to check.\n\n2. **Technical Concepts Required:** Solving this problem requires a basic understanding of Rust (file handling and string manipulation), as well as familiarity with the existing logic for parsing ignore files in the codebase. No advanced language features, complex algorithms, or design patterns are needed. The concept of ignore files (similar to .gitignore) is straightforward and does not require deep domain-specific knowledge beyond what a typical developer working on a file system tool like broot would already know.\n\n3. **Edge Cases and Error Handling:** The problem statement does not explicitly mention edge cases, and the code changes do not introduce new error handling logic beyond what is already in place for .gitignore files. However, a developer might need to consider minor edge cases, such as the presence of multiple ignore files in the same directory or performance implications of checking additional files, though these are not complex to address.\n\n4. **Overall Complexity:** The task involves a simple extension of existing functionality rather than a deep refactoring or introduction of new system components. It requires understanding the current ignore file logic and replicating it for a new file type, which is a relatively straightforward modification.\n\nGiven these points, a difficulty score of 0.30 reflects the ease of the task while acknowledging the need for some understanding of the existing codebase logic and minor considerations for robustness.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "[macOS] APP crash when a web custom protocol request is aborted before or during response\n### Describe the bug\r\n\r\nWhen initiating a `register_uri_scheme_protocol` request from the web side, if the web aborts the request before or during the response, the macOS APP crashes.\r\n\r\n\r\n### Reproduction\r\n\r\n- Register a `register_asynchronous_uri_scheme_protocol`.\r\n- From the web side, initiate a request using this protocol and abort the request before the response.\r\n- The APP crashes 100% of the time.\r\n\r\n### Expected behavior\r\n\r\n- Before responding, the `responder` should check if the request has been canceled. If the request has been canceled, do not send the response.\r\n- Or, during the response, catch exceptions to prevent the APP from crashing and quitting abruptly when the request is terminated.\r\n\r\n### Full `tauri info` output\r\n\r\n```text\r\n[\u2714] Environment\r\n    - OS: Mac OS 13.6.3 X64\r\n    \u2714 Xcode Command Line Tools: installed\r\n    \u2714 rustc: 1.76.0 (07dca489a 2024-02-04)\r\n    \u2714 cargo: 1.76.0 (c84b36747 2024-01-18)\r\n    \u2714 rustup: 1.26.0 (5af9b9484 2023-04-05)\r\n    \u2714 Rust toolchain: stable-x86_64-apple-darwin (default)\r\n    - node: 18.17.1\r\n    - pnpm: 8.15.4\r\n    - npm: 9.6.7\r\n\r\n[-] Packages\r\n    - tauri [RUST]: 2.0.0-beta.10\r\n    - tauri-build [RUST]: 2.0.0-beta.8\r\n    - wry [RUST]: 0.37.0\r\n    - tao [RUST]: 0.26.1\r\n    - @tauri-apps/api [NPM]: 2.0.0-beta.5\r\n    - @tauri-apps/cli [NPM]: 2.0.0-beta.9\r\n\r\n[-] App\r\n    - build-type: bundle\r\n    - CSP: default-src x-http: x-https: blob: data: filesystem: ws: http: https: 'unsafe-eval' 'unsafe-inline'\r\n    - frontendDist: ../feiyu/dist\r\n    - devUrl: http://localhost:3000/\r\n```\r\n\r\n\r\n### Stack trace\r\n\r\n```text\r\nthread 'tokio-runtime-worker' panicked at /Users/mac/.cargo/registry/src/index.crates.io-6f17d22bba15001f/wry-0.37.0/src/wkwebview/mod.rs:262:28:\r\nUncaught exception <NSException: 0x10428cf30>\r\n```\r\n\r\n\r\n### Additional context\r\n\r\nRelated code: \r\nhttps://github.com/tauri-apps/wry/blob/5789bf759ce94e4dad5ff26a08fe81521658a4e4/src/wkwebview/mod.rs#L272\r\n<img width=\"1802\" alt=\"\u56fe\u7247\" src=\"https://github.com/tauri-apps/tauri/assets/35302658/767b0a0a-3c21-42fa-837f-fc4ed4153f57\">\r\n\r\nRelated issue: https://github.com/tauri-apps/tauri/issues/9177\n", "patch": "diff --git a/.changes/objc-exceptions.md b/.changes/objc-exceptions.md\nnew file mode 100644\nindex 000000000..97a72fab3\n--- /dev/null\n+++ b/.changes/objc-exceptions.md\n@@ -0,0 +1,5 @@\n+---\n+wry: minor\n+---\n+\n+Removed `obj-exception` feature.\ndiff --git a/Cargo.toml b/Cargo.toml\nindex 7590c1212..b86142f45 100644\n--- a/Cargo.toml\n+++ b/Cargo.toml\n@@ -26,9 +26,8 @@ rustc-args = [\"--cfg\", \"docsrs\"]\n rustdoc-args = [\"--cfg\", \"docsrs\"]\n \n [features]\n-default = [\"drag-drop\", \"objc-exception\", \"protocol\", \"os-webview\"]\n+default = [\"drag-drop\", \"protocol\", \"os-webview\"]\n serde = [\"dpi/serde\"]\n-objc-exception = [\"objc2/catch-all\"]\n drag-drop = []\n protocol = []\n devtools = []\ndiff --git a/src/wkwebview/class/url_scheme_handler.rs b/src/wkwebview/class/url_scheme_handler.rs\nindex 8300dd9d6..819c08bda 100644\n--- a/src/wkwebview/class/url_scheme_handler.rs\n+++ b/src/wkwebview/class/url_scheme_handler.rs\n@@ -16,7 +16,7 @@ use http::{\n use objc2::{\n   rc::Retained,\n   runtime::{AnyClass, AnyObject, ClassBuilder, ProtocolObject},\n-  AllocAnyThread, ClassType,\n+  AllocAnyThread, ClassType, Message,\n };\n use objc2_foundation::{\n   NSData, NSHTTPURLResponse, NSMutableDictionary, NSObject, NSObjectProtocol, NSString, NSURL,\n@@ -54,8 +54,8 @@ pub fn create(name: &str) -> &AnyClass {\n extern \"C\" fn start_task(\n   this: &AnyObject,\n   _sel: objc2::runtime::Sel,\n-  webview: &'static WryWebView,\n-  task: &'static ProtocolObject<dyn WKURLSchemeTask>,\n+  webview: &WryWebView,\n+  task: &ProtocolObject<dyn WKURLSchemeTask>,\n ) {\n   unsafe {\n     #[cfg(feature = \"tracing\")]\n@@ -180,12 +180,14 @@ extern \"C\" fn start_task(\n       // send response\n       match http_request.body(sent_form_body) {\n         Ok(final_request) => {\n+          let webview = webview.retain();\n+          let task = task.retain();\n           let responder: Box<dyn FnOnce(HttpResponse<Cow<'static, [u8]>>)> =\n             Box::new(move |sent_response| {\n               // Consolidate checks before calling into `did*` methods.\n               let validate = || -> crate::Result<()> {\n                 check_webview_id_valid(webview_id)?;\n-                check_task_is_valid(webview, task_key, task_uuid.clone())?;\n+                check_task_is_valid(&webview, task_key, task_uuid.clone())?;\n                 Ok(())\n               };\n \n@@ -198,9 +200,9 @@ extern \"C\" fn start_task(\n \n               unsafe fn response(\n                 // FIXME: though we give it a static lifetime, it's not guaranteed to be valid.\n-                task: &'static ProtocolObject<dyn WKURLSchemeTask>,\n+                task: Retained<ProtocolObject<dyn WKURLSchemeTask>>,\n                 // FIXME: though we give it a static lifetime, it's not guaranteed to be valid.\n-                webview: &'static WryWebView,\n+                webview: Retained<WryWebView>,\n                 task_key: usize,\n                 task_uuid: Retained<NSUUID>,\n                 webview_id: &str,\n@@ -209,7 +211,7 @@ extern \"C\" fn start_task(\n               ) -> crate::Result<()> {\n                 // Validate\n                 check_webview_id_valid(webview_id)?;\n-                check_task_is_valid(webview, task_key, task_uuid.clone())?;\n+                check_task_is_valid(&webview, task_key, task_uuid.clone())?;\n \n                 let content = sent_response.body();\n                 // default: application/octet-stream, but should be provided by the client\n@@ -253,7 +255,7 @@ extern \"C\" fn start_task(\n \n                 // Re-validate before calling didReceiveResponse\n                 check_webview_id_valid(webview_id)?;\n-                check_task_is_valid(webview, task_key, task_uuid.clone())?;\n+                check_task_is_valid(&webview, task_key, task_uuid.clone())?;\n \n                 // Use map_err to convert Option<Retained<Exception>> to crate::Error\n                 objc2::exception::catch(AssertUnwindSafe(|| {\n@@ -273,7 +275,7 @@ extern \"C\" fn start_task(\n \n                 // Check validity again\n                 check_webview_id_valid(webview_id)?;\n-                check_task_is_valid(webview, task_key, task_uuid.clone())?;\n+                check_task_is_valid(&webview, task_key, task_uuid.clone())?;\n \n                 objc2::exception::catch(AssertUnwindSafe(|| {\n                   task.didReceiveData(&data);\n@@ -281,7 +283,7 @@ extern \"C\" fn start_task(\n                 .map_err(|_e| crate::Error::CustomProtocolTaskInvalid)?;\n \n                 check_webview_id_valid(webview_id)?;\n-                check_task_is_valid(webview, task_key, task_uuid.clone())?;\n+                check_task_is_valid(&webview, task_key, task_uuid.clone())?;\n \n                 objc2::exception::catch(AssertUnwindSafe(|| {\n                   task.didFinish();\ndiff --git a/src/wkwebview/class/wry_web_view.rs b/src/wkwebview/class/wry_web_view.rs\nindex f96a934ab..8ae5f88d3 100644\n--- a/src/wkwebview/class/wry_web_view.rs\n+++ b/src/wkwebview/class/wry_web_view.rs\n@@ -2,7 +2,7 @@\n // SPDX-License-Identifier: Apache-2.0\n // SPDX-License-Identifier: MIT\n \n-use std::{cell::RefCell, collections::HashMap};\n+use std::{cell::RefCell, collections::HashMap, sync::Mutex};\n \n #[cfg(target_os = \"macos\")]\n use objc2::runtime::ProtocolObject;\n@@ -29,7 +29,7 @@ pub struct WryWebViewIvars {\n   pub(crate) drag_drop_handler: Box<dyn Fn(DragDropEvent) -> bool>,\n   #[cfg(target_os = \"macos\")]\n   pub(crate) accept_first_mouse: objc2::runtime::Bool,\n-  pub(crate) custom_protocol_task_ids: RefCell<HashMap<usize, Retained<NSUUID>>>,\n+  pub(crate) custom_protocol_task_ids: Mutex<HashMap<usize, Retained<NSUUID>>>,\n }\n \n define_class!(\n@@ -117,7 +117,8 @@ impl WryWebView {\n     self\n       .ivars()\n       .custom_protocol_task_ids\n-      .borrow_mut()\n+      .lock()\n+      .unwrap()\n       .insert(task_id, task_uuid.clone());\n     task_uuid\n   }\n@@ -125,14 +126,16 @@ impl WryWebView {\n     self\n       .ivars()\n       .custom_protocol_task_ids\n-      .borrow_mut()\n+      .lock()\n+      .unwrap()\n       .remove(&task_id);\n   }\n   pub(crate) fn get_custom_task_uuid(&self, task_id: usize) -> Option<Retained<NSUUID>> {\n     self\n       .ivars()\n       .custom_protocol_task_ids\n-      .borrow()\n+      .lock()\n+      .unwrap()\n       .get(&task_id)\n       .cloned()\n   }\n", "instance_id": "tauri-apps__wry-1484", "clarity": 2, "difficulty": 0.75, "clarity_explanation": "The problem statement is mostly clear in describing the issue: a macOS app crashes when a web custom protocol request is aborted before or during a response. It provides a reproduction scenario, expected behavior, and relevant stack trace information, along with links to related code and issues. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define the exact conditions under which the crash occurs (e.g., specific timing or types of requests), nor does it provide detailed examples of the input or output expected from the fix. Additionally, while the expected behavior is outlined, it lacks specificity on how to implement the check for request cancellation or exception handling. Edge cases are implied but not explicitly listed, which could lead to some uncertainty during implementation. Overall, the statement is valid and clear enough to understand the goal, but it misses some finer details that would make it comprehensive.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes involves multiple files and components within the `wry` crate, a Rust library for cross-platform WebView rendering, specifically targeting macOS's WebKit integration (`WKWebView`). The changes span modifications to custom protocol handling, task validation, and thread-safety mechanisms (e.g., replacing `RefCell` with `Mutex` for thread-safe access to task IDs). This requires a deep understanding of the codebase's architecture and interactions between Rust and Objective-C via `objc2`.\n\nSecond, the technical concepts involved are complex. Solving this requires knowledge of Rust's memory safety and concurrency models (e.g., handling `Retained` pointers and ensuring thread safety), Objective-C runtime interactions (e.g., exception handling with `objc2::exception::catch`), and macOS-specific WebKit APIs (`WKURLSchemeTask`). Additionally, familiarity with Tauri\u2019s custom protocol system and asynchronous request handling is necessary. The removal of the `objc-exception` feature suggests a shift in how exceptions are managed, adding another layer of complexity.\n\nThird, the problem involves significant edge case handling. The crash occurs under specific conditions (request abortion before or during response), and the solution must ensure robust validation of task and webview states before proceeding with responses. The code changes show repeated checks for task validity and webview ID, indicating a focus on preventing crashes due to invalid states, which adds to the intricacy of the fix.\n\nFinally, while the changes do not appear to impact the broader system architecture fundamentally, they do affect a critical component (custom protocol handling in WebView), which is central to Tauri\u2019s functionality on macOS. The amount of code change is moderate but highly technical, requiring precision to avoid introducing new bugs in a crash-prone area. Given these factors\u2014deep technical requirements, cross-language integration, and careful edge case handling\u2014I rate this problem at 0.75, reflecting a hard but not extremely challenging task that still demands significant expertise and caution.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Put encoding_rs dependency behind a Cargo feature?\nI'm doing binary size analysis of my release binary using Size Bench: https://devblogs.microsoft.com/performance-diagnostics/sizebench-a-new-tool-for-analyzing-windows-binary-size/\r\nA significant contributor to the size of the .rdata section is encoding_rs's data tables: https://raw.githubusercontent.com/hsivonen/encoding_rs/master/src/data.rs\r\nIt would be nice to place the dependency on encoding_rs behind a Cargo feature to avoid this size increase, e.g. in cases where Reqwest is used only to consume binary data or REST endpoints that speak utf-8.\n", "patch": "diff --git a/.github/workflows/ci.yml b/.github/workflows/ci.yml\nindex 1b314b9a1..aabd79d16 100644\n--- a/.github/workflows/ci.yml\n+++ b/.github/workflows/ci.yml\n@@ -71,10 +71,12 @@ jobs:\n           - \"feat.: default-tls disabled\"\n           - \"feat.: rustls-tls\"\n           - \"feat.: rustls-tls-manual-roots\"\n+          - \"feat.: rustls-tls-native-roots\"\n           - \"feat.: native-tls\"\n           - \"feat.: default-tls and rustls-tls\"\n           - \"feat.: cookies\"\n           - \"feat.: blocking\"\n+          - \"feat.: blocking only\"\n           - \"feat.: gzip\"\n           - \"feat.: brotli\"\n           - \"feat.: deflate\"\n@@ -101,23 +103,23 @@ jobs:\n           - name: windows / stable-x86_64-msvc\n             os: windows-latest\n             target: x86_64-pc-windows-msvc\n-            features: \"--features blocking,gzip,brotli,deflate,json,multipart\"\n+            features: \"--features blocking,gzip,brotli,deflate,json,multipart,stream\"\n           - name: windows / stable-i686-msvc\n             os: windows-latest\n             target: i686-pc-windows-msvc\n-            features: \"--features blocking,gzip,brotli,deflate,json,multipart\"\n+            features: \"--features blocking,gzip,brotli,deflate,json,multipart,stream\"\n           - name: windows / stable-x86_64-gnu\n             os: windows-latest\n             rust: stable-x86_64-pc-windows-gnu\n             target: x86_64-pc-windows-gnu\n-            features: \"--features blocking,gzip,brotli,deflate,json,multipart\"\n+            features: \"--features blocking,gzip,brotli,deflate,json,multipart,stream\"\n             package_name: mingw-w64-x86_64-gcc\n             mingw64_path: \"C:\\\\msys64\\\\mingw64\\\\bin\"\n           - name: windows / stable-i686-gnu\n             os: windows-latest\n             rust: stable-i686-pc-windows-gnu\n             target: i686-pc-windows-gnu\n-            features: \"--features blocking,gzip,brotli,deflate,json,multipart\"\n+            features: \"--features blocking,gzip,brotli,deflate,json,multipart,stream\"\n             package_name: mingw-w64-i686-gcc\n             mingw64_path: \"C:\\\\msys64\\\\mingw32\\\\bin\"\n \n@@ -127,6 +129,8 @@ jobs:\n             features: \"--no-default-features --features rustls-tls\"\n           - name: \"feat.: rustls-tls-manual-roots\"\n             features: \"--no-default-features --features rustls-tls-manual-roots\"\n+          - name: \"feat.: rustls-tls-native-roots\"\n+            features: \"--no-default-features --features rustls-tls-native-roots\"\n           - name: \"feat.: native-tls\"\n             features: \"--features native-tls\"\n           - name: \"feat.: default-tls and rustls-tls\"\n@@ -135,12 +139,14 @@ jobs:\n             features: \"--features cookies\"\n           - name: \"feat.: blocking\"\n             features: \"--features blocking\"\n+          - name: \"feat.: blocking only\"\n+            features: \"--no-default-features --features blocking\"\n           - name: \"feat.: gzip\"\n-            features: \"--features gzip\"\n+            features: \"--features gzip,stream\"\n           - name: \"feat.: brotli\"\n-            features: \"--features brotli\"\n+            features: \"--features brotli,stream\"\n           - name: \"feat.: deflate\"\n-            features: \"--features deflate\"\n+            features: \"--features deflate,stream\"\n           - name: \"feat.: json\"\n             features: \"--features json\"\n           - name: \"feat.: multipart\"\n@@ -204,11 +210,12 @@ jobs:\n         with:\n           toolchain: 'stable'\n \n-      - name: Check\n-        run: RUSTFLAGS=\"--cfg reqwest_unstable\" cargo check --features http3\n+      #- name: Check\n+      #  run: RUSTFLAGS=\"--cfg reqwest_unstable\" cargo check --features http3\n \n   docs:\n     name: Docs\n+    needs: [test]\n     runs-on: ubuntu-latest\n \n     steps:\ndiff --git a/CHANGELOG.md b/CHANGELOG.md\nindex 1b0386b03..1e8fa47e2 100644\n--- a/CHANGELOG.md\n+++ b/CHANGELOG.md\n@@ -1,3 +1,14 @@\n+# v0.12.0\n+\n+- Upgrade to `hyper`, `http`, and `http-body` v1.\n+- Add better support for converting to and from `http::Request` and `http::Response`.\n+- Add `http2` optional cargo feature, default on.\n+- Add `charset` optional cargo feature, default on.\n+- Add `macos-system-configuration` cargo feature, default on.\n+- Change all optional dependencies to no longer be exposed as implicit features.\n+- Add `ClientBuilder::interface(str)` to specify the local interface to bind to.\n+- Experimental: disables the `http3` feature temporarily.\n+\n ## v0.11.27\n \n - Add `hickory-dns` feature, deprecating `trust-dns`.\ndiff --git a/Cargo.toml b/Cargo.toml\nindex eb0b2c185..859a3c92c 100644\n--- a/Cargo.toml\n+++ b/Cargo.toml\n@@ -1,6 +1,6 @@\n [package]\n name = \"reqwest\"\n-version = \"0.11.27\" # remember to update html_root_url\n+version = \"0.12.0\"\n description = \"higher level HTTP client library\"\n keywords = [\"http\", \"request\", \"client\"]\n categories = [\"web-programming::http-client\", \"wasm\"]\n@@ -27,63 +27,71 @@ features = [\n ]\n \n [features]\n-default = [\"default-tls\"]\n+default = [\"default-tls\", \"charset\", \"http2\", \"macos-system-configuration\"]\n \n # Note: this doesn't enable the 'native-tls' feature, which adds specific\n # functionality for it.\n-default-tls = [\"hyper-tls\", \"native-tls-crate\", \"__tls\", \"tokio-native-tls\"]\n+default-tls = [\"dep:hyper-tls\", \"dep:native-tls-crate\", \"__tls\", \"dep:tokio-native-tls\"]\n+\n+http2 = [\"h2\", \"hyper/http2\", \"hyper-util/http2\"]\n \n # Enables native-tls specific functionality not available by default.\n native-tls = [\"default-tls\"]\n-native-tls-alpn = [\"native-tls\", \"native-tls-crate/alpn\"]\n-native-tls-vendored = [\"native-tls\", \"native-tls-crate/vendored\"]\n+native-tls-alpn = [\"native-tls\", \"native-tls-crate?/alpn\", \"hyper-tls?/alpn\"]\n+native-tls-vendored = [\"native-tls\", \"native-tls-crate?/vendored\"]\n \n rustls-tls = [\"rustls-tls-webpki-roots\"]\n rustls-tls-manual-roots = [\"__rustls\"]\n-rustls-tls-webpki-roots = [\"webpki-roots\", \"__rustls\"]\n-rustls-tls-native-roots = [\"rustls-native-certs\", \"__rustls\"]\n+rustls-tls-webpki-roots = [\"dep:webpki-roots\", \"__rustls\"]\n+rustls-tls-native-roots = [\"dep:rustls-native-certs\", \"__rustls\"]\n+\n+blocking = [\"futures-channel/sink\", \"futures-util/io\", \"futures-util/sink\", \"tokio/rt-multi-thread\", \"tokio/sync\"]\n \n-blocking = [\"futures-util/io\", \"tokio/sync\"]\n+charset = [\"dep:encoding_rs\"]\n \n-cookies = [\"cookie_crate\", \"cookie_store\"]\n+cookies = [\"dep:cookie_crate\", \"dep:cookie_store\"]\n \n-gzip = [\"async-compression\", \"async-compression/gzip\", \"tokio-util\"]\n+gzip = [\"dep:async-compression\", \"async-compression?/gzip\", \"dep:tokio-util\"]\n \n-brotli = [\"async-compression\", \"async-compression/brotli\", \"tokio-util\"]\n+brotli = [\"dep:async-compression\", \"async-compression?/brotli\", \"dep:tokio-util\"]\n \n-deflate = [\"async-compression\", \"async-compression/zlib\", \"tokio-util\"]\n+deflate = [\"dep:async-compression\", \"async-compression?/zlib\", \"dep:tokio-util\"]\n \n-json = [\"serde_json\"]\n+json = [\"dep:serde_json\"]\n \n-multipart = [\"mime_guess\"]\n+multipart = [\"dep:mime_guess\"]\n \n # Deprecated, remove this feature while bumping minor versions.\n-trust-dns = [\"hickory-dns\"]\n-hickory-dns = [\"hickory-resolver\"]\n+trust-dns = []\n+hickory-dns = [\"dep:hickory-resolver\"]\n+\n+stream = [\"tokio/fs\", \"dep:tokio-util\", \"dep:wasm-streams\"]\n \n-stream = [\"tokio/fs\", \"tokio-util\", \"wasm-streams\"]\n+socks = [\"dep:tokio-socks\"]\n \n-socks = [\"tokio-socks\"]\n+# Use the system's proxy configuration.\n+macos-system-configuration = [\"dep:system-configuration\"]\n \n # Experimental HTTP/3 client.\n-http3 = [\"rustls-tls-manual-roots\", \"h3\", \"h3-quinn\", \"quinn\", \"futures-channel\"]\n+# Disabled while waiting for quinn to upgrade.\n+#http3 = [\"rustls-tls-manual-roots\", \"dep:h3\", \"dep:h3-quinn\", \"dep:quinn\", \"dep:futures-channel\"]\n \n # Internal (PRIVATE!) features used to aid testing.\n # Don't rely on these whatsoever. They may disappear at anytime.\n \n # Enables common types used for TLS. Useless on its own.\n-__tls = [\"dep:rustls-pemfile\"]\n+__tls = [\"dep:rustls-pemfile\", \"tokio/io-util\"]\n \n # Enables common rustls code.\n # Equivalent to rustls-tls-manual-roots but shorter :)\n-__rustls = [\"hyper-rustls\", \"tokio-rustls\", \"rustls\", \"__tls\"]\n+__rustls = [\"dep:hyper-rustls\", \"dep:tokio-rustls\", \"dep:rustls\", \"__tls\", \"dep:rustls-pemfile\", \"rustls-pki-types\"]\n \n # When enabled, disable using the cached SYS_PROXIES.\n __internal_proxy_sys_no_cache = []\n \n [dependencies]\n base64 = \"0.21\"\n-http = \"0.2\"\n+http = \"1\"\n url = \"2.2\"\n bytes = \"1.0\"\n serde = \"1.0\"\n@@ -101,10 +109,12 @@ serde_json = { version = \"1.0\", optional = true }\n mime_guess = { version = \"2.0\", default-features = false, optional = true }\n \n [target.'cfg(not(target_arch = \"wasm32\"))'.dependencies]\n-encoding_rs = \"0.8\"\n-http-body = \"0.4.0\"\n-hyper = { version = \"0.14.21\", default-features = false, features = [\"tcp\", \"http1\", \"http2\", \"client\", \"runtime\"] }\n-h2 = \"0.3.14\"\n+encoding_rs = { version = \"0.8\", optional = true }\n+http-body = \"1\"\n+http-body-util = \"0.1\"\n+hyper = { version = \"1\", features = [\"http1\", \"client\"] }\n+hyper-util = { version = \"0.1.3\", features = [\"http1\", \"client\", \"client-legacy\", \"tokio\"] }\n+h2 = { version = \"0.4\", optional = true }\n once_cell = \"1\"\n log = \"0.4\"\n mime = \"0.3.16\"\n@@ -117,16 +127,17 @@ ipnet = \"2.3\"\n rustls-pemfile = { version = \"1.0\", optional = true }\n \n ## default-tls\n-hyper-tls = { version = \"0.5\", optional = true }\n+hyper-tls = { version = \"0.6\", optional = true }\n native-tls-crate = { version = \"0.2.10\", optional = true, package = \"native-tls\" }\n tokio-native-tls = { version = \"0.3.0\", optional = true }\n \n # rustls-tls\n-hyper-rustls = { version = \"0.24.0\", default-features = false, optional = true }\n-rustls = { version = \"0.21.6\", features = [\"dangerous_configuration\"], optional = true }\n-tokio-rustls = { version = \"0.24\", optional = true }\n-webpki-roots = { version = \"0.25\", optional = true }\n-rustls-native-certs = { version = \"0.6\", optional = true }\n+hyper-rustls = { version = \"0.26.0\", default-features = false, optional = true }\n+rustls = { version = \"0.22.2\", optional = true }\n+rustls-pki-types = { version = \"1.1.0\", features = [\"alloc\"] ,optional = true }\n+tokio-rustls = { version = \"0.25\", optional = true }\n+webpki-roots = { version = \"0.26.0\", optional = true }\n+rustls-native-certs = { version = \"0.7\", optional = true }\n \n ## cookies\n cookie_crate = { version = \"0.17.0\", package = \"cookie\", optional = true }\n@@ -143,15 +154,16 @@ tokio-socks = { version = \"0.5.1\", optional = true }\n hickory-resolver = { version = \"0.24\", optional = true, features = [\"tokio-runtime\"] }\n \n # HTTP/3 experimental support\n-h3 = { version = \"0.0.3\", optional = true }\n-h3-quinn = { version = \"0.0.4\", optional = true }\n+h3 = { version = \"0.0.4\", optional = true }\n+h3-quinn = { version = \"0.0.5\", optional = true }\n quinn = { version = \"0.10\", default-features = false, features = [\"tls-rustls\", \"ring\", \"runtime-tokio\"], optional = true }\n futures-channel = { version = \"0.3\", optional = true }\n \n \n [target.'cfg(not(target_arch = \"wasm32\"))'.dev-dependencies]\n env_logger = \"0.10\"\n-hyper = { version = \"0.14\", default-features = false, features = [\"tcp\", \"stream\", \"http1\", \"http2\", \"client\", \"server\", \"runtime\"] }\n+hyper = { version = \"1.1.0\", default-features = false, features = [\"http1\", \"http2\", \"client\", \"server\"] }\n+hyper-util = { version = \"0.1\", features = [\"http1\", \"http2\", \"client\", \"client-legacy\", \"server-auto\", \"tokio\"] }\n serde = { version = \"1.0\", features = [\"derive\"] }\n libflate = \"1.0\"\n brotli_crate = { package = \"brotli\", version = \"3.3.0\" }\n@@ -163,7 +175,7 @@ futures-util = { version = \"0.3.0\", default-features = false, features = [\"std\",\n winreg = \"0.50.0\"\n \n [target.'cfg(target_os = \"macos\")'.dependencies]\n-system-configuration = \"0.5.1\"\n+system-configuration = { version = \"0.5.1\", optional = true }\n \n # wasm\n \n@@ -239,17 +251,17 @@ required-features = [\"cookies\"]\n [[test]]\n name = \"gzip\"\n path = \"tests/gzip.rs\"\n-required-features = [\"gzip\"]\n+required-features = [\"gzip\", \"stream\"]\n \n [[test]]\n name = \"brotli\"\n path = \"tests/brotli.rs\"\n-required-features = [\"brotli\"]\n+required-features = [\"brotli\", \"stream\"]\n \n [[test]]\n name = \"deflate\"\n path = \"tests/deflate.rs\"\n-required-features = [\"deflate\"]\n+required-features = [\"deflate\", \"stream\"]\n \n [[test]]\n name = \"multipart\"\ndiff --git a/src/async_impl/body.rs b/src/async_impl/body.rs\nindex 0d0357cb6..ff5446e53 100644\n--- a/src/async_impl/body.rs\n+++ b/src/async_impl/body.rs\n@@ -4,10 +4,9 @@ use std::pin::Pin;\n use std::task::{Context, Poll};\n \n use bytes::Bytes;\n-use futures_core::Stream;\n use http_body::Body as HttpBody;\n-use pin_project_lite::pin_project;\n-use sync_wrapper::SyncWrapper;\n+use http_body_util::combinators::BoxBody;\n+//use sync_wrapper::SyncWrapper;\n #[cfg(feature = \"stream\")]\n use tokio::fs::File;\n use tokio::time::Sleep;\n@@ -19,31 +18,22 @@ pub struct Body {\n     inner: Inner,\n }\n \n-// The `Stream` trait isn't stable, so the impl isn't public.\n-pub(crate) struct ImplStream(Body);\n-\n enum Inner {\n     Reusable(Bytes),\n-    Streaming {\n-        body: Pin<\n-            Box<\n-                dyn HttpBody<Data = Bytes, Error = Box<dyn std::error::Error + Send + Sync>>\n-                    + Send\n-                    + Sync,\n-            >,\n-        >,\n-        timeout: Option<Pin<Box<Sleep>>>,\n-    },\n+    Streaming(BoxBody<Bytes, Box<dyn std::error::Error + Send + Sync>>),\n }\n \n-pin_project! {\n-    struct WrapStream<S> {\n-        #[pin]\n-        inner: SyncWrapper<S>,\n-    }\n+/// A body with a total timeout.\n+///\n+/// The timeout does not reset upon each chunk, but rather requires the whole\n+/// body be streamed before the deadline is reached.\n+pub(crate) struct TotalTimeoutBody<B> {\n+    inner: B,\n+    timeout: Pin<Box<Sleep>>,\n }\n \n-struct WrapHyper(hyper::Body);\n+/// Converts any `impl Body` into a `impl Stream` of just its DATA frames.\n+pub(crate) struct DataStream<B>(pub(crate) B);\n \n impl Body {\n     /// Returns a reference to the internal data of the `Body`.\n@@ -52,7 +42,7 @@ impl Body {\n     pub fn as_bytes(&self) -> Option<&[u8]> {\n         match &self.inner {\n             Inner::Reusable(bytes) => Some(bytes.as_ref()),\n-            Inner::Streaming { .. } => None,\n+            Inner::Streaming(..) => None,\n         }\n     }\n \n@@ -83,50 +73,44 @@ impl Body {\n     #[cfg_attr(docsrs, doc(cfg(feature = \"stream\")))]\n     pub fn wrap_stream<S>(stream: S) -> Body\n     where\n-        S: futures_core::stream::TryStream + Send + 'static,\n+        S: futures_core::stream::TryStream + Send + Sync + 'static,\n         S::Error: Into<Box<dyn std::error::Error + Send + Sync>>,\n         Bytes: From<S::Ok>,\n     {\n         Body::stream(stream)\n     }\n \n+    #[cfg(any(feature = \"stream\", feature = \"multipart\", feature = \"blocking\"))]\n     pub(crate) fn stream<S>(stream: S) -> Body\n     where\n-        S: futures_core::stream::TryStream + Send + 'static,\n+        S: futures_core::stream::TryStream + Send + Sync + 'static,\n         S::Error: Into<Box<dyn std::error::Error + Send + Sync>>,\n         Bytes: From<S::Ok>,\n     {\n         use futures_util::TryStreamExt;\n-\n-        let body = Box::pin(WrapStream {\n-            inner: SyncWrapper::new(stream.map_ok(Bytes::from).map_err(Into::into)),\n-        });\n+        use http_body::Frame;\n+        use http_body_util::StreamBody;\n+\n+        let body = http_body_util::BodyExt::boxed(StreamBody::new(\n+            stream\n+                .map_ok(|d| Frame::data(Bytes::from(d)))\n+                .map_err(Into::into),\n+        ));\n         Body {\n-            inner: Inner::Streaming {\n-                body,\n-                timeout: None,\n-            },\n-        }\n-    }\n-\n-    pub(crate) fn response(body: hyper::Body, timeout: Option<Pin<Box<Sleep>>>) -> Body {\n-        Body {\n-            inner: Inner::Streaming {\n-                body: Box::pin(WrapHyper(body)),\n-                timeout,\n-            },\n+            inner: Inner::Streaming(body),\n         }\n     }\n \n+    /*\n     #[cfg(feature = \"blocking\")]\n     pub(crate) fn wrap(body: hyper::Body) -> Body {\n         Body {\n             inner: Inner::Streaming {\n                 body: Box::pin(WrapHyper(body)),\n-                timeout: None,\n             },\n         }\n     }\n+    */\n \n     pub(crate) fn empty() -> Body {\n         Body::reusable(Bytes::new())\n@@ -138,6 +122,25 @@ impl Body {\n         }\n     }\n \n+    // pub?\n+    pub(crate) fn streaming<B>(inner: B) -> Body\n+    where\n+        B: HttpBody + Send + Sync + 'static,\n+        B::Data: Into<Bytes>,\n+        B::Error: Into<Box<dyn std::error::Error + Send + Sync>>,\n+    {\n+        use http_body_util::BodyExt;\n+\n+        let boxed = inner\n+            .map_frame(|f| f.map_data(Into::into))\n+            .map_err(Into::into)\n+            .boxed();\n+\n+        Body {\n+            inner: Inner::Streaming(boxed),\n+        }\n+    }\n+\n     pub(crate) fn try_reuse(self) -> (Option<Bytes>, Self) {\n         let reuse = match self.inner {\n             Inner::Reusable(ref chunk) => Some(chunk.clone()),\n@@ -154,30 +157,39 @@ impl Body {\n         }\n     }\n \n-    pub(crate) fn into_stream(self) -> ImplStream {\n-        ImplStream(self)\n+    #[cfg(feature = \"multipart\")]\n+    pub(crate) fn into_stream(self) -> DataStream<Body> {\n+        DataStream(self)\n     }\n \n     #[cfg(feature = \"multipart\")]\n     pub(crate) fn content_length(&self) -> Option<u64> {\n         match self.inner {\n             Inner::Reusable(ref bytes) => Some(bytes.len() as u64),\n-            Inner::Streaming { ref body, .. } => body.size_hint().exact(),\n+            Inner::Streaming(ref body) => body.size_hint().exact(),\n         }\n     }\n }\n \n+impl Default for Body {\n+    #[inline]\n+    fn default() -> Body {\n+        Body::empty()\n+    }\n+}\n+\n+/*\n impl From<hyper::Body> for Body {\n     #[inline]\n     fn from(body: hyper::Body) -> Body {\n         Self {\n             inner: Inner::Streaming {\n                 body: Box::pin(WrapHyper(body)),\n-                timeout: None,\n             },\n         }\n     }\n }\n+*/\n \n impl From<Bytes> for Body {\n     #[inline]\n@@ -229,132 +241,112 @@ impl fmt::Debug for Body {\n     }\n }\n \n-// ===== impl ImplStream =====\n-\n-impl HttpBody for ImplStream {\n+impl HttpBody for Body {\n     type Data = Bytes;\n     type Error = crate::Error;\n \n-    fn poll_data(\n+    fn poll_frame(\n         mut self: Pin<&mut Self>,\n         cx: &mut Context,\n-    ) -> Poll<Option<Result<Self::Data, Self::Error>>> {\n-        let opt_try_chunk = match self.0.inner {\n-            Inner::Streaming {\n-                ref mut body,\n-                ref mut timeout,\n-            } => {\n-                if let Some(ref mut timeout) = timeout {\n-                    if let Poll::Ready(()) = timeout.as_mut().poll(cx) {\n-                        return Poll::Ready(Some(Err(crate::error::body(crate::error::TimedOut))));\n-                    }\n-                }\n-                futures_core::ready!(Pin::new(body).poll_data(cx))\n-                    .map(|opt_chunk| opt_chunk.map(Into::into).map_err(crate::error::body))\n-            }\n+    ) -> Poll<Option<Result<hyper::body::Frame<Self::Data>, Self::Error>>> {\n+        match self.inner {\n             Inner::Reusable(ref mut bytes) => {\n-                if bytes.is_empty() {\n-                    None\n+                let out = bytes.split_off(0);\n+                if out.is_empty() {\n+                    Poll::Ready(None)\n                 } else {\n-                    Some(Ok(std::mem::replace(bytes, Bytes::new())))\n+                    Poll::Ready(Some(Ok(hyper::body::Frame::data(out))))\n                 }\n             }\n-        };\n-\n-        Poll::Ready(opt_try_chunk)\n-    }\n-\n-    fn poll_trailers(\n-        self: Pin<&mut Self>,\n-        _cx: &mut Context,\n-    ) -> Poll<Result<Option<http::HeaderMap>, Self::Error>> {\n-        Poll::Ready(Ok(None))\n-    }\n-\n-    fn is_end_stream(&self) -> bool {\n-        match self.0.inner {\n-            Inner::Streaming { ref body, .. } => body.is_end_stream(),\n-            Inner::Reusable(ref bytes) => bytes.is_empty(),\n+            Inner::Streaming(ref mut body) => Poll::Ready(\n+                futures_core::ready!(Pin::new(body).poll_frame(cx))\n+                    .map(|opt_chunk| opt_chunk.map_err(crate::error::body)),\n+            ),\n         }\n     }\n \n     fn size_hint(&self) -> http_body::SizeHint {\n-        match self.0.inner {\n-            Inner::Streaming { ref body, .. } => body.size_hint(),\n+        match self.inner {\n             Inner::Reusable(ref bytes) => {\n                 let mut hint = http_body::SizeHint::default();\n                 hint.set_exact(bytes.len() as u64);\n                 hint\n             }\n+            Inner::Streaming(ref body) => body.size_hint(),\n         }\n     }\n }\n \n-impl Stream for ImplStream {\n-    type Item = Result<Bytes, crate::Error>;\n+// ===== impl TotalTimeoutBody =====\n \n-    fn poll_next(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {\n-        self.poll_data(cx)\n+pub(crate) fn total_timeout<B>(body: B, timeout: Pin<Box<Sleep>>) -> TotalTimeoutBody<B> {\n+    TotalTimeoutBody {\n+        inner: body,\n+        timeout,\n     }\n }\n \n-// ===== impl WrapStream =====\n-\n-impl<S, D, E> HttpBody for WrapStream<S>\n+impl<B> hyper::body::Body for TotalTimeoutBody<B>\n where\n-    S: Stream<Item = Result<D, E>>,\n-    D: Into<Bytes>,\n-    E: Into<Box<dyn std::error::Error + Send + Sync>>,\n+    B: hyper::body::Body + Unpin,\n+    B::Error: Into<Box<dyn std::error::Error + Send + Sync>>,\n {\n-    type Data = Bytes;\n-    type Error = E;\n+    type Data = B::Data;\n+    type Error = crate::Error;\n \n-    fn poll_data(\n-        self: Pin<&mut Self>,\n+    fn poll_frame(\n+        mut self: Pin<&mut Self>,\n         cx: &mut Context,\n-    ) -> Poll<Option<Result<Self::Data, Self::Error>>> {\n-        let item = futures_core::ready!(self.project().inner.get_pin_mut().poll_next(cx)?);\n-\n-        Poll::Ready(item.map(|val| Ok(val.into())))\n-    }\n-\n-    fn poll_trailers(\n-        self: Pin<&mut Self>,\n-        _cx: &mut Context,\n-    ) -> Poll<Result<Option<http::HeaderMap>, Self::Error>> {\n-        Poll::Ready(Ok(None))\n+    ) -> Poll<Option<Result<hyper::body::Frame<Self::Data>, Self::Error>>> {\n+        if let Poll::Ready(()) = self.timeout.as_mut().poll(cx) {\n+            return Poll::Ready(Some(Err(crate::error::body(crate::error::TimedOut))));\n+        }\n+        Poll::Ready(\n+            futures_core::ready!(Pin::new(&mut self.inner).poll_frame(cx))\n+                .map(|opt_chunk| opt_chunk.map_err(crate::error::body)),\n+        )\n     }\n }\n \n-// ===== impl WrapHyper =====\n+pub(crate) type ResponseBody =\n+    http_body_util::combinators::BoxBody<Bytes, Box<dyn std::error::Error + Send + Sync>>;\n \n-impl HttpBody for WrapHyper {\n-    type Data = Bytes;\n-    type Error = Box<dyn std::error::Error + Send + Sync>;\n+pub(crate) fn response(\n+    body: hyper::body::Incoming,\n+    timeout: Option<Pin<Box<Sleep>>>,\n+) -> ResponseBody {\n+    use http_body_util::BodyExt;\n \n-    fn poll_data(\n-        mut self: Pin<&mut Self>,\n-        cx: &mut Context,\n-    ) -> Poll<Option<Result<Self::Data, Self::Error>>> {\n-        // safe pin projection\n-        Pin::new(&mut self.0)\n-            .poll_data(cx)\n-            .map(|opt| opt.map(|res| res.map_err(Into::into)))\n-    }\n-\n-    fn poll_trailers(\n-        self: Pin<&mut Self>,\n-        _cx: &mut Context,\n-    ) -> Poll<Result<Option<http::HeaderMap>, Self::Error>> {\n-        Poll::Ready(Ok(None))\n+    if let Some(timeout) = timeout {\n+        total_timeout(body, timeout).map_err(Into::into).boxed()\n+    } else {\n+        body.map_err(Into::into).boxed()\n     }\n+}\n \n-    fn is_end_stream(&self) -> bool {\n-        self.0.is_end_stream()\n-    }\n+// ===== impl DataStream =====\n \n-    fn size_hint(&self) -> http_body::SizeHint {\n-        HttpBody::size_hint(&self.0)\n+impl<B> futures_core::Stream for DataStream<B>\n+where\n+    B: HttpBody<Data = Bytes> + Unpin,\n+{\n+    type Item = Result<Bytes, B::Error>;\n+\n+    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {\n+        loop {\n+            return match futures_core::ready!(Pin::new(&mut self.0).poll_frame(cx)) {\n+                Some(Ok(frame)) => {\n+                    // skip non-data frames\n+                    if let Ok(buf) = frame.into_data() {\n+                        Poll::Ready(Some(Ok(buf)))\n+                    } else {\n+                        continue;\n+                    }\n+                }\n+                Some(Err(err)) => Poll::Ready(Some(Err(err))),\n+                None => Poll::Ready(None),\n+            };\n+        }\n     }\n }\n \ndiff --git a/src/async_impl/client.rs b/src/async_impl/client.rs\nindex b247624ed..926e21e59 100644\n--- a/src/async_impl/client.rs\n+++ b/src/async_impl/client.rs\n@@ -13,8 +13,8 @@ use http::header::{\n };\n use http::uri::Scheme;\n use http::Uri;\n-use hyper::client::{HttpConnector, ResponseFuture as HyperResponseFuture};\n-#[cfg(feature = \"native-tls-crate\")]\n+use hyper_util::client::legacy::connect::HttpConnector;\n+#[cfg(feature = \"default-tls\")]\n use native_tls_crate::TlsConnector;\n use pin_project_lite::pin_project;\n use std::future::Future;\n@@ -46,12 +46,14 @@ use crate::Certificate;\n #[cfg(any(feature = \"native-tls\", feature = \"__rustls\"))]\n use crate::Identity;\n use crate::{IntoUrl, Method, Proxy, StatusCode, Url};\n-use log::{debug, trace};\n+use log::debug;\n #[cfg(feature = \"http3\")]\n use quinn::TransportConfig;\n #[cfg(feature = \"http3\")]\n use quinn::VarInt;\n \n+type HyperResponseFuture = hyper_util::client::legacy::ResponseFuture;\n+\n /// An asynchronous `Client` to make Requests with.\n ///\n /// The Client has various configuration values to tweak, but the defaults\n@@ -78,6 +80,7 @@ pub struct ClientBuilder {\n \n enum HttpVersionPref {\n     Http1,\n+    #[cfg(feature = \"http2\")]\n     Http2,\n     #[cfg(feature = \"http3\")]\n     Http3,\n@@ -124,14 +127,23 @@ struct Config {\n     http1_allow_obsolete_multiline_headers_in_responses: bool,\n     http1_ignore_invalid_headers_in_responses: bool,\n     http1_allow_spaces_after_header_name_in_responses: bool,\n+    #[cfg(feature = \"http2\")]\n     http2_initial_stream_window_size: Option<u32>,\n+    #[cfg(feature = \"http2\")]\n     http2_initial_connection_window_size: Option<u32>,\n+    #[cfg(feature = \"http2\")]\n     http2_adaptive_window: bool,\n+    #[cfg(feature = \"http2\")]\n     http2_max_frame_size: Option<u32>,\n+    #[cfg(feature = \"http2\")]\n     http2_keep_alive_interval: Option<Duration>,\n+    #[cfg(feature = \"http2\")]\n     http2_keep_alive_timeout: Option<Duration>,\n+    #[cfg(feature = \"http2\")]\n     http2_keep_alive_while_idle: bool,\n     local_address: Option<IpAddr>,\n+    #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+    interface: Option<String>,\n     nodelay: bool,\n     #[cfg(feature = \"cookies\")]\n     cookie_store: Option<Arc<dyn cookie::CookieStore>>,\n@@ -209,14 +221,23 @@ impl ClientBuilder {\n                 http1_allow_obsolete_multiline_headers_in_responses: false,\n                 http1_ignore_invalid_headers_in_responses: false,\n                 http1_allow_spaces_after_header_name_in_responses: false,\n+                #[cfg(feature = \"http2\")]\n                 http2_initial_stream_window_size: None,\n+                #[cfg(feature = \"http2\")]\n                 http2_initial_connection_window_size: None,\n+                #[cfg(feature = \"http2\")]\n                 http2_adaptive_window: false,\n+                #[cfg(feature = \"http2\")]\n                 http2_max_frame_size: None,\n+                #[cfg(feature = \"http2\")]\n                 http2_keep_alive_interval: None,\n+                #[cfg(feature = \"http2\")]\n                 http2_keep_alive_timeout: None,\n+                #[cfg(feature = \"http2\")]\n                 http2_keep_alive_while_idle: false,\n                 local_address: None,\n+                #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+                interface: None,\n                 nodelay: true,\n                 hickory_dns: cfg!(feature = \"hickory-dns\"),\n                 #[cfg(feature = \"cookies\")]\n@@ -347,6 +368,7 @@ impl ClientBuilder {\n                             HttpVersionPref::Http1 => {\n                                 tls.request_alpns(&[\"http/1.1\"]);\n                             }\n+                            #[cfg(feature = \"http2\")]\n                             HttpVersionPref::Http2 => {\n                                 tls.request_alpns(&[\"h2\"]);\n                             }\n@@ -412,6 +434,12 @@ impl ClientBuilder {\n                         proxies.clone(),\n                         user_agent(&config.headers),\n                         config.local_address,\n+                        #[cfg(any(\n+                            target_os = \"android\",\n+                            target_os = \"fuchsia\",\n+                            target_os = \"linux\"\n+                        ))]\n+                        config.interface.as_deref(),\n                         config.nodelay,\n                         config.tls_info,\n                     )?\n@@ -423,6 +451,8 @@ impl ClientBuilder {\n                     proxies.clone(),\n                     user_agent(&config.headers),\n                     config.local_address,\n+                    #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+                    config.interface.as_deref(),\n                     config.nodelay,\n                     config.tls_info,\n                 ),\n@@ -438,6 +468,12 @@ impl ClientBuilder {\n                             config.quic_receive_window,\n                             config.quic_send_window,\n                             config.local_address,\n+                            #[cfg(any(\n+                                target_os = \"android\",\n+                                target_os = \"fuchsia\",\n+                                target_os = \"linux\"\n+                            ))]\n+                            config.interface.as_deref(),\n                             &config.http_version_pref,\n                         )?;\n                     }\n@@ -448,6 +484,12 @@ impl ClientBuilder {\n                         proxies.clone(),\n                         user_agent(&config.headers),\n                         config.local_address,\n+                        #[cfg(any(\n+                            target_os = \"android\",\n+                            target_os = \"fuchsia\",\n+                            target_os = \"linux\"\n+                        ))]\n+                        config.interface.as_deref(),\n                         config.nodelay,\n                         config.tls_info,\n                     )\n@@ -464,18 +506,7 @@ impl ClientBuilder {\n \n                     #[cfg(feature = \"rustls-tls-webpki-roots\")]\n                     if config.tls_built_in_root_certs {\n-                        use rustls::OwnedTrustAnchor;\n-\n-                        let trust_anchors =\n-                            webpki_roots::TLS_SERVER_ROOTS.iter().map(|trust_anchor| {\n-                                OwnedTrustAnchor::from_subject_spki_name_constraints(\n-                                    trust_anchor.subject,\n-                                    trust_anchor.spki,\n-                                    trust_anchor.name_constraints,\n-                                )\n-                            });\n-\n-                        root_cert_store.add_trust_anchors(trust_anchors);\n+                        root_cert_store.extend(webpki_roots::TLS_SERVER_ROOTS.iter().cloned());\n                     }\n \n                     #[cfg(feature = \"rustls-tls-native-roots\")]\n@@ -485,17 +516,14 @@ impl ClientBuilder {\n                         for cert in rustls_native_certs::load_native_certs()\n                             .map_err(crate::error::builder)?\n                         {\n-                            let cert = rustls::Certificate(cert.0);\n                             // Continue on parsing errors, as native stores often include ancient or syntactically\n                             // invalid certificates, like root certificates without any X509 extensions.\n                             // Inspiration: https://github.com/rustls/rustls/blob/633bf4ba9d9521a95f68766d04c22e2b01e68318/rustls/src/anchors.rs#L105-L112\n-                            match root_cert_store.add(&cert) {\n+                            match root_cert_store.add(cert.into()) {\n                                 Ok(_) => valid_count += 1,\n                                 Err(err) => {\n                                     invalid_count += 1;\n-                                    log::warn!(\n-                                        \"rustls failed to parse DER certificate {err:?} {cert:?}\"\n-                                    );\n+                                    log::debug!(\"rustls failed to parse DER certificate: {err:?}\");\n                                 }\n                             }\n                         }\n@@ -530,12 +558,8 @@ impl ClientBuilder {\n                     }\n \n                     // Build TLS config\n-                    let config_builder = rustls::ClientConfig::builder()\n-                        .with_safe_default_cipher_suites()\n-                        .with_safe_default_kx_groups()\n-                        .with_protocol_versions(&versions)\n-                        .map_err(crate::error::builder)?\n-                        .with_root_certificates(root_cert_store);\n+                    let config_builder =\n+                        rustls::ClientConfig::builder().with_root_certificates(root_cert_store);\n \n                     // Finalize TLS config\n                     let mut tls = if let Some(id) = config.identity {\n@@ -557,6 +581,7 @@ impl ClientBuilder {\n                         HttpVersionPref::Http1 => {\n                             tls.alpn_protocols = vec![\"http/1.1\".into()];\n                         }\n+                        #[cfg(feature = \"http2\")]\n                         HttpVersionPref::Http2 => {\n                             tls.alpn_protocols = vec![\"h2\".into()];\n                         }\n@@ -591,6 +616,12 @@ impl ClientBuilder {\n                         proxies.clone(),\n                         user_agent(&config.headers),\n                         config.local_address,\n+                        #[cfg(any(\n+                            target_os = \"android\",\n+                            target_os = \"fuchsia\",\n+                            target_os = \"linux\"\n+                        ))]\n+                        config.interface.as_deref(),\n                         config.nodelay,\n                         config.tls_info,\n                     )\n@@ -610,35 +641,42 @@ impl ClientBuilder {\n         connector.set_timeout(config.connect_timeout);\n         connector.set_verbose(config.connection_verbose);\n \n-        let mut builder = hyper::Client::builder();\n-        if matches!(config.http_version_pref, HttpVersionPref::Http2) {\n-            builder.http2_only(true);\n-        }\n-\n-        if let Some(http2_initial_stream_window_size) = config.http2_initial_stream_window_size {\n-            builder.http2_initial_stream_window_size(http2_initial_stream_window_size);\n-        }\n-        if let Some(http2_initial_connection_window_size) =\n-            config.http2_initial_connection_window_size\n+        let mut builder =\n+            hyper_util::client::legacy::Client::builder(hyper_util::rt::TokioExecutor::new());\n+        #[cfg(feature = \"http2\")]\n         {\n-            builder.http2_initial_connection_window_size(http2_initial_connection_window_size);\n-        }\n-        if config.http2_adaptive_window {\n-            builder.http2_adaptive_window(true);\n-        }\n-        if let Some(http2_max_frame_size) = config.http2_max_frame_size {\n-            builder.http2_max_frame_size(http2_max_frame_size);\n-        }\n-        if let Some(http2_keep_alive_interval) = config.http2_keep_alive_interval {\n-            builder.http2_keep_alive_interval(http2_keep_alive_interval);\n-        }\n-        if let Some(http2_keep_alive_timeout) = config.http2_keep_alive_timeout {\n-            builder.http2_keep_alive_timeout(http2_keep_alive_timeout);\n-        }\n-        if config.http2_keep_alive_while_idle {\n-            builder.http2_keep_alive_while_idle(true);\n+            if matches!(config.http_version_pref, HttpVersionPref::Http2) {\n+                builder.http2_only(true);\n+            }\n+\n+            if let Some(http2_initial_stream_window_size) = config.http2_initial_stream_window_size\n+            {\n+                builder.http2_initial_stream_window_size(http2_initial_stream_window_size);\n+            }\n+            if let Some(http2_initial_connection_window_size) =\n+                config.http2_initial_connection_window_size\n+            {\n+                builder.http2_initial_connection_window_size(http2_initial_connection_window_size);\n+            }\n+            if config.http2_adaptive_window {\n+                builder.http2_adaptive_window(true);\n+            }\n+            if let Some(http2_max_frame_size) = config.http2_max_frame_size {\n+                builder.http2_max_frame_size(http2_max_frame_size);\n+            }\n+            if let Some(http2_keep_alive_interval) = config.http2_keep_alive_interval {\n+                builder.http2_keep_alive_interval(http2_keep_alive_interval);\n+            }\n+            if let Some(http2_keep_alive_timeout) = config.http2_keep_alive_timeout {\n+                builder.http2_keep_alive_timeout(http2_keep_alive_timeout);\n+            }\n+            if config.http2_keep_alive_while_idle {\n+                builder.http2_keep_alive_while_idle(true);\n+            }\n         }\n \n+        #[cfg(not(target_arch = \"wasm32\"))]\n+        builder.timer(hyper_util::rt::TokioTimer::new());\n         builder.pool_idle_timeout(config.pool_idle_timeout);\n         builder.pool_max_idle_per_host(config.pool_max_idle_per_host);\n         connector.set_keepalive(config.tcp_keepalive);\n@@ -1102,6 +1140,8 @@ impl ClientBuilder {\n     }\n \n     /// Only use HTTP/2.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_prior_knowledge(mut self) -> ClientBuilder {\n         self.config.http_version_pref = HttpVersionPref::Http2;\n         self\n@@ -1118,6 +1158,8 @@ impl ClientBuilder {\n     /// Sets the `SETTINGS_INITIAL_WINDOW_SIZE` option for HTTP2 stream-level flow control.\n     ///\n     /// Default is currently 65,535 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_initial_stream_window_size(mut self, sz: impl Into<Option<u32>>) -> ClientBuilder {\n         self.config.http2_initial_stream_window_size = sz.into();\n         self\n@@ -1126,6 +1168,8 @@ impl ClientBuilder {\n     /// Sets the max connection-level flow control for HTTP2\n     ///\n     /// Default is currently 65,535 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_initial_connection_window_size(\n         mut self,\n         sz: impl Into<Option<u32>>,\n@@ -1138,6 +1182,8 @@ impl ClientBuilder {\n     ///\n     /// Enabling this will override the limits set in `http2_initial_stream_window_size` and\n     /// `http2_initial_connection_window_size`.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_adaptive_window(mut self, enabled: bool) -> ClientBuilder {\n         self.config.http2_adaptive_window = enabled;\n         self\n@@ -1146,6 +1192,8 @@ impl ClientBuilder {\n     /// Sets the maximum frame size to use for HTTP2.\n     ///\n     /// Default is currently 16,384 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_max_frame_size(mut self, sz: impl Into<Option<u32>>) -> ClientBuilder {\n         self.config.http2_max_frame_size = sz.into();\n         self\n@@ -1155,6 +1203,8 @@ impl ClientBuilder {\n     ///\n     /// Pass `None` to disable HTTP2 keep-alive.\n     /// Default is currently disabled.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_keep_alive_interval(\n         mut self,\n         interval: impl Into<Option<Duration>>,\n@@ -1168,6 +1218,8 @@ impl ClientBuilder {\n     /// If the ping is not acknowledged within the timeout, the connection will be closed.\n     /// Does nothing if `http2_keep_alive_interval` is disabled.\n     /// Default is currently disabled.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_keep_alive_timeout(mut self, timeout: Duration) -> ClientBuilder {\n         self.config.http2_keep_alive_timeout = Some(timeout);\n         self\n@@ -1179,6 +1231,8 @@ impl ClientBuilder {\n     /// If enabled, pings are also sent when no streams are active.\n     /// Does nothing if `http2_keep_alive_interval` is disabled.\n     /// Default is `false`.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_keep_alive_while_idle(mut self, enabled: bool) -> ClientBuilder {\n         self.config.http2_keep_alive_while_idle = enabled;\n         self\n@@ -1213,6 +1267,22 @@ impl ClientBuilder {\n         self\n     }\n \n+    /// Bind to an interface by `SO_BINDTODEVICE`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// let interface = \"lo\";\n+    /// let client = reqwest::Client::builder()\n+    ///     .interface(interface)\n+    ///     .build().unwrap();\n+    /// ```\n+    #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+    pub fn interface(mut self, interface: &str) -> ClientBuilder {\n+        self.config.interface = Some(interface.to_string());\n+        self\n+    }\n+\n     /// Set that all sockets have `SO_KEEPALIVE` set with the supplied duration.\n     ///\n     /// If `None`, the option will not be set.\n@@ -1472,9 +1542,7 @@ impl ClientBuilder {\n         let mut tls = Some(tls);\n         #[cfg(feature = \"native-tls\")]\n         {\n-            if let Some(conn) =\n-                (&mut tls as &mut dyn Any).downcast_mut::<Option<native_tls_crate::TlsConnector>>()\n-            {\n+            if let Some(conn) = (&mut tls as &mut dyn Any).downcast_mut::<Option<TlsConnector>>() {\n                 let tls = conn.take().expect(\"is definitely Some\");\n                 let tls = crate::tls::TlsBackend::BuiltNativeTls(tls);\n                 self.config.tls = tls;\n@@ -1691,7 +1759,7 @@ impl ClientBuilder {\n     }\n }\n \n-type HyperClient = hyper::Client<Connector, super::body::ImplStream>;\n+type HyperClient = hyper_util::client::legacy::Client<Connector, super::Body>;\n \n impl Default for Client {\n     fn default() -> Self {\n@@ -1871,9 +1939,7 @@ impl Client {\n                 ResponseFuture::H3(self.inner.h3_client.as_ref().unwrap().request(req))\n             }\n             _ => {\n-                let mut req = builder\n-                    .body(body.into_stream())\n-                    .expect(\"valid request parts\");\n+                let mut req = builder.body(body).expect(\"valid request parts\");\n                 *req.headers_mut() = headers.clone();\n                 ResponseFuture::Default(self.inner.hyper.request(req))\n             }\n@@ -2023,6 +2089,7 @@ impl Config {\n             f.field(\"http1_only\", &true);\n         }\n \n+        #[cfg(feature = \"http2\")]\n         if matches!(self.http_version_pref, HttpVersionPref::Http2) {\n             f.field(\"http2_prior_knowledge\", &true);\n         }\n@@ -2039,6 +2106,11 @@ impl Config {\n             f.field(\"local_address\", v);\n         }\n \n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        if let Some(ref v) = self.interface {\n+            f.field(\"interface\", v);\n+        }\n+\n         if self.nodelay {\n             f.field(\"tcp_nodelay\", &true);\n         }\n@@ -2069,7 +2141,7 @@ impl Config {\n             f.field(\"tls_info\", &self.tls_info);\n         }\n \n-        #[cfg(all(feature = \"native-tls-crate\", feature = \"__rustls\"))]\n+        #[cfg(all(feature = \"default-tls\", feature = \"__rustls\"))]\n         {\n             f.field(\"tls_backend\", &self.tls);\n         }\n@@ -2192,7 +2264,10 @@ impl PendingRequest {\n         self.project().headers\n     }\n \n+    #[cfg(feature = \"http2\")]\n     fn retry_error(mut self: Pin<&mut Self>, err: &(dyn std::error::Error + 'static)) -> bool {\n+        use log::trace;\n+\n         if !is_retryable_error(err) {\n             return false;\n         }\n@@ -2238,7 +2313,7 @@ impl PendingRequest {\n                 let mut req = hyper::Request::builder()\n                     .method(self.method.clone())\n                     .uri(uri)\n-                    .body(body.into_stream())\n+                    .body(body)\n                     .expect(\"valid request parts\");\n                 *req.headers_mut() = self.headers.clone();\n                 ResponseFuture::Default(self.client.hyper.request(req))\n@@ -2249,7 +2324,15 @@ impl PendingRequest {\n     }\n }\n \n+#[cfg(feature = \"http2\")]\n fn is_retryable_error(err: &(dyn std::error::Error + 'static)) -> bool {\n+    // pop the legacy::Error\n+    let err = if let Some(err) = err.source() {\n+        err\n+    } else {\n+        return false;\n+    };\n+\n     #[cfg(feature = \"http3\")]\n     if let Some(cause) = err.source() {\n         if let Some(err) = cause.downcast_ref::<h3::Error>() {\n@@ -2319,6 +2402,7 @@ impl Future for PendingRequest {\n             let res = match self.as_mut().in_flight().get_mut() {\n                 ResponseFuture::Default(r) => match Pin::new(r).poll(cx) {\n                     Poll::Ready(Err(e)) => {\n+                        #[cfg(feature = \"http2\")]\n                         if self.as_mut().retry_error(&e) {\n                             continue;\n                         }\n@@ -2474,7 +2558,7 @@ impl Future for PendingRequest {\n                                         let mut req = hyper::Request::builder()\n                                             .method(self.method.clone())\n                                             .uri(uri.clone())\n-                                            .body(body.into_stream())\n+                                            .body(body)\n                                             .expect(\"valid request parts\");\n                                         *req.headers_mut() = headers.clone();\n                                         std::mem::swap(self.as_mut().headers(), &mut headers);\ndiff --git a/src/async_impl/decoder.rs b/src/async_impl/decoder.rs\nindex 86eb6e5d9..128f77ecb 100644\n--- a/src/async_impl/decoder.rs\n+++ b/src/async_impl/decoder.rs\n@@ -16,14 +16,15 @@ use bytes::Bytes;\n use futures_core::Stream;\n use futures_util::stream::Peekable;\n use http::HeaderMap;\n-use hyper::body::HttpBody;\n+use hyper::body::Body as HttpBody;\n+use hyper::body::Frame;\n \n #[cfg(any(feature = \"gzip\", feature = \"brotli\", feature = \"deflate\"))]\n use tokio_util::codec::{BytesCodec, FramedRead};\n #[cfg(any(feature = \"gzip\", feature = \"brotli\", feature = \"deflate\"))]\n use tokio_util::io::StreamReader;\n \n-use super::super::Body;\n+use super::body::ResponseBody;\n use crate::error;\n \n #[derive(Clone, Copy, Debug)]\n@@ -36,6 +37,19 @@ pub(super) struct Accepts {\n     pub(super) deflate: bool,\n }\n \n+impl Accepts {\n+    pub fn none() -> Self {\n+        Self {\n+            #[cfg(feature = \"gzip\")]\n+            gzip: false,\n+            #[cfg(feature = \"brotli\")]\n+            brotli: false,\n+            #[cfg(feature = \"deflate\")]\n+            deflate: false,\n+        }\n+    }\n+}\n+\n /// A response decompressor over a non-blocking stream of chunks.\n ///\n /// The inner decoder may be constructed asynchronously.\n@@ -50,7 +64,7 @@ type PeekableIoStreamReader = StreamReader<PeekableIoStream, Bytes>;\n \n enum Inner {\n     /// A `PlainText` decoder just returns the response content as is.\n-    PlainText(super::body::ImplStream),\n+    PlainText(ResponseBody),\n \n     /// A `Gzip` decoder will uncompress the gzipped response content before returning it.\n     #[cfg(feature = \"gzip\")]\n@@ -72,7 +86,7 @@ enum Inner {\n /// A future attempt to poll the response body for EOF so we know whether to use gzip or not.\n struct Pending(PeekableIoStream, DecoderType);\n \n-struct IoStream(super::body::ImplStream);\n+pub(crate) struct IoStream<B = ResponseBody>(B);\n \n enum DecoderType {\n     #[cfg(feature = \"gzip\")]\n@@ -93,16 +107,21 @@ impl Decoder {\n     #[cfg(feature = \"blocking\")]\n     pub(crate) fn empty() -> Decoder {\n         Decoder {\n-            inner: Inner::PlainText(Body::empty().into_stream()),\n+            inner: Inner::PlainText(empty()),\n         }\n     }\n \n+    #[cfg(feature = \"blocking\")]\n+    pub(crate) fn into_stream(self) -> IoStream<Self> {\n+        IoStream(self)\n+    }\n+\n     /// A plain text decoder.\n     ///\n     /// This decoder will emit the underlying chunks as-is.\n-    fn plain_text(body: Body) -> Decoder {\n+    fn plain_text(body: ResponseBody) -> Decoder {\n         Decoder {\n-            inner: Inner::PlainText(body.into_stream()),\n+            inner: Inner::PlainText(body),\n         }\n     }\n \n@@ -110,12 +129,12 @@ impl Decoder {\n     ///\n     /// This decoder will buffer and decompress chunks that are gzipped.\n     #[cfg(feature = \"gzip\")]\n-    fn gzip(body: Body) -> Decoder {\n+    fn gzip(body: ResponseBody) -> Decoder {\n         use futures_util::StreamExt;\n \n         Decoder {\n             inner: Inner::Pending(Box::pin(Pending(\n-                IoStream(body.into_stream()).peekable(),\n+                IoStream(body).peekable(),\n                 DecoderType::Gzip,\n             ))),\n         }\n@@ -125,12 +144,12 @@ impl Decoder {\n     ///\n     /// This decoder will buffer and decompress chunks that are brotlied.\n     #[cfg(feature = \"brotli\")]\n-    fn brotli(body: Body) -> Decoder {\n+    fn brotli(body: ResponseBody) -> Decoder {\n         use futures_util::StreamExt;\n \n         Decoder {\n             inner: Inner::Pending(Box::pin(Pending(\n-                IoStream(body.into_stream()).peekable(),\n+                IoStream(body).peekable(),\n                 DecoderType::Brotli,\n             ))),\n         }\n@@ -140,12 +159,12 @@ impl Decoder {\n     ///\n     /// This decoder will buffer and decompress chunks that are deflated.\n     #[cfg(feature = \"deflate\")]\n-    fn deflate(body: Body) -> Decoder {\n+    fn deflate(body: ResponseBody) -> Decoder {\n         use futures_util::StreamExt;\n \n         Decoder {\n             inner: Inner::Pending(Box::pin(Pending(\n-                IoStream(body.into_stream()).peekable(),\n+                IoStream(body).peekable(),\n                 DecoderType::Deflate,\n             ))),\n         }\n@@ -187,7 +206,11 @@ impl Decoder {\n     /// how to decode the content body of the request.\n     ///\n     /// Uses the correct variant by inspecting the Content-Encoding header.\n-    pub(super) fn detect(_headers: &mut HeaderMap, body: Body, _accepts: Accepts) -> Decoder {\n+    pub(super) fn detect(\n+        _headers: &mut HeaderMap,\n+        body: ResponseBody,\n+        _accepts: Accepts,\n+    ) -> Decoder {\n         #[cfg(feature = \"gzip\")]\n         {\n             if _accepts.gzip && Decoder::detect_encoding(_headers, \"gzip\") {\n@@ -213,26 +236,35 @@ impl Decoder {\n     }\n }\n \n-impl Stream for Decoder {\n-    type Item = Result<Bytes, error::Error>;\n+impl HttpBody for Decoder {\n+    type Data = Bytes;\n+    type Error = crate::Error;\n \n-    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {\n-        // Do a read or poll for a pending decoder value.\n+    fn poll_frame(\n+        mut self: Pin<&mut Self>,\n+        cx: &mut Context,\n+    ) -> Poll<Option<Result<Frame<Self::Data>, Self::Error>>> {\n         match self.inner {\n             #[cfg(any(feature = \"brotli\", feature = \"gzip\", feature = \"deflate\"))]\n             Inner::Pending(ref mut future) => match Pin::new(future).poll(cx) {\n                 Poll::Ready(Ok(inner)) => {\n                     self.inner = inner;\n-                    self.poll_next(cx)\n+                    self.poll_frame(cx)\n                 }\n                 Poll::Ready(Err(e)) => Poll::Ready(Some(Err(crate::error::decode_io(e)))),\n                 Poll::Pending => Poll::Pending,\n             },\n-            Inner::PlainText(ref mut body) => Pin::new(body).poll_next(cx),\n+            Inner::PlainText(ref mut body) => {\n+                match futures_core::ready!(Pin::new(body).poll_frame(cx)) {\n+                    Some(Ok(frame)) => Poll::Ready(Some(Ok(frame))),\n+                    Some(Err(err)) => Poll::Ready(Some(Err(crate::error::decode(err)))),\n+                    None => Poll::Ready(None),\n+                }\n+            }\n             #[cfg(feature = \"gzip\")]\n             Inner::Gzip(ref mut decoder) => {\n                 match futures_core::ready!(Pin::new(decoder).poll_next(cx)) {\n-                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(bytes.freeze()))),\n+                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(Frame::data(bytes.freeze())))),\n                     Some(Err(err)) => Poll::Ready(Some(Err(crate::error::decode_io(err)))),\n                     None => Poll::Ready(None),\n                 }\n@@ -240,7 +272,7 @@ impl Stream for Decoder {\n             #[cfg(feature = \"brotli\")]\n             Inner::Brotli(ref mut decoder) => {\n                 match futures_core::ready!(Pin::new(decoder).poll_next(cx)) {\n-                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(bytes.freeze()))),\n+                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(Frame::data(bytes.freeze())))),\n                     Some(Err(err)) => Poll::Ready(Some(Err(crate::error::decode_io(err)))),\n                     None => Poll::Ready(None),\n                 }\n@@ -248,32 +280,13 @@ impl Stream for Decoder {\n             #[cfg(feature = \"deflate\")]\n             Inner::Deflate(ref mut decoder) => {\n                 match futures_core::ready!(Pin::new(decoder).poll_next(cx)) {\n-                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(bytes.freeze()))),\n+                    Some(Ok(bytes)) => Poll::Ready(Some(Ok(Frame::data(bytes.freeze())))),\n                     Some(Err(err)) => Poll::Ready(Some(Err(crate::error::decode_io(err)))),\n                     None => Poll::Ready(None),\n                 }\n             }\n         }\n     }\n-}\n-\n-impl HttpBody for Decoder {\n-    type Data = Bytes;\n-    type Error = crate::Error;\n-\n-    fn poll_data(\n-        self: Pin<&mut Self>,\n-        cx: &mut Context,\n-    ) -> Poll<Option<Result<Self::Data, Self::Error>>> {\n-        self.poll_next(cx)\n-    }\n-\n-    fn poll_trailers(\n-        self: Pin<&mut Self>,\n-        _cx: &mut Context,\n-    ) -> Poll<Result<Option<http::HeaderMap>, Self::Error>> {\n-        Poll::Ready(Ok(None))\n-    }\n \n     fn size_hint(&self) -> http_body::SizeHint {\n         match self.inner {\n@@ -285,6 +298,11 @@ impl HttpBody for Decoder {\n     }\n }\n \n+fn empty() -> ResponseBody {\n+    use http_body_util::{combinators::BoxBody, BodyExt, Empty};\n+    BoxBody::new(Empty::new().map_err(|never| match never {}))\n+}\n+\n impl Future for Pending {\n     type Output = Result<Inner, std::io::Error>;\n \n@@ -303,13 +321,10 @@ impl Future for Pending {\n                 .expect(\"just peeked Some\")\n                 .unwrap_err()));\n             }\n-            None => return Poll::Ready(Ok(Inner::PlainText(Body::empty().into_stream()))),\n+            None => return Poll::Ready(Ok(Inner::PlainText(empty()))),\n         };\n \n-        let _body = std::mem::replace(\n-            &mut self.0,\n-            IoStream(Body::empty().into_stream()).peekable(),\n-        );\n+        let _body = std::mem::replace(&mut self.0, IoStream(empty()).peekable());\n \n         match self.1 {\n             #[cfg(feature = \"brotli\")]\n@@ -331,14 +346,27 @@ impl Future for Pending {\n     }\n }\n \n-impl Stream for IoStream {\n+impl<B> Stream for IoStream<B>\n+where\n+    B: HttpBody<Data = Bytes> + Unpin,\n+    B::Error: Into<Box<dyn std::error::Error + Send + Sync>>,\n+{\n     type Item = Result<Bytes, std::io::Error>;\n \n     fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<Self::Item>> {\n-        match futures_core::ready!(Pin::new(&mut self.0).poll_next(cx)) {\n-            Some(Ok(chunk)) => Poll::Ready(Some(Ok(chunk))),\n-            Some(Err(err)) => Poll::Ready(Some(Err(err.into_io()))),\n-            None => Poll::Ready(None),\n+        loop {\n+            return match futures_core::ready!(Pin::new(&mut self.0).poll_frame(cx)) {\n+                Some(Ok(frame)) => {\n+                    // skip non-data frames\n+                    if let Ok(buf) = frame.into_data() {\n+                        Poll::Ready(Some(Ok(buf)))\n+                    } else {\n+                        continue;\n+                    }\n+                }\n+                Some(Err(err)) => Poll::Ready(Some(Err(error::into_io(err.into())))),\n+                None => Poll::Ready(None),\n+            };\n         }\n     }\n }\n@@ -346,6 +374,7 @@ impl Stream for IoStream {\n // ===== impl Accepts =====\n \n impl Accepts {\n+    /*\n     pub(super) fn none() -> Self {\n         Accepts {\n             #[cfg(feature = \"gzip\")]\n@@ -356,6 +385,7 @@ impl Accepts {\n             deflate: false,\n         }\n     }\n+    */\n \n     pub(super) fn as_str(&self) -> Option<&'static str> {\n         match (self.is_gzip(), self.is_brotli(), self.is_deflate()) {\ndiff --git a/src/async_impl/h3_client/connect.rs b/src/async_impl/h3_client/connect.rs\nindex 968704713..ec732f66a 100644\n--- a/src/async_impl/h3_client/connect.rs\n+++ b/src/async_impl/h3_client/connect.rs\n@@ -5,7 +5,7 @@ use bytes::Bytes;\n use h3::client::SendRequest;\n use h3_quinn::{Connection, OpenStreams};\n use http::Uri;\n-use hyper::client::connect::dns::Name;\n+use hyper_util::client::legacy::connect::dns::Name;\n use quinn::{ClientConfig, Endpoint, TransportConfig};\n use std::net::{IpAddr, SocketAddr};\n use std::str::FromStr;\ndiff --git a/src/async_impl/h3_client/dns.rs b/src/async_impl/h3_client/dns.rs\nindex 9cb50d1e3..bd59daaed 100644\n--- a/src/async_impl/h3_client/dns.rs\n+++ b/src/async_impl/h3_client/dns.rs\n@@ -1,5 +1,5 @@\n use core::task;\n-use hyper::client::connect::dns::Name;\n+use hyper_util::client::legacy::connect::dns::Name;\n use std::future::Future;\n use std::net::SocketAddr;\n use std::task::Poll;\ndiff --git a/src/async_impl/h3_client/pool.rs b/src/async_impl/h3_client/pool.rs\nindex d9ca3a661..d6442c81a 100644\n--- a/src/async_impl/h3_client/pool.rs\n+++ b/src/async_impl/h3_client/pool.rs\n@@ -13,7 +13,7 @@ use h3::client::SendRequest;\n use h3_quinn::{Connection, OpenStreams};\n use http::uri::{Authority, Scheme};\n use http::{Request, Response, Uri};\n-use hyper::Body as HyperBody;\n+use hyper::body as HyperBody;\n use log::trace;\n \n pub(super) type Key = (Scheme, Authority);\ndiff --git a/src/async_impl/response.rs b/src/async_impl/response.rs\nindex 77a3e53aa..d2ddfc3a1 100644\n--- a/src/async_impl/response.rs\n+++ b/src/async_impl/response.rs\n@@ -3,11 +3,9 @@ use std::net::SocketAddr;\n use std::pin::Pin;\n \n use bytes::Bytes;\n-use encoding_rs::{Encoding, UTF_8};\n-use futures_util::stream::StreamExt;\n-use hyper::client::connect::HttpInfo;\n+use http_body_util::BodyExt;\n use hyper::{HeaderMap, StatusCode, Version};\n-use mime::Mime;\n+use hyper_util::client::legacy::connect::HttpInfo;\n #[cfg(feature = \"json\")]\n use serde::de::DeserializeOwned;\n #[cfg(feature = \"json\")]\n@@ -17,9 +15,14 @@ use url::Url;\n \n use super::body::Body;\n use super::decoder::{Accepts, Decoder};\n+use crate::async_impl::body::ResponseBody;\n #[cfg(feature = \"cookies\")]\n use crate::cookie;\n-use crate::response::ResponseUrl;\n+\n+#[cfg(feature = \"charset\")]\n+use encoding_rs::{Encoding, UTF_8};\n+#[cfg(feature = \"charset\")]\n+use mime::Mime;\n \n /// A Response to a submitted `Request`.\n pub struct Response {\n@@ -31,13 +34,17 @@ pub struct Response {\n \n impl Response {\n     pub(super) fn new(\n-        res: hyper::Response<hyper::Body>,\n+        res: hyper::Response<hyper::body::Incoming>,\n         url: Url,\n         accepts: Accepts,\n         timeout: Option<Pin<Box<Sleep>>>,\n     ) -> Response {\n         let (mut parts, body) = res.into_parts();\n-        let decoder = Decoder::detect(&mut parts.headers, Body::response(body, timeout), accepts);\n+        let decoder = Decoder::detect(\n+            &mut parts.headers,\n+            super::body::response(body, timeout),\n+            accepts,\n+        );\n         let res = hyper::Response::from_parts(parts, decoder);\n \n         Response {\n@@ -78,9 +85,9 @@ impl Response {\n     /// - The response is compressed and automatically decoded (thus changing\n     ///   the actual decoded length).\n     pub fn content_length(&self) -> Option<u64> {\n-        use hyper::body::HttpBody;\n+        use hyper::body::Body;\n \n-        HttpBody::size_hint(self.res.body()).exact()\n+        Body::size_hint(self.res.body()).exact()\n     }\n \n     /// Retrieve the cookies contained in the response.\n@@ -131,6 +138,11 @@ impl Response {\n     ///\n     /// Note that the BOM is stripped from the returned String.\n     ///\n+    /// # Note\n+    ///\n+    /// If the `charset` feature is disabled the method will only attempt to decode the\n+    /// response as UTF-8, regardless of the given `Content-Type`\n+    ///\n     /// # Example\n     ///\n     /// ```\n@@ -145,7 +157,17 @@ impl Response {\n     /// # }\n     /// ```\n     pub async fn text(self) -> crate::Result<String> {\n-        self.text_with_charset(\"utf-8\").await\n+        #[cfg(feature = \"charset\")]\n+        {\n+            self.text_with_charset(\"utf-8\").await\n+        }\n+\n+        #[cfg(not(feature = \"charset\"))]\n+        {\n+            let full = self.bytes().await?;\n+            let text = String::from_utf8_lossy(&full);\n+            Ok(text.into_owned())\n+        }\n     }\n \n     /// Get the full response text given a specific encoding.\n@@ -160,6 +182,10 @@ impl Response {\n     ///\n     /// [`encoding_rs`]: https://docs.rs/encoding_rs/0.8/encoding_rs/#relationship-with-windows-code-pages\n     ///\n+    /// # Optional\n+    ///\n+    /// This requires the optional `encoding_rs` feature enabled.\n+    ///\n     /// # Example\n     ///\n     /// ```\n@@ -173,6 +199,8 @@ impl Response {\n     /// # Ok(())\n     /// # }\n     /// ```\n+    #[cfg(feature = \"charset\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"charset\")))]\n     pub async fn text_with_charset(self, default_encoding: &str) -> crate::Result<String> {\n         let content_type = self\n             .headers()\n@@ -256,7 +284,11 @@ impl Response {\n     /// # }\n     /// ```\n     pub async fn bytes(self) -> crate::Result<Bytes> {\n-        hyper::body::to_bytes(self.res.into_body()).await\n+        use http_body_util::BodyExt;\n+\n+        BodyExt::collect(self.res.into_body())\n+            .await\n+            .map(|buf| buf.to_bytes())\n     }\n \n     /// Stream a chunk of the response body.\n@@ -276,10 +308,19 @@ impl Response {\n     /// # }\n     /// ```\n     pub async fn chunk(&mut self) -> crate::Result<Option<Bytes>> {\n-        if let Some(item) = self.res.body_mut().next().await {\n-            Ok(Some(item?))\n-        } else {\n-            Ok(None)\n+        use http_body_util::BodyExt;\n+\n+        // loop to ignore unrecognized frames\n+        loop {\n+            if let Some(res) = self.res.body_mut().frame().await {\n+                let frame = res?;\n+                if let Ok(buf) = frame.into_data() {\n+                    return Ok(Some(buf));\n+                }\n+                // else continue\n+            } else {\n+                return Ok(None);\n+            }\n         }\n     }\n \n@@ -308,7 +349,7 @@ impl Response {\n     #[cfg(feature = \"stream\")]\n     #[cfg_attr(docsrs, doc(cfg(feature = \"stream\")))]\n     pub fn bytes_stream(self) -> impl futures_core::Stream<Item = crate::Result<Bytes>> {\n-        self.res.into_body()\n+        super::body::DataStream(self.res.into_body())\n     }\n \n     // util methods\n@@ -396,11 +437,26 @@ impl fmt::Debug for Response {\n     }\n }\n \n+/// A `Response` can be piped as the `Body` of another request.\n+impl From<Response> for Body {\n+    fn from(r: Response) -> Body {\n+        Body::streaming(r.res.into_body())\n+    }\n+}\n+\n+// I'm not sure this conversion is that useful... People should be encouraged\n+// to use `http::Resposne`, not `reqwest::Response`.\n impl<T: Into<Body>> From<http::Response<T>> for Response {\n     fn from(r: http::Response<T>) -> Response {\n+        use crate::response::ResponseUrl;\n+\n         let (mut parts, body) = r.into_parts();\n-        let body = body.into();\n-        let decoder = Decoder::detect(&mut parts.headers, body, Accepts::none());\n+        let body: crate::async_impl::body::Body = body.into();\n+        let decoder = Decoder::detect(\n+            &mut parts.headers,\n+            ResponseBody::new(body.map_err(Into::into)),\n+            Accepts::none(),\n+        );\n         let url = parts\n             .extensions\n             .remove::<ResponseUrl>()\n@@ -414,10 +470,13 @@ impl<T: Into<Body>> From<http::Response<T>> for Response {\n     }\n }\n \n-/// A `Response` can be piped as the `Body` of another request.\n-impl From<Response> for Body {\n-    fn from(r: Response) -> Body {\n-        Body::stream(r.res.into_body())\n+/// A `Response` can be converted into a `http::Response`.\n+// It's supposed to be the inverse of the conversion above.\n+impl From<Response> for http::Response<Body> {\n+    fn from(r: Response) -> http::Response<Body> {\n+        let (parts, body) = r.res.into_parts();\n+        let body = Body::streaming(body);\n+        http::Response::from_parts(parts, body)\n     }\n }\n \ndiff --git a/src/async_impl/upgrade.rs b/src/async_impl/upgrade.rs\nindex 4a69b4db5..3b599d0ad 100644\n--- a/src/async_impl/upgrade.rs\n+++ b/src/async_impl/upgrade.rs\n@@ -3,11 +3,12 @@ use std::task::{self, Poll};\n use std::{fmt, io};\n \n use futures_util::TryFutureExt;\n+use hyper_util::rt::TokioIo;\n use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\n \n /// An upgraded HTTP connection.\n pub struct Upgraded {\n-    inner: hyper::upgrade::Upgraded,\n+    inner: TokioIo<hyper::upgrade::Upgraded>,\n }\n \n impl AsyncRead for Upgraded {\n@@ -58,7 +59,9 @@ impl fmt::Debug for Upgraded {\n \n impl From<hyper::upgrade::Upgraded> for Upgraded {\n     fn from(inner: hyper::upgrade::Upgraded) -> Self {\n-        Upgraded { inner }\n+        Upgraded {\n+            inner: TokioIo::new(inner),\n+        }\n     }\n }\n \ndiff --git a/src/blocking/body.rs b/src/blocking/body.rs\nindex db46cde05..dd44c6fa2 100644\n--- a/src/blocking/body.rs\n+++ b/src/blocking/body.rs\n@@ -9,6 +9,7 @@ use std::ptr;\n \n use bytes::buf::UninitSlice;\n use bytes::Bytes;\n+use futures_channel::mpsc;\n \n use crate::async_impl;\n \n@@ -133,12 +134,12 @@ impl Body {\n     pub(crate) fn into_async(self) -> (Option<Sender>, async_impl::Body, Option<u64>) {\n         match self.kind {\n             Kind::Reader(read, len) => {\n-                let (tx, rx) = hyper::Body::channel();\n+                let (tx, rx) = mpsc::channel(0);\n                 let tx = Sender {\n                     body: (read, len),\n                     tx,\n                 };\n-                (Some(tx), async_impl::Body::wrap(rx), len)\n+                (Some(tx), async_impl::Body::stream(rx), len)\n             }\n             Kind::Bytes(chunk) => {\n                 let len = chunk.len() as u64;\n@@ -257,11 +258,23 @@ impl Read for Reader {\n \n pub(crate) struct Sender {\n     body: (Box<dyn Read + Send>, Option<u64>),\n-    tx: hyper::body::Sender,\n+    tx: mpsc::Sender<Result<Bytes, Abort>>,\n }\n \n+#[derive(Debug)]\n+struct Abort;\n+\n+impl fmt::Display for Abort {\n+    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n+        f.write_str(\"abort request body\")\n+    }\n+}\n+\n+impl std::error::Error for Abort {}\n+\n async fn send_future(sender: Sender) -> Result<(), crate::Error> {\n     use bytes::{BufMut, BytesMut};\n+    use futures_util::SinkExt;\n     use std::cmp;\n \n     let con_len = sender.body.1;\n@@ -312,7 +325,11 @@ async fn send_future(sender: Sender) -> Result<(), crate::Error> {\n                     buf.advance_mut(n);\n                 },\n                 Err(e) => {\n-                    tx.take().expect(\"tx only taken on error\").abort();\n+                    let _ = tx\n+                        .take()\n+                        .expect(\"tx only taken on error\")\n+                        .clone()\n+                        .try_send(Err(Abort));\n                     return Err(crate::error::body(e));\n                 }\n             }\n@@ -324,7 +341,7 @@ async fn send_future(sender: Sender) -> Result<(), crate::Error> {\n         let buf_len = buf.len() as u64;\n         tx.as_mut()\n             .expect(\"tx only taken on error\")\n-            .send_data(buf.split().freeze())\n+            .send(Ok(buf.split().freeze()))\n             .await\n             .map_err(crate::error::body)?;\n \ndiff --git a/src/blocking/client.rs b/src/blocking/client.rs\nindex 8a419c26c..5b861cb3e 100644\n--- a/src/blocking/client.rs\n+++ b/src/blocking/client.rs\n@@ -445,6 +445,8 @@ impl ClientBuilder {\n     }\n \n     /// Only use HTTP/2.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_prior_knowledge(self) -> ClientBuilder {\n         self.with_inner(|inner| inner.http2_prior_knowledge())\n     }\n@@ -452,6 +454,8 @@ impl ClientBuilder {\n     /// Sets the `SETTINGS_INITIAL_WINDOW_SIZE` option for HTTP2 stream-level flow control.\n     ///\n     /// Default is currently 65,535 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_initial_stream_window_size(self, sz: impl Into<Option<u32>>) -> ClientBuilder {\n         self.with_inner(|inner| inner.http2_initial_stream_window_size(sz))\n     }\n@@ -459,6 +463,8 @@ impl ClientBuilder {\n     /// Sets the max connection-level flow control for HTTP2\n     ///\n     /// Default is currently 65,535 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_initial_connection_window_size(self, sz: impl Into<Option<u32>>) -> ClientBuilder {\n         self.with_inner(|inner| inner.http2_initial_connection_window_size(sz))\n     }\n@@ -467,6 +473,8 @@ impl ClientBuilder {\n     ///\n     /// Enabling this will override the limits set in `http2_initial_stream_window_size` and\n     /// `http2_initial_connection_window_size`.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_adaptive_window(self, enabled: bool) -> ClientBuilder {\n         self.with_inner(|inner| inner.http2_adaptive_window(enabled))\n     }\n@@ -474,6 +482,8 @@ impl ClientBuilder {\n     /// Sets the maximum frame size to use for HTTP2.\n     ///\n     /// Default is currently 16,384 but may change internally to optimize for common uses.\n+    #[cfg(feature = \"http2\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"http2\")))]\n     pub fn http2_max_frame_size(self, sz: impl Into<Option<u32>>) -> ClientBuilder {\n         self.with_inner(|inner| inner.http2_max_frame_size(sz))\n     }\n@@ -513,6 +523,21 @@ impl ClientBuilder {\n         self.with_inner(move |inner| inner.local_address(addr))\n     }\n \n+    /// Bind to an interface by `SO_BINDTODEVICE`.\n+    ///\n+    /// # Example\n+    ///\n+    /// ```\n+    /// let interface = \"lo\";\n+    /// let client = reqwest::blocking::Client::builder()\n+    ///     .interface(interface)\n+    ///     .build().unwrap();\n+    /// ```\n+    #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+    pub fn interface(self, interface: &str) -> ClientBuilder {\n+        self.with_inner(move |inner| inner.interface(interface))\n+    }\n+\n     /// Set that all sockets have `SO_KEEPALIVE` set with the supplied duration.\n     ///\n     /// If `None`, the option will not be set.\n@@ -1196,7 +1221,7 @@ impl Default for Timeout {\n     }\n }\n \n-pub(crate) struct KeepCoreThreadAlive(#[allow(unused)] Option<Arc<InnerClientHandle>>);\n+pub(crate) struct KeepCoreThreadAlive(#[allow(dead_code)] Option<Arc<InnerClientHandle>>);\n \n impl KeepCoreThreadAlive {\n     pub(crate) fn empty() -> KeepCoreThreadAlive {\ndiff --git a/src/blocking/response.rs b/src/blocking/response.rs\nindex 2da634f68..1a4685115 100644\n--- a/src/blocking/response.rs\n+++ b/src/blocking/response.rs\n@@ -270,6 +270,11 @@ impl Response {\n     /// Encoding is determined from the `charset` parameter of `Content-Type` header,\n     /// and defaults to `utf-8` if not presented.\n     ///\n+    /// # Note\n+    ///\n+    /// If the `charset` feature is disabled the method will only attempt to decode the\n+    /// response as UTF-8, regardless of the given `Content-Type`\n+    ///\n     /// # Example\n     ///\n     /// ```rust\n@@ -280,7 +285,10 @@ impl Response {\n     /// # }\n     /// ```\n     pub fn text(self) -> crate::Result<String> {\n-        self.text_with_charset(\"utf-8\")\n+        wait::timeout(self.inner.text(), self.timeout).map_err(|e| match e {\n+            wait::Waited::TimedOut(e) => crate::error::decode(e),\n+            wait::Waited::Inner(e) => e,\n+        })\n     }\n \n     /// Get the response text given a specific encoding.\n@@ -293,6 +301,10 @@ impl Response {\n     ///\n     /// [`encoding_rs`]: https://docs.rs/encoding_rs/0.8/encoding_rs/#relationship-with-windows-code-pages\n     ///\n+    /// # Optional\n+    ///\n+    /// This requires the optional `charset` feature enabled.\n+    ///\n     /// # Example\n     ///\n     /// ```rust\n@@ -303,6 +315,8 @@ impl Response {\n     /// # Ok(())\n     /// # }\n     /// ```\n+    #[cfg(feature = \"charset\")]\n+    #[cfg_attr(docsrs, doc(cfg(feature = \"charset\")))]\n     pub fn text_with_charset(self, default_encoding: &str) -> crate::Result<String> {\n         wait::timeout(self.inner.text_with_charset(default_encoding), self.timeout).map_err(|e| {\n             match e {\n@@ -397,7 +411,7 @@ impl Response {\n         if self.body.is_none() {\n             let body = mem::replace(self.inner.body_mut(), async_impl::Decoder::empty());\n \n-            let body = body.map_err(crate::error::into_io).into_async_read();\n+            let body = body.into_stream().into_async_read();\n \n             self.body = Some(Box::pin(body));\n         }\ndiff --git a/src/connect.rs b/src/connect.rs\nindex b6b51130e..79c069016 100644\n--- a/src/connect.rs\n+++ b/src/connect.rs\n@@ -2,11 +2,13 @@\n use http::header::HeaderValue;\n use http::uri::{Authority, Scheme};\n use http::Uri;\n-use hyper::client::connect::{Connected, Connection};\n-use hyper::service::Service;\n-#[cfg(feature = \"native-tls-crate\")]\n+use hyper::rt::{Read, ReadBufCursor, Write};\n+use hyper_util::client::legacy::connect::{Connected, Connection};\n+#[cfg(any(feature = \"socks\", feature = \"__tls\"))]\n+use hyper_util::rt::TokioIo;\n+#[cfg(feature = \"default-tls\")]\n use native_tls_crate::{TlsConnector, TlsConnectorBuilder};\n-use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\n+use tower_service::Service;\n \n use pin_project_lite::pin_project;\n use std::future::Future;\n@@ -25,7 +27,7 @@ use crate::dns::DynResolver;\n use crate::error::BoxError;\n use crate::proxy::{Proxy, ProxyScheme};\n \n-pub(crate) type HttpConnector = hyper::client::HttpConnector<DynResolver>;\n+pub(crate) type HttpConnector = hyper_util::client::legacy::connect::HttpConnector<DynResolver>;\n \n #[derive(Clone)]\n pub(crate) struct Connector {\n@@ -84,6 +86,8 @@ impl Connector {\n         proxies: Arc<Vec<Proxy>>,\n         user_agent: Option<HeaderValue>,\n         local_addr: T,\n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        interface: Option<&str>,\n         nodelay: bool,\n         tls_info: bool,\n     ) -> crate::Result<Connector>\n@@ -92,7 +96,15 @@ impl Connector {\n     {\n         let tls = tls.build().map_err(crate::error::builder)?;\n         Ok(Self::from_built_default_tls(\n-            http, tls, proxies, user_agent, local_addr, nodelay, tls_info,\n+            http,\n+            tls,\n+            proxies,\n+            user_agent,\n+            local_addr,\n+            #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+            interface,\n+            nodelay,\n+            tls_info,\n         ))\n     }\n \n@@ -103,6 +115,8 @@ impl Connector {\n         proxies: Arc<Vec<Proxy>>,\n         user_agent: Option<HeaderValue>,\n         local_addr: T,\n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        interface: Option<&str>,\n         nodelay: bool,\n         tls_info: bool,\n     ) -> Connector\n@@ -110,6 +124,10 @@ impl Connector {\n         T: Into<Option<IpAddr>>,\n     {\n         http.set_local_address(local_addr.into());\n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        if let Some(interface) = interface {\n+            http.set_interface(interface);\n+        }\n         http.set_nodelay(nodelay);\n         http.enforce_http(false);\n \n@@ -131,6 +149,8 @@ impl Connector {\n         proxies: Arc<Vec<Proxy>>,\n         user_agent: Option<HeaderValue>,\n         local_addr: T,\n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        interface: Option<&str>,\n         nodelay: bool,\n         tls_info: bool,\n     ) -> Connector\n@@ -138,6 +158,10 @@ impl Connector {\n         T: Into<Option<IpAddr>>,\n     {\n         http.set_local_address(local_addr.into());\n+        #[cfg(any(target_os = \"android\", target_os = \"fuchsia\", target_os = \"linux\"))]\n+        if let Some(interface) = interface {\n+            http.set_interface(interface.to_owned());\n+        }\n         http.set_nodelay(nodelay);\n         http.enforce_http(false);\n \n@@ -193,8 +217,11 @@ impl Connector {\n                 if dst.scheme() == Some(&Scheme::HTTPS) {\n                     let host = dst.host().ok_or(\"no host in url\")?.to_string();\n                     let conn = socks::connect(proxy, dst, dns).await?;\n+                    let conn = TokioIo::new(conn);\n+                    let conn = TokioIo::new(conn);\n                     let tls_connector = tokio_native_tls::TlsConnector::from(tls.clone());\n                     let io = tls_connector.connect(&host, conn).await?;\n+                    let io = TokioIo::new(io);\n                     return Ok(Conn {\n                         inner: self.verbose.wrap(NativeTlsConn { inner: io }),\n                         is_proxy: false,\n@@ -211,11 +238,15 @@ impl Connector {\n                     let tls = tls_proxy.clone();\n                     let host = dst.host().ok_or(\"no host in url\")?.to_string();\n                     let conn = socks::connect(proxy, dst, dns).await?;\n-                    let server_name = rustls::ServerName::try_from(host.as_str())\n-                        .map_err(|_| \"Invalid Server Name\")?;\n+                    let conn = TokioIo::new(conn);\n+                    let conn = TokioIo::new(conn);\n+                    let server_name =\n+                        rustls_pki_types::ServerName::try_from(host.as_str().to_owned())\n+                            .map_err(|_| \"Invalid Server Name\")?;\n                     let io = RustlsConnector::from(tls)\n                         .connect(server_name, conn)\n                         .await?;\n+                    let io = TokioIo::new(io);\n                     return Ok(Conn {\n                         inner: self.verbose.wrap(RustlsTlsConn { inner: io }),\n                         is_proxy: false,\n@@ -228,7 +259,7 @@ impl Connector {\n         }\n \n         socks::connect(proxy, dst, dns).await.map(|tcp| Conn {\n-            inner: self.verbose.wrap(tcp),\n+            inner: self.verbose.wrap(TokioIo::new(tcp)),\n             is_proxy: false,\n             tls_info: false,\n         })\n@@ -262,7 +293,14 @@ impl Connector {\n \n                 if let hyper_tls::MaybeHttpsStream::Https(stream) = io {\n                     if !self.nodelay {\n-                        stream.get_ref().get_ref().get_ref().set_nodelay(false)?;\n+                        stream\n+                            .inner()\n+                            .get_ref()\n+                            .get_ref()\n+                            .get_ref()\n+                            .inner()\n+                            .inner()\n+                            .set_nodelay(false)?;\n                     }\n                     Ok(Conn {\n                         inner: self.verbose.wrap(NativeTlsConn { inner: stream }),\n@@ -293,8 +331,8 @@ impl Connector {\n \n                 if let hyper_rustls::MaybeHttpsStream::Https(stream) = io {\n                     if !self.nodelay {\n-                        let (io, _) = stream.get_ref();\n-                        io.set_nodelay(false)?;\n+                        let (io, _) = stream.inner().get_ref();\n+                        io.inner().inner().set_nodelay(false)?;\n                     }\n                     Ok(Conn {\n                         inner: self.verbose.wrap(RustlsTlsConn { inner: stream }),\n@@ -350,10 +388,12 @@ impl Connector {\n                     .await?;\n                     let tls_connector = tokio_native_tls::TlsConnector::from(tls.clone());\n                     let io = tls_connector\n-                        .connect(host.ok_or(\"no host in url\")?, tunneled)\n+                        .connect(host.ok_or(\"no host in url\")?, TokioIo::new(tunneled))\n                         .await?;\n                     return Ok(Conn {\n-                        inner: self.verbose.wrap(NativeTlsConn { inner: io }),\n+                        inner: self.verbose.wrap(NativeTlsConn {\n+                            inner: TokioIo::new(io),\n+                        }),\n                         is_proxy: false,\n                         tls_info: false,\n                     });\n@@ -366,7 +406,7 @@ impl Connector {\n                 tls_proxy,\n             } => {\n                 if dst.scheme() == Some(&Scheme::HTTPS) {\n-                    use rustls::ServerName;\n+                    use rustls_pki_types::ServerName;\n                     use std::convert::TryFrom;\n                     use tokio_rustls::TlsConnector as RustlsConnector;\n \n@@ -377,16 +417,18 @@ impl Connector {\n                     let tls = tls.clone();\n                     let conn = http.call(proxy_dst).await?;\n                     log::trace!(\"tunneling HTTPS over proxy\");\n-                    let maybe_server_name =\n-                        ServerName::try_from(host.as_str()).map_err(|_| \"Invalid Server Name\");\n+                    let maybe_server_name = ServerName::try_from(host.as_str().to_owned())\n+                        .map_err(|_| \"Invalid Server Name\");\n                     let tunneled = tunnel(conn, host, port, self.user_agent.clone(), auth).await?;\n                     let server_name = maybe_server_name?;\n                     let io = RustlsConnector::from(tls)\n-                        .connect(server_name, tunneled)\n+                        .connect(server_name, TokioIo::new(tunneled))\n                         .await?;\n \n                     return Ok(Conn {\n-                        inner: self.verbose.wrap(RustlsTlsConn { inner: io }),\n+                        inner: self.verbose.wrap(RustlsTlsConn {\n+                            inner: TokioIo::new(io),\n+                        }),\n                         is_proxy: false,\n                         tls_info: false,\n                     });\n@@ -476,18 +518,15 @@ impl TlsInfoFactory for tokio::net::TcpStream {\n     }\n }\n \n-#[cfg(feature = \"default-tls\")]\n-impl TlsInfoFactory for hyper_tls::MaybeHttpsStream<tokio::net::TcpStream> {\n+#[cfg(feature = \"__tls\")]\n+impl<T: TlsInfoFactory> TlsInfoFactory for TokioIo<T> {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n-        match self {\n-            hyper_tls::MaybeHttpsStream::Https(tls) => tls.tls_info(),\n-            hyper_tls::MaybeHttpsStream::Http(_) => None,\n-        }\n+        self.inner().tls_info()\n     }\n }\n \n #[cfg(feature = \"default-tls\")]\n-impl TlsInfoFactory for hyper_tls::TlsStream<hyper_tls::MaybeHttpsStream<tokio::net::TcpStream>> {\n+impl TlsInfoFactory for tokio_native_tls::TlsStream<TokioIo<TokioIo<tokio::net::TcpStream>>> {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n         let peer_certificate = self\n             .get_ref()\n@@ -500,7 +539,11 @@ impl TlsInfoFactory for hyper_tls::TlsStream<hyper_tls::MaybeHttpsStream<tokio::\n }\n \n #[cfg(feature = \"default-tls\")]\n-impl TlsInfoFactory for tokio_native_tls::TlsStream<tokio::net::TcpStream> {\n+impl TlsInfoFactory\n+    for tokio_native_tls::TlsStream<\n+        TokioIo<hyper_tls::MaybeHttpsStream<TokioIo<tokio::net::TcpStream>>>,\n+    >\n+{\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n         let peer_certificate = self\n             .get_ref()\n@@ -512,32 +555,35 @@ impl TlsInfoFactory for tokio_native_tls::TlsStream<tokio::net::TcpStream> {\n     }\n }\n \n-#[cfg(feature = \"__rustls\")]\n-impl TlsInfoFactory for hyper_rustls::MaybeHttpsStream<tokio::net::TcpStream> {\n+#[cfg(feature = \"default-tls\")]\n+impl TlsInfoFactory for hyper_tls::MaybeHttpsStream<TokioIo<tokio::net::TcpStream>> {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n         match self {\n-            hyper_rustls::MaybeHttpsStream::Https(tls) => tls.tls_info(),\n-            hyper_rustls::MaybeHttpsStream::Http(_) => None,\n+            hyper_tls::MaybeHttpsStream::Https(tls) => tls.tls_info(),\n+            hyper_tls::MaybeHttpsStream::Http(_) => None,\n         }\n     }\n }\n \n #[cfg(feature = \"__rustls\")]\n-impl TlsInfoFactory for tokio_rustls::TlsStream<tokio::net::TcpStream> {\n+impl TlsInfoFactory for tokio_rustls::client::TlsStream<TokioIo<TokioIo<tokio::net::TcpStream>>> {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n         let peer_certificate = self\n             .get_ref()\n             .1\n             .peer_certificates()\n             .and_then(|certs| certs.first())\n-            .map(|c| c.0.clone());\n+            .map(|c| c.first())\n+            .and_then(|c| c.map(|cc| vec![*cc]));\n         Some(crate::tls::TlsInfo { peer_certificate })\n     }\n }\n \n #[cfg(feature = \"__rustls\")]\n impl TlsInfoFactory\n-    for tokio_rustls::client::TlsStream<hyper_rustls::MaybeHttpsStream<tokio::net::TcpStream>>\n+    for tokio_rustls::client::TlsStream<\n+        TokioIo<hyper_rustls::MaybeHttpsStream<TokioIo<tokio::net::TcpStream>>>,\n+    >\n {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n         let peer_certificate = self\n@@ -545,30 +591,28 @@ impl TlsInfoFactory\n             .1\n             .peer_certificates()\n             .and_then(|certs| certs.first())\n-            .map(|c| c.0.clone());\n+            .map(|c| c.first())\n+            .and_then(|c| c.map(|cc| vec![*cc]));\n         Some(crate::tls::TlsInfo { peer_certificate })\n     }\n }\n \n #[cfg(feature = \"__rustls\")]\n-impl TlsInfoFactory for tokio_rustls::client::TlsStream<tokio::net::TcpStream> {\n+impl TlsInfoFactory for hyper_rustls::MaybeHttpsStream<TokioIo<tokio::net::TcpStream>> {\n     fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n-        let peer_certificate = self\n-            .get_ref()\n-            .1\n-            .peer_certificates()\n-            .and_then(|certs| certs.first())\n-            .map(|c| c.0.clone());\n-        Some(crate::tls::TlsInfo { peer_certificate })\n+        match self {\n+            hyper_rustls::MaybeHttpsStream::Https(tls) => tls.tls_info(),\n+            hyper_rustls::MaybeHttpsStream::Http(_) => None,\n+        }\n     }\n }\n \n pub(crate) trait AsyncConn:\n-    AsyncRead + AsyncWrite + Connection + Send + Sync + Unpin + 'static\n+    Read + Write + Connection + Send + Sync + Unpin + 'static\n {\n }\n \n-impl<T: AsyncRead + AsyncWrite + Connection + Send + Sync + Unpin + 'static> AsyncConn for T {}\n+impl<T: Read + Write + Connection + Send + Sync + Unpin + 'static> AsyncConn for T {}\n \n #[cfg(feature = \"__tls\")]\n trait AsyncConnWithInfo: AsyncConn + TlsInfoFactory {}\n@@ -614,25 +658,25 @@ impl Connection for Conn {\n     }\n }\n \n-impl AsyncRead for Conn {\n+impl Read for Conn {\n     fn poll_read(\n         self: Pin<&mut Self>,\n         cx: &mut Context,\n-        buf: &mut ReadBuf<'_>,\n+        buf: ReadBufCursor<'_>,\n     ) -> Poll<io::Result<()>> {\n         let this = self.project();\n-        AsyncRead::poll_read(this.inner, cx, buf)\n+        Read::poll_read(this.inner, cx, buf)\n     }\n }\n \n-impl AsyncWrite for Conn {\n+impl Write for Conn {\n     fn poll_write(\n         self: Pin<&mut Self>,\n         cx: &mut Context,\n         buf: &[u8],\n     ) -> Poll<Result<usize, io::Error>> {\n         let this = self.project();\n-        AsyncWrite::poll_write(this.inner, cx, buf)\n+        Write::poll_write(this.inner, cx, buf)\n     }\n \n     fn poll_write_vectored(\n@@ -641,7 +685,7 @@ impl AsyncWrite for Conn {\n         bufs: &[IoSlice<'_>],\n     ) -> Poll<Result<usize, io::Error>> {\n         let this = self.project();\n-        AsyncWrite::poll_write_vectored(this.inner, cx, bufs)\n+        Write::poll_write_vectored(this.inner, cx, bufs)\n     }\n \n     fn is_write_vectored(&self) -> bool {\n@@ -650,12 +694,12 @@ impl AsyncWrite for Conn {\n \n     fn poll_flush(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Result<(), io::Error>> {\n         let this = self.project();\n-        AsyncWrite::poll_flush(this.inner, cx)\n+        Write::poll_flush(this.inner, cx)\n     }\n \n     fn poll_shutdown(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Result<(), io::Error>> {\n         let this = self.project();\n-        AsyncWrite::poll_shutdown(this.inner, cx)\n+        Write::poll_shutdown(this.inner, cx)\n     }\n }\n \n@@ -670,8 +714,9 @@ async fn tunnel<T>(\n     auth: Option<HeaderValue>,\n ) -> Result<T, BoxError>\n where\n-    T: AsyncRead + AsyncWrite + Unpin,\n+    T: Read + Write + Unpin,\n {\n+    use hyper_util::rt::TokioIo;\n     use tokio::io::{AsyncReadExt, AsyncWriteExt};\n \n     let mut buf = format!(\n@@ -700,13 +745,15 @@ where\n     // headers end\n     buf.extend_from_slice(b\"\\r\\n\");\n \n-    conn.write_all(&buf).await?;\n+    let mut tokio_conn = TokioIo::new(&mut conn);\n+\n+    tokio_conn.write_all(&buf).await?;\n \n     let mut buf = [0; 8192];\n     let mut pos = 0;\n \n     loop {\n-        let n = conn.read(&mut buf[pos..]).await?;\n+        let n = tokio_conn.read(&mut buf[pos..]).await?;\n \n         if n == 0 {\n             return Err(tunnel_eof());\n@@ -738,62 +785,69 @@ fn tunnel_eof() -> BoxError {\n #[cfg(feature = \"default-tls\")]\n mod native_tls_conn {\n     use super::TlsInfoFactory;\n-    use hyper::client::connect::{Connected, Connection};\n+    use hyper::rt::{Read, ReadBufCursor, Write};\n+    use hyper_tls::MaybeHttpsStream;\n+    use hyper_util::client::legacy::connect::{Connected, Connection};\n+    use hyper_util::rt::TokioIo;\n     use pin_project_lite::pin_project;\n     use std::{\n         io::{self, IoSlice},\n         pin::Pin,\n         task::{Context, Poll},\n     };\n-    use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\n+    use tokio::io::{AsyncRead, AsyncWrite};\n+    use tokio::net::TcpStream;\n     use tokio_native_tls::TlsStream;\n \n     pin_project! {\n         pub(super) struct NativeTlsConn<T> {\n-            #[pin] pub(super) inner: TlsStream<T>,\n+            #[pin] pub(super) inner: TokioIo<TlsStream<T>>,\n         }\n     }\n \n-    impl<T: Connection + AsyncRead + AsyncWrite + Unpin> Connection for NativeTlsConn<T> {\n-        #[cfg(feature = \"native-tls-alpn\")]\n+    impl Connection for NativeTlsConn<TokioIo<TokioIo<TcpStream>>> {\n         fn connected(&self) -> Connected {\n-            match self.inner.get_ref().negotiated_alpn().ok() {\n-                Some(Some(alpn_protocol)) if alpn_protocol == b\"h2\" => self\n-                    .inner\n-                    .get_ref()\n-                    .get_ref()\n-                    .get_ref()\n-                    .connected()\n-                    .negotiated_h2(),\n-                _ => self.inner.get_ref().get_ref().get_ref().connected(),\n-            }\n+            self.inner\n+                .inner()\n+                .get_ref()\n+                .get_ref()\n+                .get_ref()\n+                .inner()\n+                .connected()\n         }\n+    }\n \n-        #[cfg(not(feature = \"native-tls-alpn\"))]\n+    impl Connection for NativeTlsConn<TokioIo<MaybeHttpsStream<TokioIo<TcpStream>>>> {\n         fn connected(&self) -> Connected {\n-            self.inner.get_ref().get_ref().get_ref().connected()\n+            self.inner\n+                .inner()\n+                .get_ref()\n+                .get_ref()\n+                .get_ref()\n+                .inner()\n+                .connected()\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncRead for NativeTlsConn<T> {\n+    impl<T: AsyncRead + AsyncWrite + Unpin> Read for NativeTlsConn<T> {\n         fn poll_read(\n             self: Pin<&mut Self>,\n             cx: &mut Context,\n-            buf: &mut ReadBuf<'_>,\n+            buf: ReadBufCursor<'_>,\n         ) -> Poll<tokio::io::Result<()>> {\n             let this = self.project();\n-            AsyncRead::poll_read(this.inner, cx, buf)\n+            Read::poll_read(this.inner, cx, buf)\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncWrite for NativeTlsConn<T> {\n+    impl<T: AsyncRead + AsyncWrite + Unpin> Write for NativeTlsConn<T> {\n         fn poll_write(\n             self: Pin<&mut Self>,\n             cx: &mut Context,\n             buf: &[u8],\n         ) -> Poll<Result<usize, tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_write(this.inner, cx, buf)\n+            Write::poll_write(this.inner, cx, buf)\n         }\n \n         fn poll_write_vectored(\n@@ -802,7 +856,7 @@ mod native_tls_conn {\n             bufs: &[IoSlice<'_>],\n         ) -> Poll<Result<usize, io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_write_vectored(this.inner, cx, bufs)\n+            Write::poll_write_vectored(this.inner, cx, bufs)\n         }\n \n         fn is_write_vectored(&self) -> bool {\n@@ -814,7 +868,7 @@ mod native_tls_conn {\n             cx: &mut Context,\n         ) -> Poll<Result<(), tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_flush(this.inner, cx)\n+            Write::poll_flush(this.inner, cx)\n         }\n \n         fn poll_shutdown(\n@@ -822,17 +876,14 @@ mod native_tls_conn {\n             cx: &mut Context,\n         ) -> Poll<Result<(), tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_shutdown(this.inner, cx)\n+            Write::poll_shutdown(this.inner, cx)\n         }\n     }\n \n-    impl TlsInfoFactory for NativeTlsConn<tokio::net::TcpStream> {\n-        fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n-            self.inner.tls_info()\n-        }\n-    }\n-\n-    impl TlsInfoFactory for NativeTlsConn<hyper_tls::MaybeHttpsStream<tokio::net::TcpStream>> {\n+    impl<T> TlsInfoFactory for NativeTlsConn<T>\n+    where\n+        TokioIo<TlsStream<T>>: TlsInfoFactory,\n+    {\n         fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n             self.inner.tls_info()\n         }\n@@ -842,51 +893,76 @@ mod native_tls_conn {\n #[cfg(feature = \"__rustls\")]\n mod rustls_tls_conn {\n     use super::TlsInfoFactory;\n-    use hyper::client::connect::{Connected, Connection};\n+    use hyper::rt::{Read, ReadBufCursor, Write};\n+    use hyper_rustls::MaybeHttpsStream;\n+    use hyper_util::client::legacy::connect::{Connected, Connection};\n+    use hyper_util::rt::TokioIo;\n     use pin_project_lite::pin_project;\n     use std::{\n         io::{self, IoSlice},\n         pin::Pin,\n         task::{Context, Poll},\n     };\n-    use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\n+    use tokio::io::{AsyncRead, AsyncWrite};\n+    use tokio::net::TcpStream;\n     use tokio_rustls::client::TlsStream;\n \n     pin_project! {\n         pub(super) struct RustlsTlsConn<T> {\n-            #[pin] pub(super) inner: TlsStream<T>,\n+            #[pin] pub(super) inner: TokioIo<TlsStream<T>>,\n         }\n     }\n \n-    impl<T: Connection + AsyncRead + AsyncWrite + Unpin> Connection for RustlsTlsConn<T> {\n+    impl Connection for RustlsTlsConn<TokioIo<TokioIo<TcpStream>>> {\n         fn connected(&self) -> Connected {\n-            if self.inner.get_ref().1.alpn_protocol() == Some(b\"h2\") {\n-                self.inner.get_ref().0.connected().negotiated_h2()\n+            if self.inner.inner().get_ref().1.alpn_protocol() == Some(b\"h2\") {\n+                self.inner\n+                    .inner()\n+                    .get_ref()\n+                    .0\n+                    .inner()\n+                    .connected()\n+                    .negotiated_h2()\n+            } else {\n+                self.inner.inner().get_ref().0.inner().connected()\n+            }\n+        }\n+    }\n+    impl Connection for RustlsTlsConn<TokioIo<MaybeHttpsStream<TokioIo<TcpStream>>>> {\n+        fn connected(&self) -> Connected {\n+            if self.inner.inner().get_ref().1.alpn_protocol() == Some(b\"h2\") {\n+                self.inner\n+                    .inner()\n+                    .get_ref()\n+                    .0\n+                    .inner()\n+                    .connected()\n+                    .negotiated_h2()\n             } else {\n-                self.inner.get_ref().0.connected()\n+                self.inner.inner().get_ref().0.inner().connected()\n             }\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncRead for RustlsTlsConn<T> {\n+    impl<T: AsyncRead + AsyncWrite + Unpin> Read for RustlsTlsConn<T> {\n         fn poll_read(\n             self: Pin<&mut Self>,\n             cx: &mut Context,\n-            buf: &mut ReadBuf<'_>,\n+            buf: ReadBufCursor<'_>,\n         ) -> Poll<tokio::io::Result<()>> {\n             let this = self.project();\n-            AsyncRead::poll_read(this.inner, cx, buf)\n+            Read::poll_read(this.inner, cx, buf)\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncWrite for RustlsTlsConn<T> {\n+    impl<T: AsyncRead + AsyncWrite + Unpin> Write for RustlsTlsConn<T> {\n         fn poll_write(\n             self: Pin<&mut Self>,\n             cx: &mut Context,\n             buf: &[u8],\n         ) -> Poll<Result<usize, tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_write(this.inner, cx, buf)\n+            Write::poll_write(this.inner, cx, buf)\n         }\n \n         fn poll_write_vectored(\n@@ -895,7 +971,7 @@ mod rustls_tls_conn {\n             bufs: &[IoSlice<'_>],\n         ) -> Poll<Result<usize, io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_write_vectored(this.inner, cx, bufs)\n+            Write::poll_write_vectored(this.inner, cx, bufs)\n         }\n \n         fn is_write_vectored(&self) -> bool {\n@@ -907,7 +983,7 @@ mod rustls_tls_conn {\n             cx: &mut Context,\n         ) -> Poll<Result<(), tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_flush(this.inner, cx)\n+            Write::poll_flush(this.inner, cx)\n         }\n \n         fn poll_shutdown(\n@@ -915,17 +991,13 @@ mod rustls_tls_conn {\n             cx: &mut Context,\n         ) -> Poll<Result<(), tokio::io::Error>> {\n             let this = self.project();\n-            AsyncWrite::poll_shutdown(this.inner, cx)\n+            Write::poll_shutdown(this.inner, cx)\n         }\n     }\n-\n-    impl TlsInfoFactory for RustlsTlsConn<tokio::net::TcpStream> {\n-        fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n-            self.inner.tls_info()\n-        }\n-    }\n-\n-    impl TlsInfoFactory for RustlsTlsConn<hyper_rustls::MaybeHttpsStream<tokio::net::TcpStream>> {\n+    impl<T> TlsInfoFactory for RustlsTlsConn<T>\n+    where\n+        TokioIo<TlsStream<T>>: TlsInfoFactory,\n+    {\n         fn tls_info(&self) -> Option<crate::tls::TlsInfo> {\n             self.inner.tls_info()\n         }\n@@ -998,13 +1070,13 @@ mod socks {\n }\n \n mod verbose {\n-    use hyper::client::connect::{Connected, Connection};\n+    use hyper::rt::{Read, ReadBufCursor, Write};\n+    use hyper_util::client::legacy::connect::{Connected, Connection};\n     use std::cmp::min;\n     use std::fmt;\n     use std::io::{self, IoSlice};\n     use std::pin::Pin;\n     use std::task::{Context, Poll};\n-    use tokio::io::{AsyncRead, AsyncWrite, ReadBuf};\n \n     pub(super) const OFF: Wrapper = Wrapper(false);\n \n@@ -1030,21 +1102,24 @@ mod verbose {\n         inner: T,\n     }\n \n-    impl<T: Connection + AsyncRead + AsyncWrite + Unpin> Connection for Verbose<T> {\n+    impl<T: Connection + Read + Write + Unpin> Connection for Verbose<T> {\n         fn connected(&self) -> Connected {\n             self.inner.connected()\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncRead for Verbose<T> {\n+    impl<T: Read + Write + Unpin> Read for Verbose<T> {\n         fn poll_read(\n             mut self: Pin<&mut Self>,\n             cx: &mut Context,\n-            buf: &mut ReadBuf<'_>,\n+            buf: ReadBufCursor<'_>,\n         ) -> Poll<std::io::Result<()>> {\n             match Pin::new(&mut self.inner).poll_read(cx, buf) {\n                 Poll::Ready(Ok(())) => {\n+                    /*\n                     log::trace!(\"{:08x} read: {:?}\", self.id, Escape(buf.filled()));\n+                    */\n+                    log::trace!(\"TODO: verbose poll_read\");\n                     Poll::Ready(Ok(()))\n                 }\n                 Poll::Ready(Err(e)) => Poll::Ready(Err(e)),\n@@ -1053,7 +1128,7 @@ mod verbose {\n         }\n     }\n \n-    impl<T: AsyncRead + AsyncWrite + Unpin> AsyncWrite for Verbose<T> {\n+    impl<T: Read + Write + Unpin> Write for Verbose<T> {\n         fn poll_write(\n             mut self: Pin<&mut Self>,\n             cx: &mut Context,\n@@ -1169,6 +1244,7 @@ mod verbose {\n mod tests {\n     use super::tunnel;\n     use crate::proxy;\n+    use hyper_util::rt::TokioIo;\n     use std::io::{Read, Write};\n     use std::net::TcpListener;\n     use std::thread;\n@@ -1231,7 +1307,7 @@ mod tests {\n             .build()\n             .expect(\"new rt\");\n         let f = async move {\n-            let tcp = TcpStream::connect(&addr).await?;\n+            let tcp = TokioIo::new(TcpStream::connect(&addr).await?);\n             let host = addr.ip().to_string();\n             let port = addr.port();\n             tunnel(tcp, host, port, ua(), None).await\n@@ -1249,7 +1325,7 @@ mod tests {\n             .build()\n             .expect(\"new rt\");\n         let f = async move {\n-            let tcp = TcpStream::connect(&addr).await?;\n+            let tcp = TokioIo::new(TcpStream::connect(&addr).await?);\n             let host = addr.ip().to_string();\n             let port = addr.port();\n             tunnel(tcp, host, port, ua(), None).await\n@@ -1267,7 +1343,7 @@ mod tests {\n             .build()\n             .expect(\"new rt\");\n         let f = async move {\n-            let tcp = TcpStream::connect(&addr).await?;\n+            let tcp = TokioIo::new(TcpStream::connect(&addr).await?);\n             let host = addr.ip().to_string();\n             let port = addr.port();\n             tunnel(tcp, host, port, ua(), None).await\n@@ -1291,7 +1367,7 @@ mod tests {\n             .build()\n             .expect(\"new rt\");\n         let f = async move {\n-            let tcp = TcpStream::connect(&addr).await?;\n+            let tcp = TokioIo::new(TcpStream::connect(&addr).await?);\n             let host = addr.ip().to_string();\n             let port = addr.port();\n             tunnel(tcp, host, port, ua(), None).await\n@@ -1313,7 +1389,7 @@ mod tests {\n             .build()\n             .expect(\"new rt\");\n         let f = async move {\n-            let tcp = TcpStream::connect(&addr).await?;\n+            let tcp = TokioIo::new(TcpStream::connect(&addr).await?);\n             let host = addr.ip().to_string();\n             let port = addr.port();\n             tunnel(\ndiff --git a/src/dns/gai.rs b/src/dns/gai.rs\nindex f32f3b0e0..4993acc30 100644\n--- a/src/dns/gai.rs\n+++ b/src/dns/gai.rs\n@@ -1,8 +1,8 @@\n use futures_util::future::FutureExt;\n-use hyper::client::connect::dns::{GaiResolver as HyperGaiResolver, Name};\n-use hyper::service::Service;\n+use hyper_util::client::legacy::connect::dns::GaiResolver as HyperGaiResolver;\n+use tower_service::Service;\n \n-use crate::dns::{Addrs, Resolve, Resolving};\n+use crate::dns::{Addrs, Name, Resolve, Resolving};\n use crate::error::BoxError;\n \n #[derive(Debug)]\n@@ -23,7 +23,7 @@ impl Default for GaiResolver {\n impl Resolve for GaiResolver {\n     fn resolve(&self, name: Name) -> Resolving {\n         let this = &mut self.0.clone();\n-        Box::pin(Service::<Name>::call(this, name).map(|result| {\n+        Box::pin(this.call(name.0).map(|result| {\n             result\n                 .map(|addrs| -> Addrs { Box::new(addrs) })\n                 .map_err(|err| -> BoxError { Box::new(err) })\ndiff --git a/src/dns/hickory.rs b/src/dns/hickory.rs\nindex 7ee46bc72..042707006 100644\n--- a/src/dns/hickory.rs\n+++ b/src/dns/hickory.rs\n@@ -1,14 +1,13 @@\n //! DNS resolution via the [hickory-resolver](https://github.com/hickory-dns/hickory-dns) crate\n \n use hickory_resolver::{lookup_ip::LookupIpIntoIter, system_conf, TokioAsyncResolver};\n-use hyper::client::connect::dns::Name;\n use once_cell::sync::OnceCell;\n \n use std::io;\n use std::net::SocketAddr;\n use std::sync::Arc;\n \n-use super::{Addrs, Resolve, Resolving};\n+use super::{Addrs, Name, Resolve, Resolving};\n \n /// Wrapper around an `AsyncResolver`, which implements the `Resolve` trait.\n #[derive(Debug, Default, Clone)]\ndiff --git a/src/dns/mod.rs b/src/dns/mod.rs\nindex f3e221276..92aaf04f0 100644\n--- a/src/dns/mod.rs\n+++ b/src/dns/mod.rs\n@@ -1,6 +1,6 @@\n //! DNS resolution\n \n-pub use resolve::{Addrs, Resolve, Resolving};\n+pub use resolve::{Addrs, Name, Resolve, Resolving};\n pub(crate) use resolve::{DnsResolverWithOverrides, DynResolver};\n \n pub(crate) mod gai;\ndiff --git a/src/dns/resolve.rs b/src/dns/resolve.rs\nindex 3686765a0..1300edd51 100644\n--- a/src/dns/resolve.rs\n+++ b/src/dns/resolve.rs\n@@ -1,5 +1,5 @@\n-use hyper::client::connect::dns::Name;\n-use hyper::service::Service;\n+use hyper_util::client::legacy::connect::dns::Name as HyperName;\n+use tower_service::Service;\n \n use std::collections::HashMap;\n use std::future::Future;\n@@ -29,6 +29,17 @@ pub trait Resolve: Send + Sync {\n     fn resolve(&self, name: Name) -> Resolving;\n }\n \n+/// A name that must be resolved to addresses.\n+#[derive(Debug)]\n+pub struct Name(pub(super) HyperName);\n+\n+impl Name {\n+    /// View the name as a string.\n+    pub fn as_str(&self) -> &str {\n+        self.0.as_str()\n+    }\n+}\n+\n #[derive(Clone)]\n pub(crate) struct DynResolver {\n     resolver: Arc<dyn Resolve>,\n@@ -40,7 +51,7 @@ impl DynResolver {\n     }\n }\n \n-impl Service<Name> for DynResolver {\n+impl Service<HyperName> for DynResolver {\n     type Response = Addrs;\n     type Error = BoxError;\n     type Future = Resolving;\n@@ -49,8 +60,8 @@ impl Service<Name> for DynResolver {\n         Poll::Ready(Ok(()))\n     }\n \n-    fn call(&mut self, name: Name) -> Self::Future {\n-        self.resolver.resolve(name)\n+    fn call(&mut self, name: HyperName) -> Self::Future {\n+        self.resolver.resolve(Name(name))\n     }\n }\n \ndiff --git a/src/error.rs b/src/error.rs\nindex 9ffb6ed17..c558ebbac 100644\n--- a/src/error.rs\n+++ b/src/error.rs\n@@ -127,7 +127,7 @@ impl Error {\n         let mut source = self.source();\n \n         while let Some(err) = source {\n-            if let Some(hyper_err) = err.downcast_ref::<hyper::Error>() {\n+            if let Some(hyper_err) = err.downcast_ref::<hyper_util::client::legacy::Error>() {\n                 if hyper_err.is_connect() {\n                     return true;\n                 }\n@@ -291,9 +291,8 @@ pub(crate) fn upgrade<E: Into<BoxError>>(e: E) -> Error {\n \n // io::Error helpers\n \n-#[allow(unused)]\n-pub(crate) fn into_io(e: Error) -> io::Error {\n-    e.into_io()\n+pub(crate) fn into_io(e: BoxError) -> io::Error {\n+    io::Error::new(io::ErrorKind::Other, e)\n }\n \n #[allow(unused)]\ndiff --git a/src/lib.rs b/src/lib.rs\nindex 25965b181..ce4549dd9 100644\n--- a/src/lib.rs\n+++ b/src/lib.rs\n@@ -178,6 +178,7 @@\n //! The following are a list of [Cargo features][cargo-features] that can be\n //! enabled or disabled:\n //!\n+//! - **http2** *(enabled by default)*: Enables HTTP/2 support.\n //! - **default-tls** *(enabled by default)*: Provides TLS support to connect\n //!   over HTTPS.\n //! - **native-tls**: Enables TLS functionality provided by `native-tls`.\n@@ -192,6 +193,7 @@\n //! - **rustls-tls-native-roots**: Enables TLS functionality provided by `rustls`,\n //!   while using root certificates from the `rustls-native-certs` crate.\n //! - **blocking**: Provides the [blocking][] client API.\n+//! - **charset** *(enabled by default)*: Improved support for decoding text.\n //! - **cookies**: Provides cookie session support.\n //! - **gzip**: Provides response body gzip decompression.\n //! - **brotli**: Provides response body brotli decompression.\ndiff --git a/src/proxy.rs b/src/proxy.rs\nindex e4ad3a98c..17670cf4a 100644\n--- a/src/proxy.rs\n+++ b/src/proxy.rs\n@@ -13,7 +13,7 @@ use std::collections::HashMap;\n use std::env;\n use std::error::Error;\n use std::net::IpAddr;\n-#[cfg(target_os = \"macos\")]\n+#[cfg(all(target_os = \"macos\", feature = \"macos-system-configuration\"))]\n use system_configuration::{\n     core_foundation::{\n         base::CFType,\n@@ -947,7 +947,7 @@ fn get_from_platform_impl() -> Result<Option<String>, Box<dyn Error>> {\n     Ok((proxy_enable == 1).then_some(proxy_server))\n }\n \n-#[cfg(target_os = \"macos\")]\n+#[cfg(all(target_os = \"macos\", feature = \"macos-system-configuration\"))]\n fn parse_setting_from_dynamic_store(\n     proxies_map: &CFDictionary<CFString, CFType>,\n     enabled_key: CFStringRef,\n@@ -985,7 +985,7 @@ fn parse_setting_from_dynamic_store(\n     None\n }\n \n-#[cfg(target_os = \"macos\")]\n+#[cfg(all(target_os = \"macos\", feature = \"macos-system-configuration\"))]\n fn get_from_platform_impl() -> Result<Option<String>, Box<dyn Error>> {\n     let store = SCDynamicStoreBuilder::new(\"reqwest\").build();\n \n@@ -1016,12 +1016,18 @@ fn get_from_platform_impl() -> Result<Option<String>, Box<dyn Error>> {\n     }\n }\n \n-#[cfg(any(target_os = \"windows\", target_os = \"macos\"))]\n+#[cfg(any(\n+    target_os = \"windows\",\n+    all(target_os = \"macos\", feature = \"macos-system-configuration\")\n+))]\n fn get_from_platform() -> Option<String> {\n     get_from_platform_impl().ok().flatten()\n }\n \n-#[cfg(not(any(target_os = \"windows\", target_os = \"macos\")))]\n+#[cfg(not(any(\n+    target_os = \"windows\",\n+    all(target_os = \"macos\", feature = \"macos-system-configuration\")\n+)))]\n fn get_from_platform() -> Option<String> {\n     None\n }\ndiff --git a/src/tls.rs b/src/tls.rs\nindex 3f53d875f..a502ab09d 100644\n--- a/src/tls.rs\n+++ b/src/tls.rs\n@@ -46,9 +46,11 @@\n \n #[cfg(feature = \"__rustls\")]\n use rustls::{\n-    client::HandshakeSignatureValid, client::ServerCertVerified, client::ServerCertVerifier,\n-    DigitallySignedStruct, Error as TLSError, ServerName,\n+    client::danger::HandshakeSignatureValid, client::danger::ServerCertVerified,\n+    client::danger::ServerCertVerifier, DigitallySignedStruct, Error as TLSError, SignatureScheme,\n };\n+#[cfg(feature = \"__rustls\")]\n+use rustls_pki_types::{ServerName, UnixTime};\n use std::{\n     fmt,\n     io::{BufRead, BufReader},\n@@ -57,7 +59,7 @@ use std::{\n /// Represents a server X509 certificate.\n #[derive(Clone)]\n pub struct Certificate {\n-    #[cfg(feature = \"native-tls-crate\")]\n+    #[cfg(feature = \"default-tls\")]\n     native: native_tls_crate::Certificate,\n     #[cfg(feature = \"__rustls\")]\n     original: Cert,\n@@ -77,7 +79,6 @@ pub struct Identity {\n     inner: ClientCert,\n }\n \n-#[derive(Clone)]\n enum ClientCert {\n     #[cfg(feature = \"native-tls\")]\n     Pkcs12(native_tls_crate::Identity),\n@@ -85,11 +86,32 @@ enum ClientCert {\n     Pkcs8(native_tls_crate::Identity),\n     #[cfg(feature = \"__rustls\")]\n     Pem {\n-        key: rustls::PrivateKey,\n-        certs: Vec<rustls::Certificate>,\n+        key: rustls_pki_types::PrivateKeyDer<'static>,\n+        certs: Vec<rustls_pki_types::CertificateDer<'static>>,\n     },\n }\n \n+impl Clone for ClientCert {\n+    fn clone(&self) -> Self {\n+        match self {\n+            #[cfg(feature = \"native-tls\")]\n+            Self::Pkcs8(i) => Self::Pkcs8(i.clone()),\n+            #[cfg(feature = \"native-tls\")]\n+            Self::Pkcs12(i) => Self::Pkcs12(i.clone()),\n+            #[cfg(feature = \"__rustls\")]\n+            ClientCert::Pem { key, certs } => ClientCert::Pem {\n+                key: key.clone_key(),\n+                certs: certs.clone(),\n+            },\n+            #[cfg_attr(\n+                any(feature = \"native-tls\", feature = \"__rustls\"),\n+                allow(unreachable_patterns)\n+            )]\n+            _ => unreachable!(),\n+        }\n+    }\n+}\n+\n impl Certificate {\n     /// Create a `Certificate` from a binary DER encoded certificate\n     ///\n@@ -109,7 +131,7 @@ impl Certificate {\n     /// ```\n     pub fn from_der(der: &[u8]) -> crate::Result<Certificate> {\n         Ok(Certificate {\n-            #[cfg(feature = \"native-tls-crate\")]\n+            #[cfg(feature = \"default-tls\")]\n             native: native_tls_crate::Certificate::from_der(der).map_err(crate::error::builder)?,\n             #[cfg(feature = \"__rustls\")]\n             original: Cert::Der(der.to_owned()),\n@@ -134,7 +156,7 @@ impl Certificate {\n     /// ```\n     pub fn from_pem(pem: &[u8]) -> crate::Result<Certificate> {\n         Ok(Certificate {\n-            #[cfg(feature = \"native-tls-crate\")]\n+            #[cfg(feature = \"default-tls\")]\n             native: native_tls_crate::Certificate::from_pem(pem).map_err(crate::error::builder)?,\n             #[cfg(feature = \"__rustls\")]\n             original: Cert::Pem(pem.to_owned()),\n@@ -167,7 +189,7 @@ impl Certificate {\n             .collect::<crate::Result<Vec<Certificate>>>()\n     }\n \n-    #[cfg(feature = \"native-tls-crate\")]\n+    #[cfg(feature = \"default-tls\")]\n     pub(crate) fn add_to_native_tls(self, tls: &mut native_tls_crate::TlsConnectorBuilder) {\n         tls.add_root_certificate(self.native);\n     }\n@@ -181,14 +203,14 @@ impl Certificate {\n \n         match self.original {\n             Cert::Der(buf) => root_cert_store\n-                .add(&rustls::Certificate(buf))\n+                .add(buf.into())\n                 .map_err(crate::error::builder)?,\n             Cert::Pem(buf) => {\n                 let mut reader = Cursor::new(buf);\n                 let certs = Self::read_pem_certs(&mut reader)?;\n                 for c in certs {\n                     root_cert_store\n-                        .add(&rustls::Certificate(c))\n+                        .add(c.into())\n                         .map_err(crate::error::builder)?;\n                 }\n             }\n@@ -308,8 +330,8 @@ impl Identity {\n \n         let (key, certs) = {\n             let mut pem = Cursor::new(buf);\n-            let mut sk = Vec::<rustls::PrivateKey>::new();\n-            let mut certs = Vec::<rustls::Certificate>::new();\n+            let mut sk = Vec::<rustls_pki_types::PrivateKeyDer>::new();\n+            let mut certs = Vec::<rustls_pki_types::CertificateDer>::new();\n \n             for item in std::iter::from_fn(|| rustls_pemfile::read_one(&mut pem).transpose()) {\n                 match item.map_err(|_| {\n@@ -317,12 +339,16 @@ impl Identity {\n                         \"Invalid identity PEM file\",\n                     )))\n                 })? {\n-                    rustls_pemfile::Item::X509Certificate(cert) => {\n-                        certs.push(rustls::Certificate(cert))\n+                    rustls_pemfile::Item::X509Certificate(cert) => certs.push(cert.into()),\n+                    rustls_pemfile::Item::PKCS8Key(key) => {\n+                        sk.push(rustls_pki_types::PrivateKeyDer::Pkcs8(key.into()))\n+                    }\n+                    rustls_pemfile::Item::RSAKey(key) => {\n+                        sk.push(rustls_pki_types::PrivateKeyDer::Pkcs1(key.into()))\n+                    }\n+                    rustls_pemfile::Item::ECKey(key) => {\n+                        sk.push(rustls_pki_types::PrivateKeyDer::Sec1(key.into()))\n                     }\n-                    rustls_pemfile::Item::PKCS8Key(key) => sk.push(rustls::PrivateKey(key)),\n-                    rustls_pemfile::Item::RSAKey(key) => sk.push(rustls::PrivateKey(key)),\n-                    rustls_pemfile::Item::ECKey(key) => sk.push(rustls::PrivateKey(key)),\n                     _ => {\n                         return Err(crate::error::builder(TLSError::General(String::from(\n                             \"No valid certificate was found\",\n@@ -365,7 +391,8 @@ impl Identity {\n         self,\n         config_builder: rustls::ConfigBuilder<\n             rustls::ClientConfig,\n-            rustls::client::WantsTransparencyPolicyOrClientCert,\n+            // Not sure here\n+            rustls::client::WantsClientCert,\n         >,\n     ) -> crate::Result<rustls::ClientConfig> {\n         match self.inner {\n@@ -491,18 +518,18 @@ impl Default for TlsBackend {\n }\n \n #[cfg(feature = \"__rustls\")]\n+#[derive(Debug)]\n pub(crate) struct NoVerifier;\n \n #[cfg(feature = \"__rustls\")]\n impl ServerCertVerifier for NoVerifier {\n     fn verify_server_cert(\n         &self,\n-        _end_entity: &rustls::Certificate,\n-        _intermediates: &[rustls::Certificate],\n+        _end_entity: &rustls_pki_types::CertificateDer,\n+        _intermediates: &[rustls_pki_types::CertificateDer],\n         _server_name: &ServerName,\n-        _scts: &mut dyn Iterator<Item = &[u8]>,\n         _ocsp_response: &[u8],\n-        _now: std::time::SystemTime,\n+        _now: UnixTime,\n     ) -> Result<ServerCertVerified, TLSError> {\n         Ok(ServerCertVerified::assertion())\n     }\n@@ -510,7 +537,7 @@ impl ServerCertVerifier for NoVerifier {\n     fn verify_tls12_signature(\n         &self,\n         _message: &[u8],\n-        _cert: &rustls::Certificate,\n+        _cert: &rustls_pki_types::CertificateDer,\n         _dss: &DigitallySignedStruct,\n     ) -> Result<HandshakeSignatureValid, TLSError> {\n         Ok(HandshakeSignatureValid::assertion())\n@@ -519,11 +546,29 @@ impl ServerCertVerifier for NoVerifier {\n     fn verify_tls13_signature(\n         &self,\n         _message: &[u8],\n-        _cert: &rustls::Certificate,\n+        _cert: &rustls_pki_types::CertificateDer,\n         _dss: &DigitallySignedStruct,\n     ) -> Result<HandshakeSignatureValid, TLSError> {\n         Ok(HandshakeSignatureValid::assertion())\n     }\n+\n+    fn supported_verify_schemes(&self) -> Vec<SignatureScheme> {\n+        vec![\n+            SignatureScheme::RSA_PKCS1_SHA1,\n+            SignatureScheme::ECDSA_SHA1_Legacy,\n+            SignatureScheme::RSA_PKCS1_SHA256,\n+            SignatureScheme::ECDSA_NISTP256_SHA256,\n+            SignatureScheme::RSA_PKCS1_SHA384,\n+            SignatureScheme::ECDSA_NISTP384_SHA384,\n+            SignatureScheme::RSA_PKCS1_SHA512,\n+            SignatureScheme::ECDSA_NISTP521_SHA512,\n+            SignatureScheme::RSA_PSS_SHA256,\n+            SignatureScheme::RSA_PSS_SHA384,\n+            SignatureScheme::RSA_PSS_SHA512,\n+            SignatureScheme::ED25519,\n+            SignatureScheme::ED448,\n+        ]\n+    }\n }\n \n /// Hyper extension carrying extra TLS layer information.\n", "instance_id": "seanmonstar__reqwest-2188", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in its intent to put the `encoding_rs` dependency behind a Cargo feature to reduce binary size when it's not needed, such as when `reqwest` is used for binary data or UTF-8 REST endpoints. It provides context about binary size analysis and references specific data tables in `encoding_rs` that contribute to the size increase. However, it lacks detailed requirements or examples of how the feature should be implemented (e.g., naming of the feature, default behavior, or specific use cases). Additionally, edge cases or potential impacts on existing users who rely on `encoding_rs` are not mentioned, which could lead to ambiguity during implementation. Overall, the goal is understandable, but minor details are missing to make it comprehensive.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes is significant, as seen in the provided diff, which spans multiple files including `Cargo.toml`, CI configuration, and core library components like `body.rs`, `client.rs`, and `response.rs`. This indicates a need to understand and modify interactions across different parts of the `reqwest` codebase. Second, the changes involve advanced Rust concepts such as Cargo features, conditional compilation, and dependency management, requiring a deep understanding of Rust's build system and feature flags. Third, the modifications impact the library's architecture by altering how dependencies are included and used, which could have downstream effects on users and requires careful consideration of backward compatibility. Additionally, the problem involves handling potential edge cases, such as ensuring that users who need `encoding_rs` for charset handling are not broken by the feature flag, and updating documentation or tests accordingly. While not at the extreme end of difficulty (e.g., implementing a new protocol), it requires a solid grasp of the `reqwest` library's design and Rust ecosystem, justifying a score of 0.65.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Lower log level for unexpected WS disconnects\nCurrently this is at warn, causing spam for larger bots where WS disconnects are expected. This should be lowered to `info` and only `warn` or `error` if a reconnection fails entirely.\r\n\r\n![image](https://github.com/user-attachments/assets/4bd07dfe-63c0-4f12-b6fd-41ede81ea1c0)\r\n\n", "patch": "diff --git a/src/gateway/shard.rs b/src/gateway/shard.rs\nindex 4e6f7f29402..19ab0942461 100644\n--- a/src/gateway/shard.rs\n+++ b/src/gateway/shard.rs\n@@ -482,7 +482,7 @@ impl Shard {\n                 self.handle_gateway_closed(data.as_ref())\n             },\n             Err(Error::Tungstenite(why)) => {\n-                warn!(\"[{:?}] Websocket error: {:?}\", self.shard_info, why);\n+                info!(\"[{:?}] Websocket error: {:?}\", self.shard_info, why);\n                 info!(\"[{:?}] Will attempt to auto-reconnect\", self.shard_info);\n \n                 Ok(Some(ShardAction::Reconnect(self.reconnection_type())))\n", "instance_id": "serenity-rs__serenity-3002", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in its intent to lower the log level for unexpected WebSocket (WS) disconnects from 'warn' to 'info' to reduce log spam for larger bots, while suggesting that 'warn' or 'error' levels should be used if reconnection fails entirely. However, there are minor ambiguities and missing details. For instance, the statement does not explicitly define under what specific conditions a reconnection failure should trigger a 'warn' or 'error' log level, nor does it provide examples of what constitutes a \"larger bot\" or expected disconnects. Additionally, the included image link is not accessible in this context, so any supplementary information it might provide is unavailable for evaluation. Despite these minor gaps, the core goal of adjusting log levels is understandable, and the code change aligns with the stated intent.", "difficulty_explanation": "The difficulty of this problem is very low, as it involves a straightforward modification to the logging level in a single line of code within a specific file (shard.rs). The change requires minimal understanding of the codebase\u2014just the context of logging in the WebSocket error handling logic. The scope is extremely limited, affecting only one log statement, with no impact on the system's architecture or interactions between modules. No complex technical concepts, algorithms, or domain-specific knowledge are required beyond basic familiarity with logging macros (e.g., warn! and info! in Rust). There are no edge cases or additional error handling requirements mentioned or implied in the problem statement or code change. The task is essentially a simple adjustment of a constant value (log level), fitting within the 0.0-0.2 range for very easy tasks. I\u2019ve rated it slightly above the minimum (0.15) to account for the need to understand the context of WebSocket error handling, though this is still a trivial task for any developer with basic Rust experience.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Feature request: More accurate types in generated rune API documentation\nCurrently when a generic type (e.g. `Option<MyCustomType>`) is part of a function signature in an external function. the rune docs only show the outermost type (e.g. `Option`). It would be very useful to be able to see the full type.\r\n\r\nI'm not sure how hard this would be to add, I would be interested in looking into this if this is a \"relatively easy\" thing.\n", "patch": "diff --git a/crates/rune/src/doc/build.rs b/crates/rune/src/doc/build.rs\nindex 7edf19c31..6ef93d2c3 100644\n--- a/crates/rune/src/doc/build.rs\n+++ b/crates/rune/src/doc/build.rs\n@@ -25,6 +25,7 @@ use crate::doc::artifacts::Test;\n use crate::doc::context::{Function, Kind, Meta, Signature};\n use crate::doc::templating;\n use crate::doc::{Artifacts, Context, Visitor};\n+use crate::runtime::static_type;\n use crate::std::borrow::ToOwned;\n use crate::Hash;\n \n@@ -411,6 +412,22 @@ impl<'m> Ctxt<'_, 'm> {\n         ))\n     }\n \n+    /// Render an optional return type parameter.\n+    ///\n+    /// Returning `None` indicates that the return type is the default return\n+    /// type, which is `()`.\n+    fn return_type(&self, ty: &meta::DocType) -> Result<Option<String>> {\n+        match *ty {\n+            meta::DocType {\n+                base, ref generics, ..\n+            } if base == static_type::TUPLE_TYPE.hash && generics.is_empty() => Ok(None),\n+            meta::DocType {\n+                base, ref generics, ..\n+            } if !base.is_empty() => Ok(Some(self.link(base, None, generics)?)),\n+            _ => Ok(None),\n+        }\n+    }\n+\n     /// Render line docs.\n     fn render_line_docs<S>(&mut self, meta: Meta<'_>, docs: &[S]) -> Result<Option<String>>\n     where\n@@ -564,57 +581,68 @@ impl<'m> Ctxt<'_, 'm> {\n             }\n         }\n \n-        let mut it = self\n-            .context\n-            .meta_by_hash(hash)?\n-            .into_iter()\n-            .flat_map(|m| Some((m, into_item_kind(m)?)));\n+        if hash == static_type::TUPLE_TYPE.hash {\n+            write!(o, \"(\")?;\n+            self.write_generics(o, generics)?;\n+            write!(o, \")\")?;\n+        } else {\n+            let mut it = self\n+                .context\n+                .meta_by_hash(hash)?\n+                .into_iter()\n+                .flat_map(|m| Some((m, into_item_kind(m)?)));\n \n-        let Some((meta, kind)) = it.next() else {\n-            tracing::warn!(?hash, \"No link for hash\");\n+            let Some((meta, kind)) = it.next() else {\n+                tracing::warn!(?hash, \"No link for hash\");\n \n-            for meta in self.context.meta_by_hash(hash)? {\n-                tracing::warn!(\"Candidate: {:?}\", meta.kind);\n-            }\n+                for meta in self.context.meta_by_hash(hash)? {\n+                    tracing::warn!(\"Candidate: {:?}\", meta.kind);\n+                }\n \n-            write!(o, \"{hash}\")?;\n-            return Ok(());\n-        };\n+                write!(o, \"{hash}\")?;\n+                return Ok(());\n+            };\n \n-        let item = meta.item.context(\"Missing item link meta\")?;\n+            let item = meta.item.context(\"Missing item link meta\")?;\n \n-        let name = match text {\n-            Some(text) => text,\n-            None => item\n-                .last()\n-                .and_then(|c| c.as_str())\n-                .context(\"missing name\")?,\n-        };\n+            let name = match text {\n+                Some(text) => text,\n+                None => item\n+                    .last()\n+                    .and_then(|c| c.as_str())\n+                    .context(\"missing name\")?,\n+            };\n+\n+            let path = self.item_path(item, kind)?;\n \n-        let path = self.item_path(item, kind)?;\n+            write!(o, \"<a class=\\\"{kind}\\\" href=\\\"{path}\\\">{name}</a>\")?;\n \n-        write!(o, \"<a class=\\\"{kind}\\\" href=\\\"{path}\\\">{name}</a>\")?;\n+            if !generics.is_empty() {\n+                write!(o, \"<\")?;\n+                self.write_generics(o, generics)?;\n+                write!(o, \">\")?;\n+            }\n+        }\n \n-        if !generics.is_empty() {\n-            let mut it = generics.iter().peekable();\n-            write!(o, \"<\")?;\n+        Ok(())\n+    }\n \n-            while let Some(ty) = it.next() {\n-                match ty.base.as_non_empty() {\n-                    Some(hash) => {\n-                        self.write_link(o, hash, None, &ty.generics)?;\n-                    }\n-                    None => {\n-                        write!(o, \"?\")?;\n-                    }\n-                }\n+    fn write_generics(&self, o: &mut dyn TryWrite, generics: &[meta::DocType]) -> Result<()> {\n+        let mut it = generics.iter().peekable();\n \n-                if it.peek().is_some() {\n-                    write!(o, \", \")?;\n+        while let Some(ty) = it.next() {\n+            match ty.base.as_non_empty() {\n+                Some(hash) => {\n+                    self.write_link(o, hash, None, &ty.generics)?;\n+                }\n+                None => {\n+                    write!(o, \"any\")?;\n                 }\n             }\n \n-            write!(o, \">\")?;\n+            if it.peek().is_some() {\n+                write!(o, \", \")?;\n+            }\n         }\n \n         Ok(())\n@@ -1109,12 +1137,7 @@ fn build_function<'m>(cx: &mut Ctxt<'_, 'm>, meta: Meta<'m>) -> Result<Builder<'\n \n     let doc = cx.render_docs(meta, meta.docs, true)?;\n \n-    let return_type = match f.return_type {\n-        meta::DocType { base, generics, .. } if !base.is_empty() => {\n-            Some(cx.link(*base, None, generics)?)\n-        }\n-        _ => None,\n-    };\n+    let return_type = cx.return_type(f.return_type)?;\n \n     let item = meta.item.context(\"Missing item\")?;\n     let deprecated = meta.deprecated;\ndiff --git a/crates/rune/src/doc/build/type_.rs b/crates/rune/src/doc/build/type_.rs\nindex a1e5c34f8..706a2b94a 100644\n--- a/crates/rune/src/doc/build/type_.rs\n+++ b/crates/rune/src/doc/build/type_.rs\n@@ -5,7 +5,7 @@ use crate::alloc::borrow::Cow;\n use crate::alloc::fmt::TryWrite;\n use crate::alloc::prelude::*;\n use crate::alloc::{String, Vec};\n-use crate::compile::{meta, ComponentRef, Item};\n+use crate::compile::{ComponentRef, Item};\n use crate::doc::build::{Builder, Ctxt, IndexEntry, IndexKind};\n use crate::doc::context::{Assoc, AssocFnKind, Meta};\n \n@@ -110,12 +110,7 @@ pub(super) fn build_assoc_fns<'m>(\n                             name,\n                             args: cx.args_to_string(sig, assoc.arguments)?,\n                             parameters,\n-                            return_type: match assoc.return_type {\n-                                meta::DocType { base, generics, .. } if !base.is_empty() => {\n-                                    Some(cx.link(*base, None, generics)?)\n-                                }\n-                                _ => None,\n-                            },\n+                            return_type: cx.return_type(assoc.return_type)?,\n                             line_doc,\n                             doc,\n                         })?;\n@@ -140,12 +135,7 @@ pub(super) fn build_assoc_fns<'m>(\n                     name: protocol.name,\n                     field,\n                     repr,\n-                    return_type: match assoc.return_type {\n-                        meta::DocType { base, generics, .. } if !base.is_empty() => {\n-                            Some(cx.link(*base, None, generics)?)\n-                        }\n-                        _ => None,\n-                    },\n+                    return_type: cx.return_type(assoc.return_type)?,\n                     doc,\n                     deprecated: assoc.deprecated,\n                 })?;\ndiff --git a/crates/rune/src/modules/string.rs b/crates/rune/src/modules/string.rs\nindex ffdef5bcc..ad4d86170 100644\n--- a/crates/rune/src/modules/string.rs\n+++ b/crates/rune/src/modules/string.rs\n@@ -55,6 +55,7 @@ pub fn module() -> Result<Module, ContextError> {\n     module.function_meta(shrink_to_fit)?;\n     module.function_meta(char_at)?;\n     module.function_meta(split)?;\n+    module.function_meta(split_once)?;\n     module\n         .associated_function(\"split_str\", __rune_fn__split)?\n         .deprecated(\"Use String::split instead\")?;\n@@ -816,6 +817,57 @@ fn split(this: &str, value: Value) -> VmResult<Iterator> {\n     VmResult::Ok(Iterator::from_double_ended(NAME, lines.into_iter()))\n }\n \n+/// Splits the string on the first occurrence of the specified delimiter and\n+/// returns prefix before delimiter and suffix after delimiter.\n+///\n+/// # Examples\n+///\n+/// ```rune\n+/// assert_eq!(\"cfg\".split_once('='), None);\n+/// assert_eq!(\"cfg=\".split_once('='), Some((\"cfg\", \"\")));\n+/// assert_eq!(\"cfg=foo\".split_once('='), Some((\"cfg\", \"foo\")));\n+/// assert_eq!(\"cfg=foo=bar\".split_once('='), Some((\"cfg\", \"foo=bar\")));\n+/// ```\n+#[rune::function(instance)]\n+fn split_once(this: &str, value: Value) -> VmResult<Option<(String, String)>> {\n+    let outcome = match *vm_try!(value.borrow_kind_ref()) {\n+        ValueKind::String(ref s) => this.split_once(s.as_str()),\n+        ValueKind::Char(pat) => this.split_once(pat),\n+        ValueKind::Function(ref f) => {\n+            let mut err = None;\n+\n+            let outcome = this.split_once(|c: char| match f.call::<bool>((c,)) {\n+                VmResult::Ok(b) => b,\n+                VmResult::Err(e) => {\n+                    if err.is_none() {\n+                        err = Some(e);\n+                    }\n+\n+                    false\n+                }\n+            });\n+\n+            if let Some(e) = err.take() {\n+                return VmResult::Err(e);\n+            }\n+\n+            outcome\n+        }\n+        ref actual => {\n+            return VmResult::err([\n+                VmErrorKind::expected::<String>(actual.type_info()),\n+                VmErrorKind::bad_argument(0),\n+            ])\n+        }\n+    };\n+\n+    let Some((a, b)) = outcome else {\n+        return VmResult::Ok(None);\n+    };\n+\n+    VmResult::Ok(Some((vm_try!(a.try_to_owned()), vm_try!(b.try_to_owned()))))\n+}\n+\n /// Returns a string slice with leading and trailing whitespace removed.\n ///\n /// 'Whitespace' is defined according to the terms of the Unicode Derived Core\n", "instance_id": "rune-rs__rune-764", "clarity": 2, "difficulty": 0.55, "clarity_explanation": "The problem statement is mostly clear in describing the goal: to improve the accuracy of type information in the generated Rune API documentation by showing full generic types (e.g., `Option<MyCustomType>` instead of just `Option`). It identifies the issue with the current implementation and expresses the desired outcome. However, it lacks specific details about the expected behavior in edge cases (e.g., nested generics, complex type structures) and does not provide explicit input/output formats or constraints for the documentation rendering. Additionally, the statement includes a note of uncertainty from the requester about the difficulty, which indicates a lack of depth in defining the scope or potential challenges. Despite these minor ambiguities, the intent and primary requirement are understandable, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the medium range (0.4-0.6) due to several factors. First, the scope of code changes involves multiple files (`build.rs`, `type_.rs`, and `string.rs`) within the Rune crate, indicating a need to understand and modify different parts of the documentation generation system. The primary changes focus on enhancing type rendering logic to handle generics more accurately, which requires a moderate understanding of the existing codebase structure, particularly how type metadata (`meta::DocType`) is processed and rendered into HTML documentation. \n\nThe technical concepts involved include Rust's type system, generics, and familiarity with the Rune project's custom type metadata and documentation generation pipeline. The code changes also introduce a new utility function (`return_type`) and modify existing rendering logic (`write_link`, `write_generics`), which demands careful handling to avoid breaking existing functionality. Additionally, there is an unrelated change in `string.rs` adding a `split_once` method, which appears to be a separate feature or bug fix bundled into the diff. This adds a small amount of complexity but is relatively straightforward compared to the documentation changes.\n\nEdge cases are not explicitly mentioned in the problem statement, but the code changes suggest potential challenges with rendering nested generics or handling empty/invalid type metadata, which the developer must account for. The modifications do not significantly impact the system's architecture but do require a nuanced understanding of how type information flows through the documentation builder.\n\nOverall, this task is not overly complex but goes beyond simple modifications, requiring a solid grasp of Rust, the project's internals, and careful testing to ensure correctness across various type scenarios. A score of 0.55 reflects this medium difficulty, leaning slightly above the midpoint due to the multi-file changes and the need for precision in type rendering logic.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "`joinp`: align `--ignore-leading-zeros` handling to be the same as `join`\n### Discussed in https://github.com/dathere/qsv/discussions/2424\r\n\r\n<div type='discussions-op-text'>\r\n\r\n<sup>Originally posted by **datatraveller1** January  8, 2025</sup>\r\nHi @jqnatividad, first of all, thank you very much for the new `--ignore-leading-zero` (shortcut `-z`) option.\r\n\r\nIt works great, but I have a question. e.g. I use:\r\n`qsv joinp -i -z --left-semi --cache-schema=-1 company_id,art_no file1.csv company_id,art_no file2.csv -o left-semi.csv`\r\n\r\nThis works correctly except that the leading zeros are stripped from the output column `art_no` in` left-semi.csv`. I had hoped that stripping leadings zeros would only happen for the keys, but if the original value of art_no is `01`, the value in the output file gets `1`.\r\n\r\nReading the documentation, I'm not sure what is the expected behaviour: \r\n\"`When set, joins are done ignoring leading zeros. Note that this is only applied to the join keys for both numeric and string columns. The output columns will not have leading zeros.`\"\r\nIf \"`will not have leading zeros`\" isn't a typo, the behaviour is as expected. If this should read \"`will not have omitted zeros`\", it would be a problem. Thank you very much!</div>\n", "patch": "diff --git a/src/cmd/joinp.rs b/src/cmd/joinp.rs\nindex c7ff2873e..36e91dde0 100644\n--- a/src/cmd/joinp.rs\n+++ b/src/cmd/joinp.rs\n@@ -29,11 +29,6 @@ joinp arguments:\n     Note that <input1> is the left CSV data set and <input2> is the right CSV data set.\n \n joinp options:\n-    -i, --ignore-case      When set, joins are done case insensitively.\n--z, --ignore-leading-zeros  When set, joins are done ignoring leading zeros.\n-                           Note that this is only applied to the join keys for\n-                           both numeric and string columns. The output columns\n-                           will not have leading zeros.\n     --left                 Do a 'left outer' join. This returns all rows in\n                            first CSV data set, including rows with no\n                            corresponding row in the second data set. When no\n@@ -220,6 +215,15 @@ joinp options:\n    --null-value <arg>        The string to use when writing null values.\n                              (default: <empty string>)\n \n+    -i, --ignore-case        When set, joins are done case insensitively.\n+-z, --ignore-leading-zeros   When set, joins are done ignoring leading zeros.\n+                             Note that this is only applied to the join keys for\n+                             both numeric and string columns. Also note that\n+                             Polars will automatically remove leading zeros from\n+                             numeric columns when it infers the schema.\n+                             To force the schema to be all String types,\n+                             set --cache-schema to -1 or -2.\n+\n Common options:\n     -h, --help             Display this message\n     -o, --output <file>    Write output to <file> instead of stdout.\n@@ -237,7 +241,7 @@ use std::{\n     str,\n };\n \n-use polars::{datatypes::AnyValue, prelude as pl, prelude::*, sql::SQLContext};\n+use polars::prelude::*;\n use serde::Deserialize;\n use tempfile::tempdir;\n \n@@ -544,40 +548,70 @@ impl JoinStruct {\n             .map(polars::lazy::dsl::col)\n             .collect();\n \n-        // If ignore_case is enabled, create lowercase versions of the join columns\n-        // but only if ignore_leading_zeros is not enabled\n-        // because leading zeros handling does its own lowercase conversion\n-        if self.ignore_case && !self.ignore_leading_zeros {\n-            // Create temporary lowercase versions of join columns in left dataframe\n+        // Handle ignore_case and ignore_leading_zeros transformations\n+        if self.ignore_case || self.ignore_leading_zeros {\n+            // Create temporary versions of join columns in left dataframe\n             for col in &left_selcols {\n-                self.left_lf = self\n-                    .left_lf\n-                    .with_column(col.clone().str().to_lowercase().alias(format!(\n-                        \"_qsv-{}-lower\",\n-                        col.to_string()\n-                            .trim_start_matches(r#\"col(\"\"#)\n-                            .trim_end_matches(r#\"\")\"#)\n-                    )));\n+                let col_str = col.to_string();\n+                let col_name = col_str\n+                    .trim_start_matches(r#\"col(\"\"#)\n+                    .trim_end_matches(r#\"\")\"#)\n+                    .to_string();\n+                let temp_col_name = format!(\"_qsv-{col_name}-transformed\");\n+\n+                // Create a temporary transformed column for joining\n+                // we need to cast to string as the original column may be of a different type\n+                // and we need a string type for the transformations\n+                let transformed = col.clone().cast(DataType::String);\n+                let transformed = if self.ignore_leading_zeros {\n+                    transformed\n+                        .str()\n+                        .replace_all(lit(r\"^0+\"), lit(\"\"), false)\n+                        .str()\n+                        .to_lowercase()\n+                } else if self.ignore_case {\n+                    transformed.str().to_lowercase()\n+                } else {\n+                    transformed\n+                };\n+\n+                // Add transformed column for joining - keep original untouched\n+                self.left_lf = self.left_lf.with_column(transformed.alias(&temp_col_name));\n             }\n \n-            // Create temporary lowercase versions of join columns in right dataframe\n+            // Create temporary versions of join columns in right dataframe\n             for col in &right_selcols {\n-                self.right_lf = self\n-                    .right_lf\n-                    .with_column(col.clone().str().to_lowercase().alias(format!(\n-                        \"_qsv-{}-lower\",\n-                        col.to_string()\n-                            .trim_start_matches(r#\"col(\"\"#)\n-                            .trim_end_matches(r#\"\")\"#)\n-                    )));\n+                let col_str = col.to_string();\n+                let col_name = col_str\n+                    .trim_start_matches(r#\"col(\"\"#)\n+                    .trim_end_matches(r#\"\")\"#)\n+                    .to_string();\n+                let temp_col_name = format!(\"_qsv-{col_name}-transformed\");\n+\n+                // Create a temporary transformed column for joining\n+                let transformed = col.clone().cast(DataType::String);\n+                let transformed = if self.ignore_leading_zeros {\n+                    transformed\n+                        .str()\n+                        .replace_all(lit(r\"^0+\"), lit(\"\"), false)\n+                        .str()\n+                        .to_lowercase()\n+                } else if self.ignore_case {\n+                    transformed.str().to_lowercase()\n+                } else {\n+                    transformed\n+                };\n+\n+                // Add transformed column for joining - keep original untouched\n+                self.right_lf = self.right_lf.with_column(transformed.alias(&temp_col_name));\n             }\n \n-            // Create new vectors for the lowercase column names\n+            // Update selcols to use the transformed columns for joining\n             let left_selcols_w: Vec<_> = left_selcols\n                 .iter()\n                 .map(|col| {\n                     polars::lazy::dsl::col(format!(\n-                        \"_qsv-{}-lower\",\n+                        \"_qsv-{}-transformed\",\n                         col.to_string()\n                             .trim_start_matches(r#\"col(\"\"#)\n                             .trim_end_matches(r#\"\")\"#)\n@@ -585,11 +619,12 @@ impl JoinStruct {\n                 })\n                 .collect();\n             left_selcols = left_selcols_w;\n+\n             let right_selcols_w: Vec<_> = right_selcols\n                 .iter()\n                 .map(|col| {\n                     polars::lazy::dsl::col(format!(\n-                        \"_qsv-{}-lower\",\n+                        \"_qsv-{}-transformed\",\n                         col.to_string()\n                             .trim_start_matches(r#\"col(\"\"#)\n                             .trim_end_matches(r#\"\")\"#)\n@@ -705,7 +740,7 @@ impl JoinStruct {\n         };\n \n         let mut results_df = if let Some(sql_filter) = &self.sql_filter {\n-            let mut ctx = SQLContext::new();\n+            let mut ctx = polars::sql::SQLContext::new();\n             ctx.register(\"join_result\", join_results.lazy());\n             ctx.execute(sql_filter)\n                 .and_then(polars::prelude::LazyFrame::collect)?\n@@ -713,17 +748,34 @@ impl JoinStruct {\n             join_results\n         };\n \n-        // if self.ignore_case, remove the temporary lowercase columns from the dataframe\n-        if self.ignore_case && !self.ignore_leading_zeros {\n-            // Get all column names\n+        if self.ignore_case || self.ignore_leading_zeros {\n+            // Remove temporary transformed columns and\n+            // duplicate right-side join columns if coalesce is true\n             let cols = results_df.get_column_names();\n-            // Filter out the lowercase columns (those with \"_qsv-*-lower\" pattern)\n-            let keep_cols: Vec<String> = cols\n-                .iter()\n-                .filter(|&col| !(col.starts_with(\"_qsv-\") && col.ends_with(\"-lower\")))\n-                .map(|&s| s.to_string())\n+            let mut keep_cols: Vec<String> = Vec::new();\n+\n+            let left_join_cols: Vec<String> = self\n+                .left_sel\n+                .split(',')\n+                .map(std::string::ToString::to_string)\n                 .collect();\n-            // Select only the non-lowercase columns\n+\n+            for col in cols {\n+                if col.contains(\"-transformed\") {\n+                    continue;\n+                }\n+\n+                // For join columns, only keep the left version if coalesce is true\n+                if self.coalesce && col.ends_with(\"_right\") {\n+                    let base_col = col.trim_end_matches(\"_right\");\n+                    if left_join_cols.contains(&base_col.to_string()) {\n+                        continue;\n+                    }\n+                }\n+\n+                keep_cols.push(col.to_string());\n+            }\n+\n             results_df = results_df.select(keep_cols)?;\n         }\n \n@@ -1060,98 +1112,6 @@ impl Args {\n             right_lf = right_lf.filter(filter_right_expr);\n         }\n \n-        if self.flag_ignore_leading_zeros {\n-            // Transform the join keys in the left and right dataframe to handle leading zeros\n-            // For each join key column:\n-            //   1. Cast to string type\n-            //   2. If ignore_case is true, convert to lowercase\n-            //   3. Trim leading zeros, regardless of the original type\n-            // This allows joins to match on values like \"001\" and \"1\", \"0001ABZ\" and \"1ABZ\".\n-            // Note that the output columns will not have leading zeros for the join keys.\n-            //\n-            // We had to add ignore_case handling to ignore_leading_zeros in the join keys because\n-            // the existing code for ignore_case was not working for leading zeros if they are both\n-            // used at the same time.\n-            // The ignore_case code was creating temporary join key columns while\n-            // ignore_leading_zeros was using the existing join key columns.\n-            let ignore_case = self.flag_ignore_case;\n-            left_lf = left_lf.with_columns(\n-                self.arg_columns1\n-                    .split(',')\n-                    .map(|col| {\n-                        let col_name = col.to_string();\n-                        pl::col(&col_name).cast(pl::DataType::String).map(\n-                            move |s| {\n-                                Ok(Some(\n-                                    pl::Series::new(\n-                                        col_name.clone().into(),\n-                                        s.str()?\n-                                            .into_iter()\n-                                            .map(|x| {\n-                                                x.map(|val| {\n-                                                    let v = if ignore_case {\n-                                                        val.to_lowercase()\n-                                                    } else {\n-                                                        val.to_string()\n-                                                    };\n-                                                    if v.starts_with('0') {\n-                                                        v.trim_start_matches('0').to_string()\n-                                                    } else {\n-                                                        v\n-                                                    }\n-                                                })\n-                                                .unwrap_or_default()\n-                                            })\n-                                            .collect::<Vec<String>>(),\n-                                    )\n-                                    .into(),\n-                                ))\n-                            },\n-                            pl::GetOutput::from_type(pl::DataType::String),\n-                        )\n-                    })\n-                    .collect::<Vec<_>>(),\n-            );\n-\n-            right_lf = right_lf.with_columns(\n-                self.arg_columns2\n-                    .split(',')\n-                    .map(|col| {\n-                        let col_name = col.to_string();\n-                        pl::col(&col_name).cast(pl::DataType::String).map(\n-                            move |s| {\n-                                Ok(Some(\n-                                    pl::Series::new(\n-                                        col_name.clone().into(),\n-                                        s.str()?\n-                                            .into_iter()\n-                                            .map(|x| {\n-                                                x.map(|val| {\n-                                                    let v = if ignore_case {\n-                                                        val.to_lowercase()\n-                                                    } else {\n-                                                        val.to_string()\n-                                                    };\n-                                                    if v.starts_with('0') {\n-                                                        v.trim_start_matches('0').to_string()\n-                                                    } else {\n-                                                        v\n-                                                    }\n-                                                })\n-                                                .unwrap_or_default()\n-                                            })\n-                                            .collect::<Vec<String>>(),\n-                                    )\n-                                    .into(),\n-                                ))\n-                            },\n-                            pl::GetOutput::from_type(pl::DataType::String),\n-                        )\n-                    })\n-                    .collect::<Vec<_>>(),\n-            );\n-        }\n-\n         Ok(JoinStruct {\n             left_lf,\n             left_sel: self.arg_columns1.clone(),\n", "instance_id": "dathere__qsv-2433", "clarity": 2, "difficulty": 0.55, "clarity_explanation": "The problem statement is mostly clear in describing the issue with the `--ignore-leading-zeros` option in the `joinp` command of the `qsv` tool. It highlights a discrepancy between expected and actual behavior regarding the stripping of leading zeros in output columns, and references a discussion for context. The goal is to align the behavior with the `join` command, though the exact desired behavior (whether leading zeros should be preserved in output or not) is somewhat ambiguous due to the user's uncertainty about the documentation. Additionally, the problem statement lacks explicit mention of edge cases or specific constraints beyond the general behavior. However, the intent to fix the handling of leading zeros in join keys versus output columns is evident, and the provided discussion link offers supplementary context. Thus, while the statement is valid and mostly clear, minor details about the expected output format and edge cases are missing, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the medium range due to several factors. First, the scope of code changes is moderate, primarily confined to a single file (`joinp.rs`), but involves significant modifications to the logic for handling join keys and temporary columns in a data processing library (Polars). The changes require understanding and manipulating Polars' lazy frame API, string transformations, and schema inference behaviors, which are non-trivial concepts. Second, the problem demands familiarity with specific Rust and Polars library features, such as column transformations, data type casting, and SQL context handling, adding to the technical depth. Third, the code changes address interactions between options like `--ignore-case` and `--ignore-leading-zeros`, requiring careful handling to avoid conflicts or unintended side effects. While the problem does not impact the broader system architecture, it involves nuanced logic to preserve original column values in output while transforming join keys, which introduces complexity. Edge cases, such as mixed data types or schema inference issues, are implicitly relevant (as hinted by the `--cache-schema` option) but not extensively detailed in the statement, requiring the developer to anticipate and handle them. Overall, this problem requires a solid understanding of multiple concepts and careful implementation, justifying a difficulty score of 0.55, in the medium range (0.4-0.6), leaning slightly higher due to the library-specific intricacies.", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
{"problem_statement": "Add confirmation prompt to deletion action\nThis is my WIP attempt to resolve #1136, but it isn't working at the moment. Clearly, I don't understand Rust and the whole borrowing logic enough for me to resolve this at the moment. I tried many different things but can't get the logic \"Rusty\" enough. At the moment, the issue is that the `&appwindow` reference in trash.rs doesn't live long enough. I tried creating a clone, among other things, but that didn't help either.\r\n\r\nOther than that, I tried to copy the style of the other dialogues as much as possible to keep the whole architectural idea the same.\r\n\r\nI'll keep working on this sometime, but in the meantime, if someone knows how to properly do this, feel free to point me in the right direction or open a PR.\nprompt for confirmation when removing folders\n**Describe the bug**  \r\nI deleted the 'Documents' directory from the Default Workspace, corresponding to '~/Documents' linux directory.\r\n\r\nThe directory was permanently deleted, and not even a user dialog warning about this was issued.\r\n\r\nThe deleted directory wasn't moved to the Trash bin, it was permanently deleted.\r\n\r\nI tried recovering it with the Linux tool 'testdisk' without success.\r\n\r\n**To Reproduce**  \r\nSteps to reproduce the behavior:\r\n1. Go to the Workspace\r\n2. Delete a directory\r\n\r\n**Expected behavior**  \r\n\r\nThe deleted directory should have been moved to the Trash bin, or at least warn me that it was going to be permanently deleted.\r\n\r\n**Console Output**  \r\n\r\nI can't provide the output because I turned off the computer to try to recover the deleted data with 'testdisk' Linux utility. I'm afraid that turning it on again will overwrite the unallocated disk sectors that were originally occupied by the deleted data.\r\n\r\n**Desktop**  \r\n - OS: Kubuntu 22.04\r\n - App Version: Rnote v0.10.2\r\n - Installation Source: Flatpak\r\n - Desktop Environment: KDE Plasma 5.24 \r\n - Display Server: Wayland\r\n - Input Source: Mouse and Keyboard, External Graphics Tablet\r\n\r\n\n", "patch": "diff --git a/AUTHORS b/AUTHORS\nindex afeb6efa87..b10e34db63 100644\n--- a/AUTHORS\n+++ b/AUTHORS\n@@ -4,4 +4,5 @@ Seio Inoue\n Moritz Mechelk\n PhilProg\n Silvan Schmidt\n-Doublonmousse\n\\ No newline at end of file\n+Doublonmousse\n+RayJW\ndiff --git a/crates/rnote-ui/data/ui/dialogs/dialogs.ui b/crates/rnote-ui/data/ui/dialogs/dialogs.ui\nindex 35345f7d86..a375d6e11e 100644\n--- a/crates/rnote-ui/data/ui/dialogs/dialogs.ui\n+++ b/crates/rnote-ui/data/ui/dialogs/dialogs.ui\n@@ -203,4 +203,15 @@ Changes which are not saved will be permanently lost.</property>\n       <object class=\"RnIconPicker\" id=\"edit_selected_workspace_icon_picker\"></object>\n     </child>\n   </object>\n+\n+  <object class=\"AdwAlertDialog\" id=\"dialog_trash_file\">\n+    <property name=\"heading\" translatable=\"yes\">Trash File</property>\n+    <property name=\"body\" translatable=\"yes\">Are you sure you want to move this file to the trash?</property>\n+    <property name=\"default-response\">cancel</property>\n+    <property name=\"close-response\">cancel</property>\n+    <responses>\n+      <response id=\"cancel\" translatable=\"yes\">Cancel</response>\n+      <response id=\"trash\" appearance=\"destructive\" translatable=\"yes\">Trash</response>\n+    </responses>\n+  </object>\n </interface>\ndiff --git a/crates/rnote-ui/src/dialogs/mod.rs b/crates/rnote-ui/src/dialogs/mod.rs\nindex 86bcd3f84d..013ddab299 100644\n--- a/crates/rnote-ui/src/dialogs/mod.rs\n+++ b/crates/rnote-ui/src/dialogs/mod.rs\n@@ -586,6 +586,50 @@ pub(crate) async fn dialog_edit_selected_workspace(appwindow: &RnAppWindow) {\n     dialog.present(appwindow.root().as_ref());\n }\n \n+pub(crate) async fn dialog_trash_file(appwindow: &RnAppWindow, current_file: &gio::File) {\n+    let builder = Builder::from_resource(\n+        (String::from(config::APP_IDPATH) + \"ui/dialogs/dialogs.ui\").as_str(),\n+    );\n+    let dialog: adw::AlertDialog = builder.object(\"dialog_trash_file\").unwrap();\n+\n+    match dialog.choose_future(appwindow).await.as_str() {\n+        \"trash\" => {\n+            glib::spawn_future_local(clone!(\n+                #[weak]\n+                appwindow,\n+                #[strong]\n+                current_file,\n+                async move {\n+                    current_file.trash_async(\n+                        glib::source::Priority::DEFAULT,\n+                        None::<&gio::Cancellable>,\n+                        clone!(\n+                            #[weak]\n+                            appwindow,\n+                            #[strong]\n+                            current_file,\n+                            move |res| {\n+                                if let Err(e) = res {\n+                                    appwindow\n+                                        .overlays()\n+                                        .dispatch_toast_error(&gettext(\"Trashing file failed\"));\n+                                    error!(\n+                                        \"Trash filerow file `{current_file:?}` failed , Err: {e:?}\"\n+                                    );\n+                                    return;\n+                                }\n+                            }\n+                        ),\n+                    );\n+                }\n+            ));\n+        }\n+        _ => {\n+            // Cancel\n+        }\n+    }\n+}\n+\n const WORKSPACELISTENTRY_ICONS_LIST: &[&str] = &[\n     \"workspacelistentryicon-bandaid-symbolic\",\n     \"workspacelistentryicon-bank-symbolic\",\ndiff --git a/crates/rnote-ui/src/workspacebrowser/filerow/actions/trash.rs b/crates/rnote-ui/src/workspacebrowser/filerow/actions/trash.rs\nindex aa8d9df682..c5b67b29be 100644\n--- a/crates/rnote-ui/src/workspacebrowser/filerow/actions/trash.rs\n+++ b/crates/rnote-ui/src/workspacebrowser/filerow/actions/trash.rs\n@@ -1,9 +1,7 @@\n // Imports\n-use crate::workspacebrowser::RnFileRow;\n use crate::RnAppWindow;\n-use gettextrs::gettext;\n-use gtk4::{gio, glib, glib::clone, prelude::FileExt};\n-use tracing::debug;\n+use crate::{dialogs, workspacebrowser::RnFileRow};\n+use gtk4::{gio, glib, glib::clone};\n \n /// Create a new `trash` action.\n pub(crate) fn trash(filerow: &RnFileRow, appwindow: &RnAppWindow) -> gio::SimpleAction {\n@@ -13,30 +11,19 @@ pub(crate) fn trash(filerow: &RnFileRow, appwindow: &RnAppWindow) -> gio::Simple\n         filerow,\n         #[weak]\n         appwindow,\n-        move |_action_trash_file, _| {\n+        move |_, _| {\n             let Some(current_file) = filerow.current_file() else {\n                 return;\n             };\n-            current_file.trash_async(\n-                glib::source::Priority::DEFAULT,\n-                None::<&gio::Cancellable>,\n-                clone!(\n-                    #[weak]\n-                    filerow,\n-                    #[strong]\n-                    current_file,\n-                    move |res| {\n-                        if let Err(e) = res {\n-                            appwindow\n-                                .overlays()\n-                                .dispatch_toast_error(&gettext(\"Trashing file failed\"));\n-                            debug!(\"Trash filerow file `{current_file:?}` failed , Err: {e:?}\");\n-                            return;\n-                        }\n-                        filerow.set_current_file(None);\n-                    }\n-                ),\n-            );\n+            glib::spawn_future_local(clone!(\n+                #[weak]\n+                appwindow,\n+                #[strong]\n+                current_file,\n+                async move {\n+                    dialogs::dialog_trash_file(&appwindow, &current_file).await;\n+                }\n+            ));\n         }\n     ));\n     action\n", "instance_id": "flxzt__rnote-1237", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "\nThe problem statement is mostly clear in its intent: it describes a bug where deleting a directory in the application results in permanent deletion without a confirmation prompt or moving the file to the trash bin. The goal of adding a confirmation prompt for deletion actions is evident, and the expected behavior (either moving to trash or warning about permanent deletion) is specified. The reproduction steps and context (e.g., OS, app version) are also provided, which adds clarity. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define whether the confirmation dialog should apply to all deletion actions or only specific ones (e.g., directories vs. files). Additionally, edge cases such as handling permissions issues, non-existent files, or user cancellation are not mentioned. While the issue description is tied to a specific bug report (#1136), the lack of detailed requirements around these edge cases prevents it from being fully comprehensive.\n", "difficulty_explanation": "\nI rate the difficulty of this problem as medium (0.45) based on the following analysis of the factors:\n\n1. **Clarity and Complexity of the Problem Description**: As noted, the problem is mostly clear but lacks specifics on edge cases. Understanding the goal (adding a confirmation prompt) is straightforward, but implementing it correctly requires interpreting the intended scope (e.g., all deletions or specific ones).\n\n2. **Scope and Depth of Code Changes**: The provided code changes affect multiple files, including UI definitions (`dialogs.ui`), dialog logic (`mod.rs`), and the deletion action itself (`trash.rs`). The changes are relatively localized, focusing on integrating a new dialog and updating the trash action to use it. However, they require understanding the interaction between the UI components, asynchronous file operations, and the application's event handling system. The amount of code change is moderate, with new dialog definitions and logic added, but it does not significantly impact the overall architecture of the system.\n\n3. **Number of Technical Concepts**: Solving this problem requires familiarity with several Rust and GTK-related concepts, including:\n   - Rust's ownership and borrowing model (as the submitter struggled with lifetime issues around `&appwindow`).\n   - Asynchronous programming in Rust using `async/await` and `glib::spawn_future_local`.\n   - GTK4 and Adwaita UI framework for creating dialogs (`AdwAlertDialog`).\n   - File operations using `gio::File` and handling asynchronous results.\n   - Error handling and user feedback (e.g., toast notifications).\n   These concepts are moderately complex, especially for someone less experienced with Rust's strict ownership rules or GTK's event-driven model.\n\n4. **Potential Edge Cases and Error Handling**: The problem statement does not explicitly mention edge cases, but the code changes show some error handling for failed trash operations (e.g., displaying a toast error message). Additional edge cases to consider include:\n   - Files that cannot be trashed due to permissions or filesystem limitations.\n   - User cancellation of the dialog (handled minimally in the code).\n   - Situations where the file no longer exists at the time of deletion.\n   These edge cases are not overly complex but require careful handling to ensure a robust solution.\n\nOverall, this problem falls into the medium difficulty range because it involves understanding multiple technical concepts (Rust ownership, GTK dialogs, async operations) and making changes across a few files. It is not a simple bug fix or feature addition (which would be 0.2-0.4), nor does it require deep architectural changes or advanced domain knowledge (which would push it to 0.6-0.8). The primary challenge lies in correctly handling Rust's borrowing rules and integrating the dialog into the existing UI flow, which the submitter struggled with, indicating a moderate learning curve for less experienced developers.\n", "clarity_label": -1, "difficulty_label": -1, "human_clarity": -1, "human_difficulty": -1}
