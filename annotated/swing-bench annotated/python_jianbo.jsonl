{"problem_statement": "API Design Proposal for LiSSA algorithm ihvp\n## Background\r\n\r\nWith the `hvp` functions implemented before, further complete the LiSSA algorithm for ihvp calculation. Compared with CG, LiSSA algorithm reduces the number of hvp calculation and is more suitable for large datasets.\r\n\r\n## Algorithm description\r\n\r\nLiSSA algorithm approximates the ihvp function by averaging multiple samples. The samples are estimated by recursion based on Taylor expansion.\r\n\r\n## API Design\r\nThe API design basically follows the existing implementations of `hvp` and `ihvp_cg`. There are also two versions which calculate the hvp for fixed or non-fixed x's.\r\n\r\nThe first input of the LiSSA algorithms is a function for estimation, such as $L(\\cdot, \\cdot)$. The input list should be a list of the form $[(z_0, \\theta), \\dots, (z_n,\\ theta)]$.\r\n\r\n```python\r\ndef ihvp_lissa(func: Callable,\r\n               argnums: int = 0,\r\n               num_repeat: int = 10, \r\n               recursion_depth: int = 5000,\r\n               mode: str = \"rev-rev\") -> Callable:\r\n    \"\"\"LiSSA ihvp algorithm function.\r\n\r\n    Standing for the inverse-hessian-vector product, returns a function that,\r\n    when given vectors, computes the product of inverse-hessian and vector.\r\n\r\n    LiSSA algorithm approximates the ihvp function by averaging multiple samples.\r\n    The samples are estimated by recursion based on Taylor expansion.\r\n\r\n    Args:\r\n        func (Callable): A Python function that takes one or more arguments.\r\n            Must return a single-element Tensor. The hessian will\r\n            be estimated on this function.\r\n        argnums (int): An integer default to 0. Specifies which argument of func\r\n            to compute inverse hessian with respect to.\r\n        num_repeat (int): An integer default 10. Specifies the number of samples\r\n            of the hvp approximation to average on.\r\n        recursion_depth (int): A integer default to 5000. Specifies the number of\r\n            recursions used to estimate each ihvp sample.\r\n        mode (str): The auto diff mode, which can have one of the following values:\r\n            - rev-rev: calculate the hessian with two reverse-mode auto-diff. It has\r\n                       better compatibility while cost more memory.\r\n            - rev-fwd: calculate the hessian with the composing of reverse-mode and\r\n                       forward-mode. It's more memory-efficient but may not be supported\r\n                       by some operator.\r\n\r\n    Returns:\r\n        A function that takes a list of tuples of Tensor `x` and a vector `v` and returns\r\n        the IHVP of the Hessian of `func` and `v`.\r\n    \"\"\"\r\n```\r\n\r\n```python\r\ndef ihvp_at_x_lissa(func: Callable,\r\n                    input_list: List[Tuple],\r\n                    argnums: int = 0,\r\n                    num_repeat: int =10, \r\n                    recursion_depth: int =5000,\r\n                    mode: str = \"rev-rev\") -> Callable:\r\n    \"\"\"LiSSA ihvp algorithm function (with fixed x).\r\n\r\n    Standing for the inverse-hessian-vector product, returns a function that,\r\n    when given vectors, computes the product of inverse-hessian and vector.\r\n\r\n    LiSSA algorithm approximates the ihvp function by averaging multiple samples.\r\n    The samples are estimated by recursion based on Taylor expansion.\r\n\r\n    Args:\r\n        func (Callable): A Python function that takes one or more arguments.\r\n            Must return a single-element Tensor. The hessian will\r\n            be estimated on this function.\r\n        input_list (List[Tuple]): List of arguments for multiple calls of `func`. Each tuple\r\n            inside the list should be a pair of valid arguments\r\n        argnums (int): An integer default to 0. Specifies which argument of func\r\n            to compute inverse hessian with respect to.\r\n        num_repeat (int): An integer default 10. Specifies the number of samples\r\n            of the hvp approximation to average on.\r\n        recursion_depth (int): A integer default to 5000. Specifies the number of\r\n            recursions used to estimate each ihvp sample.\r\n        mode (str): The auto diff mode, which can have one of the following values:\r\n            - rev-rev: calculate the hessian with two reverse-mode auto-diff. It has\r\n                       better compatibility while cost more memory.\r\n            - rev-fwd: calculate the hessian with the composing of reverse-mode and\r\n                       forward-mode. It's more memory-efficient but may not be supported\r\n                       by some operator.\r\n\r\n    Returns:\r\n        A function that takes a vector `v` and returns the IHVP of the Hessian\r\n        of `func` and `v`.\r\n    \"\"\"\r\n```\r\n\r\n## Demonstration\r\n\r\n```python\r\ndef mse_loss(x, y, theta):\r\n    return (x * theta - y)**2\r\n\r\nihvp = ihvp_lissa(mse_loss, argnums=2)\r\n\r\ntheta = torch.randn(1)\r\ninput_list = [\r\n    (torch.randn(1), torch.randn(1), theta),\r\n    (torch.randn(1), torch.randn(1), theta)\r\n]\r\nvec = torch.randn(5, 2)\r\nihvp(input_list, vec)\r\n```\r\n\n", "patch": "diff --git a/dattri/func/ihvp.py b/dattri/func/ihvp.py\nindex b5185cd7..3f743b7b 100644\n--- a/dattri/func/ihvp.py\n+++ b/dattri/func/ihvp.py\n@@ -16,7 +16,8 @@\n \n if TYPE_CHECKING:\n     from collections.abc import Callable\n-    from typing import Tuple, Union\n+    from typing import Optional, Tuple, Union\n+\n \n import torch\n from torch import Tensor\n@@ -679,5 +680,236 @@ def _ihvp_at_x_arnoldi(v: Tensor) -> Tensor:\n     return _ihvp_at_x_arnoldi\n \n \n+def _check_input_size(*x, in_dims: Optional[Tuple] = None) -> int:\n+    \"\"\"Check and return the size of input data.\n+\n+    Args:\n+        *x: List of arguments to check. Each argument shoule be either:\n+            1. A tensor with a batch size dimension. Each data point i\n+            will take the i-th element along this dimension.\n+            2. A tensor without a batch size dimension. Each data point will\n+            share this tensor.\n+        in_dims (Optional[Tuple]): A tuple with the same shape as *x, indicating\n+            which dimension should be considered as batch size dimension. Take the\n+            first dimension as batch size dimension by default.\n+\n+    Returns:\n+        An integer indicating the number of input data.\n+\n+    Raises:\n+        IHVPUsageError: if the input size is ambiguous or mismatches.\n+    \"\"\"\n+    if in_dims is None:\n+        in_dims = (0,) * len(x)\n+\n+    # Check batch size mismatch\n+    batch_size = None\n+    for i, (x_in, dim) in enumerate(zip(x, in_dims)):\n+        if dim is None:\n+            continue\n+\n+        if batch_size is None:\n+            batch_size = x_in.shape[dim]\n+        elif batch_size != x_in.shape[dim]:\n+            message = (f\"Input batch size mismatch! Expected {batch_size},\"\n+                       f\"found {x_in.shape[dim]} for input tensor {i}.\")\n+            raise IHVPUsageError(message)\n+\n+    if batch_size is None:\n+        message = \"All inputs are identical for LiSSA ihvp!\"\n+        raise IHVPUsageError(message)\n+\n+    return batch_size\n+\n+\n+def _sample_random_batch(*x,\n+                         num_samples: int,\n+                         in_dims: Optional[Tuple] = None,\n+                         batch_size: int = 1) -> Tuple[torch.Tensor, ...]:\n+    \"\"\"Randomly sample a batch of `batch_size` from the input data, without replacement.\n+\n+    Args:\n+        *x: List of arguments to check. Each argument shoule be either:\n+            1. A tensor with a batch size dimension. Each data point i\n+            will take the i-th element along this dimension.\n+            2. A tensor without a batch size dimension. Each data point will\n+            share this tensor.\n+        num_samples (int): An integer, indicating the total number of samples.\n+        batch_size (int): An integer default to 1, indicating the batch size.\n+        in_dims (Optional[Tuple]): A tuple with the same shape as *x, indicating\n+            which dimension should be considered as batch size dimension. Take the\n+            first dimension as batch size dimension by default.\n+\n+    Returns:\n+        An tuple of tensors corresponding to a batch of input data.\n+    \"\"\"\n+    if in_dims is None:\n+        in_dims = (0,) * len(x)\n+\n+    # Randomly sample and collate a batch\n+    sampled_indices = torch.randperm(num_samples)[:batch_size]\n+\n+    return tuple(\n+        x_in.index_select(dim, sampled_indices)\n+        if dim is not None else x_in\n+        for x_in, dim in zip(x, in_dims)\n+    )\n+\n+\n+def ihvp_lissa(func: Callable,\n+               argnums: int = 0,\n+               batch_size: int = 1,\n+               num_repeat: int = 1,\n+               recursion_depth: int = 5000,\n+               damping: int = 0.0,\n+               scaling: int = 50.0,\n+               mode: str = \"rev-rev\") -> Callable:\n+    \"\"\"IHVP via LiSSA algorithm.\n+\n+    Standing for the inverse-hessian-vector product, returns a function that,\n+    when given vectors, computes the product of inverse-hessian and vector.\n+\n+    LiSSA algorithm approximates the ihvp function by averaging multiple samples.\n+    The samples are estimated by recursion based on Taylor expansion.\n+\n+    Args:\n+        func (Callable): A Python function that takes one or more arguments.\n+            Must return a single-element Tensor. The hessian will\n+            be estimated on this function.\n+        argnums (int): An integer default to 0. Specifies which argument of func\n+            to compute inverse hessian with respect to.\n+        batch_size (int): An integer default to 1. Specifies the batch size used\n+            for LiSSA inner loop update.\n+        num_repeat (int): An integer default to 1. Specifies the number of samples\n+            of the hvp approximation to average on.\n+        recursion_depth (int): A integer default to 5000. Specifies the number of\n+            recursions used to estimate each ihvp sample.\n+        damping (int): Damping factor used for non-convexity in LiSSA ihvp calculation.\n+        scaling (int): Scaling factor used for convergence in LiSSA ihvp calculation.\n+        mode (str): The auto diff mode, which can have one of the following values:\n+            - rev-rev: calculate the hessian with two reverse-mode auto-diff. It has\n+                       better compatibility while cost more memory.\n+            - rev-fwd: calculate the hessian with the composing of reverse-mode and\n+                       forward-mode. It's more memory-efficient but may not be supported\n+                       by some operator.\n+\n+    Returns:\n+        A function that takes a list of tuples of Tensor `x` and a vector `v` and\n+        returns the IHVP of the Hessian of `func` and `v`.\n+    \"\"\"\n+    hvp_func = hvp(func, argnums=argnums, mode=mode)\n+\n+    def _ihvp_lissa_func(x: Tuple[torch.Tensor, ...],\n+                         v: Tensor,\n+                         in_dims: Optional[Tuple] = None) -> Tensor:\n+        \"\"\"The IHVP function via LiSSA algorithm.\n+\n+        Args:\n+            x (Tuple[torch.Tensor, ...]): The function will computed the\n+                inverse hessian matrix with respect to these arguments.\n+            v (Tensor): The vector to be produced on the inverse hessian matrix.\n+            in_dims (Optional[Tuple]): A tuple with the same shape as *x. Indicating\n+                which dimension should be considered as batch size dimension.\n+\n+        Returns:\n+            The IHVP value.\n+        \"\"\"\n+        num_samples = _check_input_size(*x, in_dims=in_dims)\n+        if v.ndim == 1:\n+            v = v.unsqueeze(0)\n+\n+        def _lissa_loop(vec: torch.Tensor) -> torch.Tensor:\n+            ihvp_estimations = []\n+            for _ in range(num_repeat):\n+                curr_estimate = vec.detach().clone()  # No gradient on v\n+                for _ in range(recursion_depth):\n+                    sampled_input = _sample_random_batch(*x,\n+                                                         batch_size=batch_size,\n+                                                         num_samples=num_samples,\n+                                                         in_dims=in_dims)\n+                    hvp = hvp_func(sampled_input, curr_estimate)\n+                    curr_estimate = (vec\n+                                     + (1 - damping) * curr_estimate\n+                                     - hvp / scaling)\n+\n+                ihvp_estimations.append(curr_estimate / scaling)\n+\n+            return torch.mean(torch.stack(ihvp_estimations), dim=0)\n+\n+        return torch.vmap(_lissa_loop, randomness=\"different\")(v)\n+\n+    return _ihvp_lissa_func\n+\n+\n+def ihvp_at_x_lissa(func: Callable,\n+                    *x,\n+                    in_dims: Optional[Tuple] = None,\n+                    argnums: int = 0,\n+                    batch_size: int = 1,\n+                    num_repeat: int = 1,\n+                    recursion_depth: int = 5000,\n+                    damping: int = 0.0,\n+                    scaling: int = 50.0,\n+                    mode: str = \"rev-rev\") -> Callable:\n+    \"\"\"IHVP with fixed func inputs via LiSSA algorithm.\n+\n+    Standing for the inverse-hessian-vector product, returns a function that,\n+    when given vectors, computes the product of inverse-hessian and vector.\n+\n+    LiSSA algorithm approximates the ihvp function by averaging multiple samples.\n+    The samples are estimated by recursion based on Taylor expansion.\n+\n+    Args:\n+        func (Callable): A Python function that takes one or more arguments.\n+            Must return a single-element Tensor. The hessian will\n+            be estimated on this function.\n+        *x: List of arguments for `func`.\n+        in_dims (Optional[Tuple]): A tuple with the same shape as *x, indicating\n+            which dimension should be considered as batch size dimension. Take the\n+            first dimension as batch size dimension by default.\n+        argnums (int): An integer default to 0. Specifies which argument of func\n+            to compute inverse hessian with respect to.\n+        batch_size (int): An integer default to 1. Specifies the batch size used\n+            for LiSSA inner loop update.\n+        num_repeat (int): An integer default to 1. Specifies the number of samples\n+            of the hvp approximation to average on.\n+        recursion_depth (int): A integer default to 5000. Specifies the number of\n+            recursions used to estimate each ihvp sample.\n+        damping (int): Damping factor used for non-convexity in LiSSA ihvp calculation.\n+        scaling (int): Scaling factor used for convergence in LiSSA ihvp calculation.\n+        mode (str): The auto diff mode, which can have one of the following values:\n+            - rev-rev: calculate the hessian with two reverse-mode auto-diff. It has\n+                       better compatibility while cost more memory.\n+            - rev-fwd: calculate the hessian with the composing of reverse-mode and\n+                       forward-mode. It's more memory-efficient but may not be supported\n+                       by some operator.\n+\n+    Returns:\n+        A function that takes a vector `v` and returns the IHVP of the Hessian\n+        of `func` and `v`.\n+    \"\"\"\n+\n+    def _ihvp_at_x_lissa_func(v: Tensor) -> Tensor:\n+        \"\"\"The IHVP function with fixed func inputs using LiSSA.\n+\n+        Args:\n+            v (Tensor): The vector to be produced on the inverse hessian matrix.\n+\n+        Returns:\n+            The IHVP value.\n+        \"\"\"\n+        ihvp_lissa_func = ihvp_lissa(func,\n+                                     argnums,\n+                                     num_repeat,\n+                                     batch_size,\n+                                     recursion_depth,\n+                                     damping,\n+                                     scaling,\n+                                     mode)\n+        return ihvp_lissa_func(x, v, in_dims=in_dims)\n+\n+    return _ihvp_at_x_lissa_func\n+\n+\n class IHVPUsageError(Exception):\n     \"\"\"The usage exception class for ihvp module.\"\"\"\n", "instance_id": "TRAIS-Lab__dattri-30", "clarity": 2, "difficulty": 0.75, "clarity_explanation": "The problem statement is mostly clear, providing a background on the LiSSA algorithm for inverse Hessian-vector product (IHVP) calculation, an API design with detailed function signatures, and a demonstration of usage. The goal of implementing the LiSSA algorithm as an improvement over the CG method for large datasets is evident, and the input/output formats are specified through the function signatures and example. However, there are minor ambiguities and missing details that prevent a perfect score. For instance, the problem statement does not explicitly discuss edge cases (e.g., handling non-convex functions beyond the damping parameter, or behavior with very small/large datasets). Additionally, the mathematical formulation of the LiSSA algorithm (e.g., the exact recursion based on Taylor expansion) is mentioned but not detailed, which could leave room for interpretation. Constraints on input tensor shapes or potential failure modes are also not fully specified. Despite these minor gaps, the statement is actionable and provides a solid foundation for implementation.", "difficulty_explanation": "The difficulty score of 0.75 reflects a hard problem that requires a deep understanding of both the domain (numerical optimization and Hessian computations) and the codebase. Several factors contribute to this assessment:\n\n1. **Clarity and Complexity of Problem Description**: While mostly clear, the problem involves implementing a specialized numerical algorithm (LiSSA for IHVP), which inherently carries complexity due to its reliance on concepts like Taylor expansion and recursive estimation. Understanding the theoretical underpinnings is necessary to ensure correctness.\n\n2. **Scope and Depth of Code Changes**: The code changes are significant, adding over 200 lines of code to a single file (`ihvp.py`). The modifications introduce two new functions (`ihvp_lissa` and `ihvp_at_x_lissa`) along with helper functions for input validation and batch sampling. While confined to one file, the changes require integration with existing functionality (e.g., reusing the `hvp` function) and careful handling of input data structures. The impact is not architectural but still substantial within the module.\n\n3. **Number of Technical Concepts**: Solving this problem demands familiarity with multiple advanced concepts, including:\n   - **Numerical Optimization**: Understanding inverse Hessian-vector products and the LiSSA algorithm's approximation technique.\n   - **Automatic Differentiation**: Handling different modes (`rev-rev`, `rev-fwd`) for Hessian computation using PyTorch's autograd system.\n   - **PyTorch-Specific Features**: Using `torch.vmap` for vectorized operations, tensor indexing with `index_select`, and managing randomness in sampling.\n   - **Algorithmic Design**: Implementing recursive updates with damping and scaling factors, and averaging multiple samples for approximation.\n   These concepts are moderately to highly complex, especially for someone without prior experience in numerical methods or deep learning frameworks.\n\n4. **Edge Cases and Error Handling**: The problem statement does not explicitly mention many edge cases, but the code changes include input validation (e.g., batch size mismatch checks via `_check_input_size`) and error handling through custom exceptions (`IHVPUsageError`). Potential edge cases like numerical instability, non-convexity (addressed partially via damping), or memory issues with large recursion depths are implicitly handled or configurable via parameters. Implementing robust error handling and ensuring stability across diverse inputs adds to the difficulty.\n\nOverall, this problem falls into the 'hard' category due to the need for domain-specific knowledge in numerical methods, proficiency in PyTorch's advanced features, and the complexity of implementing a recursive approximation algorithm with attention to performance and correctness. It does not reach 'very hard' (0.8-1.0) as it does not involve system-level design or distributed computing challenges, and the scope is limited to a single module without broader architectural impact.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.75}
{"problem_statement": "[FR]: download markdown request report\n### What is the feature you are proposing?\n\nAn API endpoint to be able to download a full request report in markdown format.\n\n### What would this feature improve or what problem would it solve?\n\nIt would give the UX access to the report in markdown format to present to the user (or download as a separate output result)\n\n### What alternatives have you considered?\n\nNone\n", "patch": "diff --git a/poetry.lock b/poetry.lock\nindex aa15b1500..56ed17549 100644\n--- a/poetry.lock\n+++ b/poetry.lock\n@@ -273,13 +273,13 @@ isodate = \">=0.6.1\"\n \n [[package]]\n name = \"azure-storage-blob\"\n-version = \"12.20.0\"\n+version = \"12.21.0\"\n description = \"Microsoft Azure Blob Storage Client Library for Python\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"azure-storage-blob-12.20.0.tar.gz\", hash = \"sha256:eeb91256e41d4b5b9bad6a87fd0a8ade07dd58aa52344e2c8d2746e27a017d3b\"},\n-    {file = \"azure_storage_blob-12.20.0-py3-none-any.whl\", hash = \"sha256:de6b3bf3a90e9341a6bcb96a2ebe981dffff993e9045818f6549afea827a52a9\"},\n+    {file = \"azure-storage-blob-12.21.0.tar.gz\", hash = \"sha256:b9722725072f5b7373c0f4dd6d78fbae2bb37bffc5c3e01731ab8c750ee8dd7e\"},\n+    {file = \"azure_storage_blob-12.21.0-py3-none-any.whl\", hash = \"sha256:f9ede187dd5a0ef296b583a7c1861c6938ddd6708d6e70f4203a163c2ab42d43\"},\n ]\n \n [package.dependencies]\n@@ -357,17 +357,17 @@ wcwidth = \">=0.1.4\"\n \n [[package]]\n name = \"boto3\"\n-version = \"1.34.138\"\n+version = \"1.34.149\"\n description = \"The AWS SDK for Python\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"boto3-1.34.138-py3-none-any.whl\", hash = \"sha256:81518aa95fad71279411fb5c94da4b4a554a5d53fc876faca62b7b5c8737f1cb\"},\n-    {file = \"boto3-1.34.138.tar.gz\", hash = \"sha256:f79c15e33eb7706f197d98d828b193cf0891966682ad3ec5e900f6f9e7362e35\"},\n+    {file = \"boto3-1.34.149-py3-none-any.whl\", hash = \"sha256:11edeeacdd517bda3b7615b754d8440820cdc9ddd66794cc995a9693ddeaa3be\"},\n+    {file = \"boto3-1.34.149.tar.gz\", hash = \"sha256:f4e6489ba9dc7fb37d53e0e82dbc97f2cb0a4969ef3970e2c88b8f94023ae81a\"},\n ]\n \n [package.dependencies]\n-botocore = \">=1.34.138,<1.35.0\"\n+botocore = \">=1.34.149,<1.35.0\"\n jmespath = \">=0.7.1,<2.0.0\"\n s3transfer = \">=0.10.0,<0.11.0\"\n \n@@ -376,13 +376,13 @@ crt = [\"botocore[crt] (>=1.21.0,<2.0a0)\"]\n \n [[package]]\n name = \"botocore\"\n-version = \"1.34.138\"\n+version = \"1.34.149\"\n description = \"Low-level, data-driven core of boto 3.\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"botocore-1.34.138-py3-none-any.whl\", hash = \"sha256:84e96a954c39a6f09cae4ea95b2ae582b5ae01b5040c92507b60509c9be5377a\"},\n-    {file = \"botocore-1.34.138.tar.gz\", hash = \"sha256:f558bbea96c4a4abbaeeedc477dabb00902311ba1ca6327974a6819b9f384920\"},\n+    {file = \"botocore-1.34.149-py3-none-any.whl\", hash = \"sha256:ae6c4be52eeee96f68c116b27d252bab069cd046d61a17cfe8e9da411cf22906\"},\n+    {file = \"botocore-1.34.149.tar.gz\", hash = \"sha256:2e1eb5ef40102a3d796bb3dd05f2ac5e8fb43fe1ff114b4f6d33153437f5a372\"},\n ]\n \n [package.dependencies]\n@@ -406,13 +406,13 @@ files = [\n \n [[package]]\n name = \"cachetools\"\n-version = \"5.3.3\"\n+version = \"5.4.0\"\n description = \"Extensible memoizing collections and decorators\"\n optional = false\n python-versions = \">=3.7\"\n files = [\n-    {file = \"cachetools-5.3.3-py3-none-any.whl\", hash = \"sha256:0abad1021d3f8325b2fc1d2e9c8b9c9d57b04c3932657a72465447332c24d945\"},\n-    {file = \"cachetools-5.3.3.tar.gz\", hash = \"sha256:ba29e2dfa0b8b556606f097407ed1aa62080ee108ab0dc5ec9d6a723a007d105\"},\n+    {file = \"cachetools-5.4.0-py3-none-any.whl\", hash = \"sha256:3ae3b49a3d5e28a77a0be2b37dbcb89005058959cb2323858c2657c4a8cab474\"},\n+    {file = \"cachetools-5.4.0.tar.gz\", hash = \"sha256:b8adc2e7c07f105ced7bc56dbb6dfbe7c4a00acce20e2227b3f355be89bc6827\"},\n ]\n \n [[package]]\n@@ -732,63 +732,63 @@ files = [\n \n [[package]]\n name = \"coverage\"\n-version = \"7.5.4\"\n+version = \"7.6.0\"\n description = \"Code coverage measurement for Python\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"coverage-7.5.4-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:6cfb5a4f556bb51aba274588200a46e4dd6b505fb1a5f8c5ae408222eb416f99\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:2174e7c23e0a454ffe12267a10732c273243b4f2d50d07544a91198f05c48f47\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:2214ee920787d85db1b6a0bd9da5f8503ccc8fcd5814d90796c2f2493a2f4d2e\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:1137f46adb28e3813dec8c01fefadcb8c614f33576f672962e323b5128d9a68d\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:b385d49609f8e9efc885790a5a0e89f2e3ae042cdf12958b6034cc442de428d3\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:b4a474f799456e0eb46d78ab07303286a84a3140e9700b9e154cfebc8f527016\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-musllinux_1_2_i686.whl\", hash = \"sha256:5cd64adedf3be66f8ccee418473c2916492d53cbafbfcff851cbec5a8454b136\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-musllinux_1_2_x86_64.whl\", hash = \"sha256:e564c2cf45d2f44a9da56f4e3a26b2236504a496eb4cb0ca7221cd4cc7a9aca9\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-win32.whl\", hash = \"sha256:7076b4b3a5f6d2b5d7f1185fde25b1e54eb66e647a1dfef0e2c2bfaf9b4c88c8\"},\n-    {file = \"coverage-7.5.4-cp310-cp310-win_amd64.whl\", hash = \"sha256:018a12985185038a5b2bcafab04ab833a9a0f2c59995b3cec07e10074c78635f\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:db14f552ac38f10758ad14dd7b983dbab424e731588d300c7db25b6f89e335b5\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:3257fdd8e574805f27bb5342b77bc65578e98cbc004a92232106344053f319ba\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:3a6612c99081d8d6134005b1354191e103ec9705d7ba2754e848211ac8cacc6b\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:d45d3cbd94159c468b9b8c5a556e3f6b81a8d1af2a92b77320e887c3e7a5d080\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:ed550e7442f278af76d9d65af48069f1fb84c9f745ae249c1a183c1e9d1b025c\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:7a892be37ca35eb5019ec85402c3371b0f7cda5ab5056023a7f13da0961e60da\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-musllinux_1_2_i686.whl\", hash = \"sha256:8192794d120167e2a64721d88dbd688584675e86e15d0569599257566dec9bf0\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-musllinux_1_2_x86_64.whl\", hash = \"sha256:820bc841faa502e727a48311948e0461132a9c8baa42f6b2b84a29ced24cc078\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-win32.whl\", hash = \"sha256:6aae5cce399a0f065da65c7bb1e8abd5c7a3043da9dceb429ebe1b289bc07806\"},\n-    {file = \"coverage-7.5.4-cp311-cp311-win_amd64.whl\", hash = \"sha256:d2e344d6adc8ef81c5a233d3a57b3c7d5181f40e79e05e1c143da143ccb6377d\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-macosx_10_9_x86_64.whl\", hash = \"sha256:54317c2b806354cbb2dc7ac27e2b93f97096912cc16b18289c5d4e44fc663233\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:042183de01f8b6d531e10c197f7f0315a61e8d805ab29c5f7b51a01d62782747\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:a6bb74ed465d5fb204b2ec41d79bcd28afccf817de721e8a807d5141c3426638\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:b3d45ff86efb129c599a3b287ae2e44c1e281ae0f9a9bad0edc202179bcc3a2e\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:5013ed890dc917cef2c9f765c4c6a8ae9df983cd60dbb635df8ed9f4ebc9f555\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:1014fbf665fef86cdfd6cb5b7371496ce35e4d2a00cda501cf9f5b9e6fced69f\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-musllinux_1_2_i686.whl\", hash = \"sha256:3684bc2ff328f935981847082ba4fdc950d58906a40eafa93510d1b54c08a66c\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-musllinux_1_2_x86_64.whl\", hash = \"sha256:581ea96f92bf71a5ec0974001f900db495488434a6928a2ca7f01eee20c23805\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-win32.whl\", hash = \"sha256:73ca8fbc5bc622e54627314c1a6f1dfdd8db69788f3443e752c215f29fa87a0b\"},\n-    {file = \"coverage-7.5.4-cp312-cp312-win_amd64.whl\", hash = \"sha256:cef4649ec906ea7ea5e9e796e68b987f83fa9a718514fe147f538cfeda76d7a7\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:cdd31315fc20868c194130de9ee6bfd99755cc9565edff98ecc12585b90be882\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:02ff6e898197cc1e9fa375581382b72498eb2e6d5fc0b53f03e496cfee3fac6d\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:d05c16cf4b4c2fc880cb12ba4c9b526e9e5d5bb1d81313d4d732a5b9fe2b9d53\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:c5986ee7ea0795a4095ac4d113cbb3448601efca7f158ec7f7087a6c705304e4\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:5df54843b88901fdc2f598ac06737f03d71168fd1175728054c8f5a2739ac3e4\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-musllinux_1_2_aarch64.whl\", hash = \"sha256:ab73b35e8d109bffbda9a3e91c64e29fe26e03e49addf5b43d85fc426dde11f9\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-musllinux_1_2_i686.whl\", hash = \"sha256:aea072a941b033813f5e4814541fc265a5c12ed9720daef11ca516aeacd3bd7f\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-musllinux_1_2_x86_64.whl\", hash = \"sha256:16852febd96acd953b0d55fc842ce2dac1710f26729b31c80b940b9afcd9896f\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-win32.whl\", hash = \"sha256:8f894208794b164e6bd4bba61fc98bf6b06be4d390cf2daacfa6eca0a6d2bb4f\"},\n-    {file = \"coverage-7.5.4-cp38-cp38-win_amd64.whl\", hash = \"sha256:e2afe743289273209c992075a5a4913e8d007d569a406ffed0bd080ea02b0633\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:b95c3a8cb0463ba9f77383d0fa8c9194cf91f64445a63fc26fb2327e1e1eb088\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:3d7564cc09dd91b5a6001754a5b3c6ecc4aba6323baf33a12bd751036c998be4\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:44da56a2589b684813f86d07597fdf8a9c6ce77f58976727329272f5a01f99f7\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:e16f3d6b491c48c5ae726308e6ab1e18ee830b4cdd6913f2d7f77354b33f91c8\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:dbc5958cb471e5a5af41b0ddaea96a37e74ed289535e8deca404811f6cb0bc3d\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:a04e990a2a41740b02d6182b498ee9796cf60eefe40cf859b016650147908029\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-musllinux_1_2_i686.whl\", hash = \"sha256:ddbd2f9713a79e8e7242d7c51f1929611e991d855f414ca9996c20e44a895f7c\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-musllinux_1_2_x86_64.whl\", hash = \"sha256:b1ccf5e728ccf83acd313c89f07c22d70d6c375a9c6f339233dcf792094bcbf7\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-win32.whl\", hash = \"sha256:56b4eafa21c6c175b3ede004ca12c653a88b6f922494b023aeb1e836df953ace\"},\n-    {file = \"coverage-7.5.4-cp39-cp39-win_amd64.whl\", hash = \"sha256:65e528e2e921ba8fd67d9055e6b9f9e34b21ebd6768ae1c1723f4ea6ace1234d\"},\n-    {file = \"coverage-7.5.4-pp38.pp39.pp310-none-any.whl\", hash = \"sha256:79b356f3dd5b26f3ad23b35c75dbdaf1f9e2450b6bcefc6d0825ea0aa3f86ca5\"},\n-    {file = \"coverage-7.5.4.tar.gz\", hash = \"sha256:a44963520b069e12789d0faea4e9fdb1e410cdc4aab89d94f7f55cbb7fef0353\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:dff044f661f59dace805eedb4a7404c573b6ff0cdba4a524141bc63d7be5c7fd\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:a8659fd33ee9e6ca03950cfdcdf271d645cf681609153f218826dd9805ab585c\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:7792f0ab20df8071d669d929c75c97fecfa6bcab82c10ee4adb91c7a54055463\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:d4b3cd1ca7cd73d229487fa5caca9e4bc1f0bca96526b922d61053ea751fe791\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e7e128f85c0b419907d1f38e616c4f1e9f1d1b37a7949f44df9a73d5da5cd53c\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:a94925102c89247530ae1dab7dc02c690942566f22e189cbd53579b0693c0783\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-musllinux_1_2_i686.whl\", hash = \"sha256:dcd070b5b585b50e6617e8972f3fbbee786afca71b1936ac06257f7e178f00f6\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-musllinux_1_2_x86_64.whl\", hash = \"sha256:d50a252b23b9b4dfeefc1f663c568a221092cbaded20a05a11665d0dbec9b8fb\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-win32.whl\", hash = \"sha256:0e7b27d04131c46e6894f23a4ae186a6a2207209a05df5b6ad4caee6d54a222c\"},\n+    {file = \"coverage-7.6.0-cp310-cp310-win_amd64.whl\", hash = \"sha256:54dece71673b3187c86226c3ca793c5f891f9fc3d8aa183f2e3653da18566169\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:c7b525ab52ce18c57ae232ba6f7010297a87ced82a2383b1afd238849c1ff933\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:4bea27c4269234e06f621f3fac3925f56ff34bc14521484b8f66a580aacc2e7d\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:ed8d1d1821ba5fc88d4a4f45387b65de52382fa3ef1f0115a4f7a20cdfab0e94\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:01c322ef2bbe15057bc4bf132b525b7e3f7206f071799eb8aa6ad1940bcf5fb1\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:03cafe82c1b32b770a29fd6de923625ccac3185a54a5e66606da26d105f37dac\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:0d1b923fc4a40c5832be4f35a5dab0e5ff89cddf83bb4174499e02ea089daf57\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-musllinux_1_2_i686.whl\", hash = \"sha256:4b03741e70fb811d1a9a1d75355cf391f274ed85847f4b78e35459899f57af4d\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-musllinux_1_2_x86_64.whl\", hash = \"sha256:a73d18625f6a8a1cbb11eadc1d03929f9510f4131879288e3f7922097a429f63\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-win32.whl\", hash = \"sha256:65fa405b837060db569a61ec368b74688f429b32fa47a8929a7a2f9b47183713\"},\n+    {file = \"coverage-7.6.0-cp311-cp311-win_amd64.whl\", hash = \"sha256:6379688fb4cfa921ae349c76eb1a9ab26b65f32b03d46bb0eed841fd4cb6afb1\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-macosx_10_9_x86_64.whl\", hash = \"sha256:f7db0b6ae1f96ae41afe626095149ecd1b212b424626175a6633c2999eaad45b\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:bbdf9a72403110a3bdae77948b8011f644571311c2fb35ee15f0f10a8fc082e8\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:9cc44bf0315268e253bf563f3560e6c004efe38f76db03a1558274a6e04bf5d5\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:da8549d17489cd52f85a9829d0e1d91059359b3c54a26f28bec2c5d369524807\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:0086cd4fc71b7d485ac93ca4239c8f75732c2ae3ba83f6be1c9be59d9e2c6382\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:1fad32ee9b27350687035cb5fdf9145bc9cf0a094a9577d43e909948ebcfa27b\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-musllinux_1_2_i686.whl\", hash = \"sha256:044a0985a4f25b335882b0966625270a8d9db3d3409ddc49a4eb00b0ef5e8cee\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-musllinux_1_2_x86_64.whl\", hash = \"sha256:76d5f82213aa78098b9b964ea89de4617e70e0d43e97900c2778a50856dac605\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-win32.whl\", hash = \"sha256:3c59105f8d58ce500f348c5b56163a4113a440dad6daa2294b5052a10db866da\"},\n+    {file = \"coverage-7.6.0-cp312-cp312-win_amd64.whl\", hash = \"sha256:ca5d79cfdae420a1d52bf177de4bc2289c321d6c961ae321503b2ca59c17ae67\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-macosx_10_9_x86_64.whl\", hash = \"sha256:d39bd10f0ae453554798b125d2f39884290c480f56e8a02ba7a6ed552005243b\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-macosx_11_0_arm64.whl\", hash = \"sha256:beb08e8508e53a568811016e59f3234d29c2583f6b6e28572f0954a6b4f7e03d\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b2e16f4cd2bc4d88ba30ca2d3bbf2f21f00f382cf4e1ce3b1ddc96c634bc48ca\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:6616d1c9bf1e3faea78711ee42a8b972367d82ceae233ec0ac61cc7fec09fa6b\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:ad4567d6c334c46046d1c4c20024de2a1c3abc626817ae21ae3da600f5779b44\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-musllinux_1_2_aarch64.whl\", hash = \"sha256:d17c6a415d68cfe1091d3296ba5749d3d8696e42c37fca5d4860c5bf7b729f03\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-musllinux_1_2_i686.whl\", hash = \"sha256:9146579352d7b5f6412735d0f203bbd8d00113a680b66565e205bc605ef81bc6\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-musllinux_1_2_x86_64.whl\", hash = \"sha256:cdab02a0a941af190df8782aafc591ef3ad08824f97850b015c8c6a8b3877b0b\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-win32.whl\", hash = \"sha256:df423f351b162a702c053d5dddc0fc0ef9a9e27ea3f449781ace5f906b664428\"},\n+    {file = \"coverage-7.6.0-cp38-cp38-win_amd64.whl\", hash = \"sha256:f2501d60d7497fd55e391f423f965bbe9e650e9ffc3c627d5f0ac516026000b8\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:7221f9ac9dad9492cecab6f676b3eaf9185141539d5c9689d13fd6b0d7de840c\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:ddaaa91bfc4477d2871442bbf30a125e8fe6b05da8a0015507bfbf4718228ab2\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:c4cbe651f3904e28f3a55d6f371203049034b4ddbce65a54527a3f189ca3b390\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:831b476d79408ab6ccfadaaf199906c833f02fdb32c9ab907b1d4aa0713cfa3b\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:46c3d091059ad0b9c59d1034de74a7f36dcfa7f6d3bde782c49deb42438f2450\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:4d5fae0a22dc86259dee66f2cc6c1d3e490c4a1214d7daa2a93d07491c5c04b6\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-musllinux_1_2_i686.whl\", hash = \"sha256:07ed352205574aad067482e53dd606926afebcb5590653121063fbf4e2175166\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-musllinux_1_2_x86_64.whl\", hash = \"sha256:49c76cdfa13015c4560702574bad67f0e15ca5a2872c6a125f6327ead2b731dd\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-win32.whl\", hash = \"sha256:482855914928c8175735a2a59c8dc5806cf7d8f032e4820d52e845d1f731dca2\"},\n+    {file = \"coverage-7.6.0-cp39-cp39-win_amd64.whl\", hash = \"sha256:543ef9179bc55edfd895154a51792b01c017c87af0ebaae092720152e19e42ca\"},\n+    {file = \"coverage-7.6.0-pp38.pp39.pp310-none-any.whl\", hash = \"sha256:6fe885135c8a479d3e37a7aae61cbd3a0fb2deccb4dda3c25f92a49189f766d6\"},\n+    {file = \"coverage-7.6.0.tar.gz\", hash = \"sha256:289cc803fa1dc901f84701ac10c9ee873619320f2f9aff38794db4a4a0268d51\"},\n ]\n \n [package.extras]\n@@ -1119,13 +1119,13 @@ idna = \">=2.0.0\"\n \n [[package]]\n name = \"exceptiongroup\"\n-version = \"1.2.1\"\n+version = \"1.2.2\"\n description = \"Backport of PEP 654 (exception groups)\"\n optional = false\n python-versions = \">=3.7\"\n files = [\n-    {file = \"exceptiongroup-1.2.1-py3-none-any.whl\", hash = \"sha256:5258b9ed329c5bbdd31a309f53cbfb0b155341807f6ff7606a1e801a891b29ad\"},\n-    {file = \"exceptiongroup-1.2.1.tar.gz\", hash = \"sha256:a4785e48b045528f5bfe627b6ad554ff32def154f42372786903b7abcfe1aa16\"},\n+    {file = \"exceptiongroup-1.2.2-py3-none-any.whl\", hash = \"sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b\"},\n+    {file = \"exceptiongroup-1.2.2.tar.gz\", hash = \"sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc\"},\n ]\n \n [package.extras]\n@@ -1265,13 +1265,13 @@ grpcio-gcp = [\"grpcio-gcp (>=0.2.2,<1.0.dev0)\"]\n \n [[package]]\n name = \"google-api-python-client\"\n-version = \"2.136.0\"\n+version = \"2.138.0\"\n description = \"Google API Client Library for Python\"\n optional = false\n python-versions = \">=3.7\"\n files = [\n-    {file = \"google-api-python-client-2.136.0.tar.gz\", hash = \"sha256:161c722c8864e7ed39393e2b7eea76ef4e1c933a6a59f9d7c70409b6635f225d\"},\n-    {file = \"google_api_python_client-2.136.0-py2.py3-none-any.whl\", hash = \"sha256:5a554c8b5edf0a609b905d89d7ced82e8f6ac31da1e4d8d5684ef63dbc0e49f5\"},\n+    {file = \"google_api_python_client-2.138.0-py2.py3-none-any.whl\", hash = \"sha256:1dd279124e4e77cbda4769ffb4abe7e7c32528ef1e18739320fef2a07b750764\"},\n+    {file = \"google_api_python_client-2.138.0.tar.gz\", hash = \"sha256:31080fbf0e64687876135cc23d1bec1ca3b80d7702177dd17b04131ea889eb70\"},\n ]\n \n [package.dependencies]\n@@ -1283,13 +1283,13 @@ uritemplate = \">=3.0.1,<5\"\n \n [[package]]\n name = \"google-auth\"\n-version = \"2.31.0\"\n+version = \"2.32.0\"\n description = \"Google Authentication Library\"\n optional = false\n python-versions = \">=3.7\"\n files = [\n-    {file = \"google-auth-2.31.0.tar.gz\", hash = \"sha256:87805c36970047247c8afe614d4e3af8eceafc1ebba0c679fe75ddd1d575e871\"},\n-    {file = \"google_auth-2.31.0-py2.py3-none-any.whl\", hash = \"sha256:042c4702efa9f7d3c48d3a69341c209381b125faa6dbf3ebe56bc7e40ae05c23\"},\n+    {file = \"google_auth-2.32.0-py2.py3-none-any.whl\", hash = \"sha256:53326ea2ebec768070a94bee4e1b9194c9646ea0c2bd72422785bd0f9abfad7b\"},\n+    {file = \"google_auth-2.32.0.tar.gz\", hash = \"sha256:49315be72c55a6a37d62819e3573f6b416aca00721f7e3e31a008d928bf64022\"},\n ]\n \n [package.dependencies]\n@@ -1321,13 +1321,13 @@ httplib2 = \">=0.19.0\"\n \n [[package]]\n name = \"google-auth-oauthlib\"\n-version = \"1.2.0\"\n+version = \"1.2.1\"\n description = \"Google Authentication Library\"\n optional = false\n python-versions = \">=3.6\"\n files = [\n-    {file = \"google-auth-oauthlib-1.2.0.tar.gz\", hash = \"sha256:292d2d3783349f2b0734a0a0207b1e1e322ac193c2c09d8f7c613fb7cc501ea8\"},\n-    {file = \"google_auth_oauthlib-1.2.0-py2.py3-none-any.whl\", hash = \"sha256:297c1ce4cb13a99b5834c74a1fe03252e1e499716718b190f56bcb9c4abc4faf\"},\n+    {file = \"google_auth_oauthlib-1.2.1-py2.py3-none-any.whl\", hash = \"sha256:2d58a27262d55aa1b87678c3ba7142a080098cbc2024f903c62355deb235d91f\"},\n+    {file = \"google_auth_oauthlib-1.2.1.tar.gz\", hash = \"sha256:afd0cad092a2eaa53cd8e8298557d6de1034c6cb4a740500b5357b648af97263\"},\n ]\n \n [package.dependencies]\n@@ -1339,12 +1339,12 @@ tool = [\"click (>=6.0.0)\"]\n \n [[package]]\n name = \"google-generativeai\"\n-version = \"0.7.1\"\n+version = \"0.7.2\"\n description = \"Google Generative AI High level API client library and tools.\"\n optional = false\n python-versions = \">=3.9\"\n files = [\n-    {file = \"google_generativeai-0.7.1-py3-none-any.whl\", hash = \"sha256:25017b1278c873b6db65ba41c70566ee9fce8f265498e8b2f6aac036528ba1c7\"},\n+    {file = \"google_generativeai-0.7.2-py3-none-any.whl\", hash = \"sha256:3117d1ebc92ee77710d4bc25ab4763492fddce9b6332eb25d124cf5d8b78b339\"},\n ]\n \n [package.dependencies]\n@@ -1379,61 +1379,61 @@ grpc = [\"grpcio (>=1.44.0,<2.0.0.dev0)\"]\n \n [[package]]\n name = \"grpcio\"\n-version = \"1.64.1\"\n+version = \"1.65.1\"\n description = \"HTTP/2-based RPC framework\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"grpcio-1.64.1-cp310-cp310-linux_armv7l.whl\", hash = \"sha256:55697ecec192bc3f2f3cc13a295ab670f51de29884ca9ae6cd6247df55df2502\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-macosx_12_0_universal2.whl\", hash = \"sha256:3b64ae304c175671efdaa7ec9ae2cc36996b681eb63ca39c464958396697daff\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-manylinux_2_17_aarch64.whl\", hash = \"sha256:bac71b4b28bc9af61efcdc7630b166440bbfbaa80940c9a697271b5e1dabbc61\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:6c024ffc22d6dc59000faf8ad781696d81e8e38f4078cb0f2630b4a3cf231a90\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e7cd5c1325f6808b8ae31657d281aadb2a51ac11ab081ae335f4f7fc44c1721d\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-musllinux_1_1_i686.whl\", hash = \"sha256:0a2813093ddb27418a4c99f9b1c223fab0b053157176a64cc9db0f4557b69bd9\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:2981c7365a9353f9b5c864595c510c983251b1ab403e05b1ccc70a3d9541a73b\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-win32.whl\", hash = \"sha256:1262402af5a511c245c3ae918167eca57342c72320dffae5d9b51840c4b2f86d\"},\n-    {file = \"grpcio-1.64.1-cp310-cp310-win_amd64.whl\", hash = \"sha256:19264fc964576ddb065368cae953f8d0514ecc6cb3da8903766d9fb9d4554c33\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-linux_armv7l.whl\", hash = \"sha256:58b1041e7c870bb30ee41d3090cbd6f0851f30ae4eb68228955d973d3efa2e61\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-macosx_10_9_universal2.whl\", hash = \"sha256:bbc5b1d78a7822b0a84c6f8917faa986c1a744e65d762ef6d8be9d75677af2ca\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-manylinux_2_17_aarch64.whl\", hash = \"sha256:5841dd1f284bd1b3d8a6eca3a7f062b06f1eec09b184397e1d1d43447e89a7ae\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:8caee47e970b92b3dd948371230fcceb80d3f2277b3bf7fbd7c0564e7d39068e\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:73819689c169417a4f978e562d24f2def2be75739c4bed1992435d007819da1b\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-musllinux_1_1_i686.whl\", hash = \"sha256:6503b64c8b2dfad299749cad1b595c650c91e5b2c8a1b775380fcf8d2cbba1e9\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:1de403fc1305fd96cfa75e83be3dee8538f2413a6b1685b8452301c7ba33c294\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-win32.whl\", hash = \"sha256:d4d29cc612e1332237877dfa7fe687157973aab1d63bd0f84cf06692f04c0367\"},\n-    {file = \"grpcio-1.64.1-cp311-cp311-win_amd64.whl\", hash = \"sha256:5e56462b05a6f860b72f0fa50dca06d5b26543a4e88d0396259a07dc30f4e5aa\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-linux_armv7l.whl\", hash = \"sha256:4657d24c8063e6095f850b68f2d1ba3b39f2b287a38242dcabc166453e950c59\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-macosx_10_9_universal2.whl\", hash = \"sha256:62b4e6eb7bf901719fce0ca83e3ed474ae5022bb3827b0a501e056458c51c0a1\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-manylinux_2_17_aarch64.whl\", hash = \"sha256:ee73a2f5ca4ba44fa33b4d7d2c71e2c8a9e9f78d53f6507ad68e7d2ad5f64a22\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:198908f9b22e2672a998870355e226a725aeab327ac4e6ff3a1399792ece4762\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:39b9d0acaa8d835a6566c640f48b50054f422d03e77e49716d4c4e8e279665a1\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-musllinux_1_1_i686.whl\", hash = \"sha256:5e42634a989c3aa6049f132266faf6b949ec2a6f7d302dbb5c15395b77d757eb\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:b1a82e0b9b3022799c336e1fc0f6210adc019ae84efb7321d668129d28ee1efb\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-win32.whl\", hash = \"sha256:55260032b95c49bee69a423c2f5365baa9369d2f7d233e933564d8a47b893027\"},\n-    {file = \"grpcio-1.64.1-cp312-cp312-win_amd64.whl\", hash = \"sha256:c1a786ac592b47573a5bb7e35665c08064a5d77ab88a076eec11f8ae86b3e3f6\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-linux_armv7l.whl\", hash = \"sha256:a011ac6c03cfe162ff2b727bcb530567826cec85eb8d4ad2bfb4bd023287a52d\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-macosx_10_9_universal2.whl\", hash = \"sha256:4d6dab6124225496010bd22690f2d9bd35c7cbb267b3f14e7a3eb05c911325d4\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-manylinux_2_17_aarch64.whl\", hash = \"sha256:a5e771d0252e871ce194d0fdcafd13971f1aae0ddacc5f25615030d5df55c3a2\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:2c3c1b90ab93fed424e454e93c0ed0b9d552bdf1b0929712b094f5ecfe7a23ad\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:20405cb8b13fd779135df23fabadc53b86522d0f1cba8cca0e87968587f50650\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-musllinux_1_1_i686.whl\", hash = \"sha256:0cc79c982ccb2feec8aad0e8fb0d168bcbca85bc77b080d0d3c5f2f15c24ea8f\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-musllinux_1_1_x86_64.whl\", hash = \"sha256:a3a035c37ce7565b8f4f35ff683a4db34d24e53dc487e47438e434eb3f701b2a\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-win32.whl\", hash = \"sha256:1257b76748612aca0f89beec7fa0615727fd6f2a1ad580a9638816a4b2eb18fd\"},\n-    {file = \"grpcio-1.64.1-cp38-cp38-win_amd64.whl\", hash = \"sha256:0a12ddb1678ebc6a84ec6b0487feac020ee2b1659cbe69b80f06dbffdb249122\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-linux_armv7l.whl\", hash = \"sha256:75dbbf415026d2862192fe1b28d71f209e2fd87079d98470db90bebe57b33179\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-macosx_10_9_universal2.whl\", hash = \"sha256:e3d9f8d1221baa0ced7ec7322a981e28deb23749c76eeeb3d33e18b72935ab62\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-manylinux_2_17_aarch64.whl\", hash = \"sha256:5f8b75f64d5d324c565b263c67dbe4f0af595635bbdd93bb1a88189fc62ed2e5\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:c84ad903d0d94311a2b7eea608da163dace97c5fe9412ea311e72c3684925602\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:940e3ec884520155f68a3b712d045e077d61c520a195d1a5932c531f11883489\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-musllinux_1_1_i686.whl\", hash = \"sha256:f10193c69fc9d3d726e83bbf0f3d316f1847c3071c8c93d8090cf5f326b14309\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:ac15b6c2c80a4d1338b04d42a02d376a53395ddf0ec9ab157cbaf44191f3ffdd\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-win32.whl\", hash = \"sha256:03b43d0ccf99c557ec671c7dede64f023c7da9bb632ac65dbc57f166e4970040\"},\n-    {file = \"grpcio-1.64.1-cp39-cp39-win_amd64.whl\", hash = \"sha256:ed6091fa0adcc7e4ff944090cf203a52da35c37a130efa564ded02b7aff63bcd\"},\n-    {file = \"grpcio-1.64.1.tar.gz\", hash = \"sha256:8d51dd1c59d5fa0f34266b80a3805ec29a1f26425c2a54736133f6d87fc4968a\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-linux_armv7l.whl\", hash = \"sha256:3dc5f928815b8972fb83b78d8db5039559f39e004ec93ebac316403fe031a062\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-macosx_12_0_universal2.whl\", hash = \"sha256:8333ca46053c35484c9f2f7e8d8ec98c1383a8675a449163cea31a2076d93de8\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-manylinux_2_17_aarch64.whl\", hash = \"sha256:7af64838b6e615fff0ec711960ed9b6ee83086edfa8c32670eafb736f169d719\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:dbb64b4166362d9326f7efbf75b1c72106c1aa87f13a8c8b56a1224fac152f5c\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:a8422dc13ad93ec8caa2612b5032a2b9cd6421c13ed87f54db4a3a2c93afaf77\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-musllinux_1_1_i686.whl\", hash = \"sha256:4effc0562b6c65d4add6a873ca132e46ba5e5a46f07c93502c37a9ae7f043857\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:a6c71575a2fedf259724981fd73a18906513d2f306169c46262a5bae956e6364\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-win32.whl\", hash = \"sha256:34966cf526ef0ea616e008d40d989463e3db157abb213b2f20c6ce0ae7928875\"},\n+    {file = \"grpcio-1.65.1-cp310-cp310-win_amd64.whl\", hash = \"sha256:ca931de5dd6d9eb94ff19a2c9434b23923bce6f767179fef04dfa991f282eaad\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-linux_armv7l.whl\", hash = \"sha256:bbb46330cc643ecf10bd9bd4ca8e7419a14b6b9dedd05f671c90fb2c813c6037\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-macosx_10_9_universal2.whl\", hash = \"sha256:d827a6fb9215b961eb73459ad7977edb9e748b23e3407d21c845d1d8ef6597e5\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-manylinux_2_17_aarch64.whl\", hash = \"sha256:6e71aed8835f8d9fbcb84babc93a9da95955d1685021cceb7089f4f1e717d719\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:9a1c84560b3b2d34695c9ba53ab0264e2802721c530678a8f0a227951f453462\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:27adee2338d697e71143ed147fe286c05810965d5d30ec14dd09c22479bfe48a\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-musllinux_1_1_i686.whl\", hash = \"sha256:f62652ddcadc75d0e7aa629e96bb61658f85a993e748333715b4ab667192e4e8\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:71a05fd814700dd9cb7d9a507f2f6a1ef85866733ccaf557eedacec32d65e4c2\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-win32.whl\", hash = \"sha256:b590f1ad056294dfaeac0b7e1b71d3d5ace638d8dd1f1147ce4bd13458783ba8\"},\n+    {file = \"grpcio-1.65.1-cp311-cp311-win_amd64.whl\", hash = \"sha256:12e9bdf3b5fd48e5fbe5b3da382ad8f97c08b47969f3cca81dd9b36b86ed39e2\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-linux_armv7l.whl\", hash = \"sha256:54cb822e177374b318b233e54b6856c692c24cdbd5a3ba5335f18a47396bac8f\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-macosx_10_9_universal2.whl\", hash = \"sha256:aaf3c54419a28d45bd1681372029f40e5bfb58e5265e3882eaf21e4a5f81a119\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-manylinux_2_17_aarch64.whl\", hash = \"sha256:557de35bdfbe8bafea0a003dbd0f4da6d89223ac6c4c7549d78e20f92ead95d9\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:8bfd95ef3b097f0cc86ade54eafefa1c8ed623aa01a26fbbdcd1a3650494dd11\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:9e6a8f3d6c41e6b642870afe6cafbaf7b61c57317f9ec66d0efdaf19db992b90\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-musllinux_1_1_i686.whl\", hash = \"sha256:1faaf7355ceed07ceaef0b9dcefa4c98daf1dd8840ed75c2de128c3f4a4d859d\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:60f1f38eed830488ad2a1b11579ef0f345ff16fffdad1d24d9fbc97ba31804ff\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-win32.whl\", hash = \"sha256:e75acfa52daf5ea0712e8aa82f0003bba964de7ae22c26d208cbd7bc08500177\"},\n+    {file = \"grpcio-1.65.1-cp312-cp312-win_amd64.whl\", hash = \"sha256:ff5a84907e51924973aa05ed8759210d8cdae7ffcf9e44fd17646cf4a902df59\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-linux_armv7l.whl\", hash = \"sha256:1fbd6331f18c3acd7e09d17fd840c096f56eaf0ef830fbd50af45ae9dc8dfd83\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-macosx_10_9_universal2.whl\", hash = \"sha256:de5b6be29116e094c5ef9d9e4252e7eb143e3d5f6bd6d50a78075553ab4930b0\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-manylinux_2_17_aarch64.whl\", hash = \"sha256:e4a3cdba62b2d6aeae6027ae65f350de6dc082b72e6215eccf82628e79efe9ba\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:941c4869aa229d88706b78187d60d66aca77fe5c32518b79e3c3e03fc26109a2\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:f40cebe5edb518d78b8131e87cb83b3ee688984de38a232024b9b44e74ee53d3\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-musllinux_1_1_i686.whl\", hash = \"sha256:2ca684ba331fb249d8a1ce88db5394e70dbcd96e58d8c4b7e0d7b141a453dce9\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-musllinux_1_1_x86_64.whl\", hash = \"sha256:8558f0083ddaf5de64a59c790bffd7568e353914c0c551eae2955f54ee4b857f\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-win32.whl\", hash = \"sha256:8d8143a3e3966f85dce6c5cc45387ec36552174ba5712c5dc6fcc0898fb324c0\"},\n+    {file = \"grpcio-1.65.1-cp38-cp38-win_amd64.whl\", hash = \"sha256:76e81a86424d6ca1ce7c16b15bdd6a964a42b40544bf796a48da241fdaf61153\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-linux_armv7l.whl\", hash = \"sha256:cb5175f45c980ff418998723ea1b3869cce3766d2ab4e4916fbd3cedbc9d0ed3\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-macosx_10_9_universal2.whl\", hash = \"sha256:b12c1aa7b95abe73b3e04e052c8b362655b41c7798da69f1eaf8d186c7d204df\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-manylinux_2_17_aarch64.whl\", hash = \"sha256:3019fb50128b21a5e018d89569ffaaaa361680e1346c2f261bb84a91082eb3d3\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl\", hash = \"sha256:7ae15275ed98ea267f64ee9ddedf8ecd5306a5b5bb87972a48bfe24af24153e8\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:5f096ffb881f37e8d4f958b63c74bfc400c7cebd7a944b027357cd2fb8d91a57\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-musllinux_1_1_i686.whl\", hash = \"sha256:2f56b5a68fdcf17a0a1d524bf177218c3c69b3947cb239ea222c6f1867c3ab68\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:941596d419b9736ab548aa0feb5bbba922f98872668847bf0720b42d1d227b9e\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-win32.whl\", hash = \"sha256:5fd7337a823b890215f07d429f4f193d24b80d62a5485cf88ee06648591a0c57\"},\n+    {file = \"grpcio-1.65.1-cp39-cp39-win_amd64.whl\", hash = \"sha256:1bceeec568372cbebf554eae1b436b06c2ff24cfaf04afade729fb9035408c6c\"},\n+    {file = \"grpcio-1.65.1.tar.gz\", hash = \"sha256:3c492301988cd720cd145d84e17318d45af342e29ef93141228f9cd73222368b\"},\n ]\n \n [package.extras]\n-protobuf = [\"grpcio-tools (>=1.64.1)\"]\n+protobuf = [\"grpcio-tools (>=1.65.1)\"]\n \n [[package]]\n name = \"grpcio-status\"\n@@ -1582,13 +1582,13 @@ files = [\n \n [[package]]\n name = \"importlib-metadata\"\n-version = \"8.0.0\"\n+version = \"8.2.0\"\n description = \"Read metadata from Python packages\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"importlib_metadata-8.0.0-py3-none-any.whl\", hash = \"sha256:15584cf2b1bf449d98ff8a6ff1abef57bf20f3ac6454f431736cd3e660921b2f\"},\n-    {file = \"importlib_metadata-8.0.0.tar.gz\", hash = \"sha256:188bd24e4c346d3f0a933f275c2fec67050326a856b9a359881d7c2a697e8812\"},\n+    {file = \"importlib_metadata-8.2.0-py3-none-any.whl\", hash = \"sha256:11901fa0c2f97919b288679932bb64febaeacf289d18ac84dd68cb2e74213369\"},\n+    {file = \"importlib_metadata-8.2.0.tar.gz\", hash = \"sha256:72e8d4399996132204f9a16dcc751af254a48f8d1b20b9ff0f98d4a8f901e73d\"},\n ]\n \n [package.dependencies]\n@@ -2944,13 +2944,13 @@ files = [\n \n [[package]]\n name = \"msal\"\n-version = \"1.29.0\"\n+version = \"1.30.0\"\n description = \"The Microsoft Authentication Library (MSAL) for Python library enables your app to access the Microsoft Cloud by supporting authentication of users with Microsoft Azure Active Directory accounts (AAD) and Microsoft Accounts (MSA) using industry standard OAuth2 and OpenID Connect.\"\n optional = false\n python-versions = \">=3.7\"\n files = [\n-    {file = \"msal-1.29.0-py3-none-any.whl\", hash = \"sha256:6b301e63f967481f0cc1a3a3bac0cf322b276855bc1b0955468d9deb3f33d511\"},\n-    {file = \"msal-1.29.0.tar.gz\", hash = \"sha256:8f6725f099752553f9b2fe84125e2a5ebe47b49f92eacca33ebedd3a9ebaae25\"},\n+    {file = \"msal-1.30.0-py3-none-any.whl\", hash = \"sha256:423872177410cb61683566dc3932db7a76f661a5d2f6f52f02a047f101e1c1de\"},\n+    {file = \"msal-1.30.0.tar.gz\", hash = \"sha256:b4bf00850092e465157d814efa24a18f788284c9a479491024d62903085ea2fb\"},\n ]\n \n [package.dependencies]\n@@ -3026,56 +3026,56 @@ files = [\n \n [[package]]\n name = \"numpy\"\n-version = \"2.0.0\"\n+version = \"2.0.1\"\n description = \"Fundamental package for array computing in Python\"\n optional = false\n python-versions = \">=3.9\"\n files = [\n-    {file = \"numpy-2.0.0-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:04494f6ec467ccb5369d1808570ae55f6ed9b5809d7f035059000a37b8d7e86f\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:2635dbd200c2d6faf2ef9a0d04f0ecc6b13b3cad54f7c67c61155138835515d2\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-macosx_14_0_arm64.whl\", hash = \"sha256:0a43f0974d501842866cc83471bdb0116ba0dffdbaac33ec05e6afed5b615238\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-macosx_14_0_x86_64.whl\", hash = \"sha256:8d83bb187fb647643bd56e1ae43f273c7f4dbcdf94550d7938cfc32566756514\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:79e843d186c8fb1b102bef3e2bc35ef81160ffef3194646a7fdd6a73c6b97196\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:6d7696c615765091cc5093f76fd1fa069870304beaccfd58b5dcc69e55ef49c1\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:b4c76e3d4c56f145d41b7b6751255feefae92edbc9a61e1758a98204200f30fc\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:acd3a644e4807e73b4e1867b769fbf1ce8c5d80e7caaef0d90dcdc640dfc9787\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-win32.whl\", hash = \"sha256:cee6cc0584f71adefe2c908856ccc98702baf95ff80092e4ca46061538a2ba98\"},\n-    {file = \"numpy-2.0.0-cp310-cp310-win_amd64.whl\", hash = \"sha256:ed08d2703b5972ec736451b818c2eb9da80d66c3e84aed1deeb0c345fefe461b\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:ad0c86f3455fbd0de6c31a3056eb822fc939f81b1618f10ff3406971893b62a5\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:e7f387600d424f91576af20518334df3d97bc76a300a755f9a8d6e4f5cadd289\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-macosx_14_0_arm64.whl\", hash = \"sha256:34f003cb88b1ba38cb9a9a4a3161c1604973d7f9d5552c38bc2f04f829536609\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-macosx_14_0_x86_64.whl\", hash = \"sha256:b6f6a8f45d0313db07d6d1d37bd0b112f887e1369758a5419c0370ba915b3871\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:5f64641b42b2429f56ee08b4f427a4d2daf916ec59686061de751a55aafa22e4\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:a7039a136017eaa92c1848152827e1424701532ca8e8967fe480fe1569dae581\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:46e161722e0f619749d1cd892167039015b2c2817296104487cd03ed4a955995\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:0e50842b2295ba8414c8c1d9d957083d5dfe9e16828b37de883f51fc53c4016f\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-win32.whl\", hash = \"sha256:2ce46fd0b8a0c947ae047d222f7136fc4d55538741373107574271bc00e20e8f\"},\n-    {file = \"numpy-2.0.0-cp311-cp311-win_amd64.whl\", hash = \"sha256:fbd6acc766814ea6443628f4e6751d0da6593dae29c08c0b2606164db026970c\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-macosx_10_9_x86_64.whl\", hash = \"sha256:354f373279768fa5a584bac997de6a6c9bc535c482592d7a813bb0c09be6c76f\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:4d2f62e55a4cd9c58c1d9a1c9edaedcd857a73cb6fda875bf79093f9d9086f85\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-macosx_14_0_arm64.whl\", hash = \"sha256:1e72728e7501a450288fc8e1f9ebc73d90cfd4671ebbd631f3e7857c39bd16f2\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-macosx_14_0_x86_64.whl\", hash = \"sha256:84554fc53daa8f6abf8e8a66e076aff6ece62de68523d9f665f32d2fc50fd66e\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:c73aafd1afca80afecb22718f8700b40ac7cab927b8abab3c3e337d70e10e5a2\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:49d9f7d256fbc804391a7f72d4a617302b1afac1112fac19b6c6cec63fe7fe8a\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:0ec84b9ba0654f3b962802edc91424331f423dcf5d5f926676e0150789cb3d95\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:feff59f27338135776f6d4e2ec7aeeac5d5f7a08a83e80869121ef8164b74af9\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-win32.whl\", hash = \"sha256:c5a59996dc61835133b56a32ebe4ef3740ea5bc19b3983ac60cc32be5a665d54\"},\n-    {file = \"numpy-2.0.0-cp312-cp312-win_amd64.whl\", hash = \"sha256:a356364941fb0593bb899a1076b92dfa2029f6f5b8ba88a14fd0984aaf76d0df\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:e61155fae27570692ad1d327e81c6cf27d535a5d7ef97648a17d922224b216de\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:4554eb96f0fd263041baf16cf0881b3f5dafae7a59b1049acb9540c4d57bc8cb\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-macosx_14_0_arm64.whl\", hash = \"sha256:903703372d46bce88b6920a0cd86c3ad82dae2dbef157b5fc01b70ea1cfc430f\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-macosx_14_0_x86_64.whl\", hash = \"sha256:3e8e01233d57639b2e30966c63d36fcea099d17c53bf424d77f088b0f4babd86\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:1cde1753efe513705a0c6d28f5884e22bdc30438bf0085c5c486cdaff40cd67a\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:821eedb7165ead9eebdb569986968b541f9908979c2da8a4967ecac4439bae3d\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:9a1712c015831da583b21c5bfe15e8684137097969c6d22e8316ba66b5baabe4\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:9c27f0946a3536403efb0e1c28def1ae6730a72cd0d5878db38824855e3afc44\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-win32.whl\", hash = \"sha256:63b92c512d9dbcc37f9d81b123dec99fdb318ba38c8059afc78086fe73820275\"},\n-    {file = \"numpy-2.0.0-cp39-cp39-win_amd64.whl\", hash = \"sha256:3f6bed7f840d44c08ebdb73b1825282b801799e325bcbdfa6bc5c370e5aecc65\"},\n-    {file = \"numpy-2.0.0-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\", hash = \"sha256:9416a5c2e92ace094e9f0082c5fd473502c91651fb896bc17690d6fc475128d6\"},\n-    {file = \"numpy-2.0.0-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\", hash = \"sha256:17067d097ed036636fa79f6a869ac26df7db1ba22039d962422506640314933a\"},\n-    {file = \"numpy-2.0.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:38ecb5b0582cd125f67a629072fed6f83562d9dd04d7e03256c9829bdec027ad\"},\n-    {file = \"numpy-2.0.0-pp39-pypy39_pp73-win_amd64.whl\", hash = \"sha256:cef04d068f5fb0518a77857953193b6bb94809a806bd0a14983a8f12ada060c9\"},\n-    {file = \"numpy-2.0.0.tar.gz\", hash = \"sha256:cf5d1c9e6837f8af9f92b6bd3e86d513cdc11f60fd62185cc49ec7d1aba34864\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-macosx_10_9_x86_64.whl\", hash = \"sha256:0fbb536eac80e27a2793ffd787895242b7f18ef792563d742c2d673bfcb75134\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:69ff563d43c69b1baba77af455dd0a839df8d25e8590e79c90fcbe1499ebde42\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-macosx_14_0_arm64.whl\", hash = \"sha256:1b902ce0e0a5bb7704556a217c4f63a7974f8f43e090aff03fcf262e0b135e02\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-macosx_14_0_x86_64.whl\", hash = \"sha256:f1659887361a7151f89e79b276ed8dff3d75877df906328f14d8bb40bb4f5101\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:4658c398d65d1b25e1760de3157011a80375da861709abd7cef3bad65d6543f9\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:4127d4303b9ac9f94ca0441138acead39928938660ca58329fe156f84b9f3015\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:e5eeca8067ad04bc8a2a8731183d51d7cbaac66d86085d5f4766ee6bf19c7f87\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-musllinux_1_2_aarch64.whl\", hash = \"sha256:9adbd9bb520c866e1bfd7e10e1880a1f7749f1f6e5017686a5fbb9b72cf69f82\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-win32.whl\", hash = \"sha256:7b9853803278db3bdcc6cd5beca37815b133e9e77ff3d4733c247414e78eb8d1\"},\n+    {file = \"numpy-2.0.1-cp310-cp310-win_amd64.whl\", hash = \"sha256:81b0893a39bc5b865b8bf89e9ad7807e16717f19868e9d234bdaf9b1f1393868\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-macosx_10_9_x86_64.whl\", hash = \"sha256:75b4e316c5902d8163ef9d423b1c3f2f6252226d1aa5cd8a0a03a7d01ffc6268\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:6e4eeb6eb2fced786e32e6d8df9e755ce5be920d17f7ce00bc38fcde8ccdbf9e\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-macosx_14_0_arm64.whl\", hash = \"sha256:a1e01dcaab205fbece13c1410253a9eea1b1c9b61d237b6fa59bcc46e8e89343\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-macosx_14_0_x86_64.whl\", hash = \"sha256:a8fc2de81ad835d999113ddf87d1ea2b0f4704cbd947c948d2f5513deafe5a7b\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:5a3d94942c331dd4e0e1147f7a8699a4aa47dffc11bf8a1523c12af8b2e91bbe\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:15eb4eca47d36ec3f78cde0a3a2ee24cf05ca7396ef808dda2c0ddad7c2bde67\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:b83e16a5511d1b1f8a88cbabb1a6f6a499f82c062a4251892d9ad5d609863fb7\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-musllinux_1_2_aarch64.whl\", hash = \"sha256:1f87fec1f9bc1efd23f4227becff04bd0e979e23ca50cc92ec88b38489db3b55\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-win32.whl\", hash = \"sha256:36d3a9405fd7c511804dc56fc32974fa5533bdeb3cd1604d6b8ff1d292b819c4\"},\n+    {file = \"numpy-2.0.1-cp311-cp311-win_amd64.whl\", hash = \"sha256:08458fbf403bff5e2b45f08eda195d4b0c9b35682311da5a5a0a0925b11b9bd8\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-macosx_10_9_x86_64.whl\", hash = \"sha256:6bf4e6f4a2a2e26655717a1983ef6324f2664d7011f6ef7482e8c0b3d51e82ac\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:7d6fddc5fe258d3328cd8e3d7d3e02234c5d70e01ebe377a6ab92adb14039cb4\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-macosx_14_0_arm64.whl\", hash = \"sha256:5daab361be6ddeb299a918a7c0864fa8618af66019138263247af405018b04e1\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-macosx_14_0_x86_64.whl\", hash = \"sha256:ea2326a4dca88e4a274ba3a4405eb6c6467d3ffbd8c7d38632502eaae3820587\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:529af13c5f4b7a932fb0e1911d3a75da204eff023ee5e0e79c1751564221a5c8\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:6790654cb13eab303d8402354fabd47472b24635700f631f041bd0b65e37298a\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:cbab9fc9c391700e3e1287666dfd82d8666d10e69a6c4a09ab97574c0b7ee0a7\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-musllinux_1_2_aarch64.whl\", hash = \"sha256:99d0d92a5e3613c33a5f01db206a33f8fdf3d71f2912b0de1739894668b7a93b\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-win32.whl\", hash = \"sha256:173a00b9995f73b79eb0191129f2455f1e34c203f559dd118636858cc452a1bf\"},\n+    {file = \"numpy-2.0.1-cp312-cp312-win_amd64.whl\", hash = \"sha256:bb2124fdc6e62baae159ebcfa368708867eb56806804d005860b6007388df171\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-macosx_10_9_x86_64.whl\", hash = \"sha256:bfc085b28d62ff4009364e7ca34b80a9a080cbd97c2c0630bb5f7f770dae9414\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:8fae4ebbf95a179c1156fab0b142b74e4ba4204c87bde8d3d8b6f9c34c5825ef\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-macosx_14_0_arm64.whl\", hash = \"sha256:72dc22e9ec8f6eaa206deb1b1355eb2e253899d7347f5e2fae5f0af613741d06\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-macosx_14_0_x86_64.whl\", hash = \"sha256:ec87f5f8aca726117a1c9b7083e7656a9d0d606eec7299cc067bb83d26f16e0c\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:1f682ea61a88479d9498bf2091fdcd722b090724b08b31d63e022adc063bad59\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:8efc84f01c1cd7e34b3fb310183e72fcdf55293ee736d679b6d35b35d80bba26\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:3fdabe3e2a52bc4eff8dc7a5044342f8bd9f11ef0934fcd3289a788c0eb10018\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-musllinux_1_2_aarch64.whl\", hash = \"sha256:24a0e1befbfa14615b49ba9659d3d8818a0f4d8a1c5822af8696706fbda7310c\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-win32.whl\", hash = \"sha256:f9cf5ea551aec449206954b075db819f52adc1638d46a6738253a712d553c7b4\"},\n+    {file = \"numpy-2.0.1-cp39-cp39-win_amd64.whl\", hash = \"sha256:e9e81fa9017eaa416c056e5d9e71be93d05e2c3c2ab308d23307a8bc4443c368\"},\n+    {file = \"numpy-2.0.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl\", hash = \"sha256:61728fba1e464f789b11deb78a57805c70b2ed02343560456190d0501ba37b0f\"},\n+    {file = \"numpy-2.0.1-pp39-pypy39_pp73-macosx_14_0_x86_64.whl\", hash = \"sha256:12f5d865d60fb9734e60a60f1d5afa6d962d8d4467c120a1c0cda6eb2964437d\"},\n+    {file = \"numpy-2.0.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:eacf3291e263d5a67d8c1a581a8ebbcfd6447204ef58828caf69a5e3e8c75990\"},\n+    {file = \"numpy-2.0.1-pp39-pypy39_pp73-win_amd64.whl\", hash = \"sha256:2c3a346ae20cfd80b6cfd3e60dc179963ef2ea58da5ec074fd3d9e7a1e7ba97f\"},\n+    {file = \"numpy-2.0.1.tar.gz\", hash = \"sha256:485b87235796410c3519a699cfe1faab097e509e90ebb05dcd098db2ae87e7b3\"},\n ]\n \n [[package]]\n@@ -3180,13 +3180,13 @@ files = [\n \n [[package]]\n name = \"ovld\"\n-version = \"0.3.5\"\n+version = \"0.3.6\"\n description = \"Overloading Python functions\"\n optional = false\n-python-versions = \"<4.0,>=3.8\"\n+python-versions = \">=3.8\"\n files = [\n-    {file = \"ovld-0.3.5-py3-none-any.whl\", hash = \"sha256:d36604a9ff7202d5639ebefd6ff97955ce5b04ffff0c7f0ade6ddc3189ca9846\"},\n-    {file = \"ovld-0.3.5.tar.gz\", hash = \"sha256:838358bc800d5bf3a66afcd6d59f0826eda7a598f48f885a9c8662169ef29813\"},\n+    {file = \"ovld-0.3.6-py3-none-any.whl\", hash = \"sha256:d7903ebd68a897de4a441bc913969f085a6f0de48e3e290ce5a58df4dafc36bb\"},\n+    {file = \"ovld-0.3.6.tar.gz\", hash = \"sha256:752879502977f9f30a7f83253ecbefa7a0831d39dbac6d2f04ff92dcdb7b1ffb\"},\n ]\n \n [[package]]\n@@ -3286,13 +3286,13 @@ files = [\n \n [[package]]\n name = \"pip\"\n-version = \"24.1.1\"\n+version = \"24.1.2\"\n description = \"The PyPA recommended tool for installing Python packages.\"\n optional = true\n python-versions = \">=3.8\"\n files = [\n-    {file = \"pip-24.1.1-py3-none-any.whl\", hash = \"sha256:efca15145a95e95c00608afeab66311d40bfb73bb2266a855befd705e6bb15a0\"},\n-    {file = \"pip-24.1.1.tar.gz\", hash = \"sha256:5aa64f65e1952733ee0a9a9b1f52496ebdb3f3077cc46f80a16d983b58d1180a\"},\n+    {file = \"pip-24.1.2-py3-none-any.whl\", hash = \"sha256:7cd207eed4c60b0f411b444cd1464198fe186671c323b6cd6d433ed80fc9d247\"},\n+    {file = \"pip-24.1.2.tar.gz\", hash = \"sha256:e5458a0b89f2755e0ee8c0c77613fe5273e05f337907874d64f13171a898a7ff\"},\n ]\n \n [[package]]\n@@ -3404,13 +3404,13 @@ testing = [\"pytest\", \"pytest-benchmark\"]\n \n [[package]]\n name = \"portalocker\"\n-version = \"2.10.0\"\n+version = \"2.10.1\"\n description = \"Wraps the portalocker recipe for easy usage\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"portalocker-2.10.0-py3-none-any.whl\", hash = \"sha256:48944147b2cd42520549bc1bb8fe44e220296e56f7c3d551bc6ecce69d9b0de1\"},\n-    {file = \"portalocker-2.10.0.tar.gz\", hash = \"sha256:49de8bc0a2f68ca98bf9e219c81a3e6b27097c7bf505a87c5a112ce1aaeb9b81\"},\n+    {file = \"portalocker-2.10.1-py3-none-any.whl\", hash = \"sha256:53a5984ebc86a025552264b459b46a2086e269b21823cb572f8f28ee759e45bf\"},\n+    {file = \"portalocker-2.10.1.tar.gz\", hash = \"sha256:ef1bf844e878ab08aee7e40184156e1151f228f103aa5c6bd0724cc330960f8f\"},\n ]\n \n [package.dependencies]\n@@ -3468,22 +3468,22 @@ testing = [\"google-api-core (>=1.31.5)\"]\n \n [[package]]\n name = \"protobuf\"\n-version = \"4.25.3\"\n+version = \"4.25.4\"\n description = \"\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"protobuf-4.25.3-cp310-abi3-win32.whl\", hash = \"sha256:d4198877797a83cbfe9bffa3803602bbe1625dc30d8a097365dbc762e5790faa\"},\n-    {file = \"protobuf-4.25.3-cp310-abi3-win_amd64.whl\", hash = \"sha256:209ba4cc916bab46f64e56b85b090607a676f66b473e6b762e6f1d9d591eb2e8\"},\n-    {file = \"protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl\", hash = \"sha256:f1279ab38ecbfae7e456a108c5c0681e4956d5b1090027c1de0f934dfdb4b35c\"},\n-    {file = \"protobuf-4.25.3-cp37-abi3-manylinux2014_aarch64.whl\", hash = \"sha256:e7cb0ae90dd83727f0c0718634ed56837bfeeee29a5f82a7514c03ee1364c019\"},\n-    {file = \"protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl\", hash = \"sha256:7c8daa26095f82482307bc717364e7c13f4f1c99659be82890dcfc215194554d\"},\n-    {file = \"protobuf-4.25.3-cp38-cp38-win32.whl\", hash = \"sha256:f4f118245c4a087776e0a8408be33cf09f6c547442c00395fbfb116fac2f8ac2\"},\n-    {file = \"protobuf-4.25.3-cp38-cp38-win_amd64.whl\", hash = \"sha256:c053062984e61144385022e53678fbded7aea14ebb3e0305ae3592fb219ccfa4\"},\n-    {file = \"protobuf-4.25.3-cp39-cp39-win32.whl\", hash = \"sha256:19b270aeaa0099f16d3ca02628546b8baefe2955bbe23224aaf856134eccf1e4\"},\n-    {file = \"protobuf-4.25.3-cp39-cp39-win_amd64.whl\", hash = \"sha256:e3c97a1555fd6388f857770ff8b9703083de6bf1f9274a002a332d65fbb56c8c\"},\n-    {file = \"protobuf-4.25.3-py3-none-any.whl\", hash = \"sha256:f0700d54bcf45424477e46a9f0944155b46fb0639d69728739c0e47bab83f2b9\"},\n-    {file = \"protobuf-4.25.3.tar.gz\", hash = \"sha256:25b5d0b42fd000320bd7830b349e3b696435f3b329810427a6bcce6a5492cc5c\"},\n+    {file = \"protobuf-4.25.4-cp310-abi3-win32.whl\", hash = \"sha256:db9fd45183e1a67722cafa5c1da3e85c6492a5383f127c86c4c4aa4845867dc4\"},\n+    {file = \"protobuf-4.25.4-cp310-abi3-win_amd64.whl\", hash = \"sha256:ba3d8504116a921af46499471c63a85260c1a5fc23333154a427a310e015d26d\"},\n+    {file = \"protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl\", hash = \"sha256:eecd41bfc0e4b1bd3fa7909ed93dd14dd5567b98c941d6c1ad08fdcab3d6884b\"},\n+    {file = \"protobuf-4.25.4-cp37-abi3-manylinux2014_aarch64.whl\", hash = \"sha256:4c8a70fdcb995dcf6c8966cfa3a29101916f7225e9afe3ced4395359955d3835\"},\n+    {file = \"protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl\", hash = \"sha256:3319e073562e2515c6ddc643eb92ce20809f5d8f10fead3332f71c63be6a7040\"},\n+    {file = \"protobuf-4.25.4-cp38-cp38-win32.whl\", hash = \"sha256:7e372cbbda66a63ebca18f8ffaa6948455dfecc4e9c1029312f6c2edcd86c4e1\"},\n+    {file = \"protobuf-4.25.4-cp38-cp38-win_amd64.whl\", hash = \"sha256:051e97ce9fa6067a4546e75cb14f90cf0232dcb3e3d508c448b8d0e4265b61c1\"},\n+    {file = \"protobuf-4.25.4-cp39-cp39-win32.whl\", hash = \"sha256:90bf6fd378494eb698805bbbe7afe6c5d12c8e17fca817a646cd6a1818c696ca\"},\n+    {file = \"protobuf-4.25.4-cp39-cp39-win_amd64.whl\", hash = \"sha256:ac79a48d6b99dfed2729ccccee547b34a1d3d63289c71cef056653a846a2240f\"},\n+    {file = \"protobuf-4.25.4-py3-none-any.whl\", hash = \"sha256:bfbebc1c8e4793cfd58589acfb8a1026be0003e852b9da7db5a4285bde996978\"},\n+    {file = \"protobuf-4.25.4.tar.gz\", hash = \"sha256:0dc4a62cc4052a036ee2204d26fe4d835c62827c855c8a03f29fe6da146b380d\"},\n ]\n \n [[package]]\n@@ -3598,13 +3598,13 @@ files = [\n \n [[package]]\n name = \"puremagic\"\n-version = \"1.25\"\n+version = \"1.26\"\n description = \"Pure python implementation of magic file detection\"\n optional = true\n python-versions = \"*\"\n files = [\n-    {file = \"puremagic-1.25-py3-none-any.whl\", hash = \"sha256:b8f8731263505f19949002bb4b5506fe19b57d98582f3218fccb4bdd0124fd2d\"},\n-    {file = \"puremagic-1.25.tar.gz\", hash = \"sha256:671c801158376c5f4a43c805edf7ef87d59337e243b03a8ce23d151a7a0e9c4d\"},\n+    {file = \"puremagic-1.26-py3-none-any.whl\", hash = \"sha256:2fb5ebffeae21a1f94b0db6fde20e1dcd0b7705d915eb02ae4a0f990f1e88209\"},\n+    {file = \"puremagic-1.26.tar.gz\", hash = \"sha256:ea875d3fdd6a29134bdd035cdfeca177fed575b6bdd68acd86f83ca284edc027\"},\n ]\n \n [[package]]\n@@ -3871,13 +3871,13 @@ diagrams = [\"jinja2\", \"railroad-diagrams\"]\n \n [[package]]\n name = \"pytest\"\n-version = \"8.2.2\"\n+version = \"8.3.2\"\n description = \"pytest: simple powerful testing with Python\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"pytest-8.2.2-py3-none-any.whl\", hash = \"sha256:c434598117762e2bd304e526244f67bf66bbd7b5d6cf22138be51ff661980343\"},\n-    {file = \"pytest-8.2.2.tar.gz\", hash = \"sha256:de4bb8104e201939ccdc688b27a89a7be2079b22e2bd2b07f806b6ba71117977\"},\n+    {file = \"pytest-8.3.2-py3-none-any.whl\", hash = \"sha256:4ba08f9ae7dcf84ded419494d229b48d0903ea6407b030eaec46df5e6a73bba5\"},\n+    {file = \"pytest-8.3.2.tar.gz\", hash = \"sha256:c132345d12ce551242c87269de812483f5bcc87cdbb4722e48487ba194f9fdce\"},\n ]\n \n [package.dependencies]\n@@ -3885,7 +3885,7 @@ colorama = {version = \"*\", markers = \"sys_platform == \\\"win32\\\"\"}\n exceptiongroup = {version = \">=1.0.0rc8\", markers = \"python_version < \\\"3.11\\\"\"}\n iniconfig = \"*\"\n packaging = \"*\"\n-pluggy = \">=1.5,<2.0\"\n+pluggy = \">=1.5,<2\"\n tomli = {version = \">=1\", markers = \"python_version < \\\"3.11\\\"\"}\n \n [package.extras]\n@@ -4530,13 +4530,13 @@ zstd = [\"zstandard (>=0.18.0)\"]\n \n [[package]]\n name = \"uvicorn\"\n-version = \"0.30.1\"\n+version = \"0.30.3\"\n description = \"The lightning-fast ASGI server.\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"uvicorn-0.30.1-py3-none-any.whl\", hash = \"sha256:cd17daa7f3b9d7a24de3617820e634d0933b69eed8e33a516071174427238c81\"},\n-    {file = \"uvicorn-0.30.1.tar.gz\", hash = \"sha256:d46cd8e0fd80240baffbcd9ec1012a712938754afcf81bce56c024c1656aece8\"},\n+    {file = \"uvicorn-0.30.3-py3-none-any.whl\", hash = \"sha256:94a3608da0e530cea8f69683aa4126364ac18e3826b6630d1a65f4638aade503\"},\n+    {file = \"uvicorn-0.30.3.tar.gz\", hash = \"sha256:0d114d0831ff1adbf231d358cbf42f17333413042552a624ea6a9b4c33dcfd81\"},\n ]\n \n [package.dependencies]\ndiff --git a/turbinia/api/cli/turbinia_client/helpers/formatter.py b/turbinia/api/cli/turbinia_client/helpers/formatter.py\nindex 8204a6b84..5fc57cb28 100644\n--- a/turbinia/api/cli/turbinia_client/helpers/formatter.py\n+++ b/turbinia/api/cli/turbinia_client/helpers/formatter.py\n@@ -19,11 +19,10 @@\n \n from abc import ABC, abstractmethod\n from click import echo as click_echo\n+from httpx import Response\n from typing import Any\n from collections import defaultdict\n \n-from turbinia_api_lib.api_response import ApiResponse\n-\n import logging\n import json\n import pandas\n@@ -55,8 +54,9 @@ def echo_json(data: Any) -> None:\n \n def decode_api_response(data: Any) -> str:\n   \"\"\"Decodes ApiResponse data into a Python object\"\"\"\n-  if not isinstance(data, ApiResponse):\n+  if isinstance(data, str) or isinstance(data, Response):\n     return data\n+\n   data_attribute = None\n   response = ''\n   try:\ndiff --git a/turbinia/api/openapi.yaml b/turbinia/api/openapi.yaml\nindex b8c1282d7..6490a196a 100644\n--- a/turbinia/api/openapi.yaml\n+++ b/turbinia/api/openapi.yaml\n@@ -519,6 +519,29 @@ paths:\n       summary: Get Requests Summary\n       tags:\n       - Turbinia Requests\n+  /api/request/report/{request_id}:\n+    get:\n+      description: \"Retrieves the markdown report for a Turbinia Request.\\n\\nArgs:\\n  request (Request):\\\n+        \\ FastAPI request object.\\n  request_id (str): A Turbinia request identifier.\\n\\\n+        \\nRaises:\\n  HTTPException: if another exception is caught.\"\n+      operationId: get_request_report\n+      parameters:\n+      - in: path\n+        name: request_id\n+        required: true\n+        schema:\n+          title: Request Id\n+          type: string\n+      responses:\n+        '200':\n+          content:\n+            application/text:\n+              schema:\n+                type: string\n+          description: Successful Response\n+      summary: Get Request Markdown Report\n+      tags:\n+      - Turbinia Requests\n   /api/request/{request_id}:\n     get:\n       description: \"Retrieves status for a Turbinia Request.\\n\\nArgs:\\n  request (Request):\\\ndiff --git a/turbinia/api/routes/request.py b/turbinia/api/routes/request.py\nindex edc0a4369..3a67de618 100644\n--- a/turbinia/api/routes/request.py\n+++ b/turbinia/api/routes/request.py\n@@ -19,12 +19,13 @@\n import json\n \n from fastapi import HTTPException, APIRouter\n-from fastapi.responses import JSONResponse\n+from fastapi.responses import JSONResponse, PlainTextResponse\n from fastapi.requests import Request\n from pydantic import ValidationError\n from turbinia import TurbiniaException, client as turbinia_client\n from turbinia import evidence\n from turbinia.lib import recipe_helpers\n+from turbinia.api.cli.turbinia_client.helpers.formatter import RequestMarkdownReport\n from turbinia.api.schemas import request as turbinia_request\n from turbinia.api.models import request_status\n \n@@ -59,6 +60,32 @@ async def get_requests_summary(request: Request):\n         detail='Error retrieving requests summary') from exception\n \n \n+@router.get('/report')\n+async def get_request_report(request: Request, request_id: str):\n+  \"\"\"Retrieves the MarkDown report of a Turbinia request.\n+\n+  Raises:\n+    HTTPException: if another exception is caught.\n+  \"\"\"\n+  try:\n+    request_out = request_status.RequestStatus(request_id=request_id)\n+    if not request_out.get_request_data(request_id):\n+      raise HTTPException(\n+          status_code=404,\n+          detail='Request ID not found or the request had no associated tasks.')\n+    request_data = json.loads(request_out.json())\n+    markdownreport = RequestMarkdownReport(\n+        request_data=request_data).generate_markdown()\n+\n+    return PlainTextResponse(content=markdownreport, status_code=200)\n+  except (json.JSONDecodeError, TypeError, ValueError, AttributeError,\n+          ValidationError) as exception:\n+    log.error(f'Error retrieving markdown report: {exception!s}', exc_info=True)\n+    raise HTTPException(\n+        status_code=500,\n+        detail='Error retrieving markdown report') from exception\n+\n+\n @router.get('/{request_id}')\n async def get_request_status(request: Request, request_id: str):\n   \"\"\"Retrieves status for a Turbinia Request.\n", "instance_id": "google__turbinia-1516", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "The problem statement is mostly clear in its intent to add an API endpoint for downloading a full request report in markdown format. The goal is explicitly stated, and the purpose (providing UX access to the report) is defined. However, there are minor ambiguities and missing details. For instance, the problem statement does not specify the expected format or structure of the markdown report, nor does it mention any constraints or specific requirements for the API endpoint (e.g., authentication, size limits, or error handling). Additionally, there are no examples provided for the input or expected output. While the intent is clear, these missing details prevent it from being comprehensive, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls in the medium range due to several factors. First, the scope of code changes involves multiple files, including the addition of a new API endpoint in the OpenAPI specification, implementation in the request routing logic, and a helper for markdown report generation. This requires understanding the existing FastAPI-based architecture and integrating with the Turbinia client library to fetch and format request data. Second, the technical concepts involved include familiarity with FastAPI routing, response handling (e.g., PlainTextResponse), JSON parsing, and markdown generation, which are moderately complex but not overly challenging for an experienced developer. Third, while the problem statement does not explicitly mention edge cases, the code changes suggest potential issues like handling invalid request IDs (with a 404 response) and error conditions during data retrieval or formatting (with a 500 response), indicating some need for error handling logic. However, these are not overly complex. The changes do not significantly impact the system's architecture, as they are additive rather than transformative. Overall, the task requires understanding multiple concepts and making targeted modifications across a few files, justifying a difficulty score of 0.45, which sits in the medium range (0.4-0.6).", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.45}
{"problem_statement": "Improve `repr`s for key Parcels classes\nSo far, we haven't really worked on the output of `print()` on objects like `Field`, `FieldSet` etc. While there is a [`ParticleSet.__repr__`](https://github.com/OceanParcels/Parcels/blob/5fff42c2ea4cc12d03df8c936dd391e251658c8f/parcels/particleset.py#L339-L340), even that is pretty clunky and doesn't take into account notebook functionality.\r\n\r\nIt would be nice to have better `print()` implementation for at least the following classes\r\n- [x] `Field`\r\n- [x] `FieldSet`\r\n- [x] `ParticleSet`\r\n- [x] `Particle`\r\n- [x] `ParticleFile`\r\n- ~~`Kernel`(?)~~ EDIT Vecko: Out of scope\nImprove `repr`s for key Parcels classes\nSo far, we haven't really worked on the output of `print()` on objects like `Field`, `FieldSet` etc. While there is a [`ParticleSet.__repr__`](https://github.com/OceanParcels/Parcels/blob/5fff42c2ea4cc12d03df8c936dd391e251658c8f/parcels/particleset.py#L339-L340), even that is pretty clunky and doesn't take into account notebook functionality.\r\n\r\nIt would be nice to have better `print()` implementation for at least the following classes\r\n- [x] `Field`\r\n- [x] `FieldSet`\r\n- [x] `ParticleSet`\r\n- [x] `Particle`\r\n- [x] `ParticleFile`\r\n- ~~`Kernel`(?)~~ EDIT Vecko: Out of scope\n", "patch": "diff --git a/docs/examples/parcels_tutorial.ipynb b/docs/examples/parcels_tutorial.ipynb\nindex 5936644aa..102a87419 100644\n--- a/docs/examples/parcels_tutorial.ipynb\n+++ b/docs/examples/parcels_tutorial.ipynb\n@@ -72,11 +72,41 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n    \"metadata\": {},\n-   \"outputs\": [],\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"<FieldSet>\\n\",\n+      \"    fields:\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'U'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00,  172800.00, ...,  432000.00,  518400.00,  604800.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'V'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00,  172800.00, ...,  432000.00,  518400.00,  604800.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <VectorField>\\n\",\n+      \"            name: 'UV'\\n\",\n+      \"            U: <parcels.field.Field object at 0x1580e0980>\\n\",\n+      \"            V: <parcels.field.Field object at 0x1585d8920>\\n\",\n+      \"            W: None\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n     \"example_dataset_folder = parcels.download_example_dataset(\\\"MovingEddies_data\\\")\\n\",\n     \"\\n\",\n-    \"fieldset = parcels.FieldSet.from_parcels(f\\\"{example_dataset_folder}/moving_eddies\\\")\"\n+    \"fieldset = parcels.FieldSet.from_parcels(f\\\"{example_dataset_folder}/moving_eddies\\\")\\n\",\n+    \"\\n\",\n+    \"print(fieldset)\"\n    ]\n   },\n   {\n@@ -152,8 +182,35 @@\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"P[0](lon=330000.000000, lat=100000.000000, depth=0.000000, time=not_yet_set)\\n\",\n-      \"P[1](lon=330000.000000, lat=280000.000000, depth=0.000000, time=not_yet_set)\\n\"\n+      \"<ParticleSet>\\n\",\n+      \"    fieldset   : <FieldSet>\\n\",\n+      \"    fields:\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'U'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'V'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <VectorField>\\n\",\n+      \"            name: 'UV'\\n\",\n+      \"            U: <parcels.field.Field object at 0x1580e0980>\\n\",\n+      \"            V: <parcels.field.Field object at 0x1585d8920>\\n\",\n+      \"            W: None\\n\",\n+      \"    pclass     : <class 'parcels.particle.JITParticle'>\\n\",\n+      \"    repeatdt   : None\\n\",\n+      \"    # particles: 2\\n\",\n+      \"    particles  : [\\n\",\n+      \"        P[0](lon=330000.000000, lat=100000.000000, depth=0.000000, time=not_yet_set),\\n\",\n+      \"        P[1](lon=330000.000000, lat=280000.000000, depth=0.000000, time=not_yet_set)\\n\",\n+      \"    ]\\n\"\n      ]\n     }\n    ],\n@@ -208,7 +265,7 @@\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n-    \"The final step is to run (or 'execute') the `ParticelSet`. We run the particles using the `AdvectionRK4` kernel, which is a 4th order Runge-Kutte implementation that comes with Parcels. We run the particles for 6 days (using the `timedelta` function from `datetime`), at an RK4 timestep of 5 minutes. We store the trajectory information at an interval of 1 hour in a file called `EddyParticles.zarr`. Because `time` was `not_yet_set`, the particles will be advected from the first date available in the `fieldset`, which is the default behaviour.\\n\"\n+    \"We can now create `ParticleFile` objects to store the output of the particles. We will store the output at an interval of 1 hour in a `zarr` file called `EddyParticles.zar`. See the [Working with Parcels output tutorial](https://docs.oceanparcels.org/en/latest/examples/tutorial_output.html) for more information on the `zarr` format.\"\n    ]\n   },\n   {\n@@ -220,8 +277,7 @@\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"INFO: Output files are stored in EddyParticles.zarr.\\n\",\n-      \"100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 518400.0/518400.0 [00:03<00:00, 172443.78it/s]\\n\"\n+      \"ParticleFile(name='EddyParticles.zarr', particleset=<parcels.particleset.ParticleSet object at 0x1584ee7e0>, outputdt=3600.0, chunks=None, create_new_zarrfile=True)\\n\"\n      ]\n     }\n    ],\n@@ -230,6 +286,32 @@\n     \"    name=\\\"EddyParticles.zarr\\\",  # the file name\\n\",\n     \"    outputdt=timedelta(hours=1),  # the time step of the outputs\\n\",\n     \")\\n\",\n+    \"\\n\",\n+    \"print(output_file)\"\n+   ]\n+  },\n+  {\n+   \"attachments\": {},\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The final step is to run (or 'execute') the `ParticelSet`. We run the particles using the `AdvectionRK4` kernel, which is a 4th order Runge-Kutte implementation that comes with Parcels. We run the particles for 6 days (using the `timedelta` function from `datetime`), at an RK4 timestep of 5 minutes. Because `time` was `not_yet_set`, the particles will be advected from the first date available in the `fieldset`, which is the default behaviour.\\n\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 8,\n+   \"metadata\": {},\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 518400.0/518400.0 [00:05<00:00, 95421.55it/s] \\n\"\n+     ]\n+    }\n+   ],\n+   \"source\": [\n     \"pset.execute(\\n\",\n     \"    parcels.AdvectionRK4,  # the kernel (which defines how particles move)\\n\",\n     \"    runtime=timedelta(days=6),  # the total length of the run\\n\",\n@@ -248,15 +330,42 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 9,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"P[0](lon=226905.562500, lat=82515.218750, depth=0.000000, time=518100.000000)\\n\",\n-      \"P[1](lon=260835.125000, lat=320403.343750, depth=0.000000, time=518100.000000)\\n\"\n+      \"<ParticleSet>\\n\",\n+      \"    fieldset   : <FieldSet>\\n\",\n+      \"    fields:\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'U'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 432000.00,  518400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'V'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 432000.00,  518400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <VectorField>\\n\",\n+      \"            name: 'UV'\\n\",\n+      \"            U: <parcels.field.Field object at 0x1580e0980>\\n\",\n+      \"            V: <parcels.field.Field object at 0x1585d8920>\\n\",\n+      \"            W: None\\n\",\n+      \"    pclass     : <class 'parcels.particle.JITParticle'>\\n\",\n+      \"    repeatdt   : None\\n\",\n+      \"    # particles: 2\\n\",\n+      \"    particles  : [\\n\",\n+      \"        P[0](lon=226905.562500, lat=82515.218750, depth=0.000000, time=518100.000000),\\n\",\n+      \"        P[1](lon=260835.125000, lat=320403.343750, depth=0.000000, time=518100.000000)\\n\",\n+      \"    ]\\n\"\n      ]\n     },\n     {\n@@ -300,7 +409,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 10,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -333,7 +442,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 10,\n+   \"execution_count\": 11,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -371,7 +480,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 11,\n+   \"execution_count\": 12,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13159,7 +13268,7 @@\n        \"<IPython.core.display.HTML object>\"\n       ]\n      },\n-     \"execution_count\": 11,\n+     \"execution_count\": 12,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -13186,7 +13295,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 12,\n+   \"execution_count\": 13,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13221,15 +13330,42 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 13,\n+   \"execution_count\": 14,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"P[0](lon=329983.281250, lat=100495.609375, depth=0.000000, time=300.000000)\\n\",\n-      \"P[1](lon=330289.968750, lat=280418.906250, depth=0.000000, time=300.000000)\\n\"\n+      \"<ParticleSet>\\n\",\n+      \"    fieldset   : <FieldSet>\\n\",\n+      \"    fields:\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'U'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <Field>\\n\",\n+      \"            name            : 'V'\\n\",\n+      \"            grid            : RectilinearZGrid(lon=array([ 0.00,  2010.05,  4020.10, ...,  395979.91,  397989.94,  400000.00], dtype=float32), lat=array([ 0.00,  2005.73,  4011.46, ...,  695988.56,  697994.25,  700000.00], dtype=float32), time=array([ 0.00,  86400.00]), time_origin=0.0, mesh='flat')\\n\",\n+      \"            extrapolate time: False\\n\",\n+      \"            time_periodic   : False\\n\",\n+      \"            gridindexingtype: 'nemo'\\n\",\n+      \"            to_write        : False\\n\",\n+      \"        <VectorField>\\n\",\n+      \"            name: 'UV'\\n\",\n+      \"            U: <parcels.field.Field object at 0x1580e0980>\\n\",\n+      \"            V: <parcels.field.Field object at 0x1585d8920>\\n\",\n+      \"            W: None\\n\",\n+      \"    pclass     : <class 'parcels.particle.JITParticle'>\\n\",\n+      \"    repeatdt   : None\\n\",\n+      \"    # particles: 2\\n\",\n+      \"    particles  : [\\n\",\n+      \"        P[0](lon=329983.281250, lat=100495.609375, depth=0.000000, time=300.000000),\\n\",\n+      \"        P[1](lon=330289.968750, lat=280418.906250, depth=0.000000, time=300.000000)\\n\",\n+      \"    ]\\n\"\n      ]\n     },\n     {\n@@ -13281,7 +13417,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 14,\n+   \"execution_count\": 15,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13308,7 +13444,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 15,\n+   \"execution_count\": 16,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13346,7 +13482,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 16,\n+   \"execution_count\": 17,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13405,7 +13541,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 17,\n+   \"execution_count\": 18,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13427,7 +13563,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 18,\n+   \"execution_count\": 19,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13448,7 +13584,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 19,\n+   \"execution_count\": 20,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13465,7 +13601,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 20,\n+   \"execution_count\": 21,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13488,7 +13624,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 21,\n+   \"execution_count\": 22,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13522,7 +13658,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 22,\n+   \"execution_count\": 23,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13568,7 +13704,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 23,\n+   \"execution_count\": 24,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13590,7 +13726,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 24,\n+   \"execution_count\": 25,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13620,7 +13756,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 25,\n+   \"execution_count\": 26,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13663,7 +13799,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 26,\n+   \"execution_count\": 27,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13715,7 +13851,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 28,\n+   \"execution_count\": 29,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13775,7 +13911,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 29,\n+   \"execution_count\": 30,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13802,7 +13938,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 30,\n+   \"execution_count\": 31,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13841,7 +13977,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 31,\n+   \"execution_count\": 32,\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n@@ -13871,7 +14007,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 32,\n+   \"execution_count\": 33,\n    \"metadata\": {},\n    \"outputs\": [\n     {\n@@ -13904,7 +14040,7 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 33,\n+   \"execution_count\": 34,\n    \"metadata\": {},\n    \"outputs\": [\n     {\ndiff --git a/parcels/field.py b/parcels/field.py\nindex c7f5d2eac..a8a79dfc6 100644\n--- a/parcels/field.py\n+++ b/parcels/field.py\n@@ -20,7 +20,7 @@\n     assert_valid_gridindexingtype,\n     assert_valid_interp_method,\n )\n-from parcels.tools._helpers import deprecated_made_private, timedelta_to_float\n+from parcels.tools._helpers import default_repr, deprecated_made_private, field_repr, timedelta_to_float\n from parcels.tools.converters import (\n     Geographic,\n     GeographicPolar,\n@@ -149,6 +149,8 @@ class Field:\n     * `Nested Fields <../examples/tutorial_NestedFields.ipynb>`__\n     \"\"\"\n \n+    allow_time_extrapolation: bool\n+    time_periodic: TimePeriodic\n     _cast_data_dtype: type[np.float32] | type[np.float64]\n \n     def __init__(\n@@ -321,6 +323,9 @@ def __init__(\n         if len(kwargs) > 0:\n             raise SyntaxError(f'Field received an unexpected keyword argument \"{list(kwargs.keys())[0]}\"')\n \n+    def __repr__(self) -> str:\n+        return field_repr(self)\n+\n     @property\n     @deprecated_made_private  # TODO: Remove 6 months after v3.1.0\n     def dataFiles(self):\n@@ -1915,6 +1920,14 @@ def __init__(self, name: str, U: Field, V: Field, W: Field | None = None):\n                 assert W.interp_method == \"cgrid_velocity\", \"Interpolation methods of U and W are not the same.\"\n                 assert self._check_grid_dimensions(U.grid, W.grid), \"Dimensions of U and W are not the same.\"\n \n+    def __repr__(self):\n+        w_repr = default_repr(self.W) if self.W is not None else repr(self.W)\n+        return f\"\"\"<{type(self).__name__}>\n+    name: {self.name!r}\n+    U: {default_repr(self.U)}\n+    V: {default_repr(self.V)}\n+    W: {w_repr}\"\"\"\n+\n     @staticmethod\n     def _check_grid_dimensions(grid1, grid2):\n         return (\ndiff --git a/parcels/fieldset.py b/parcels/fieldset.py\nindex aad0635fa..9a7fd39da 100644\n--- a/parcels/fieldset.py\n+++ b/parcels/fieldset.py\n@@ -14,7 +14,7 @@\n from parcels.grid import Grid\n from parcels.gridset import GridSet\n from parcels.particlefile import ParticleFile\n-from parcels.tools._helpers import deprecated_made_private\n+from parcels.tools._helpers import deprecated_made_private, fieldset_repr\n from parcels.tools.converters import TimeConverter, convert_xarray_time_units\n from parcels.tools.loggers import logger\n from parcels.tools.statuscodes import TimeExtrapolationError\n@@ -56,6 +56,9 @@ def __init__(self, U: Field | NestedField | None, V: Field | NestedField | None,\n         self.compute_on_defer = None\n         self._add_UVfield()\n \n+    def __repr__(self):\n+        return fieldset_repr(self)\n+\n     @property\n     def particlefile(self):\n         return self._particlefile\ndiff --git a/parcels/particle.py b/parcels/particle.py\nindex c7f1681e0..87dce269f 100644\n--- a/parcels/particle.py\n+++ b/parcels/particle.py\n@@ -53,7 +53,7 @@ def __set__(self, instance, value):\n             setattr(instance, f\"_{self.name}\", value)\n \n     def __repr__(self):\n-        return f\"PVar<{self.name}|{self.dtype}>\"\n+        return f\"Variable(name={self._name}, dtype={self.dtype}, initial={self.initial}, to_write={self.to_write})\"\n \n     def is64bit(self):\n         \"\"\"Check whether variable is 64-bit.\"\"\"\ndiff --git a/parcels/particlefile.py b/parcels/particlefile.py\nindex c8482b9e6..4ab406b4a 100644\n--- a/parcels/particlefile.py\n+++ b/parcels/particlefile.py\n@@ -10,7 +10,7 @@\n \n import parcels\n from parcels._compat import MPI\n-from parcels.tools._helpers import deprecated, deprecated_made_private, timedelta_to_float\n+from parcels.tools._helpers import default_repr, deprecated, deprecated_made_private, timedelta_to_float\n from parcels.tools.warnings import FileWarning\n \n __all__ = [\"ParticleFile\"]\n@@ -116,6 +116,16 @@ def __init__(self, name, particleset, outputdt=np.inf, chunks=None, create_new_z\n                 fname = name if extension in [\".zarr\"] else f\"{name}.zarr\"\n         self._fname = fname\n \n+    def __repr__(self) -> str:\n+        return (\n+            f\"{type(self).__name__}(\"\n+            f\"name={self.fname!r}, \"\n+            f\"particleset={default_repr(self.particleset)}, \"\n+            f\"outputdt={self.outputdt!r}, \"\n+            f\"chunks={self.chunks!r}, \"\n+            f\"create_new_zarrfile={self.create_new_zarrfile!r})\"\n+        )\n+\n     @property\n     def create_new_zarrfile(self):\n         return self._create_new_zarrfile\ndiff --git a/parcels/particleset.py b/parcels/particleset.py\nindex 1fde32ca6..ffe7eb652 100644\n--- a/parcels/particleset.py\n+++ b/parcels/particleset.py\n@@ -27,7 +27,7 @@\n from parcels.particle import JITParticle, Variable\n from parcels.particledata import ParticleData, ParticleDataIterator\n from parcels.particlefile import ParticleFile\n-from parcels.tools._helpers import deprecated, deprecated_made_private, timedelta_to_float\n+from parcels.tools._helpers import deprecated, deprecated_made_private, particleset_repr, timedelta_to_float\n from parcels.tools.converters import _get_cftime_calendars, convert_to_flat_array\n from parcels.tools.global_statics import get_package_dir\n from parcels.tools.loggers import logger\n@@ -112,6 +112,7 @@ def __init__(\n         self.fieldset = fieldset\n         self.fieldset._check_complete()\n         self.time_origin = fieldset.time_origin\n+        self._pclass = pclass\n \n         # ==== first: create a new subclass of the pclass that includes the required variables ==== #\n         # ==== see dynamic-instantiation trick here: https://www.python-course.eu/python3_classes_and_type.php ==== #\n@@ -386,8 +387,12 @@ def size(self):\n         # ==== to change at some point - len and size are different things ==== #\n         return len(self.particledata)\n \n+    @property\n+    def pclass(self):\n+        return self._pclass\n+\n     def __repr__(self):\n-        return \"\\n\".join([str(p) for p in self])\n+        return particleset_repr(self)\n \n     def __len__(self):\n         return len(self.particledata)\ndiff --git a/parcels/tools/_helpers.py b/parcels/tools/_helpers.py\nindex 24c8ba9c4..9078690cc 100644\n--- a/parcels/tools/_helpers.py\n+++ b/parcels/tools/_helpers.py\n@@ -1,12 +1,19 @@\n \"\"\"Internal helpers for Parcels.\"\"\"\n \n+from __future__ import annotations\n+\n import functools\n+import textwrap\n import warnings\n from collections.abc import Callable\n from datetime import timedelta\n+from typing import TYPE_CHECKING, Any\n \n import numpy as np\n \n+if TYPE_CHECKING:\n+    from parcels import Field, FieldSet, ParticleSet\n+\n PACKAGE = \"Parcels\"\n \n \n@@ -61,6 +68,77 @@ def patch_docstring(obj: Callable, extra: str) -> None:\n     obj.__doc__ = f\"{obj.__doc__ or ''}{extra}\".strip()\n \n \n+def field_repr(field: Field) -> str:\n+    \"\"\"Return a pretty repr for Field\"\"\"\n+    out = f\"\"\"<{type(field).__name__}>\n+    name            : {field.name!r}\n+    grid            : {field.grid!r}\n+    extrapolate time: {field.allow_time_extrapolation!r}\n+    time_periodic   : {field.time_periodic!r}\n+    gridindexingtype: {field.gridindexingtype!r}\n+    to_write        : {field.to_write!r}\n+\"\"\"\n+    return textwrap.dedent(out).strip()\n+\n+\n+def _format_list_items_multiline(items: list[str], level: int = 1) -> str:\n+    \"\"\"Given a list of strings, formats them across multiple lines.\n+\n+    Uses indentation levels of 4 spaces provided by ``level``.\n+\n+    Example\n+    -------\n+    >>> output = _format_list_items_multiline([\"item1\", \"item2\", \"item3\"], 4)\n+    >>> f\"my_items: {output}\"\n+    my_items: [\n+        item1,\n+        item2,\n+        item3,\n+    ]\n+    \"\"\"\n+    if len(items) == 0:\n+        return \"[]\"\n+\n+    assert level >= 1, \"Indentation level >=1 supported\"\n+    indentation_str = level * 4 * \" \"\n+    indentation_str_end = (level - 1) * 4 * \" \"\n+\n+    items_str = \",\\n\".join([textwrap.indent(i, indentation_str) for i in items])\n+    return f\"[\\n{items_str}\\n{indentation_str_end}]\"\n+\n+\n+def particleset_repr(pset: ParticleSet) -> str:\n+    \"\"\"Return a pretty repr for ParticleSet\"\"\"\n+    if len(pset) < 10:\n+        particles = [repr(p) for p in pset]\n+    else:\n+        particles = [repr(pset[i]) for i in range(7)] + [\"...\"]\n+\n+    out = f\"\"\"<{type(pset).__name__}>\n+    fieldset   : {pset.fieldset}\n+    pclass     : {pset.pclass}\n+    repeatdt   : {pset.repeatdt}\n+    # particles: {len(pset)}\n+    particles  : {_format_list_items_multiline(particles, level=2)}\n+\"\"\"\n+    return textwrap.dedent(out).strip()\n+\n+\n+def fieldset_repr(fieldset: FieldSet) -> str:\n+    \"\"\"Return a pretty repr for FieldSet\"\"\"\n+    fields_repr = \"\\n\".join([repr(f) for f in fieldset.get_fields()])\n+\n+    out = f\"\"\"<{type(fieldset).__name__}>\n+    fields:\n+{textwrap.indent(fields_repr, 8 * \" \")}\n+\"\"\"\n+    return textwrap.dedent(out).strip()\n+\n+\n+def default_repr(obj: Any):\n+    return object.__repr__(obj)\n+\n+\n def timedelta_to_float(dt: float | timedelta | np.timedelta64) -> float:\n     \"\"\"Convert a timedelta to a float in seconds.\"\"\"\n     if isinstance(dt, timedelta):\n", "instance_id": "OceanParcels__Parcels-1743", "clarity": 2, "difficulty": 0.35, "clarity_explanation": "\nThe problem statement is mostly clear in its intent to improve the `repr` (string representation) for several key classes in the Parcels library (`Field`, `FieldSet`, `ParticleSet`, `Particle`, and `ParticleFile`). It specifies the goal of enhancing the output of `print()` for better readability and mentions the consideration of notebook functionality, which implies compatibility with environments like Jupyter notebooks. The statement also references an existing implementation for `ParticleSet.__repr__` as a starting point, which provides some context. However, there are minor ambiguities and missing details that prevent it from being comprehensive. For instance, it does not explicitly define what constitutes a \"better\" `print()` implementation\u2014whether it should prioritize specific attributes, formatting styles, or handle specific use cases (e.g., large datasets). Additionally, there are no explicit constraints or requirements for edge cases, such as how to handle very large objects or nested structures in the representation. While the code changes provide insight into the expected output format, the problem statement itself lacks examples or detailed guidelines on the desired output structure. Thus, while the problem is valid and mostly clear, these minor gaps in specificity result in a clarity score of 2 (Mostly Clear).\n", "difficulty_explanation": "\nI assign a difficulty score of 0.35, placing this problem in the \"Easy\" range (0.2-0.4), as it requires understanding some code logic and making relatively simple modifications across multiple files. Here's the breakdown based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes**: The code changes involve multiple files (`field.py`, `fieldset.py`, `particle.py`, `particlefile.py`, `particleset.py`, and a tutorial notebook), indicating a moderate scope. However, the modifications are focused on implementing or updating the `__repr__` method for several classes, which is a straightforward task. The changes do not impact the system's architecture or core functionality; they are purely cosmetic, aimed at improving output readability. The amount of code change is moderate, with new helper functions in `_helpers.py` and updates to class representations, but it does not involve complex logic or deep refactoring.\n\n2. **Number of Technical Concepts**: The problem requires understanding basic Python concepts, primarily the `__repr__` method and string formatting. It also involves familiarity with the Parcels library's class structure and attributes to decide what information to include in the representations. Additional concepts include handling indentation and multiline formatting (via `textwrap` in the helper functions) and ensuring compatibility with notebook environments (though this is not deeply explored in the changes). These concepts are not particularly complex for a developer with moderate Python experience, and no advanced algorithms, design patterns, or domain-specific knowledge (beyond basic familiarity with Parcels) are required.\n\n3. **Potential Edge Cases and Error Handling**: The problem statement does not mention specific edge cases, and the code changes do not introduce significant error handling logic. However, there are implicit considerations, such as handling large numbers of particles in `ParticleSet` (addressed by truncating the list with \"...\" in the code) and ensuring readable output for nested structures (e.g., `FieldSet` containing multiple `Field` objects). These edge cases are handled in a basic manner and do not add significant complexity to the task.\n\n4. **Overall Complexity**: The task is relatively straightforward\u2014implementing string representations for better user experience. It requires understanding the structure of the classes and deciding on a consistent formatting style, but it does not involve deep architectural changes, performance optimization, or complex logic. The primary challenge lies in ensuring consistency across different classes and making the output user-friendly, which is more of a design consideration than a technical one.\n\nGiven these factors, the problem leans toward the higher end of \"Easy\" due to the need to modify multiple files and ensure consistent formatting, but it does not reach \"Medium\" difficulty (0.4-0.6) as it lacks complex logic, significant edge case handling, or deep codebase understanding beyond surface-level class attributes. A score of 0.35 reflects this balance.\n", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.35}
{"problem_statement": "BUG: duplicate names `lanczos_params` and `lanczos_options` in TDVP and VUMPS\nThe TDVP is now derived from the Sweep class. The Sweep class reads out  `lanczos_params` (as documented, and saved as `self.lanczos_params`, since this is what we had in the original DMRG implementation.\r\n\r\nOn the other hand, the original TDVP implementation had `lanczos_options`, and those are the ones used in `TwoSiteTDVP.update_local()`.\r\n\r\nThe best way forward retaining backwards compatibility is probably to define the lanczos_options as deprecated alias in the TDVP config and add a deprecated property access of `TDVPEngine.lanczos_options`\r\n Given that the lanczos_options haven't been used in any of the examples, I hope this isn't super annoying for users.\r\n\r\n\nCommensurate supersolids and re-entrant transitions in an extended Bose-Hubbard ladder [https://arxiv.org/abs/2407.20107v2]\nWe have used TeNPy in a recent work:  https://arxiv.org/abs/2407.20107v2\r\n\r\nPlease include it into the list of [papers using TeNPy](https://tenpy.readthedocs.io/en/latest/papers_using_tenpy.html)\r\n\n", "patch": "diff --git a/doc/conf.py b/doc/conf.py\nindex 465941c40..f4d075a42 100644\n--- a/doc/conf.py\n+++ b/doc/conf.py\n@@ -386,7 +386,10 @@ def linkcode_resolve(domain, info):\n \n # -- sphinxcontrib.bibtex -------------------------------------------------\n \n-bibtex_bibfiles = ['literature.bib', 'papers_using_tenpy.bib']\n+bibtex_bibfiles = ['literature.bib', 'papers_using_tenpy.bib', 'theses.bib']\n+# note: these bib files are exported from the Zotero library\n+# https://www.zotero.org/groups/2569413/tenpy/library\n+# with the `betterbibtex` add-on, sorting by bibtex key (can be changed in addon settings).\n \n from pybtex.style.formatting.unsrt import Style as UnsrtStyle\n from pybtex.style.labels import BaseLabelStyle\ndiff --git a/doc/literature.bib b/doc/literature.bib\nindex be19d4cea..9a72d231a 100644\n--- a/doc/literature.bib\n+++ b/doc/literature.bib\n@@ -21,7 +21,7 @@ @article{barthel2016\n   eprint = {1607.01696},\n   pages = {115157},\n   doi = {10.1103/PhysRevB.94.115157},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{barthel2020,\n@@ -34,7 +34,7 @@ @article{barthel2020\n   eprint = {1901.04974},\n   pages = {168165},\n   doi = {10.1016/j.aop.2020.168165},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{calabrese2004,\n@@ -48,7 +48,7 @@ @article{calabrese2004\n   eprint = {hep-th/0405152},\n   pages = {P06002},\n   doi = {10.1088/1742-5468/2004/06/P06002},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cincio2013,\n@@ -62,7 +62,7 @@ @article{cincio2013\n   eprint = {1208.2623},\n   pages = {067208},\n   doi = {10.1103/PhysRevLett.110.067208},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cirac2009,\n@@ -76,7 +76,7 @@ @article{cirac2009\n   eprint = {0910.1130},\n   pages = {504004},\n   doi = {10.1088/1751-8113/42/50/504004},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cirac2020,\n@@ -88,7 +88,7 @@ @article{cirac2020\n   journal = {arXiv:2011.12127 [cond-mat, physics:hep-th, physics:quant-ph]},\n   eprint = {2011.12127},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{eisert2013,\n@@ -99,11 +99,11 @@ @article{eisert2013\n   journal = {arXiv:1308.3318 [cond-mat, physics:quant-ph]},\n   eprint = {1308.3318},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{grushin2015,\n-  title = {Characterization and Stability of a Fermionic {\\textbackslash}nu=1/3 Fractional {{Chern}} Insulator},\n+  title = {Characterization and Stability of a Fermionic \\textbackslash nu=1/3 Fractional {{Chern}} Insulator},\n   author = {Grushin, Adolfo G. and Motruk, Johannes and Zaletel, Michael P. and Pollmann, Frank},\n   year = {2015},\n   month = jan,\n@@ -113,7 +113,7 @@ @article{grushin2015\n   eprint = {1407.6985},\n   pages = {035136},\n   doi = {10.1103/PhysRevB.91.035136},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{haegeman2011,\n@@ -127,21 +127,20 @@ @article{haegeman2011\n   eprint = {1103.0936},\n   pages = {070601},\n   doi = {10.1103/PhysRevLett.107.070601},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{haegeman2012,\n-  title = {Variational matrix product ansatz for dispersion relations},\n+  title = {Variational Matrix Product Ansatz for Dispersion Relations},\n   author = {Haegeman, Jutho and Pirvu, Bogdan and Weir, David J. and Cirac, J. Ignacio and Osborne, Tobias J. and Verschelde, Henri and Verstraete, Frank},\n   year = {2012},\n   month = mar,\n   journal = {Physical Review B},\n   volume = {85},\n   number = {10},\n-  eprint = {1103.2286},\n   pages = {100408},\n-  doi = {10.1103/PhysRevB.85.100408},\n-  archiveprefix = {arxiv}\n+  publisher = {American Physical Society},\n+  doi = {10.1103/PhysRevB.85.100408}\n }\n \n @article{haegeman2016,\n@@ -155,7 +154,7 @@ @article{haegeman2016\n   eprint = {1408.5056},\n   pages = {165116},\n   doi = {10.1103/PhysRevB.94.165116},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hauschild2018,\n@@ -169,7 +168,7 @@ @article{hauschild2018\n   eprint = {1711.01288},\n   pages = {235163},\n   doi = {10.1103/PhysRevB.98.235163},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hauschild2018a,\n@@ -182,12 +181,12 @@ @article{hauschild2018a\n   eprint = {1805.00055},\n   pages = {5},\n   doi = {10.21468/SciPostPhysLectNotes.5},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hubig2015,\n   title = {A {{Strictly Single-Site DMRG Algorithm}} with {{Subspace Expansion}}},\n-  author = {Hubig, Claudius and McCulloch, Ian P. and Schollw{\\\"o}ck, Ulrich and Wolf, F. Alexander},\n+  author = {Hubig, Claudius and McCulloch, Ian P. and Schollw\u00f6ck, Ulrich and Wolf, F. Alexander},\n   year = {2015},\n   month = apr,\n   journal = {Physical Review B},\n@@ -196,7 +195,7 @@ @article{hubig2015\n   eprint = {1501.05504},\n   pages = {155115},\n   doi = {10.1103/PhysRevB.91.155115},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{karrasch2013,\n@@ -210,7 +209,20 @@ @article{karrasch2013\n   eprint = {1303.3942},\n   pages = {083031},\n   doi = {10.1088/1367-2630/15/8/083031},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@article{mcculloch2002,\n+  title = {The Non-{{Abelian}} Density Matrix Renormalization Group Algorithm},\n+  author = {McCulloch, I. P. and Gul\u00e1csi, M.},\n+  year = {2002},\n+  month = mar,\n+  journal = {EPL (Europhysics Letters)},\n+  volume = {57},\n+  number = {6},\n+  pages = {852},\n+  publisher = {IOP Publishing},\n+  doi = {10.1209/epl/i2002-00393-0}\n }\n \n @article{mcculloch2008,\n@@ -221,7 +233,7 @@ @article{mcculloch2008\n   journal = {arXiv:0804.2509 [cond-mat]},\n   eprint = {0804.2509},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{milsted2013,\n@@ -235,7 +247,7 @@ @article{milsted2013\n   eprint = {1207.0691},\n   pages = {155116},\n   doi = {10.1103/PhysRevB.88.155116},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{motruk2016,\n@@ -249,7 +261,7 @@ @article{motruk2016\n   eprint = {1512.03318},\n   pages = {155139},\n   doi = {10.1103/PhysRevB.93.155139},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{murg2010,\n@@ -263,7 +275,7 @@ @article{murg2010\n   eprint = {0804.3976},\n   pages = {025012},\n   doi = {10.1088/1367-2630/12/2/025012},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{neupert2011,\n@@ -277,7 +289,7 @@ @article{neupert2011\n   eprint = {1012.4723},\n   pages = {236804},\n   doi = {10.1103/PhysRevLett.106.236804},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{orus2014,\n@@ -291,12 +303,12 @@ @article{orus2014\n   eprint = {1306.2164},\n   pages = {117--158},\n   doi = {10.1016/j.aop.2014.06.013},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{paeckel2019,\n   title = {Time-Evolution Methods for Matrix-Product States},\n-  author = {Paeckel, Sebastian and K{\\\"o}hler, Thomas and Swoboda, Andreas and Manmana, Salvatore R. and Schollw{\\\"o}ck, Ulrich and Hubig, Claudius},\n+  author = {Paeckel, Sebastian and K\u00f6hler, Thomas and Swoboda, Andreas and Manmana, Salvatore R. and Schollw\u00f6ck, Ulrich and Hubig, Claudius},\n   year = {2019},\n   month = dec,\n   journal = {Annals of Physics},\n@@ -304,7 +316,7 @@ @article{paeckel2019\n   eprint = {1901.05824},\n   pages = {167998},\n   doi = {10.1016/j.aop.2019.167998},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{phien2012,\n@@ -318,12 +330,12 @@ @article{phien2012\n   eprint = {1207.0652},\n   pages = {245107},\n   doi = {10.1103/PhysRevB.86.245107},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{phien2013,\n   title = {Dynamical Windows for Real-Time Evolution with Matrix Product States},\n-  author = {Phien, Ho N. and Vidal, Guifr{\\'e} and McCulloch, Ian P.},\n+  author = {Phien, Ho N. and Vidal, Guifr\u00e9 and McCulloch, Ian P.},\n   year = {2013},\n   month = jul,\n   journal = {Physical Review B},\n@@ -332,7 +344,7 @@ @article{phien2013\n   eprint = {1207.0678},\n   pages = {035103},\n   doi = {10.1103/PhysRevB.88.035103},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{pollmann2009,\n@@ -346,7 +358,7 @@ @article{pollmann2009\n   eprint = {0812.2903},\n   pages = {255701},\n   doi = {10.1103/PhysRevLett.102.255701},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{pollmann2012,\n@@ -360,7 +372,7 @@ @article{pollmann2012\n   eprint = {1204.0704},\n   pages = {125441},\n   doi = {10.1103/PhysRevB.86.125441},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{resta1998,\n@@ -386,7 +398,7 @@ @article{schollwoeck2011\n   eprint = {1008.3477},\n   pages = {96--192},\n   doi = {10.1016/j.aop.2010.09.012},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{schuch2013,\n@@ -398,7 +410,7 @@ @article{schuch2013\n   journal = {arXiv:1306.5551 [cond-mat, physics:quant-ph]},\n   eprint = {1306.5551},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{shapourian2017,\n@@ -412,7 +424,7 @@ @article{shapourian2017\n   eprint = {1607.03896},\n   pages = {216402},\n   doi = {10.1103/PhysRevLett.118.216402},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{singh2010,\n@@ -426,7 +438,7 @@ @article{singh2010\n   eprint = {0907.2994},\n   pages = {050301},\n   doi = {10.1103/PhysRevA.82.050301},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{singh2011,\n@@ -440,7 +452,7 @@ @article{singh2011\n   eprint = {1008.4774},\n   pages = {115125},\n   doi = {10.1103/PhysRevB.83.115125},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{stoudenmire2010,\n@@ -454,7 +466,7 @@ @article{stoudenmire2010\n   eprint = {1002.1305},\n   pages = {055026},\n   doi = {10.1088/1367-2630/12/5/055026},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{stoudenmire2012,\n@@ -468,11 +480,11 @@ @article{stoudenmire2012\n   eprint = {1105.1374},\n   pages = {111--128},\n   doi = {10.1146/annurev-conmatphys-020911-125018},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{suzuki1991,\n-  title = {General Theory of Fractal Path Integrals with Applications to Many-body Theories and Statistical Physics},\n+  title = {General Theory of Fractal Path Integrals with Applications to Many\u2010body Theories and Statistical Physics},\n   author = {Suzuki, Masuo},\n   year = {1991},\n   month = feb,\n@@ -492,7 +504,7 @@ @article{vanderstraeten2019\n   eprint = {1810.07006},\n   pages = {7},\n   doi = {10.21468/SciPostPhysLectNotes.7},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{verstraete2008,\n@@ -506,7 +518,7 @@ @article{verstraete2008\n   eprint = {0907.2796},\n   pages = {143--224},\n   doi = {10.1080/14789940801912366},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{vidal2004,\n@@ -520,7 +532,7 @@ @article{vidal2004\n   eprint = {quant-ph/0310089},\n   pages = {040502},\n   doi = {10.1103/PhysRevLett.93.040502},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{vidal2007,\n@@ -570,7 +582,7 @@ @article{white2005\n   eprint = {cond-mat/0508709},\n   pages = {180403},\n   doi = {10.1103/PhysRevB.72.180403},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{white2009,\n@@ -583,9 +595,9 @@ @article{white2009\n   number = {19},\n   eprint = {0902.4475},\n   pages = {190601},\n-  publisher = {{American Physical Society}},\n+  publisher = {American Physical Society},\n   doi = {10.1103/PhysRevLett.102.190601},\n-  archiveprefix = {arxiv},\n+  archiveprefix = {arXiv},\n   isbn = {doi:10.1103/PhysRevLett.102.190601},\n   pmid = {19518934}\n }\n@@ -601,7 +613,7 @@ @article{yang2012\n   eprint = {1205.5792},\n   pages = {241112},\n   doi = {10.1103/PhysRevB.86.241112},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{zaletel2015,\n@@ -615,7 +627,7 @@ @article{zaletel2015\n   eprint = {1407.1832},\n   pages = {165112},\n   doi = {10.1103/PhysRevB.91.165112},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{zauner-stauber2018,\n@@ -630,7 +642,7 @@ @article{zauner-stauber2018\n   primaryclass = {cond-mat, physics:quant-ph},\n   pages = {045145},\n   doi = {10.1103/PhysRevB.97.045145},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{zauner2015,\n@@ -645,5 +657,5 @@ @article{zauner2015\n   eprint = {1207.0862},\n   pages = {425602},\n   doi = {10.1088/0953-8984/27/42/425602},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\ndiff --git a/doc/literature.rst b/doc/literature.rst\nindex a10b0bd04..513b2ab90 100644\n--- a/doc/literature.rst\n+++ b/doc/literature.rst\n@@ -110,3 +110,13 @@ References\n .. bibliography:: literature.bib\n     :style: custom1\n     :all:\n+\n+\n+PhD theses\n+----------\n+For inspiration, we also (somewhat randomly) list a few PhD theses related to tensor networks (accessible online) - they\n+often provide a very good introduction to some specific topic.\n+\n+.. bibliography:: theses.bib\n+    :all:\n+    :style: custom2\ndiff --git a/doc/papers_using_tenpy.bib b/doc/papers_using_tenpy.bib\nindex f1a8ad736..98ccb94da 100644\n--- a/doc/papers_using_tenpy.bib\n+++ b/doc/papers_using_tenpy.bib\n@@ -1,12 +1,25 @@\n+@misc{adler2024,\n+  title = {Observation of {{Hilbert-space}} Fragmentation and Fractonic Excitations in Two-Dimensional {{Hubbard}} Systems},\n+  author = {Adler, Daniel and Wei, David and Will, Melissa and Srakaew, Kritsana and Agrawal, Suchita and Weckesser, Pascal and Moessner, Roderich and Pollmann, Frank and Bloch, Immanuel and Zeiher, Johannes},\n+  year = {2024},\n+  month = apr,\n+  number = {arXiv:2404.14896},\n+  eprint = {2404.14896},\n+  primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2404.14896},\n+  archiveprefix = {arXiv}\n+}\n+\n @article{alsallom2021,\n   title = {Fate of the Non-{{Hermitian}} Skin Effect in Many-Body Fermionic Systems},\n-  author = {Alsallom, Faisal and Herviou, Lo{\\\"i}c and Yazyev, Oleg V. and Brzezi{\\'n}ska, Marta},\n+  author = {Alsallom, Faisal and Herviou, Lo\u00efc and Yazyev, Oleg V. and Brzezi\u0144ska, Marta},\n   year = {2021},\n   month = oct,\n   journal = {arXiv:2110.13164 [cond-mat]},\n   eprint = {2110.13164},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{amin2023,\n@@ -17,9 +30,9 @@ @misc{amin2023\n   number = {arXiv:2311.01306},\n   eprint = {2311.01306},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.01306},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{anand2022,\n@@ -30,24 +43,24 @@ @misc{anand2022\n   number = {arXiv:2203.00886},\n   eprint = {2203.00886},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.00886},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{andrews2020,\n-  title = {Abelian Topological Order of {\\textbackslash}nu=2/5 and 3/7 Fractional Quantum {{Hall}} States in Lattice Models},\n+  title = {Abelian Topological Order of \\textbackslash nu=2/5 and 3/7 Fractional Quantum {{Hall}} States in Lattice Models},\n   author = {Andrews, Bartholomew and Mohan, Madhav and Neupert, Titus},\n   year = {2020},\n   month = aug,\n   journal = {arXiv:2007.08870 [cond-mat]},\n   eprint = {2007.08870},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{andrews2020a,\n-  title = {Fractional Quantum {{Hall}} States for Moir{\\textbackslash}'e Superstructures in the {{Hofstadter}} Regime},\n+  title = {Fractional Quantum {{Hall}} States for Moir\\textbackslash 'e Superstructures in the {{Hofstadter}} Regime},\n   author = {Andrews, Bartholomew and Soluyanov, Alexey},\n   year = {2020},\n   month = jun,\n@@ -57,12 +70,12 @@ @article{andrews2020a\n   eprint = {2004.06602},\n   pages = {235312},\n   doi = {10.1103/PhysRevB.101.235312},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{andrews2021,\n   title = {Stability, Phase Transitions, and Numerical Breakdown of Fractional {{Chern}} Insulators in Higher {{Chern}} Bands of the {{Hofstadter}} Model},\n-  author = {Andrews, Bartholomew and Neupert, Titus and M{\\\"o}ller, Gunnar},\n+  author = {Andrews, Bartholomew and Neupert, Titus and M\u00f6ller, Gunnar},\n   year = {2021},\n   month = sep,\n   journal = {Physical Review B},\n@@ -71,33 +84,33 @@ @article{andrews2021\n   eprint = {2107.06047},\n   pages = {125107},\n   doi = {10.1103/PhysRevB.104.125107},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{arguello-luengo2022,\n   title = {Tuning Long-Range Fermion-Mediated Interactions in Cold-Atom Quantum Simulators},\n-  author = {{Arg{\\\"u}ello-Luengo}, Javier and {Gonz{\\'a}lez-Tudela}, Alejandro and {Gonz{\\'a}lez-Cuadra}, Daniel},\n+  author = {{Arg\u00fcello-Luengo}, Javier and {Gonz\u00e1lez-Tudela}, Alejandro and {Gonz\u00e1lez-Cuadra}, Daniel},\n   year = {2022},\n   month = mar,\n   number = {arXiv:2203.17022},\n   eprint = {2203.17022},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.17022},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{arguello-luengo2023,\n   title = {Stabilization of {{Hubbard-Thouless}} Pumps through Nonlocal Fermionic Repulsion},\n-  author = {{Arg{\\\"u}ello-Luengo}, Javier and Mark, Manfred J. and Ferlaino, Francesca and Lewenstein, Maciej and Barbiero, Luca and {Juli{\\`a}-Farr{\\'e}}, Sergi},\n+  author = {{Arg\u00fcello-Luengo}, Javier and Mark, Manfred J. and Ferlaino, Francesca and Lewenstein, Maciej and Barbiero, Luca and {Juli\u00e0-Farr\u00e9}, Sergi},\n   year = {2023},\n   month = sep,\n   number = {arXiv:2308.13375},\n   eprint = {2308.13375},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2308.13375},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{banuls2020,\n@@ -111,7 +124,20 @@ @article{banuls2020\n   eprint = {1912.08836},\n   pages = {033301},\n   doi = {10.1103/PhysRevResearch.2.033301},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{bao2024,\n+  title = {Magnon {{Spectra}} of {{Cuprates}} beyond {{Spin Wave Theory}}},\n+  author = {Bao, Jiahui and Gohlke, Matthias and Rau, Jeffrey G. and Shannon, Nic},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.20501},\n+  eprint = {2407.20501},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.20501},\n+  archiveprefix = {arXiv}\n }\n \n @misc{bauer2023,\n@@ -122,23 +148,23 @@ @misc{bauer2023\n   number = {arXiv:2301.04250},\n   eprint = {2301.04250},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.04250},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{beck2024,\n   title = {Phase Diagram of the \\${{J}}\\$-\\${{J}}\\_d\\$ {{Heisenberg Model}} on the {{Maple-Leaf Lattice}}: {{Neural}} Networks and Density Matrix Renormalization Group},\n   shorttitle = {Phase Diagram of the \\${{J}}\\$-\\${{J}}\\_d\\$ {{Heisenberg Model}} on the {{Maple-Leaf Lattice}}},\n-  author = {Beck, Jonas and Bodky, Jonathan and Motruk, Johannes and M{\\\"u}ller, Tobias and Thomale, Ronny and Ghosh, Pratyay},\n+  author = {Beck, Jonas and Bodky, Jonathan and Motruk, Johannes and M\u00fcller, Tobias and Thomale, Ronny and Ghosh, Pratyay},\n   year = {2024},\n   month = jan,\n   number = {arXiv:2401.04995},\n   eprint = {2401.04995},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.04995},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{beradze2023,\n@@ -149,9 +175,9 @@ @misc{beradze2023\n   number = {arXiv:2305.06911},\n   eprint = {2305.06911},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.06911},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{bhakuni2022,\n@@ -162,9 +188,9 @@ @misc{bhakuni2022\n   number = {arXiv:2202.07436},\n   eprint = {2202.07436},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.07436},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{birnkammer2020,\n@@ -175,7 +201,7 @@ @article{birnkammer2020\n   journal = {arXiv:2012.09185 [cond-mat, physics:quant-ph]},\n   eprint = {2012.09185},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{birnkammer2022,\n@@ -186,9 +212,9 @@ @misc{birnkammer2022\n   number = {arXiv:2202.12908},\n   eprint = {2202.12908},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.12908},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{birnkammer2023,\n@@ -199,9 +225,9 @@ @misc{birnkammer2023\n   number = {arXiv:2310.04500},\n   eprint = {2310.04500},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.04500},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{block2023,\n@@ -212,9 +238,9 @@ @misc{block2023\n   number = {arXiv:2301.09636},\n   eprint = {2301.09636},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.09636},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{boesl2021,\n@@ -225,7 +251,7 @@ @article{boesl2021\n   journal = {arXiv:2111.11446 [cond-mat, physics:quant-ph]},\n   eprint = {2111.11446},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{boesl2023,\n@@ -236,9 +262,9 @@ @misc{boesl2023\n   number = {arXiv:2311.08455},\n   eprint = {2311.08455},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.08455},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{bohrdt2019,\n@@ -249,18 +275,18 @@ @article{bohrdt2019\n   journal = {arXiv:1907.08214 [cond-mat, physics:quant-ph]},\n   eprint = {1907.08214},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{bohrdt2020,\n   title = {Dominant Fifth-Order Correlations in Doped Quantum Anti-Ferromagnets},\n-  author = {Bohrdt, A. and Wang, Y. and Koepsell, J. and {K{\\'a}nasz-Nagy}, M. and Demler, E. and Grusdt, F.},\n+  author = {Bohrdt, A. and Wang, Y. and Koepsell, J. and {K\u00e1nasz-Nagy}, M. and Demler, E. and Grusdt, F.},\n   year = {2020},\n   month = jul,\n   journal = {arXiv:2007.07249 [cond-mat, physics:quant-ph]},\n   eprint = {2007.07249},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{bohrdt2021,\n@@ -271,7 +297,7 @@ @article{bohrdt2021\n   journal = {arXiv:2101.09280 [cond-mat, physics:hep-th, physics:quant-ph]},\n   eprint = {2101.09280},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{bohrdt2021a,\n@@ -282,7 +308,7 @@ @article{bohrdt2021a\n   journal = {arXiv:2108.04118 [cond-mat]},\n   eprint = {2108.04118},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{borla2020,\n@@ -296,7 +322,7 @@ @article{borla2020\n   eprint = {1909.07399},\n   pages = {120503},\n   doi = {10.1103/PhysRevLett.124.120503},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{borla2020a,\n@@ -307,7 +333,7 @@ @article{borla2020a\n   journal = {arXiv:2010.00607 [cond-mat, physics:hep-lat, physics:hep-th, physics:quant-ph]},\n   eprint = {2010.00607},\n   primaryclass = {cond-mat, physics:hep-lat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{borla2021,\n@@ -318,7 +344,7 @@ @article{borla2021\n   journal = {arXiv:2012.08543 [cond-mat, physics:hep-lat, physics:hep-th]},\n   eprint = {2012.08543},\n   primaryclass = {cond-mat, physics:hep-lat, physics:hep-th},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{borla2024,\n@@ -329,9 +355,9 @@ @misc{borla2024\n   number = {arXiv:2402.00933},\n   eprint = {2402.00933},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.00933},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{bornet2023,\n@@ -342,9 +368,9 @@ @misc{bornet2023\n   number = {arXiv:2303.08053},\n   eprint = {2303.08053},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.08053},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{brenig2022,\n@@ -359,7 +385,7 @@ @article{brenig2022\n   primaryclass = {cond-mat, physics:hep-lat},\n   pages = {245105},\n   doi = {10.1103/PhysRevB.105.245105},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{buessen2022,\n@@ -370,22 +396,22 @@ @misc{buessen2022\n   number = {arXiv:2202.05285},\n   eprint = {2202.05285},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.05285},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{cardarelli2022,\n   title = {Accessing the Topological {{Mott}} Insulator in Cold Atom Quantum Simulators with Realistic {{Rydberg}} Dressing},\n-  author = {Cardarelli, Lorenzo and {Juli{\\`a}-Farr{\\'e}}, Sergi and Lewenstein, Maciej and Dauphin, Alexandre and M{\\\"u}ller, Markus},\n+  author = {Cardarelli, Lorenzo and {Juli\u00e0-Farr\u00e9}, Sergi and Lewenstein, Maciej and Dauphin, Alexandre and M\u00fcller, Markus},\n   year = {2022},\n   month = mar,\n   number = {arXiv:2203.14818},\n   eprint = {2203.14818},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.14818},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cataldi2021,\n@@ -399,7 +425,7 @@ @article{cataldi2021\n   eprint = {2105.02239},\n   pages = {556},\n   doi = {10.22331/q-2021-09-29-556},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cervia2022,\n@@ -414,7 +440,7 @@ @article{cervia2022\n   primaryclass = {hep-ph, physics:nucl-th, physics:quant-ph},\n   pages = {123025},\n   doi = {10.1103/PhysRevD.105.123025},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{chan2022,\n@@ -425,9 +451,9 @@ @misc{chan2022\n   number = {arXiv:2212.04863},\n   eprint = {2212.04863},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2212.04863},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{chen2022,\n@@ -438,9 +464,9 @@ @misc{chen2022\n   number = {arXiv:2207.12930},\n   eprint = {2207.12930},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2207.12930},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{chen2022a,\n@@ -451,22 +477,22 @@ @misc{chen2022a\n   number = {arXiv:2211.02754},\n   eprint = {2211.02754},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.02754},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{chen2023,\n-  title = {Chiral {{Fibonacci}} Spin Liquid in a \\${\\textbackslash}mathbb\\{\\vphantom\\}{{Z}}\\vphantom\\{\\}\\_3\\$ {{Kitaev}} Model},\n+  title = {Chiral {{Fibonacci}} Spin Liquid in a \\$\\textbackslash mathbb\\{\\vphantom\\}{{Z}}\\vphantom\\{\\}\\_3\\$ {{Kitaev}} Model},\n   author = {Chen, Li-Mei and Ellison, Tyler D. and Cheng, Meng and Ye, Peng and Chen, Ji-Yao},\n   year = {2023},\n   month = feb,\n   number = {arXiv:2302.05060},\n   eprint = {2302.05060},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2302.05060},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{claeys2021,\n@@ -477,7 +503,7 @@ @article{claeys2021\n   journal = {arXiv:2110.06951 [cond-mat, physics:quant-ph]},\n   eprint = {2110.06951},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{claeys2022,\n@@ -491,18 +517,18 @@ @article{claeys2022\n   primaryclass = {cond-mat, physics:nlin, physics:quant-ph},\n   pages = {738},\n   doi = {10.22331/q-2022-06-15-738},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{coissard2021,\n   title = {Imaging Tunable Quantum {{Hall}} Broken-Symmetry Orders in Charge-Neutral Graphene},\n-  author = {Coissard, A. and Wander, D. and Vignaud, H. and Grushin, A. G. and Repellin, C. and Watanabe, K. and Taniguchi, T. and Gay, F. and Winkelmann, C. and Courtois, H. and Sellier, H. and Sac{\\'e}p{\\'e}, B.},\n+  author = {Coissard, A. and Wander, D. and Vignaud, H. and Grushin, A. G. and Repellin, C. and Watanabe, K. and Taniguchi, T. and Gay, F. and Winkelmann, C. and Courtois, H. and Sellier, H. and Sac\u00e9p\u00e9, B.},\n   year = {2021},\n   month = oct,\n   journal = {arXiv:2110.02811 [cond-mat]},\n   eprint = {2110.02811},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cookmeyer2021,\n@@ -516,7 +542,7 @@ @article{cookmeyer2021\n   eprint = {2103.07438},\n   pages = {087201},\n   doi = {10.1103/PhysRevLett.127.087201},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{cookmeyer2022,\n@@ -528,9 +554,9 @@ @misc{cookmeyer2022\n   number = {arXiv:2206.04788},\n   eprint = {2206.04788},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.04788},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{cookmeyer2023,\n@@ -541,15 +567,15 @@ @misc{cookmeyer2023\n   number = {arXiv:2310.18393},\n   eprint = {2310.18393},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.18393},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{cubela2023,\n   title = {Particle Zoo in a Doped Spin Chain: {{Correlated}} States of Mesons and Magnons},\n   shorttitle = {Particle Zoo in a Doped Spin Chain},\n-  author = {{\\v C}ubela, Petar and Bohrdt, Annabelle and Greiner, Markus and Grusdt, Fabian},\n+  author = {\u010cubela, Petar and Bohrdt, Annabelle and Greiner, Markus and Grusdt, Fabian},\n   year = {2023},\n   month = jan,\n   journal = {Physical Review B},\n@@ -559,7 +585,27 @@ @article{cubela2023\n   primaryclass = {cond-mat, physics:quant-ph},\n   pages = {035105},\n   doi = {10.1103/PhysRevB.107.035105},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{cuzzuol2024,\n+  title = {Fundamental Role of Nonlocal Orders in {{1D Extended Bose-Hubbard Model}}},\n+  author = {Cuzzuol, Nitya and Montorsi, Arianna},\n+  year = {2024},\n+  month = may\n+}\n+\n+@misc{cuzzuol2024a,\n+  title = {Nonlocal Order Parameter of Pair Superfluids},\n+  author = {Cuzzuol, Nitya and Montorsi, Arianna and Barbiero, Luca},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2404.15972},\n+  eprint = {2404.15972},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2404.15972},\n+  archiveprefix = {arXiv}\n }\n \n @misc{dai2022,\n@@ -570,20 +616,20 @@ @misc{dai2022\n   number = {arXiv:2211.00043},\n   eprint = {2211.00043},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.00043},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{demidio2021,\n   title = {Diagnosing Weakly First-Order Phase Transitions by Coupling to Order Parameters},\n-  author = {D'Emidio, Jonathan and Eberharter, Alexander A. and L{\\\"a}uchli, Andreas M.},\n+  author = {D'Emidio, Jonathan and Eberharter, Alexander A. and L\u00e4uchli, Andreas M.},\n   year = {2021},\n   month = jun,\n   journal = {arXiv:2106.15462 [cond-mat]},\n   eprint = {2106.15462},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{denner2020,\n@@ -597,20 +643,20 @@ @article{denner2020\n   eprint = {2005.03014},\n   pages = {033388},\n   doi = {10.1103/PhysRevResearch.2.033388},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{desaules2023,\n   title = {Ergodicity {{Breaking Under Confinement}} in {{Cold-Atom Quantum Simulators}}},\n-  author = {Desaules, Jean-Yves and Su, Guo-Xian and McCulloch, Ian P. and Yang, Bing and Papi{\\'c}, Zlatko and Halimeh, Jad C.},\n+  author = {Desaules, Jean-Yves and Su, Guo-Xian and McCulloch, Ian P. and Yang, Bing and Papi\u0107, Zlatko and Halimeh, Jad C.},\n   year = {2023},\n   month = jan,\n   number = {arXiv:2301.07717},\n   eprint = {2301.07717},\n   primaryclass = {cond-mat, physics:hep-lat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.07717},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{devakul2021,\n@@ -622,7 +668,20 @@ @article{devakul2021\n   journal = {arXiv:2109.13909 [cond-mat]},\n   eprint = {2109.13909},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{divic2024,\n+  title = {Chiral {{Spin Liquid}} and {{Quantum Phase Transition}} in the {{Triangular Lattice Hofstadter-Hubbard Model}}},\n+  author = {Divic, Stefan and Soejima, Tomohiro and Cr\u00e9pel, Valentin and Zaletel, Michael P. and Millis, Andrew},\n+  year = {2024},\n+  month = jun,\n+  number = {arXiv:2406.15348},\n+  eprint = {2406.15348},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2406.15348},\n+  archiveprefix = {arXiv}\n }\n \n @article{doggen2020,\n@@ -633,7 +692,7 @@ @article{doggen2020\n   journal = {arXiv:2002.07635 [cond-mat]},\n   eprint = {2002.07635},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{doggen2021,\n@@ -648,7 +707,7 @@ @article{doggen2021\n   eprint = {2012.13722},\n   pages = {L100202},\n   doi = {10.1103/PhysRevB.103.L100202},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{doggen2021a,\n@@ -660,7 +719,7 @@ @article{doggen2021a\n   journal = {arXiv:2104.10451 [cond-mat, physics:quant-ph]},\n   eprint = {2104.10451},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{doggen2022,\n@@ -675,7 +734,7 @@ @article{doggen2022\n   primaryclass = {cond-mat},\n   pages = {134204},\n   doi = {10.1103/PhysRevB.105.134204},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{doggen2023,\n@@ -686,9 +745,9 @@ @misc{doggen2023\n   number = {arXiv:2303.07081},\n   eprint = {2303.07081},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.07081},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{dong2020,\n@@ -702,7 +761,7 @@ @article{dong2020\n   eprint = {1911.12854},\n   pages = {121102},\n   doi = {10.1103/PhysRevB.102.121102},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{dong2023,\n@@ -714,9 +773,9 @@ @misc{dong2023\n   number = {arXiv:2311.05568},\n   eprint = {2311.05568},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.05568},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{dong2023a,\n@@ -731,20 +790,20 @@ @article{dong2023a\n   primaryclass = {cond-mat},\n   pages = {136502},\n   doi = {10.1103/PhysRevLett.131.136502},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{dong2023b,\n   title = {Disorder-Tunable Entanglement at Infinite Temperature},\n-  author = {Dong, Hang and Desaules, Jean-Yves and Gao, Yu and Wang, Ning and Guo, Zexian and Chen, Jiachen and Zou, Yiren and Jin, Feitong and Zhu, Xuhao and Zhang, Pengfei and Li, Hekang and Wang, Zhen and Guo, Qiujiang and Zhang, Junxiang and Ying, Lei and Papi{\\'c}, Zlatko},\n+  author = {Dong, Hang and Desaules, Jean-Yves and Gao, Yu and Wang, Ning and Guo, Zexian and Chen, Jiachen and Zou, Yiren and Jin, Feitong and Zhu, Xuhao and Zhang, Pengfei and Li, Hekang and Wang, Zhen and Guo, Qiujiang and Zhang, Junxiang and Ying, Lei and Papi\u0107, Zlatko},\n   year = {2023},\n   month = dec,\n   number = {arXiv:2312.10216},\n   eprint = {2312.10216},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.10216},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{dornellas2023,\n@@ -755,9 +814,22 @@ @misc{dornellas2023\n   number = {arXiv:2312.01967},\n   eprint = {2312.01967},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.01967},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{dowarah2024,\n+  title = {Phases and Phase Transition in {{Grover}}'s Algorithm with Systematic Noise},\n+  author = {Dowarah, Sasanka and Zhang, Chuanwei and Khemani, Vedika and Kolodrubetz, Michael H.},\n+  year = {2024},\n+  month = jun,\n+  number = {arXiv:2406.10344},\n+  eprint = {2406.10344},\n+  primaryclass = {quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2406.10344},\n+  archiveprefix = {arXiv}\n }\n \n @misc{drescher2022,\n@@ -768,22 +840,55 @@ @misc{drescher2022\n   number = {arXiv:2209.03344},\n   eprint = {2209.03344},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2209.03344},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{eberharter2023,\n   title = {Extracting the {{Speed}} of {{Light}} from {{Matrix Product States}}},\n-  author = {Eberharter, Alexander A. and Vanderstraeten, Laurens and Verstraete, Frank and L{\\\"a}uchli, Andreas M.},\n+  author = {Eberharter, Alexander A. and Vanderstraeten, Laurens and Verstraete, Frank and L\u00e4uchli, Andreas M.},\n   year = {2023},\n   month = mar,\n   number = {arXiv:2303.00663},\n   eprint = {2303.00663},\n   primaryclass = {cond-mat, physics:hep-th},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.00663},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{eck2024,\n+  title = {Generalizations of {{Kitaev}}'s Honeycomb Model from Braided Fusion Categories},\n+  author = {Eck, Luisa and Fendley, Paul},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.04006},\n+  eprint = {2408.04006},\n+  primaryclass = {cond-mat, physics:hep-th, physics:math-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.04006},\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{emonts2024,\n+  title = {Effects of {{Topological Boundary Conditions}} on {{Bell Nonlocality}}},\n+  author = {Emonts, Patrick and Hu, Mengyao and Aloy, Albert and Tura, Jordi},\n+  year = {2024},\n+  month = may\n+}\n+\n+@misc{engineer2024,\n+  title = {Equilibration of Objective Observables in a Dynamical Model of Quantum Measurements},\n+  author = {Engineer, Sophie and Rivlin, Tom and Wollmann, Sabine and Malik, Mehul and Lock, Maximilian P. E.},\n+  year = {2024},\n+  month = mar,\n+  number = {arXiv:2403.18016},\n+  eprint = {2403.18016},\n+  primaryclass = {quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2403.18016},\n+  archiveprefix = {arXiv}\n }\n \n @misc{evrard2024,\n@@ -794,9 +899,9 @@ @misc{evrard2024\n   number = {arXiv:2401.06848},\n   eprint = {2401.06848},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.06848},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{fang2024,\n@@ -807,22 +912,22 @@ @misc{fang2024\n   number = {arXiv:2402.15376},\n   eprint = {2402.15376},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.15376},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{fraxanet2023,\n   title = {Higher-Order Topological {{Peierls}} Insulator in a Two-Dimensional Atom-Cavity System},\n-  author = {Fraxanet, Joana and Dauphin, Alexandre and Lewenstein, Maciej and Barbiero, Luca and {Gonz{\\'a}lez-Cuadra}, Daniel},\n+  author = {Fraxanet, Joana and Dauphin, Alexandre and Lewenstein, Maciej and Barbiero, Luca and {Gonz\u00e1lez-Cuadra}, Daniel},\n   year = {2023},\n   month = may,\n   number = {arXiv:2305.03409},\n   eprint = {2305.03409},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.03409},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{fromholz2022,\n@@ -833,9 +938,9 @@ @misc{fromholz2022\n   number = {arXiv:2207.00385},\n   eprint = {2207.00385},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2207.00385},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{gagge2020,\n@@ -846,7 +951,20 @@ @article{gagge2020\n   journal = {arXiv:2006.13588 [cond-mat, physics:quant-ph]},\n   eprint = {2006.13588},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{gallego-lizarribar2024,\n+  title = {Probing Spontaneously Symmetry-Broken Phases with Spin-Charge Separation through Noise Correlation Measurements},\n+  author = {{Gallego-Lizarribar}, Kerman and {Juli\u00e0-Farr\u00e9}, Sergi and Lewenstein, Maciej and Weitenberg, Christof and Barbiero, Luca and {Arg\u00fcello-Luengo}, Javier},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2404.08374},\n+  eprint = {2404.08374},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2404.08374},\n+  archiveprefix = {arXiv}\n }\n \n @misc{garrahan2022,\n@@ -857,9 +975,9 @@ @misc{garrahan2022\n   number = {arXiv:2203.08200},\n   eprint = {2203.08200},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.08200},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{garratt2022,\n@@ -870,9 +988,9 @@ @misc{garratt2022\n   number = {arXiv:2207.09476},\n   eprint = {2207.09476},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2207.09476},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{ge2020,\n@@ -884,7 +1002,20 @@ @article{ge2020\n   journal = {arXiv:2009.13350 [cond-mat, physics:quant-ph]},\n   eprint = {2009.13350},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{glittum2024,\n+  title = {Spin-Charge Separation and Resonant Valence Bond Spin Liquid in a Frustrated Doped {{Mott}} Insulator},\n+  author = {Glittum, Cecilie and \u0160trkalj, Antonio and Prabhakaran, Dharmalingam and Goddard, Paul A. and Batista, Cristian D. and Castelnovo, Claudio},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.03372},\n+  eprint = {2408.03372},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.03372},\n+  archiveprefix = {arXiv}\n }\n \n @article{gohlke2023,\n@@ -900,20 +1031,20 @@ @article{gohlke2023\n   primaryclass = {cond-mat, physics:physics},\n   pages = {206},\n   doi = {10.21468/SciPostPhys.15.5.206},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{gomez-lozada2023,\n   title = {Insulator Phases of {{Bose-Fermi}} Mixtures Induced by next-Neighbor Interactions between Fermions},\n-  author = {{G{\\'o}mez-Lozada}, F. and Franco, R. and {Silva-Valencia}, J.},\n+  author = {{G\u00f3mez-Lozada}, F. and Franco, R. and {Silva-Valencia}, J.},\n   year = {2023},\n   month = sep,\n   number = {arXiv:2309.05594},\n   eprint = {2309.05594},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.05594},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{grusdt2019,\n@@ -927,7 +1058,7 @@ @article{grusdt2019\n   eprint = {1901.01113},\n   pages = {224422},\n   doi = {10.1103/PhysRevB.99.224422},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{hakani2023,\n@@ -938,9 +1069,9 @@ @misc{hakani2023\n   number = {arXiv:2311.00698},\n   eprint = {2311.00698},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.00698},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{han2023,\n@@ -951,9 +1082,9 @@ @misc{han2023\n   number = {arXiv:2309.10036},\n   eprint = {2309.10036},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.10036},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hartmann2021,\n@@ -967,7 +1098,7 @@ @article{hartmann2021\n   eprint = {2103.04809},\n   pages = {064436},\n   doi = {10.1103/PhysRevB.104.064436},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{hatsugai2022,\n@@ -978,9 +1109,9 @@ @misc{hatsugai2022\n   number = {arXiv:2210.11646},\n   eprint = {2210.11646},\n   primaryclass = {cond-mat, physics:hep-th},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2210.11646},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hauschild2018_dup,\n@@ -994,7 +1125,7 @@ @article{hauschild2018_dup\n   eprint = {1711.01288},\n   pages = {235163},\n   doi = {10.1103/PhysRevB.98.235163},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hauschild2018a_dup,\n@@ -1007,15 +1138,15 @@ @article{hauschild2018a_dup\n   eprint = {1805.00055},\n   pages = {5},\n   doi = {10.21468/SciPostPhysLectNotes.5},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @phdthesis{hauschild2019,\n-  title = {Quantum {{Many-Body Systems Far Out}} of {{Equilibrium}} {\\textemdash} {{Simulations}} with {{Tensor Networks}}},\n+  title = {Quantum {{Many-Body Systems Far Out}} of {{Equilibrium}} \u2014 {{Simulations}} with {{Tensor Networks}}},\n   author = {Hauschild, Johannes Michael},\n   year = {2019},\n-  address = {{M{\\\"u}nchen}},\n-  school = {Technische Universit{\\\"a}t M{\\\"u}nchen}\n+  address = {M\u00fcnchen},\n+  school = {Technische Universit\u00e4t M\u00fcnchen}\n }\n \n @article{he2021,\n@@ -1026,7 +1157,7 @@ @article{he2021\n   journal = {arXiv:2111.01120 [cond-mat]},\n   eprint = {2111.01120},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{he2022,\n@@ -1037,9 +1168,9 @@ @misc{he2022\n   number = {arXiv:2208.02830},\n   eprint = {2208.02830},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2208.02830},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{heinsdorf2023,\n@@ -1050,22 +1181,22 @@ @misc{heinsdorf2023\n   number = {arXiv:2309.15113},\n   eprint = {2309.15113},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.15113},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{hemery2023,\n   title = {Measuring the {{Loschmidt}} Amplitude for Finite-Energy Properties of the {{Fermi-Hubbard}} Model on an Ion-Trap Quantum Computer},\n-  author = {H{\\'e}mery, K{\\'e}vin and Ghanem, Khaldoon and Crane, Eleanor and Campbell, Sara L. and Dreiling, Joan M. and Figgatt, Caroline and Foltz, Cameron and Gaebler, John P. and Johansen, Jacob and Mills, Michael and Moses, Steven A. and Pino, Juan M. and Ransford, Anthony and Rowe, Mary and Siegfried, Peter and Stutz, Russell P. and Dreyer, Henrik and Schuckert, Alexander and Nigmatullin, Ramil},\n+  author = {H\u00e9mery, K\u00e9vin and Ghanem, Khaldoon and Crane, Eleanor and Campbell, Sara L. and Dreiling, Joan M. and Figgatt, Caroline and Foltz, Cameron and Gaebler, John P. and Johansen, Jacob and Mills, Michael and Moses, Steven A. and Pino, Juan M. and Ransford, Anthony and Rowe, Mary and Siegfried, Peter and Stutz, Russell P. and Dreyer, Henrik and Schuckert, Alexander and Nigmatullin, Ramil},\n   year = {2023},\n   month = sep,\n   number = {arXiv:2309.10552},\n   eprint = {2309.10552},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.10552},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{henry2023,\n@@ -1076,9 +1207,9 @@ @misc{henry2023\n   number = {arXiv:2301.11031},\n   eprint = {2301.11031},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.11031},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{hidaka2022,\n@@ -1089,22 +1220,22 @@ @misc{hidaka2022\n   number = {arXiv:2205.15525},\n   eprint = {2205.15525},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2205.15525},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{hirthe2022,\n   title = {Magnetically Mediated Hole Pairing in Fermionic Ladders of Ultracold Atoms},\n-  author = {Hirthe, Sarah and Chalopin, Thomas and Bourgund, Dominik and Bojovi{\\'c}, Petar and Bohrdt, Annabelle and Demler, Eugene and Grusdt, Fabian and Bloch, Immanuel and Hilker, Timon A.},\n+  author = {Hirthe, Sarah and Chalopin, Thomas and Bourgund, Dominik and Bojovi\u0107, Petar and Bohrdt, Annabelle and Demler, Eugene and Grusdt, Fabian and Bloch, Immanuel and Hilker, Timon A.},\n   year = {2022},\n   month = mar,\n   number = {arXiv:2203.10027},\n   eprint = {2203.10027},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.10027},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{homeier2022,\n@@ -1115,20 +1246,27 @@ @misc{homeier2022\n   number = {arXiv:2205.08541},\n   eprint = {2205.08541},\n   primaryclass = {cond-mat, physics:hep-lat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2205.08541},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{hu2024,\n+  title = {Characterizing {{Translation-Invariant Bell Inequalities}} Using {{Tropical Algebra}} and {{Graph Polytopes}}},\n+  author = {Hu, Mengyao and Vall\u00e9e, Elo\u00efc and Seynnaeve, Tim and Emonts, Patrick and Tura, Jordi},\n+  year = {2024},\n+  month = jul\n }\n \n @article{huang2020,\n-  title = {Quantum Phase Diagram and Chiral Spin Liquid in the Extended Spin-\\${\\textbackslash}frac\\{1\\}\\{2\\}\\$ Honeycomb {{XY}} Model},\n+  title = {Quantum Phase Diagram and Chiral Spin Liquid in the Extended Spin-\\$\\textbackslash frac\\{1\\}\\{2\\}\\$ Honeycomb {{XY}} Model},\n   author = {Huang, Yixuan and Dong, Xiao-Yu and Sheng, D. N. and Ting, C. S.},\n   year = {2020},\n   month = aug,\n   journal = {arXiv:1912.11156 [cond-mat]},\n   eprint = {1912.11156},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{huang2020a,\n@@ -1139,7 +1277,7 @@ @article{huang2020a\n   journal = {arXiv:2009.13089 [cond-mat]},\n   eprint = {2009.13089},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{huang2021,\n@@ -1150,20 +1288,20 @@ @article{huang2021\n   journal = {arXiv:2108.06676 [cond-mat]},\n   eprint = {2108.06676},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{huang2023,\n-  title = {Magnetic Field-Induced Partially Polarized Chiral Spin Liquid in a Transition-Metal Dichalcogenide {{Moir}}{\\textbackslash}'e System},\n+  title = {Magnetic Field-Induced Partially Polarized Chiral Spin Liquid in a Transition-Metal Dichalcogenide {{Moir}}\\textbackslash 'e System},\n   author = {Huang, Yixuan and Sheng, D. N. and Zhu, Jian-Xin},\n   year = {2023},\n   month = jun,\n   number = {arXiv:2306.03056},\n   eprint = {2306.03056},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2306.03056},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{hubig2020,\n@@ -1178,19 +1316,19 @@ @article{hubig2020\n   eprint = {1911.01159},\n   pages = {021},\n   doi = {10.21468/SciPostPhys.8.2.021},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{iraola2021,\n   title = {Towards a {{Topological Quantum Chemistry}} Description of Correlated Systems: The Case of the {{Hubbard}} Diamond Chain},\n   shorttitle = {Towards a {{Topological Quantum Chemistry}} Description of Correlated Systems},\n-  author = {Iraola, Mikel and Heinsdorf, Niclas and Tiwari, Apoorv and Lessnich, Dominik and Mertz, Thomas and Ferrari, Francesco and Fischer, Mark H. and Winter, Stephen M. and Pollmann, Frank and Neupert, Titus and Valent{\\'i}, Roser and Vergniory, Maia G.},\n+  author = {Iraola, Mikel and Heinsdorf, Niclas and Tiwari, Apoorv and Lessnich, Dominik and Mertz, Thomas and Ferrari, Francesco and Fischer, Mark H. and Winter, Stephen M. and Pollmann, Frank and Neupert, Titus and Valent\u00ed, Roser and Vergniory, Maia G.},\n   year = {2021},\n   month = jan,\n   journal = {arXiv:2101.04135 [cond-mat]},\n   eprint = {2101.04135},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{jepsen2021,\n@@ -1201,18 +1339,18 @@ @article{jepsen2021\n   journal = {arXiv:2103.07866 [cond-mat, physics:physics, physics:quant-ph]},\n   eprint = {2103.07866},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{ji2020,\n   title = {Dynamical Interplay between a Single Hole and a {{Hubbard}} Antiferromagnet},\n-  author = {Ji, Geoffrey and Xu, Muqing and Kendrick, Lev Haldar and Chiu, Christie S. and Br{\\\"u}ggenj{\\\"u}rgen, Justus C. and Greif, Daniel and Bohrdt, Annabelle and Grusdt, Fabian and Demler, Eugene and Lebrat, Martin and Greiner, Markus},\n+  author = {Ji, Geoffrey and Xu, Muqing and Kendrick, Lev Haldar and Chiu, Christie S. and Br\u00fcggenj\u00fcrgen, Justus C. and Greif, Daniel and Bohrdt, Annabelle and Grusdt, Fabian and Demler, Eugene and Lebrat, Martin and Greiner, Markus},\n   year = {2020},\n   month = jun,\n   journal = {arXiv:2006.06672 [cond-mat, physics:quant-ph]},\n   eprint = {2006.06672},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{jin2021,\n@@ -1223,7 +1361,7 @@ @article{jin2021\n   journal = {arXiv:2111.09101 [cond-mat, physics:nucl-th, physics:physics, physics:quant-ph]},\n   eprint = {2111.09101},\n   primaryclass = {cond-mat, physics:nucl-th, physics:physics, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{jin2023,\n@@ -1234,9 +1372,9 @@ @misc{jin2023\n   number = {arXiv:2301.00472},\n   eprint = {2301.00472},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.00472},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{jin2023a,\n@@ -1251,7 +1389,7 @@ @article{jin2023a\n   primaryclass = {cond-mat},\n   pages = {L201111},\n   doi = {10.1103/PhysRevB.107.L201111},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{jin2023b,\n@@ -1262,9 +1400,9 @@ @misc{jin2023b\n   number = {arXiv:2309.15153},\n   eprint = {2309.15153},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.15153},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{jobst2022,\n@@ -1275,9 +1413,9 @@ @misc{jobst2022\n   number = {arXiv:2203.11975},\n   eprint = {2203.11975},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.11975},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{jones2021,\n@@ -1291,44 +1429,44 @@ @article{jones2021\n   eprint = {2105.12143},\n   pages = {033265},\n   doi = {10.1103/PhysRevResearch.3.033265},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{julia-farre2021,\n   title = {Revealing the Topological Nature of the Bond Order Wave in a Strongly Correlated Quantum System},\n-  author = {{Juli{\\`a}-Farr{\\'e}}, Sergi and {Gonz{\\'a}lez-Cuadra}, Daniel and Patscheider, Alexander and Mark, Manfred J. and Ferlaino, Francesca and Lewenstein, Maciej and Barbiero, Luca and Dauphin, Alexandre},\n+  author = {{Juli\u00e0-Farr\u00e9}, Sergi and {Gonz\u00e1lez-Cuadra}, Daniel and Patscheider, Alexander and Mark, Manfred J. and Ferlaino, Francesca and Lewenstein, Maciej and Barbiero, Luca and Dauphin, Alexandre},\n   year = {2021},\n   month = dec,\n   journal = {arXiv:2112.08785 [cond-mat]},\n   eprint = {2112.08785},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{julia-farre2023,\n   title = {Topological Stripe State in an Extended {{Fermi-Hubbard}} Model},\n-  author = {{Juli{\\`a}-Farr{\\'e}}, Sergi and Cardarelli, Lorenzo and Lewenstein, Maciej and M{\\\"u}ller, Markus and Dauphin, Alexandre},\n+  author = {{Juli\u00e0-Farr\u00e9}, Sergi and Cardarelli, Lorenzo and Lewenstein, Maciej and M\u00fcller, Markus and Dauphin, Alexandre},\n   year = {2023},\n   month = jan,\n   number = {arXiv:2301.03312},\n   eprint = {2301.03312},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.03312},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{julia-farre2024,\n   title = {Quantized {{Thouless}} Pumps Protected by Interactions in Dimerized {{Rydberg}} Tweezer Arrays},\n-  author = {{Juli{\\`a}-Farr{\\'e}}, Sergi and {Arg{\\\"u}ello-Luengo}, Javier and Henriet, Lo{\\\"i}c and Dauphin, Alexandre},\n+  author = {{Juli\u00e0-Farr\u00e9}, Sergi and {Arg\u00fcello-Luengo}, Javier and Henriet, Lo\u00efc and Dauphin, Alexandre},\n   year = {2024},\n   month = feb,\n   number = {arXiv:2402.09311},\n   eprint = {2402.09311},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.09311},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kadow2022,\n@@ -1339,9 +1477,9 @@ @misc{kadow2022\n   number = {arXiv:2202.03458},\n   eprint = {2202.03458},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.03458},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kadow2023,\n@@ -1353,9 +1491,9 @@ @misc{kadow2023\n   number = {arXiv:2309.15157},\n   eprint = {2309.15157},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.15157},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kamal2024,\n@@ -1366,22 +1504,22 @@ @misc{kamal2024\n   number = {arXiv:2401.08754},\n   eprint = {2401.08754},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.08754},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kebric2022,\n   title = {Confinement {{Induced Frustration}} in a {{One-Dimensional Z}}\\_2 {{Lattice Gauge Theory}}},\n-  author = {Kebri{\\v c}, Matja{\\v z} and Borla, Umberto and Schollw{\\\"o}ck, Ulrich and Moroz, Sergej and Barbiero, Luca and Grusdt, Fabian},\n+  author = {Kebri\u010d, Matja\u017e and Borla, Umberto and Schollw\u00f6ck, Ulrich and Moroz, Sergej and Barbiero, Luca and Grusdt, Fabian},\n   year = {2022},\n   month = jun,\n   number = {arXiv:2206.13487},\n   eprint = {2206.13487},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.13487},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kharkov2021,\n@@ -1392,7 +1530,7 @@ @article{kharkov2021\n   journal = {arXiv:2111.02385 [cond-mat, physics:nlin, physics:quant-ph]},\n   eprint = {2111.02385},\n   primaryclass = {cond-mat, physics:nlin, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kidd2024,\n@@ -1403,21 +1541,38 @@ @misc{kidd2024\n   number = {arXiv:2402.04218},\n   eprint = {2402.04218},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.04218},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kiese2021,\n   title = {{{TMDs}} as a Platform for Spin Liquid Physics: {{A}} Strong Coupling Study of Twisted Bilayer {{WSe}}\\$\\_2\\$},\n   shorttitle = {{{TMDs}} as a Platform for Spin Liquid Physics},\n-  author = {Kiese, Dominik and He, Yuchi and Hickey, Ciar{\\'a}n and Rubio, Angel and Kennes, Dante M.},\n+  author = {Kiese, Dominik and He, Yuchi and Hickey, Ciar\u00e1n and Rubio, Angel and Kennes, Dante M.},\n   year = {2021},\n   month = oct,\n   journal = {arXiv:2110.10179 [cond-mat]},\n   eprint = {2110.10179},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@article{kirchner2024,\n+  title = {Characterizing the {{Entanglement}} of {{Anyonic Systems}} Using the {{Anyonic Partial Transpose}}},\n+  author = {Kirchner, Nico and Choi, Wonjune and Pollmann, Frank},\n+  year = {2024},\n+  month = mar,\n+  journal = {arXiv.org},\n+  doi = {10.1103/PhysRevB.110.085143}\n+}\n+\n+@misc{kiss2024,\n+  title = {Early {{Fault-Tolerant Quantum Algorithms}} in {{Practice}}: {{Application}} to {{Ground-State Energy Estimation}}},\n+  shorttitle = {Early {{Fault-Tolerant Quantum Algorithms}} in {{Practice}}},\n+  author = {Kiss, Oriel and Azad, Utkarsh and Requena, Borja and Roggero, Alessandro and Wakeham, David and Arrazola, Juan Miguel},\n+  year = {2024},\n+  month = may\n }\n \n @article{klein2020,\n@@ -1428,7 +1583,7 @@ @article{klein2020\n   journal = {arXiv:2002.01742 [cond-mat, physics:hep-th, physics:math-ph, physics:quant-ph]},\n   eprint = {2002.01742},\n   primaryclass = {cond-mat, physics:hep-th, physics:math-ph, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kloss2020,\n@@ -1443,7 +1598,7 @@ @article{kloss2020\n   eprint = {1911.07857},\n   pages = {060201},\n   doi = {10.1103/PhysRevB.102.060201},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{koepsell2020,\n@@ -1454,7 +1609,7 @@ @article{koepsell2020\n   journal = {arXiv:2009.04440 [cond-mat, physics:quant-ph]},\n   eprint = {2009.04440},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kohlert2021,\n@@ -1465,7 +1620,20 @@ @article{kohlert2021\n   journal = {arXiv:2106.15586 [cond-mat, physics:quant-ph]},\n   eprint = {2106.15586},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{korbmacher2024,\n+  title = {Topological Floating Phase of Dipolar Bosons in an Optical Ladder},\n+  author = {Korbmacher, Henning and {Dom\u00ednguez-Castro}, Gustavo A. and \u0141\u0105cki, Mateusz and Zakrzewski, Jakub and Santos, Luis},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.15710},\n+  eprint = {2407.15710},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.15710},\n+  archiveprefix = {arXiv}\n }\n \n @article{kottmann2020,\n@@ -1476,18 +1644,18 @@ @article{kottmann2020\n   journal = {arXiv:2003.09905 [cond-mat, physics:quant-ph]},\n   eprint = {2003.09905},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kottmann2021,\n   title = {Supersolid-{{Superfluid}} Phase Separation in the Extended {{Bose-Hubbard}} Model},\n-  author = {Kottmann, Korbinian and Haller, Andreas and Ac{\\'i}n, Antonio and Astrakharchik, Grigory E. and Lewenstein, Maciej},\n+  author = {Kottmann, Korbinian and Haller, Andreas and Ac\u00edn, Antonio and Astrakharchik, Grigory E. and Lewenstein, Maciej},\n   year = {2021},\n   month = jun,\n   journal = {arXiv:2106.05893 [cond-mat, physics:quant-ph]},\n   eprint = {2106.05893},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kottmann2022,\n@@ -1498,9 +1666,22 @@ @misc{kottmann2022\n   number = {arXiv:2210.11130},\n   eprint = {2210.11130},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2210.11130},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{koyluoglu2024,\n+  title = {Floquet Engineering of Interactions and Entanglement in Periodically Driven {{Rydberg}} Chains},\n+  author = {K\u00f6yl\u00fco\u011flu, Nazl\u0131 U\u011fur and Maskara, Nishad and Feldmeier, Johannes and Lukin, Mikhail D.},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.02741},\n+  eprint = {2408.02741},\n+  primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.02741},\n+  archiveprefix = {arXiv}\n }\n \n @article{kraus2021,\n@@ -1511,7 +1692,7 @@ @article{kraus2021\n   journal = {arXiv:2112.10386 [cond-mat, physics:quant-ph]},\n   eprint = {2112.10386},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kuhlenkamp2022,\n@@ -1522,9 +1703,9 @@ @misc{kuhlenkamp2022\n   number = {arXiv:2209.05506},\n   eprint = {2209.05506},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2209.05506},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kumar2022,\n@@ -1535,9 +1716,9 @@ @misc{kumar2022\n   number = {arXiv:2208.13708},\n   eprint = {2208.13708},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2208.13708},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kumar2023,\n@@ -1548,9 +1729,9 @@ @misc{kumar2023\n   number = {arXiv:2307.00062},\n   eprint = {2307.00062},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.00062},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kuno2020,\n@@ -1561,7 +1742,7 @@ @article{kuno2020\n   journal = {arXiv:2007.11215 [cond-mat]},\n   eprint = {2007.11215},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kuno2021,\n@@ -1575,7 +1756,7 @@ @article{kuno2021\n   eprint = {2102.09325},\n   pages = {045113},\n   doi = {10.1103/PhysRevB.104.045113},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{kuno2021a,\n@@ -1589,20 +1770,33 @@ @article{kuno2021a\n   eprint = {2107.09498},\n   pages = {125146},\n   doi = {10.1103/PhysRevB.104.125146},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{kuno2023,\n-  title = {\\${{Z}}\\_2{\\textbackslash}times {{Z}}\\_2\\$ Symmetry and \\${{Z}}\\_4\\$ {{Berry}} Phase of Bosonic Ladder},\n+  title = {\\${{Z}}\\_2\\textbackslash times {{Z}}\\_2\\$ Symmetry and \\${{Z}}\\_4\\$ {{Berry}} Phase of Bosonic Ladder},\n   author = {Kuno, Yoshihito and Hatsugai, Yasuhiro},\n   year = {2023},\n   month = apr,\n   number = {arXiv:2304.09533},\n   eprint = {2304.09533},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2304.09533},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{kupczynski2024,\n+  title = {{{DMRG Analysis}} of {{Magnetic Order}} in the {{Zigzag Edges}} of {{Hexagonal CrN Nanoribbons}}},\n+  author = {Kupczy\u0144ski, Micha\u0142 and Paw\u0142owski, Jaros\u0142aw and Mogulkoc, Aybey and Modarresi, Mohsen},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.06754},\n+  eprint = {2408.06754},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.06754},\n+  archiveprefix = {arXiv}\n }\n \n @misc{lane2023,\n@@ -1613,9 +1807,16 @@ @misc{lane2023\n   number = {arXiv:2305.03867},\n   eprint = {2305.03867},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.03867},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{lastres2024a,\n+  title = {Entanglement Asymmetry in the Critical {{XXZ}} Spin Chain},\n+  author = {Lastres, Marco and Murciano, Sara and Ares, Filiberto and Calabrese, Pasquale},\n+  year = {2024},\n+  month = jul\n }\n \n @misc{lebrat2023,\n@@ -1626,9 +1827,9 @@ @misc{lebrat2023\n   number = {arXiv:2308.12269},\n   eprint = {2308.12269},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2308.12269},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{ledinauskas2023,\n@@ -1639,9 +1840,22 @@ @misc{ledinauskas2023\n   number = {arXiv:2307.15521},\n   eprint = {2307.15521},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.15521},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{ledinauskas2024,\n+  title = {Universal {{Performance Gap}} of {{Neural Quantum States Applied}} to the {{Hofstadter-Bose-Hubbard Model}}},\n+  author = {Ledinauskas, Eimantas and Anisimovas, Egidijus},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2405.01981},\n+  eprint = {2405.01981},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2405.01981},\n+  archiveprefix = {arXiv}\n }\n \n @article{lee2020,\n@@ -1652,7 +1866,7 @@ @article{lee2020\n   journal = {arXiv:2010.09999 [quant-ph]},\n   eprint = {2010.09999},\n   primaryclass = {quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{lee2021,\n@@ -1663,7 +1877,7 @@ @article{lee2021\n   journal = {arXiv:2105.12391 [quant-ph]},\n   eprint = {2105.12391},\n   primaryclass = {quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{lerose2020,\n@@ -1674,7 +1888,7 @@ @article{lerose2020\n   journal = {arXiv:2009.10105 [cond-mat, physics:quant-ph]},\n   eprint = {2009.10105},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{lerose2021,\n@@ -1688,7 +1902,7 @@ @article{lerose2021\n   eprint = {2104.07607},\n   pages = {035137},\n   doi = {10.1103/PhysRevB.104.035137},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{li2021,\n@@ -1702,7 +1916,7 @@ @article{li2021\n   eprint = {2012.02663},\n   pages = {043331},\n   doi = {10.1103/PhysRevA.103.043331},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{li2023,\n@@ -1713,9 +1927,22 @@ @misc{li2023\n   number = {arXiv:2305.06918},\n   eprint = {2305.06918},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.06918},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{li2024,\n+  title = {Quantum Metrological Capability as a Probe for Quantum Phase Transition},\n+  author = {Li, Xiangbei and Chu, Yaoming and Zhang, Shaoliang and Cai, Jianming},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.09783},\n+  eprint = {2408.09783},\n+  primaryclass = {quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.09783},\n+  archiveprefix = {arXiv}\n }\n \n @misc{liu2022,\n@@ -1726,9 +1953,22 @@ @misc{liu2022\n   number = {arXiv:2211.11786},\n   eprint = {2211.11786},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.11786},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{liu2024,\n+  title = {Supersolidity and {{Simplex Phases}} in {{Spin-1 Rydberg Atom Arrays}}},\n+  author = {Liu, Vincent S. and Bintz, Marcus and Block, Maxwell and Samajdar, Rhine and Kemp, Jack and Yao, Norman Y.},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.17554},\n+  eprint = {2407.17554},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.17554},\n+  archiveprefix = {arXiv}\n }\n \n @misc{lloyd2023,\n@@ -1739,9 +1979,9 @@ @misc{lloyd2023\n   number = {arXiv:2310.16043},\n   eprint = {2310.16043},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.16043},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{luo2022,\n@@ -1752,9 +1992,9 @@ @misc{luo2022\n   number = {arXiv:2212.14223},\n   eprint = {2212.14223},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2212.14223},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{ma2022,\n@@ -1765,9 +2005,22 @@ @misc{ma2022\n   number = {arXiv:2209.02723},\n   eprint = {2209.02723},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2209.02723},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{madhusudan2024,\n+  title = {Commensurate Supersolids and Re-Entrant Transitions in an Extended {{Bose-Hubbard}} Ladder},\n+  author = {Madhusudan, Ashwath N. and Santra, Gopal Chandra and Kaur, Inderpreet and Li, Weibin and Nath, Rejish},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2407.20107},\n+  eprint = {2407.20107},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.20107},\n+  archiveprefix = {arXiv}\n }\n \n @article{mahyaeh2020,\n@@ -1778,21 +2031,47 @@ @article{mahyaeh2020\n   journal = {arXiv:2003.07812 [cond-mat]},\n   eprint = {2003.07812},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{manovitz2024,\n+  title = {Quantum Coarsening and Collective Dynamics on a Programmable Quantum Simulator},\n+  author = {Manovitz, Tom and Li, Sophie H. and Ebadi, Sepehr and Samajdar, Rhine and Geim, Alexandra A. and Evered, Simon J. and Bluvstein, Dolev and Zhou, Hengyun and K\u00f6yl\u00fco\u011flu, Nazli U\u011fur and Feldmeier, Johannes and Dolgirev, Pavel E. and Maskara, Nishad and Kalinowski, Marcin and Sachdev, Subir and Huse, David A. and Greiner, Markus and Vuleti\u0107, Vladan and Lukin, Mikhail D.},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.03249},\n+  eprint = {2407.03249},\n+  primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.03249},\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{mariella2024,\n+  title = {Order {{Parameter Discovery}} for {{Quantum Many-Body Systems}}},\n+  author = {Mariella, Nicola and Murphy, Tara and Di Marcantonio, Francesco and Najafi, Khadijeh and Vallecorsa, Sofia and Zhuk, Sergiy and Rico, Enrique},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.01400},\n+  eprint = {2408.01400},\n+  primaryclass = {quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.01400},\n+  archiveprefix = {arXiv}\n }\n \n @misc{mendez-cordoba2022,\n   title = {From Edge to Bulk: {{Cavity}} Induced Displacement of Topological Non-Local Qubits},\n   shorttitle = {From Edge to Bulk},\n-  author = {{M{\\'e}ndez-C{\\'o}rdoba}, F. P. M. and Rodr{\\'i}guez, F. J. and Tejedor, C. and Quiroga, L.},\n+  author = {{M\u00e9ndez-C\u00f3rdoba}, F. P. M. and Rodr\u00edguez, F. J. and Tejedor, C. and Quiroga, L.},\n   year = {2022},\n   month = dec,\n   number = {arXiv:2211.14145},\n   eprint = {2211.14145},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.14145},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{metz2022,\n@@ -1803,14 +2082,27 @@ @misc{metz2022\n   number = {arXiv:2201.11790},\n   eprint = {2201.11790},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2201.11790},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{mitra2024,\n+  title = {Quantum {{Spin Liquids}} in {{Weak Mott Insulators}} with a {{Spin-Orbit Coupling}}},\n+  author = {Mitra, Asimpunya and Schultz, Daniel J. and Kim, Yong Baek},\n+  year = {2024},\n+  month = apr,\n+  number = {arXiv:2404.05806},\n+  eprint = {2404.05806},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2404.05806},\n+  archiveprefix = {arXiv}\n }\n \n @article{morera2020,\n   title = {Entanglement Entropy in Low-Energy Field Theories at Finite Chemical Potential},\n-  author = {Morera, Ivan and Fr{\\'e}rot, Ir{\\'e}n{\\'e}e and Polls, Artur and {Juli{\\'a}-D{\\'i}az}, Bruno},\n+  author = {Morera, Ivan and Fr\u00e9rot, Ir\u00e9n\u00e9e and Polls, Artur and {Juli\u00e1-D\u00edaz}, Bruno},\n   year = {2020},\n   month = jul,\n   journal = {Physical Review Research},\n@@ -1819,18 +2111,18 @@ @article{morera2020\n   eprint = {1907.01204},\n   pages = {033016},\n   doi = {10.1103/PhysRevResearch.2.033016},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{morera2020a,\n   title = {Universal Dimerized Quantum Droplets in a One-Dimensional Lattice},\n-  author = {Morera, Ivan and Astrakharchik, Grigori E. and Polls, Artur and {Juli{\\'a}-D{\\'i}az}, Bruno},\n+  author = {Morera, Ivan and Astrakharchik, Grigori E. and Polls, Artur and {Juli\u00e1-D\u00edaz}, Bruno},\n   year = {2020},\n   month = jul,\n   journal = {arXiv:2007.01786 [cond-mat, physics:quant-ph]},\n   eprint = {2007.01786},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{morera2021,\n@@ -1841,20 +2133,20 @@ @article{morera2021\n   journal = {arXiv:2106.09600 [cond-mat]},\n   eprint = {2106.09600},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{morera2022,\n   title = {High-Temperature Kinetic Magnetism in Triangular Lattices},\n-  author = {Morera, Ivan and {Kan{\\'a}sz-Nagy}, M{\\'a}rton and Smolenski, Tomasz and Ciorciaro, Livio and Imamo{\\u g}lu, Ata{\\c c} and Demler, Eugene},\n+  author = {Morera, Ivan and {Kan\u00e1sz-Nagy}, M\u00e1rton and Smolenski, Tomasz and Ciorciaro, Livio and Imamo\u011flu, Ata\u00e7 and Demler, Eugene},\n   year = {2022},\n   month = sep,\n   number = {arXiv:2209.05398},\n   eprint = {2209.05398},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2209.05398},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{morera2023,\n@@ -1866,9 +2158,9 @@ @misc{morera2023\n   number = {arXiv:2312.00768},\n   eprint = {2312.00768},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.00768},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{morera2024,\n@@ -1879,9 +2171,9 @@ @misc{morera2024\n   number = {arXiv:2402.14074},\n   eprint = {2402.14074},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.14074},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{motruk2020,\n@@ -1892,20 +2184,20 @@ @article{motruk2020\n   journal = {arXiv:2005.09860 [cond-mat, physics:quant-ph]},\n   eprint = {2005.09860},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{motruk2022,\n-  title = {Kagome {{Chiral Spin Liquid}} in {{Transition Metal Dichalcogenide Moir}}{\\textbackslash}'\\{e\\} {{Bilayers}}},\n+  title = {Kagome {{Chiral Spin Liquid}} in {{Transition Metal Dichalcogenide Moir}}\\textbackslash '\\{e\\} {{Bilayers}}},\n   author = {Motruk, Johannes and Rossi, Dario and Abanin, Dmitry A. and Rademaker, Louk},\n   year = {2022},\n   month = nov,\n   number = {arXiv:2211.15696},\n   eprint = {2211.15696},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.15696},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{murciano2023,\n@@ -1916,9 +2208,9 @@ @misc{murciano2023\n   number = {arXiv:2302.04325},\n   eprint = {2302.04325},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2302.04325},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{nakamura2024,\n@@ -1929,9 +2221,9 @@ @misc{nakamura2024\n   number = {arXiv:2401.17552},\n   eprint = {2401.17552},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.17552},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{nietner2022,\n@@ -1942,9 +2234,9 @@ @misc{nietner2022\n   number = {arXiv:2207.10696},\n   eprint = {2207.10696},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2207.10696},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{nikolaenko2023,\n@@ -1955,9 +2247,9 @@ @misc{nikolaenko2023\n   number = {arXiv:2306.09402},\n   eprint = {2306.09402},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2306.09402},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{ogino2022,\n@@ -1968,20 +2260,20 @@ @misc{ogino2022\n   number = {arXiv:2206.13048},\n   eprint = {2206.13048},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.13048},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{oppong2020,\n   title = {Probing Transport and Slow Relaxation in the Mass-Imbalanced {{Fermi-Hubbard}} Model},\n-  author = {Oppong, Nelson Darkwah and Pasqualetti, Giulio and Bettermann, Oscar and Zechmann, Philip and Knap, Michael and Bloch, Immanuel and F{\\\"o}lling, Simon},\n+  author = {Oppong, Nelson Darkwah and Pasqualetti, Giulio and Bettermann, Oscar and Zechmann, Philip and Knap, Michael and Bloch, Immanuel and F\u00f6lling, Simon},\n   year = {2020},\n   month = nov,\n   journal = {arXiv:2011.12411 [cond-mat, physics:quant-ph]},\n   eprint = {2011.12411},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{orito2021,\n@@ -1995,20 +2287,27 @@ @article{orito2021\n   eprint = {2012.13659},\n   pages = {L060301},\n   doi = {10.1103/PhysRevB.103.L060301},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{orozco-ruiz2024,\n+  title = {A Way around the Exponential Scaling in Optimal Quantum Control},\n+  author = {{Orozco-Ruiz}, Modesto and Le, Nguyen H. and Mintert, Florian},\n+  year = {2024},\n+  month = may\n }\n \n @misc{parella-dilme2023,\n   title = {Reducing {{Entanglement With Physically-Inspired Fermion-To-Qubit Mappings}}},\n-  author = {{Parella-Dilm{\\'e}}, Teodor and Kottmann, Korbinian and Zambrano, Leonardo and Mortimer, Luke and Kottmann, Jakob S. and Ac{\\'i}n, Antonio},\n+  author = {{Parella-Dilm\u00e9}, Teodor and Kottmann, Korbinian and Zambrano, Leonardo and Mortimer, Luke and Kottmann, Jakob S. and Ac\u00edn, Antonio},\n   year = {2023},\n   month = nov,\n   number = {arXiv:2311.07409},\n   eprint = {2311.07409},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.07409},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{parker2021,\n@@ -2022,7 +2321,7 @@ @article{parker2021\n   eprint = {2012.09885},\n   pages = {027601},\n   doi = {10.1103/PhysRevLett.127.027601},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{parker2021a,\n@@ -2033,20 +2332,20 @@ @article{parker2021a\n   journal = {arXiv:2112.13837 [cond-mat]},\n   eprint = {2112.13837},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{pasnoori2023,\n-  title = {Spin Fractionalization and Zero Modes in the Spin-\\${\\textbackslash}frac\\{1\\}\\{2\\}\\$ {{XXZ}} Chain with Boundary Fields},\n+  title = {Spin Fractionalization and Zero Modes in the Spin-\\$\\textbackslash frac\\{1\\}\\{2\\}\\$ {{XXZ}} Chain with Boundary Fields},\n   author = {Pasnoori, Parameshwar R. and Tang, Yicheng and Lee, Junhyun and Pixley, J. H. and Andrei, Natan and Azaria, Patrick},\n   year = {2023},\n   month = dec,\n   number = {arXiv:2312.05970},\n   eprint = {2312.05970},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.05970},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{passetti2022,\n@@ -2057,25 +2356,25 @@ @misc{passetti2022\n   number = {arXiv:2212.03011},\n   eprint = {2212.03011},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2212.03011},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{pena2021,\n   title = {Fractional Resonances and Prethermal States in {{Floquet}} Systems},\n-  author = {Pe{\\~n}a, R. and Bastidas, V. M. and Torres, F. and Munro, W. J. and Romero, G.},\n+  author = {Pe\u00f1a, R. and Bastidas, V. M. and Torres, F. and Munro, W. J. and Romero, G.},\n   year = {2021},\n   month = nov,\n   journal = {arXiv:2111.06949 [cond-mat, physics:quant-ph]},\n   eprint = {2111.06949},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{pena2022,\n   title = {Stable Many-Body Resonances in Open Quantum Systems},\n-  author = {Pe{\\~n}a, Ruben and Kyaw, Thi Ha and Romero, Guillermo},\n+  author = {Pe\u00f1a, Ruben and Kyaw, Thi Ha and Romero, Guillermo},\n   year = {2022},\n   month = dec,\n   journal = {Symmetry},\n@@ -2085,7 +2384,7 @@ @article{pena2022\n   primaryclass = {cond-mat, physics:quant-ph},\n   pages = {2562},\n   doi = {10.3390/sym14122562},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{pokart2023,\n@@ -2096,9 +2395,9 @@ @misc{pokart2023\n   number = {arXiv:2309.07961},\n   eprint = {2309.07961},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.07961},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{prembabu2022,\n@@ -2109,9 +2408,9 @@ @misc{prembabu2022\n   number = {arXiv:2208.12258},\n   eprint = {2208.12258},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2208.12258},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{quella2020,\n@@ -2123,29 +2422,36 @@ @article{quella2020\n   journal = {arXiv:2011.12679 [cond-mat, physics:math-ph]},\n   eprint = {2011.12679},\n   primaryclass = {cond-mat, physics:math-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{rader2019,\n   title = {Floating {{Phases}} in {{One-Dimensional Rydberg Ising Chains}}},\n-  author = {Rader, Michael and L{\\\"a}uchli, Andreas M.},\n+  author = {Rader, Michael and L\u00e4uchli, Andreas M.},\n   year = {2019},\n   month = aug,\n   journal = {arXiv:1908.02068 [cond-mat, physics:quant-ph]},\n   eprint = {1908.02068},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{rakov2024,\n+  title = {Gapless Deconfined Phase in a \\$\\textbackslash mathbb\\{\\vphantom\\}{{Z}}\\vphantom\\{\\}\\_{{N}}\\$ Symmetric {{Hamiltonian}} Created in a Cold-Atom Setup},\n+  author = {Rakov, Mykhailo V. and Tagliacozzo, Luca and Lewenstein, Maciej and Zakrzewski, Jakub and Chanda, Titas},\n+  year = {2024},\n+  month = jul\n }\n \n @article{repellin2020,\n   title = {Hall Drift of Fractional {{Chern}} Insulators in Few-Boson Systems},\n-  author = {Repellin, C. and L{\\'e}onard, J. and Goldman, N.},\n+  author = {Repellin, C. and L\u00e9onard, J. and Goldman, N.},\n   year = {2020},\n   month = jul,\n   journal = {arXiv:2005.09689 [cond-mat, physics:quant-ph]},\n   eprint = {2005.09689},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{rigobello2023,\n@@ -2156,9 +2462,9 @@ @misc{rigobello2023\n   number = {arXiv:2308.04488},\n   eprint = {2308.04488},\n   primaryclass = {cond-mat, physics:hep-lat, physics:hep-ph, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2308.04488},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{robertson2021,\n@@ -2169,7 +2475,7 @@ @article{robertson2021\n   journal = {arXiv:2110.07078 [cond-mat, physics:hep-th, physics:quant-ph]},\n   eprint = {2110.07078},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{robertson2023,\n@@ -2181,9 +2487,9 @@ @misc{robertson2023\n   number = {arXiv:2301.08609},\n   eprint = {2301.08609},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.08609},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{rodriguez-nieva2020,\n@@ -2194,7 +2500,7 @@ @article{rodriguez-nieva2020\n   journal = {arXiv:2011.07058 [cond-mat]},\n   eprint = {2011.07058},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{romen2023,\n@@ -2205,9 +2511,9 @@ @misc{romen2023\n   number = {arXiv:2311.06350},\n   eprint = {2311.06350},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2311.06350},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{roy2020,\n@@ -2221,7 +2527,7 @@ @article{roy2020\n   eprint = {2004.14370},\n   pages = {083104},\n   doi = {10.1088/1742-5468/aba498},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{roy2020a,\n@@ -2232,7 +2538,7 @@ @article{roy2020a\n   journal = {arXiv:2007.06874 [cond-mat, physics:hep-lat, physics:nlin, physics:quant-ph]},\n   eprint = {2007.06874},\n   primaryclass = {cond-mat, physics:hep-lat, physics:nlin, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{roy2020b,\n@@ -2246,7 +2552,7 @@ @article{roy2020b\n   eprint = {1911.08120},\n   pages = {075419},\n   doi = {10.1103/PhysRevB.101.075419},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{roy2023,\n@@ -2257,9 +2563,9 @@ @misc{roy2023\n   number = {arXiv:2306.04346},\n   eprint = {2306.04346},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2306.04346},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{roy2023a,\n@@ -2270,9 +2576,9 @@ @misc{roy2023a\n   number = {arXiv:2302.06289},\n   eprint = {2302.06289},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2302.06289},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{roy2023b,\n@@ -2283,9 +2589,9 @@ @misc{roy2023b\n   number = {arXiv:2310.10538},\n   eprint = {2310.10538},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.10538},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{roy2023c,\n@@ -2296,20 +2602,33 @@ @misc{roy2023c\n   number = {arXiv:2312.05566},\n   eprint = {2312.05566},\n   primaryclass = {cond-mat, physics:hep-lat, physics:hep-th, physics:math-ph, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.05566},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{rzepkowski2022,\n   title = {{{DMRG}} and {{Monte Carlo}} Studies of {{CrI}}\\_3 Magnetic Phases and the Phase Transition},\n-  author = {Rzepkowski, Bartosz and Kupczy{\\'n}ski, Micha{\\l} and Potasz, Pawe{\\l} and W{\\'o}js, Arkadiusz},\n+  author = {Rzepkowski, Bartosz and Kupczy\u0144ski, Micha\u0142 and Potasz, Pawe\u0142 and W\u00f3js, Arkadiusz},\n   year = {2022},\n   month = jan,\n   journal = {arXiv:2201.02586 [cond-mat]},\n   eprint = {2201.02586},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{safari2024,\n+  title = {Quantum {{Fluctuations Suppress}} the {{Critical Fields}} in {{BaCo}}\\$\\_2\\$({{AsO}}\\$\\_4\\$)\\$\\_2\\$},\n+  author = {Safari, Shiva and {Bateman-Hemphill}, William and Mitra, Asimpunya and Desrochers, F\u00e9lix and Zhang, Emily Z. and Shafeek, Lubuna and Ferrenti, Austin and McQueen, Tyrel M. and Shekhter, Arkady and K\u00f6ll\u00f6, Zolt\u00e1n and Kim, Yong Baek and Ramshaw, B. J. and Modic, K. A.},\n+  year = {2024},\n+  month = mar,\n+  number = {arXiv:2403.15315},\n+  eprint = {2403.15315},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2403.15315},\n+  archiveprefix = {arXiv}\n }\n \n @misc{sahay2023,\n@@ -2320,9 +2639,9 @@ @misc{sahay2023\n   number = {arXiv:2308.10935},\n   eprint = {2308.10935},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2308.10935},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sahu2023,\n@@ -2333,9 +2652,16 @@ @misc{sahu2023\n   number = {arXiv:2307.04267},\n   eprint = {2307.04267},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.04267},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{saiphet2024,\n+  title = {Simulation of the {{Dissipative Dynamics}} of {{Strongly Interacting NV Centers}} with {{Tensor Networks}}},\n+  author = {Saiphet, Jirawat and Braun, Daniel},\n+  year = {2024},\n+  month = jun\n }\n \n @misc{sala2023,\n@@ -2346,9 +2672,9 @@ @misc{sala2023\n   number = {arXiv:2307.08761},\n   eprint = {2307.08761},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.08761},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sala2024,\n@@ -2359,9 +2685,9 @@ @misc{sala2024\n   number = {arXiv:2403.04843},\n   eprint = {2403.04843},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2403.04843},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sander2023,\n@@ -2372,14 +2698,27 @@ @misc{sander2023\n   number = {arXiv:2305.02337},\n   eprint = {2305.02337},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.02337},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{sander2024,\n+  title = {Quantum {{Convolutional Neural Network}} for {{Phase Recognition}} in {{Two Dimensions}}},\n+  author = {Sander, Leon C. and McMahon, Nathan A. and Zapletal, Petr and Hartmann, Michael J.},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.04114},\n+  eprint = {2407.04114},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.04114},\n+  archiveprefix = {arXiv}\n }\n \n @article{scholl2021,\n   title = {Programmable Quantum Simulation of {{2D}} Antiferromagnets with Hundreds of {{Rydberg}} Atoms},\n-  author = {Scholl, Pascal and Schuler, Michael and Williams, Hannah J. and Eberharter, Alexander A. and Barredo, Daniel and Schymik, Kai-Niklas and Lienhard, Vincent and Henry, Louis-Paul and Lang, Thomas C. and Lahaye, Thierry and L{\\\"a}uchli, Andreas M. and Browaeys, Antoine},\n+  author = {Scholl, Pascal and Schuler, Michael and Williams, Hannah J. and Eberharter, Alexander A. and Barredo, Daniel and Schymik, Kai-Niklas and Lienhard, Vincent and Henry, Louis-Paul and Lang, Thomas C. and Lahaye, Thierry and L\u00e4uchli, Andreas M. and Browaeys, Antoine},\n   year = {2021},\n   month = jul,\n   journal = {Nature},\n@@ -2388,18 +2727,18 @@ @article{scholl2021\n   eprint = {2012.12268},\n   pages = {233--238},\n   doi = {10.1038/s41586-021-03585-1},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{schoonderwoerd2019,\n   title = {Interaction-Driven Plateau Transition between Integer and Fractional {{Chern Insulators}}},\n-  author = {Schoonderwoerd, Leon and Pollmann, Frank and M{\\\"o}ller, Gunnar},\n+  author = {Schoonderwoerd, Leon and Pollmann, Frank and M\u00f6ller, Gunnar},\n   year = {2019},\n   month = aug,\n   journal = {arXiv:1908.00988 [cond-mat]},\n   eprint = {1908.00988},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{schuckert2022,\n@@ -2410,9 +2749,9 @@ @misc{schuckert2022\n   number = {arXiv:2206.01756},\n   eprint = {2206.01756},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.01756},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{schuckert2023,\n@@ -2423,22 +2762,22 @@ @misc{schuckert2023\n   number = {arXiv:2310.19869},\n   eprint = {2310.19869},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.19869},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{schultz2023,\n   title = {Electric Field Control of a Quantum Spin Liquid in Weak {{Mott}} Insulators},\n-  author = {Schultz, Daniel J. and Khoury, Alexandre and Desrochers, F{\\'e}lix and Tavakol, Omid and Zhang, Emily Z. and Kim, Yong Baek},\n+  author = {Schultz, Daniel J. and Khoury, Alexandre and Desrochers, F\u00e9lix and Tavakol, Omid and Zhang, Emily Z. and Kim, Yong Baek},\n   year = {2023},\n   month = aug,\n   number = {arXiv:2309.00037},\n   eprint = {2309.00037},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2309.00037},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{schulz2018,\n@@ -2453,7 +2792,7 @@ @article{schulz2018\n   eprint = {1805.01036},\n   pages = {180201},\n   doi = {10.1103/PhysRevB.98.180201},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{secular2024,\n@@ -2465,9 +2804,9 @@ @misc{secular2024\n   number = {arXiv:2401.05301},\n   eprint = {2401.05301},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.05301},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{semeghini2021,\n@@ -2478,7 +2817,7 @@ @article{semeghini2021\n   journal = {arXiv:2104.04119 [cond-mat, physics:physics, physics:quant-ph]},\n   eprint = {2104.04119},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{shaffer2023,\n@@ -2489,9 +2828,9 @@ @misc{shaffer2023\n   number = {arXiv:2308.08588},\n   eprint = {2308.08588},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2308.08588},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{shiozaki2023,\n@@ -2502,9 +2841,16 @@ @misc{shiozaki2023\n   number = {arXiv:2305.08109},\n   eprint = {2305.08109},\n   primaryclass = {cond-mat, physics:hep-th, physics:math-ph, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.08109},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{silva-valencia2024,\n+  title = {Ground State of a Mixture of {{SU}}(\\$3\\$) Fermions and Scalar Bosons},\n+  author = {{Silva-Valencia}, J. and {Mendoza-Arenas}, J. J.},\n+  year = {2024},\n+  month = jul\n }\n \n @misc{sim2022,\n@@ -2515,9 +2861,9 @@ @misc{sim2022\n   number = {arXiv:2211.16094},\n   eprint = {2211.16094},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2211.16094},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sim2022a,\n@@ -2528,9 +2874,9 @@ @misc{sim2022a\n   number = {arXiv:2209.00720},\n   eprint = {2209.00720},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2209.00720},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sim2023,\n@@ -2542,9 +2888,9 @@ @misc{sim2023\n   number = {arXiv:2305.04920},\n   eprint = {2305.04920},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.04920},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sinha2023,\n@@ -2555,22 +2901,22 @@ @misc{sinha2023\n   number = {arXiv:2310.19703},\n   eprint = {2310.19703},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.19703},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{smid2024,\n   title = {Efficient {{Learning}} of {{Long-Range}} and {{Equivariant Quantum Systems}}},\n-  author = {{\\v S}m{\\'i}d, {\\v S}t{\\v e}p{\\'a}n and Bondesan, Roberto},\n+  author = {\u0160m\u00edd, \u0160t\u011bp\u00e1n and Bondesan, Roberto},\n   year = {2024},\n   month = jan,\n   number = {arXiv:2312.17019},\n   eprint = {2312.17019},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.17019},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{soejima2020,\n@@ -2581,7 +2927,7 @@ @article{soejima2020\n   journal = {arXiv:2009.02354 [cond-mat]},\n   eprint = {2009.02354},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{soldini2023,\n@@ -2592,20 +2938,20 @@ @misc{soldini2023\n   number = {arXiv:2312.13348},\n   eprint = {2312.13348},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.13348},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{sompet2021,\n   title = {Realising the {{Symmetry-Protected Haldane Phase}} in {{Fermi-Hubbard Ladders}}},\n-  author = {Sompet, Pimonpan and Hirthe, Sarah and Bourgund, Dominik and Chalopin, Thomas and Bibo, Julian and Koepsell, Joannis and Bojovi{\\'c}, Petar and Verresen, Ruben and Pollmann, Frank and Salomon, Guillaume and Gross, Christian and Hilker, Timon A. and Bloch, Immanuel},\n+  author = {Sompet, Pimonpan and Hirthe, Sarah and Bourgund, Dominik and Chalopin, Thomas and Bibo, Julian and Koepsell, Joannis and Bojovi\u0107, Petar and Verresen, Ruben and Pollmann, Frank and Salomon, Guillaume and Gross, Christian and Hilker, Timon A. and Bloch, Immanuel},\n   year = {2021},\n   month = sep,\n   journal = {arXiv:2103.10421 [cond-mat, physics:quant-ph]},\n   eprint = {2103.10421},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{sonner2021,\n@@ -2616,7 +2962,7 @@ @article{sonner2021\n   journal = {arXiv:2012.00777 [cond-mat, physics:quant-ph]},\n   eprint = {2012.00777},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{sonner2021a,\n@@ -2630,7 +2976,7 @@ @article{sonner2021a\n   eprint = {2103.13741},\n   pages = {168552},\n   doi = {10.1016/j.aop.2021.168552},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{sous2020,\n@@ -2641,12 +2987,12 @@ @article{sous2020\n   journal = {arXiv:2009.00619 [cond-mat]},\n   eprint = {2009.00619},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{strkalj2021,\n-  title = {Many-Body Localization in the Interpolating {{Aubry-Andr}}{\\textbackslash}'e-{{Fibonacci}} Model},\n-  author = {{\\v S}trkalj, Antonio and Doggen, Elmer V. H. and Gornyi, Igor V. and Zilberberg, Oded},\n+  title = {Many-Body Localization in the Interpolating {{Aubry-Andr}}\\textbackslash 'e-{{Fibonacci}} Model},\n+  author = {\u0160trkalj, Antonio and Doggen, Elmer V. H. and Gornyi, Igor V. and Zilberberg, Oded},\n   year = {2021},\n   month = sep,\n   journal = {Physical Review Research},\n@@ -2655,31 +3001,31 @@ @article{strkalj2021\n   eprint = {2106.13841},\n   pages = {033257},\n   doi = {10.1103/PhysRevResearch.3.033257},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{strkalj2022,\n-  title = {Coexistence of Localization and Transport in Many-Body Two-Dimensional {{Aubry-Andr}}{\\textbackslash}'e Models},\n-  author = {{\\v S}trkalj, Antonio and Doggen, Elmer V. H. and Castelnovo, Claudio},\n+  title = {Coexistence of Localization and Transport in Many-Body Two-Dimensional {{Aubry-Andr}}\\textbackslash 'e Models},\n+  author = {\u0160trkalj, Antonio and Doggen, Elmer V. H. and Castelnovo, Claudio},\n   year = {2022},\n   month = apr,\n   number = {arXiv:2204.05198},\n   eprint = {2204.05198},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2204.05198},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{su2022,\n   title = {Observation of Unconventional Many-Body Scarring in a Quantum Simulator},\n-  author = {Su, Guo-Xian and Sun, Hui and Hudomal, Ana and Desaules, Jean-Yves and Zhou, Zhao-Yu and Yang, Bing and Halimeh, Jad C. and Yuan, Zhen-Sheng and Papi{\\'c}, Zlatko and Pan, Jian-Wei},\n+  author = {Su, Guo-Xian and Sun, Hui and Hudomal, Ana and Desaules, Jean-Yves and Zhou, Zhao-Yu and Yang, Bing and Halimeh, Jad C. and Yuan, Zhen-Sheng and Papi\u0107, Zlatko and Pan, Jian-Wei},\n   year = {2022},\n   month = jan,\n   journal = {arXiv:2201.00821 [cond-mat, physics:quant-ph]},\n   eprint = {2201.00821},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{su2024,\n@@ -2690,9 +3036,9 @@ @misc{su2024\n   number = {arXiv:2401.05489},\n   eprint = {2401.05489},\n   primaryclass = {cond-mat, physics:hep-ex, physics:hep-lat, physics:hep-ph, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.05489},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sun2022,\n@@ -2703,9 +3049,9 @@ @misc{sun2022\n   number = {arXiv:2202.07892},\n   eprint = {2202.07892},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.07892},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{sun2023,\n@@ -2716,9 +3062,16 @@ @misc{sun2023\n   number = {arXiv:2301.11337},\n   eprint = {2301.11337},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.11337},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{symons2024,\n+  title = {Boosted {{Imaginary Time Evolution}} of {{Matrix Product States}}},\n+  author = {Symons, Benjamin C. B. and Manawadu, Dilhan and Galvin, David and Mensa, Stefano},\n+  year = {2024},\n+  month = may\n }\n \n @article{szasz2020,\n@@ -2733,7 +3086,7 @@ @article{szasz2020\n   eprint = {1808.00463},\n   pages = {021042},\n   doi = {10.1103/PhysRevX.10.021042},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{szasz2022,\n@@ -2744,9 +3097,9 @@ @misc{szasz2022\n   number = {arXiv:2206.04087},\n   eprint = {2206.04087},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.04087},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{tada2018,\n@@ -2760,7 +3113,7 @@ @article{tada2018\n   eprint = {1805.11226},\n   pages = {214523},\n   doi = {10.1103/PhysRevB.97.214523},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{tada2020,\n@@ -2774,7 +3127,7 @@ @article{tada2020\n   eprint = {2005.01990},\n   pages = {033363},\n   doi = {10.1103/PhysRevResearch.2.033363},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{tada2021,\n@@ -2785,7 +3138,14 @@ @article{tada2021\n   journal = {arXiv:2106.04071 [cond-mat, physics:hep-ph]},\n   eprint = {2106.04071},\n   primaryclass = {cond-mat, physics:hep-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{tan2024,\n+  title = {Entanglement Parity Effects in the {{Kane-Fisher}} Problem},\n+  author = {Tan, Chunyu and Hang, Yuxiao and Haas, Stephan and Saleur, Hubert},\n+  year = {2024},\n+  month = may\n }\n \n @article{tang2020,\n@@ -2800,7 +3160,7 @@ @article{tang2020\n   eprint = {1908.11253},\n   pages = {013022},\n   doi = {10.1103/PhysRevResearch.2.013022},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{tantivasadakarn2021,\n@@ -2811,7 +3171,7 @@ @article{tantivasadakarn2021\n   journal = {arXiv:2112.01519 [cond-mat, physics:quant-ph]},\n   eprint = {2112.01519},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{tarabunga2023,\n@@ -2822,9 +3182,9 @@ @misc{tarabunga2023\n   number = {arXiv:2303.12829},\n   eprint = {2303.12829},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.12829},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{tsitsishvili2021,\n@@ -2836,20 +3196,20 @@ @article{tsitsishvili2021\n   journal = {arXiv:2112.10421 [cond-mat, physics:hep-th, physics:quant-ph]},\n   eprint = {2112.10421},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{valles-muns2023,\n   title = {Quantum Droplets with Particle Imbalance in One-Dimensional Optical Lattices},\n-  author = {{Vall{\\`e}s-Muns}, Jofre and Morera, Ivan and Astrakharchik, Grigori E. and {Juli{\\'a}-D{\\'i}az}, Bruno},\n+  author = {{Vall\u00e8s-Muns}, Jofre and Morera, Ivan and Astrakharchik, Grigori E. and {Juli\u00e1-D\u00edaz}, Bruno},\n   year = {2023},\n   month = jun,\n   number = {arXiv:2306.12283},\n   eprint = {2306.12283},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2306.12283},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{vecsei2022,\n@@ -2864,7 +3224,7 @@ @article{vecsei2022\n   primaryclass = {cond-mat, physics:quant-ph},\n   pages = {054402},\n   doi = {10.1103/PhysRevB.106.054402},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{verresen2020,\n@@ -2875,7 +3235,7 @@ @article{verresen2020\n   journal = {arXiv:2011.12310 [cond-mat, physics:physics, physics:quant-ph]},\n   eprint = {2011.12310},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{verresen2021,\n@@ -2886,18 +3246,18 @@ @article{verresen2021\n   journal = {arXiv:2102.08967 [cond-mat, physics:quant-ph]},\n   eprint = {2102.08967},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{verresen2022,\n-  title = {Efficiently Preparing {{Schr}}{\\textbackslash}\"odinger's Cat, Fractons and Non-{{Abelian}} Topological Order in Quantum Devices},\n+  title = {Efficiently Preparing {{Schr}}\\textbackslash \"odinger's Cat, Fractons and Non-{{Abelian}} Topological Order in Quantum Devices},\n   author = {Verresen, Ruben and Tantivasadakarn, Nathanan and Vishwanath, Ashvin},\n   year = {2022},\n   month = jan,\n   journal = {arXiv:2112.03061 [cond-mat, physics:physics, physics:quant-ph]},\n   eprint = {2112.03061},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{verresen2022a,\n@@ -2908,9 +3268,9 @@ @misc{verresen2022a\n   number = {arXiv:2205.15302},\n   eprint = {2205.15302},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2205.15302},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{verresen2023,\n@@ -2921,9 +3281,9 @@ @misc{verresen2023\n   number = {arXiv:2301.11917},\n   eprint = {2301.11917},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.11917},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{villa2020,\n@@ -2934,7 +3294,7 @@ @article{villa2020\n   journal = {arXiv:2007.08381 [cond-mat]},\n   eprint = {2007.08381},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{villa2021,\n@@ -2948,7 +3308,7 @@ @article{villa2021\n   eprint = {2105.05774},\n   pages = {L021301},\n   doi = {10.1103/PhysRevA.104.L021301},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{villa2021a,\n@@ -2962,7 +3322,7 @@ @article{villa2021a\n   eprint = {2105.06396},\n   pages = {023323},\n   doi = {10.1103/PhysRevA.104.023323},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{vovrosh2021,\n@@ -2973,20 +3333,27 @@ @article{vovrosh2021\n   journal = {arXiv:2108.03976 [cond-mat]},\n   eprint = {2108.03976},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{wahl2024,\n+  title = {Exact Projected Entangled Pair Ground States with Topological {{Euler}} Invariant},\n+  author = {Wahl, Thorsten B. and Jankowski, Wojciech J. and Bouhon, Adrien and Chaudhary, Gaurav and Slager, Robert-Jan},\n+  year = {2024},\n+  month = jul\n }\n \n @misc{walter2022,\n   title = {Breakdown of Quantisation in a {{Hubbard-Thouless}} Pump},\n-  author = {Walter, Anne-Sophie and Zhu, Zijie and G{\\\"a}chter, Marius and Minguzzi, Joaqu{\\'i}n and Roschinski, Stephan and Sandholzer, Kilian and Viebahn, Konrad and Esslinger, Tilman},\n+  author = {Walter, Anne-Sophie and Zhu, Zijie and G\u00e4chter, Marius and Minguzzi, Joaqu\u00edn and Roschinski, Stephan and Sandholzer, Kilian and Viebahn, Konrad and Esslinger, Tilman},\n   year = {2022},\n   month = apr,\n   number = {arXiv:2204.06561},\n   eprint = {2204.06561},\n   primaryclass = {cond-mat, physics:physics},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2204.06561},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wang2020,\n@@ -2997,42 +3364,68 @@ @article{wang2020\n   journal = {arXiv:2003.01358 [cond-mat, physics:quant-ph]},\n   eprint = {2003.01358},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wang2020a,\n   title = {Robust and {{Ultrafast State Preparation}} by {{Ramping Artificial Gauge Potentials}}},\n-  author = {Wang, Botao and Dong, Xiao-Yu and {\\\"U}nal, F. Nur and Eckardt, Andr{\\'e}},\n+  author = {Wang, Botao and Dong, Xiao-Yu and \u00dcnal, F. Nur and Eckardt, Andr\u00e9},\n   year = {2020},\n   month = sep,\n   journal = {arXiv:2009.00560 [cond-mat, physics:quant-ph]},\n   eprint = {2009.00560},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wang2021,\n   title = {Measurable Signatures of Bosonic Fractional {{Chern}} Insulator States and Their Fractional Excitations in a Quantum-Gas Microscope},\n-  author = {Wang, Botao and Dong, Xiao-Yu and Eckardt, Andr{\\'e}},\n+  author = {Wang, Botao and Dong, Xiao-Yu and Eckardt, Andr\u00e9},\n   year = {2021},\n   month = nov,\n   journal = {arXiv:2111.01110 [cond-mat]},\n   eprint = {2111.01110},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{wang2024,\n+  title = {Floquet {{Schrieffer-Wolff}} Transform Based on {{Sylvester}} Equations},\n+  author = {Wang, Xiao and {M\u00e9ndez-C\u00f3rdoba}, Fabio Pablo Miguel and Jaksch, Dieter and Schlawin, Frank},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.08405},\n+  eprint = {2407.08405},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.08405},\n+  archiveprefix = {arXiv}\n }\n \n @misc{weber2022,\n   title = {Experimentally Accessible Scheme for a Fractional {{Chern}} Insulator in {{Rydberg}} Atoms},\n-  author = {Weber, Sebastian and Bai, Rukmani and Makki, Nastasia and M{\\\"o}gerle, Johannes and Lahaye, Thierry and Browaeys, Antoine and Daghofer, Maria and Lang, Nicolai and B{\\\"u}chler, Hans Peter},\n+  author = {Weber, Sebastian and Bai, Rukmani and Makki, Nastasia and M\u00f6gerle, Johannes and Lahaye, Thierry and Browaeys, Antoine and Daghofer, Maria and Lang, Nicolai and B\u00fcchler, Hans Peter},\n   year = {2022},\n   month = feb,\n   number = {arXiv:2202.00699},\n   eprint = {2202.00699},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2202.00699},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{weber2024,\n+  title = {Intertwined {{Superconductivity}} and {{Magnetism}} from {{Repulsive Interactions}} in {{Kondo Bilayers}}},\n+  author = {Weber, Clara S. and Kiese, Dominik and Kennes, Dante M. and Claassen, Martin},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.02847},\n+  eprint = {2408.02847},\n+  primaryclass = {cond-mat},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.02847},\n+  archiveprefix = {arXiv}\n }\n \n @misc{wei2024,\n@@ -3044,9 +3437,9 @@ @misc{wei2024\n   number = {arXiv:2312.16660},\n   eprint = {2312.16660},\n   primaryclass = {cond-mat, physics:nlin},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2312.16660},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{wienand2023,\n@@ -3057,9 +3450,9 @@ @misc{wienand2023\n   number = {arXiv:2306.11457},\n   eprint = {2306.11457},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2306.11457},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wouters2020,\n@@ -3070,7 +3463,7 @@ @article{wouters2020\n   journal = {arXiv:2005.12825 [cond-mat, physics:math-ph]},\n   eprint = {2005.12825},\n   primaryclass = {cond-mat, physics:math-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wouters2021,\n@@ -3081,7 +3474,7 @@ @article{wouters2021\n   journal = {arXiv:2106.15823 [cond-mat]},\n   eprint = {2106.15823},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wybo2020,\n@@ -3095,7 +3488,7 @@ @article{wybo2020\n   eprint = {2004.13072},\n   pages = {064304},\n   doi = {10.1103/PhysRevB.102.064304},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wybo2020a,\n@@ -3106,7 +3499,7 @@ @article{wybo2020a\n   journal = {arXiv:2010.15137 [cond-mat, physics:hep-th, physics:quant-ph]},\n   eprint = {2010.15137},\n   primaryclass = {cond-mat, physics:hep-th, physics:quant-ph},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{wybo2021,\n@@ -3118,7 +3511,7 @@ @article{wybo2021\n   eprint = {2110.07384},\n   pages = {pssb.202100161},\n   doi = {10.1002/pssb.202100161},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{wybo2022,\n@@ -3129,9 +3522,9 @@ @misc{wybo2022\n   number = {arXiv:2203.09530},\n   eprint = {2203.09530},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2203.09530},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{wybo2023,\n@@ -3142,9 +3535,9 @@ @misc{wybo2023\n   number = {arXiv:2303.16221},\n   eprint = {2303.16221},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.16221},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{xie2022,\n@@ -3155,22 +3548,22 @@ @misc{xie2022\n   number = {arXiv:2210.04928},\n   eprint = {2210.04928},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2210.04928},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{yang2023,\n-  title = {Exciton and Light Induced Ferromagnetism from Doping a Moir{\\textbackslash}'e {{Mott}} Insulator},\n+  title = {Exciton and Light Induced Ferromagnetism from Doping a Moir\\textbackslash 'e {{Mott}} Insulator},\n   author = {Yang, Hui and Zhang, Ya-Hui},\n   year = {2023},\n   month = may,\n   number = {arXiv:2305.01702},\n   eprint = {2305.01702},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2305.01702},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{yang2023a,\n@@ -3181,9 +3574,48 @@ @misc{yang2023a\n   number = {arXiv:2301.08255},\n   eprint = {2301.08255},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2301.08255},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{yang2024,\n+  title = {Chiral Spin Liquid in a Generalized {{Kitaev}} Honeycomb Model with \\$\\textbackslash mathbb\\{\\vphantom\\}{{Z}}\\vphantom\\{\\}\\_4\\$ 1-Form Symmetry},\n+  author = {Yang, Yu-Xin and Cheng, Meng and Chen, Ji-Yao},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.02046},\n+  eprint = {2408.02046},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.02046},\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{yang2024a,\n+  title = {Emergent {{Anomalous Hydrodynamics}} at {{Infinite Temperature}} in a {{Long-Range XXZ Model}}},\n+  author = {Yang, Ang and Ma, Jinlou and Ying, Lei},\n+  year = {2024},\n+  month = mar,\n+  number = {arXiv:2403.17912},\n+  eprint = {2403.17912},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2403.17912},\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{yin2024,\n+  title = {Theory of Metastable States in Many-Body Quantum Systems},\n+  author = {Yin, Chao and Surace, Federica M. and Lucas, Andrew},\n+  year = {2024},\n+  month = aug,\n+  number = {arXiv:2408.05261},\n+  eprint = {2408.05261},\n+  primaryclass = {cond-mat, physics:hep-th, physics:math-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2408.05261},\n+  archiveprefix = {arXiv}\n }\n \n @article{you2021,\n@@ -3195,7 +3627,20 @@ @article{you2021\n   journal = {arXiv:2101.01724 [cond-mat, physics:hep-th]},\n   eprint = {2101.01724},\n   primaryclass = {cond-mat, physics:hep-th},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{yousefjani2024,\n+  title = {Discrete {{Time Crystal Phase}} as a {{Resource}} for {{Quantum Enhanced Sensing}}},\n+  author = {Yousefjani, Rozhin and Sacha, Krzysztof and Bayat, Abolfazl},\n+  year = {2024},\n+  month = may,\n+  number = {arXiv:2405.00328},\n+  eprint = {2405.00328},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2405.00328},\n+  archiveprefix = {arXiv}\n }\n \n @misc{yu2023,\n@@ -3206,9 +3651,23 @@ @misc{yu2023\n   number = {arXiv:2304.00555},\n   eprint = {2304.00555},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2304.00555},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n+}\n+\n+@misc{zakharov2024,\n+  title = {Luttinger Liquid Tensor Network: Sine versus Tangent Dispersion of Massless {{Dirac}} Fermions},\n+  shorttitle = {Luttinger Liquid Tensor Network},\n+  author = {Zakharov, V. A. and Polla, S. and Vela, A. Don\u00eds and Emonts, P. and Pacholski, M. J. and Tworzyd\u0142o, J. and Beenakker, C. W. J.},\n+  year = {2024},\n+  month = jul,\n+  number = {arXiv:2407.06713},\n+  eprint = {2407.06713},\n+  primaryclass = {cond-mat, physics:quant-ph},\n+  publisher = {arXiv},\n+  doi = {10.48550/arXiv.2407.06713},\n+  archiveprefix = {arXiv}\n }\n \n @misc{zapletal2023,\n@@ -3219,9 +3678,9 @@ @misc{zapletal2023\n   number = {arXiv:2307.03711},\n   eprint = {2307.03711},\n   primaryclass = {quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.03711},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zechmann2022,\n@@ -3232,9 +3691,9 @@ @misc{zechmann2022\n   number = {arXiv:2205.12970},\n   eprint = {2205.12970},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2205.12970},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zechmann2022a,\n@@ -3245,9 +3704,9 @@ @misc{zechmann2022a\n   number = {arXiv:2210.11072},\n   eprint = {2210.11072},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2210.11072},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zechmann2023,\n@@ -3258,9 +3717,9 @@ @misc{zechmann2023\n   number = {arXiv:2310.16084},\n   eprint = {2310.16084},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2310.16084},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zeybek2023,\n@@ -3271,9 +3730,9 @@ @misc{zeybek2023\n   number = {arXiv:2303.17470},\n   eprint = {2303.17470},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2303.17470},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zeybek2024,\n@@ -3284,22 +3743,9 @@ @misc{zeybek2024\n   number = {arXiv:2403.06649},\n   eprint = {2403.06649},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n-  doi = {10.48550/arXiv.2403.06649},\n-  archiveprefix = {arxiv}\n-}\n-\n-@misc{zeybek2024a,\n-  title = {Bond-{{Order Density Wave Phases}} in {{Dimerized Extended Bose-Hubbard Models}}},\n-  author = {Zeybek, Zeki and Schmelcher, Peter and Mukherjee, Rick},\n-  year = {2024},\n-  month = mar,\n-  number = {arXiv:2403.06649},\n-  eprint = {2403.06649},\n-  primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2403.06649},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{zhang2020,\n@@ -3310,32 +3756,32 @@ @article{zhang2020\n   journal = {arXiv:2008.11204 [cond-mat]},\n   eprint = {2008.11204},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @article{zhang2021,\n-  title = {{{SU}}(4) Chiral Spin Liquid, Exciton Supersolid and Electric Detection in Moir{\\textbackslash}'e Bilayers},\n+  title = {{{SU}}(4) Chiral Spin Liquid, Exciton Supersolid and Electric Detection in Moir\\textbackslash 'e Bilayers},\n   author = {Zhang, Ya-Hui and Sheng, D. N. and Vishwanath, Ashvin},\n   year = {2021},\n   month = oct,\n   journal = {arXiv:2103.09825 [cond-mat]},\n   eprint = {2103.09825},\n   primaryclass = {cond-mat},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhang2022,\n-  title = {Doping a {{Mott}} Insulator with Excitons in Moir{\\textbackslash}'e Bilayer: Fractional Superfluid, Neutral {{Fermi}} Surface and {{Mott}} Transition},\n-  shorttitle = {Doping a {{Mott}} Insulator with Excitons in Moir{\\textbackslash}'e Bilayer},\n+  title = {Doping a {{Mott}} Insulator with Excitons in Moir\\textbackslash 'e Bilayer: Fractional Superfluid, Neutral {{Fermi}} Surface and {{Mott}} Transition},\n+  shorttitle = {Doping a {{Mott}} Insulator with Excitons in Moir\\textbackslash 'e Bilayer},\n   author = {Zhang, Ya-Hui},\n   year = {2022},\n   month = may,\n   number = {arXiv:2204.10937},\n   eprint = {2204.10937},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2204.10937},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhang2022a,\n@@ -3347,9 +3793,9 @@ @misc{zhang2022a\n   number = {arXiv:2208.01758},\n   eprint = {2208.01758},\n   primaryclass = {cond-mat, physics:physics, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2208.01758},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhang2024,\n@@ -3361,22 +3807,22 @@ @misc{zhang2024\n   number = {arXiv:2402.01247},\n   eprint = {2402.01247},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2402.01247},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhang2024a,\n-  title = {Chiral Spin Liquid and Quantum Phase Diagram of Spin-\\$1/2\\$ \\${{J}}\\_1\\$-\\${{J}}\\_2\\$-\\${{J}}\\_\\{{\\textbackslash}chi\\}\\$ Model on the Square Lattice},\n+  title = {Chiral Spin Liquid and Quantum Phase Diagram of Spin-\\$1/2\\$ \\${{J}}\\_1\\$-\\${{J}}\\_2\\$-\\${{J}}\\_\\{\\textbackslash chi\\}\\$ Model on the Square Lattice},\n   author = {Zhang, Xiao-Tian and Huang, Yixuan and Wu, Han-Qing and Sheng, D. N. and Gong, Shou-Shu},\n   year = {2024},\n   month = jan,\n   number = {arXiv:2401.07461},\n   eprint = {2401.07461},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2401.07461},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhao2022,\n@@ -3387,9 +3833,9 @@ @misc{zhao2022\n   number = {arXiv:2206.04213},\n   eprint = {2206.04213},\n   primaryclass = {cond-mat},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2206.04213},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zheng2022,\n@@ -3400,9 +3846,9 @@ @misc{zheng2022\n   number = {arXiv:2210.08556},\n   eprint = {2210.08556},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2210.08556},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zheng2024,\n@@ -3413,9 +3859,9 @@ @misc{zheng2024\n   number = {arXiv:2403.03479},\n   eprint = {2403.03479},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2403.03479},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhou2022,\n@@ -3426,9 +3872,9 @@ @misc{zhou2022\n   number = {arXiv:2205.13567},\n   eprint = {2205.13567},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2205.13567},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\n \n @misc{zhou2023,\n@@ -3439,7 +3885,7 @@ @misc{zhou2023\n   number = {arXiv:2307.16038},\n   eprint = {2307.16038},\n   primaryclass = {cond-mat, physics:quant-ph},\n-  publisher = {{arXiv}},\n+  publisher = {arXiv},\n   doi = {10.48550/arXiv.2307.16038},\n-  archiveprefix = {arxiv}\n+  archiveprefix = {arXiv}\n }\ndiff --git a/doc/theses.bib b/doc/theses.bib\nnew file mode 100644\nindex 000000000..348dc861b\n--- /dev/null\n+++ b/doc/theses.bib\n@@ -0,0 +1,80 @@\n+@phdthesis{Bauer2011,\n+  title = {Tensor Network States},\n+  author = {Bauer, Roman Bela},\n+  year = {2011},\n+  number = {19916},\n+  url = {https://doi.org/10.3929/ethz-a-006698826},\n+  school = {ETH Z\u00fcrich}\n+}\n+\n+@phdthesis{eberharter2023a,\n+  title = {Investigation of {{Quantum Dynamics}} and {{Phase Transitions}} Using {{Tensor Network Algorithms}}},\n+  author = {Eberharter, Alexander A},\n+  year = {2023},\n+  month = sep,\n+  url = {https://ulb-dok.uibk.ac.at/ulbtirolhs/content/titleinfo/9000350},\n+  school = {Universit\u00e4t Innsbruck}\n+}\n+\n+@phdthesis{Eisert2006,\n+  title = {Entanglement in Quantum Information Theory},\n+  author = {Eisert, J.},\n+  year = {2006},\n+  month = oct,\n+  url = {https://arxiv.org/abs/quant-ph/0610253},\n+  school = {University of Potsdam}\n+}\n+\n+@phdthesis{Hubig2017,\n+  title = {Symmetry-{{Protected Tensor Networks}}},\n+  author = {Hubig, Claudius},\n+  year = {2017},\n+  number = {August},\n+  url = {https://edoc.ub.uni-muenchen.de/21348/},\n+  school = {Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen}\n+}\n+\n+@phdthesis{kollath2005,\n+  title = {The Adaptive Time-Dependent Density Matrix Renormalization Group Method : Development and Applications},\n+  shorttitle = {The Adaptive Time-Dependent Density Matrix Renormalization Group Method},\n+  author = {Kollath, Corinna},\n+  year = {2005},\n+  number = {RWTH-CONV-123719},\n+  url = {https://publications.rwth-aachen.de/record/62126},\n+  school = {RWTH Aachen University}\n+}\n+\n+@phdthesis{RubenPHD,\n+  title = {Topology and Excitations in Low-Dimensional Quantum Matter},\n+  author = {Verresen, Ruben},\n+  year = {2019},\n+  address = {Dresden},\n+  url = {https://nbn-resolving.org/urn:nbn:de:bsz:14-qucosa2-356075},\n+  school = {Technische Universit\u00e4t Dresden}\n+}\n+\n+@phdthesis{schuch2007,\n+  title = {Quantum {{Entanglement}}: {{Theory}} and {{Applications}}},\n+  shorttitle = {Quantum {{Entanglement}}},\n+  author = {Schuch, Norbert},\n+  year = {2007},\n+  url = {https://mediatum.ub.tum.de/?id=620846},\n+  school = {Technische Universit\u00e4t M\u00fcnchen}\n+}\n+\n+@phdthesis{secular2024a,\n+  title = {Parallel {{Tensor Network Methods}} for {{Quantum Lattice Systems}}},\n+  author = {Secular, Paul},\n+  year = {2024},\n+  url = {https://researchportal.bath.ac.uk/en/studentTheses/parallel-tensor-network-methods-for-quantum-lattice-systems},\n+  school = {Bath}\n+}\n+\n+@phdthesis{singh2012a,\n+  title = {Tensor {{Network States}} and {{Algorithms}} in the Presence of {{Abelian}} and Non-{{Abelian Symmetries}}},\n+  author = {Singh, Sukhwinder},\n+  year = {2012},\n+  month = mar,\n+  url = {https://arxiv.org/abs/1203.2222},\n+  school = {University of Queensland}\n+}\ndiff --git a/examples/b_mps.py b/examples/b_mps.py\nindex 9b0de1643..dad771bf7 100644\n--- a/examples/b_mps.py\n+++ b/examples/b_mps.py\n@@ -22,7 +22,7 @@\n from tenpy.models.lattice import Chain\n from tenpy.networks.mps import MPS\n from tenpy.networks.mpo import MPO, MPOEnvironment\n-from tenpy.algorithms.truncation import svd_theta\n+from tenpy.linalg.truncation import svd_theta\n \n # model parameters\n Jxx, Jz = 1., 1.\ndiff --git a/tenpy/__init__.py b/tenpy/__init__.py\nindex 1d06be556..674ff7f89 100644\n--- a/tenpy/__init__.py\n+++ b/tenpy/__init__.py\n@@ -19,9 +19,9 @@\n # note that the order matters!\n from . import tools\n from . import linalg\n-from . import algorithms\n from . import networks\n from . import models\n+from . import algorithms\n from . import simulations\n from . import version  # needs to be after linalg!\n \n@@ -37,7 +37,7 @@\n                               TimeDependentTwoSiteTDVP)\n from .algorithms.vumps import SingleSiteVUMPSEngine, TwoSiteVUMPSEngine\n from .algorithms.tebd import TEBDEngine, QRBasedTEBDEngine, RandomUnitaryEvolution, TimeDependentTEBD\n-from .algorithms.truncation import TruncationError, truncate, svd_theta, decompose_theta_qr_based\n+from .linalg.truncation import TruncationError, truncate, svd_theta, decompose_theta_qr_based\n from .linalg.charges import ChargeInfo, LegCharge, LegPipe\n from .linalg.krylov_based import Arnoldi, LanczosGroundState, LanczosEvolution, lanczos_arpack\n from .linalg.np_conserved import (Array, zeros, ones, eye_like, diag,\ndiff --git a/tenpy/__main__.py b/tenpy/__main__.py\nindex ed3b56d1a..cf51defe0 100644\n--- a/tenpy/__main__.py\n+++ b/tenpy/__main__.py\n@@ -5,4 +5,5 @@\n \n if __name__ == \"__main__\":\n     import sys  # noqa 401\n-    raise SystemExit(tenpy.console_main())\n+    tenpy.console_main()\n+    sys.exit(0)\ndiff --git a/tenpy/algorithms/__init__.py b/tenpy/algorithms/__init__.py\nindex cb717298d..a153ff892 100644\n--- a/tenpy/algorithms/__init__.py\n+++ b/tenpy/algorithms/__init__.py\n@@ -6,7 +6,6 @@\n     :toctree: .\n \n     algorithm\n-    truncation\n     tebd\n     mps_common\n     dmrg\n@@ -22,7 +21,7 @@\n \"\"\"\n # Copyright (C) TeNPy Developers, GNU GPLv3\n \n-from . import algorithm, truncation, dmrg, dmrg_parallel, disentangler, mps_common, tebd, tdvp, \\\n+from . import algorithm, dmrg, dmrg_parallel, disentangler, mps_common, tebd, tdvp, \\\n     exact_diag, purification, network_contractor, mpo_evolution, vumps, plane_wave_excitation\n from .algorithm import *\n from .disentangler import *\n@@ -35,14 +34,12 @@\n from .purification import *\n from .tdvp import *\n from .tebd import *\n-from .truncation import *\n from .vumps import *\n from .plane_wave_excitation import *\n \n \n __all__ = [\n     \"algorithm\",\n-    \"truncation\",\n     \"dmrg\",\n     \"dmrg_parallel\",\n     \"mps_common\",\n@@ -56,7 +53,6 @@\n     \"vumps\",\n     \"plane_wave_excitation\",\n     *algorithm.__all__,\n-    *truncation.__all__,\n     *[n for n in dmrg.__all__ if n not in ['Mixer', 'SubspaceExpansion', 'DensityMatrixMixer']],\n     *dmrg_parallel.__all__,\n     *disentangler.__all__,\ndiff --git a/tenpy/algorithms/algorithm.py b/tenpy/algorithms/algorithm.py\nindex 178350e58..16f9e77d8 100644\n--- a/tenpy/algorithms/algorithm.py\n+++ b/tenpy/algorithms/algorithm.py\n@@ -6,7 +6,7 @@\n import logging\n logger = logging.getLogger(__name__)\n \n-from .truncation import TruncationError\n+from ..linalg.truncation import TruncationError\n from ..tools.misc import consistency_check\n from ..tools.events import EventHandler\n from ..tools.params import asConfig\n@@ -347,13 +347,18 @@ class TimeEvolutionAlgorithm(Algorithm):\n         preserve_norm : bool\n             Whether the state will be normalized to its initial norm after each time step.\n             Per default, this is ``False`` for real time evolution and ``True`` for imaginary time.\n+        start_trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n+            Initial truncation error for :attr:`trunc_err`.\n \n     Attributes\n     ----------\n     evolved_time : float | complex\n         Indicating how long `psi` has been evolved, ``psi = exp(-i * evolved_time * H) psi(t=0)``.\n-        Not that the real-part of `t` is increasing for a real-time evolution,\n+        Note that the real-part of `t` is increasing for a real-time evolution,\n         while the imaginary-part of `t` is *decreasing* for a imaginary time evolution.\n+    trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n+        Upper bound for the accumulated error of the represented state,\n+        which is introduced due to the truncation during the sequence of update steps.\n     \"\"\"\n     time_dependent_H = False  #: whether the algorithm supports time-dependent H\n \ndiff --git a/tenpy/algorithms/disentangler.py b/tenpy/algorithms/disentangler.py\nindex fb3427b55..955022df3 100644\n--- a/tenpy/algorithms/disentangler.py\n+++ b/tenpy/algorithms/disentangler.py\n@@ -14,7 +14,7 @@\n logger = logging.getLogger(__name__)\n \n from ..linalg import np_conserved as npc\n-from .truncation import svd_theta\n+from ..linalg.truncation import svd_theta\n from ..tools.math import entropy\n from ..linalg import random_matrix as rand_mat\n \ndiff --git a/tenpy/algorithms/dmrg.py b/tenpy/algorithms/dmrg.py\nindex 27ca54389..692ce36b8 100644\n--- a/tenpy/algorithms/dmrg.py\n+++ b/tenpy/algorithms/dmrg.py\n@@ -40,7 +40,7 @@\n \n from ..linalg import np_conserved as npc\n from ..linalg.krylov_based import lanczos_arpack, LanczosGroundState\n-from .truncation import svd_theta\n+from ..linalg.truncation import svd_theta\n from ..tools.params import asConfig\n from ..tools.math import entropy\n from ..tools.process import memory_usage\n@@ -67,7 +67,7 @@ def run(psi, model, options, **kwargs):\n     model : :class:`~tenpy.models.MPOModel`\n         The model representing the Hamiltonian for which we want to find the ground state.\n     options : dict\n-        Further optional parameters as described in :cfg:config:`DMRGEngine`.\n+        Further optional parameters as described in :cfg:config:`DMRG`.\n     **kwargs :\n         Further keyword arguments for the algorithm classes :class:`TwoSiteDMRGEngine` or\n         :class:`SingleSiteDMRGEngine`.\n@@ -124,22 +124,6 @@ class DMRGEngine(IterativeSweeps):\n \n     Attributes\n     ----------\n-    EffectiveH : class type\n-        Class for the effective Hamiltonian, i.e., a subclass of\n-        :class:`~tenpy.algorithms.mps_common.EffectiveH`. Has a `length` class attribute which\n-        specifies the number of sites updated at once (e.g., whether we do single-site vs. two-site\n-        DMRG).\n-    chi_list : dict | ``None``\n-        See :cfg:option:`DMRGEngine.chi_list`\n-    eff_H : :class:`~tenpy.algorithms.mps_common.EffectiveH`\n-        Effective two-site Hamiltonian.\n-    shelve : bool\n-        If a simulation runs out of time (`time.time() - start_time > max_seconds`), the run will\n-        terminate with `shelve = True`.\n-    sweeps : int\n-        The number of sweeps already performed. (Useful for re-start).\n-    time0 : float\n-        Time marker for the start of the run.\n     update_stats : dict\n         A dictionary with detailed statistics of the convergence at local update-level.\n         For each key in the following table, the dictionary contains a list where one value is\n@@ -213,14 +197,14 @@ def __init__(self, psi, model, options, **kwargs):\n         if self.chi_list is not None:\n             default_min_sweeps = max(max(self.chi_list.keys()), default_min_sweeps)\n         self.options.setdefault('min_sweeps', default_min_sweeps)\n-        mixer_options = self.options.subconfig('mixer_params')\n-        mixer_options.setdefault('amplitude', 1.e-5)\n+        mixer_params = self.options.subconfig('mixer_params')\n+        mixer_params.setdefault('amplitude', 1.e-5)\n         disable_finite = 15\n         disable_infinite = 50\n         decay_finite = 2.\n         decay_infinite = decay_finite ** (disable_finite / disable_infinite)\n-        mixer_options.setdefault('decay', decay_finite if self.finite else decay_infinite)\n-        mixer_options.setdefault('disable_after', disable_finite if self.finite else disable_infinite)\n+        mixer_params.setdefault('decay', decay_finite if self.finite else decay_infinite)\n+        mixer_params.setdefault('disable_after', disable_finite if self.finite else disable_infinite)\n \n     def pre_run_initialize(self):\n         super().pre_run_initialize()\n@@ -233,7 +217,7 @@ def run_iteration(self):\n         Options\n         -------\n         .. cfg:configoptions :: DMRGEngine\n-        \n+\n             E_tol_to_trunc : float\n                 It's reasonable to choose the Lanczos convergence criteria\n                 ``'E_tol'`` not many magnitudes lower than the current\n@@ -300,7 +284,7 @@ def run_iteration(self):\n         else:\n             E_old = self.sweep_stats['E'][-1]\n             S_old = self.sweep_stats['S'][-1]\n-        \n+\n         # perform sweeps\n         logger.info('Running sweep with optimization')\n         for i in range(self.N_sweeps_check - 1):\n@@ -390,7 +374,7 @@ def is_converged(self):\n         Options\n         -------\n         .. cfg:configoptions :: DMRGEngine\n-        \n+\n             max_E_err : float\n                 Convergence if the change of the energy in each step\n                 satisfies ``|Delta E / max(E, 1)| < max_E_err``. Note that\n@@ -406,14 +390,14 @@ def is_converged(self):\n         Delta_E = self.sweep_stats['Delta_E'][-1]\n         Delta_S = self.sweep_stats['Delta_S'][-1]\n         return abs(Delta_E / max(E, 1.)) < max_E_err and abs(Delta_S) < max_S_err\n-    \n+\n     def post_run_cleanup(self):\n         \"\"\"Perform any final steps or clean up after the main loop has terminated.\n \n         Options\n         -------\n         .. cfg:configoptions :: DMRGEngine\n-        \n+\n             norm_tol : float\n                 After the DMRG run, update the environment with at most\n                 `norm_tol_iter` sweeps until\n@@ -427,7 +411,7 @@ def post_run_cleanup(self):\n                 :meth:`~tenpy.networks.mps.canonical_form` to canonicalize\n                 instead. This tolerance should be stricter than `norm_tol`\n                 to ensure canonical form even if DMRG cannot fully converge.\n-        \n+\n         \"\"\"\n         super().post_run_cleanup()\n         self._canonicalize(True)\n@@ -457,7 +441,7 @@ def run(self):\n             i.e. just a reference to :attr:`psi`.\n         \"\"\"\n         return super().run()\n-    \n+\n     def _canonicalize(self, warn=False):\n         #Update environment until norm_tol is reached. If norm_tol_final\n         #is not reached, call canonical_form.\n@@ -494,20 +478,7 @@ def _canonicalize(self, warn=False):\n             self.psi.canonical_form()\n \n     def reset_stats(self, resume_data=None):\n-        \"\"\"Reset the statistics, useful if you want to start a new sweep run.\n-\n-        .. cfg:configoptions :: DMRGEngine\n-\n-            chi_list : dict | None\n-                A dictionary to gradually increase the `chi_max` parameter of\n-                `trunc_params`. The key defines starting from which sweep\n-                `chi_max` is set to the value, e.g. ``{0: 50, 20: 100}`` uses\n-                ``chi_max=50`` for the first 20 sweeps and ``chi_max=100``\n-                afterwards. Overwrites `trunc_params['chi_list']``.\n-                By default (``None``) this feature is disabled.\n-            sweep_0 : int\n-                The number of sweeps already performed. (Useful for re-start).\n-        \"\"\"\n+        \"\"\"Reset the statistics, useful if you want to start a new sweep run.\"\"\"\n         super().reset_stats(resume_data)\n         self.update_stats = {\n             'i0': [],\n@@ -874,66 +845,6 @@ class TwoSiteDMRGEngine(DMRGEngine):\n     .. cfg:config :: TwoSiteDMRGEngine\n         :include: DMRGEngine\n \n-    Attributes\n-    ----------\n-    eff_H : :class:`~tenpy.algorithms.mps_common.EffectiveH`\n-        Effective two-site Hamiltonian.\n-    mixer : :class:`~tenpy.algorithms.mps_common.Mixer` | ``None``\n-        If ``None``, no mixer is used (anymore), otherwise the mixer instance.\n-    shelve : bool\n-        If a simulation runs out of time (`time.time() - start_time > max_seconds`), the run will\n-        terminate with ``shelve = True``.\n-    sweeps : int\n-        The number of sweeps already performed. (Useful for re-start).\n-    time0 : float\n-        Time marker for the start of the run.\n-    update_stats : dict\n-        A dictionary with detailed statistics of the convergence.\n-        For each key in the following table, the dictionary contains a list where one value is\n-        added each time :meth:`DMRGEngine.update_bond` is called.\n-\n-        =========== ===================================================================\n-        key         description\n-        =========== ===================================================================\n-        i0          An update was performed on sites ``i0, i0+1``.\n-        ----------- -------------------------------------------------------------------\n-        age         The number of physical sites involved in the simulation.\n-        ----------- -------------------------------------------------------------------\n-        E_total     The total energy before truncation.\n-        ----------- -------------------------------------------------------------------\n-        N_lanczos   Dimension of the Krylov space used in the lanczos diagonalization.\n-        ----------- -------------------------------------------------------------------\n-        time        Wallclock time evolved since :attr:`time0` (in seconds).\n-        =========== ===================================================================\n-\n-    sweep_stats : dict\n-        A dictionary with detailed statistics of the convergence.\n-        For each key in the following table, the dictionary contains a list where one value is\n-        added each time :meth:`DMRGEngine.sweep` is called (with ``optimize=True``).\n-\n-        ============= ===================================================================\n-        key           description\n-        ============= ===================================================================\n-        sweep         Number of sweeps performed so far.\n-        ------------- -------------------------------------------------------------------\n-        E             The energy *before* truncation (as calculated by Lanczos).\n-        ------------- -------------------------------------------------------------------\n-        Delta_E       The change in `E` (above) since the last iteration.\n-        ------------- -------------------------------------------------------------------\n-        S             Maximum entanglement entropy.\n-        ------------- -------------------------------------------------------------------\n-        Delta_S       The change in `S` (above) since the last iteration.\n-        ------------- -------------------------------------------------------------------\n-        time          Wallclock time evolved since :attr:`time0` (in seconds).\n-        ------------- -------------------------------------------------------------------\n-        max_trunc_err The maximum truncation error in the last sweep\n-        ------------- -------------------------------------------------------------------\n-        max_E_trunc   Maximum change or Energy due to truncation in the last sweep.\n-        ------------- -------------------------------------------------------------------\n-        max_chi       Maximum bond dimension used.\n-        ------------- -------------------------------------------------------------------\n-        norm_err      Error of canonical form ``np.linalg.norm(psi.norm_test())``.\n-        ============= ===================================================================\n     \"\"\"\n     EffectiveH = TwoSiteH\n     DefaultMixer = mps_common.DensityMatrixMixer\n@@ -1040,71 +951,6 @@ class SingleSiteDMRGEngine(DMRGEngine):\n     .. cfg:config :: SingleSiteDMRGEngine\n         :include: DMRGEngine\n \n-    Attributes\n-    ----------\n-    chi_list : dict | ``None``\n-        A dictionary to gradually increase the `chi_max` parameter of `trunc_params`. The key\n-        defines starting from which sweep `chi_max` is set to the value, e.g. ``{0: 50, 20: 100}``\n-        uses ``chi_max=50`` for the first 20 sweeps and ``chi_max=100`` afterwards. Overwrites\n-        `trunc_params['chi_list']``. By default (``None``) this feature is disabled.\n-    eff_H : :class:`~tenpy.algorithms.mps_common.EffectiveH`\n-        Effective two-site Hamiltonian.\n-    mixer : :class:`~tenpy.algorithms.mps_common.Mixer` | ``None``\n-        If ``None``, no mixer is used (anymore), otherwise the mixer instance.\n-    shelve : bool\n-        If a simulation runs out of time (`time.time() - start_time > max_seconds`), the run will\n-        terminate with ``shelve = True``.\n-    sweeps : int\n-        The number of sweeps already performed. (Useful for re-start).\n-    time0 : float\n-        Time marker for the start of the run.\n-    update_stats : dict\n-        A dictionary with detailed statistics of the convergence.\n-        For each key in the following table, the dictionary contains a list where one value is\n-        added each time :meth:`DMRGEngine.update_bond` is called.\n-\n-        =========== ===================================================================\n-        key         description\n-        =========== ===================================================================\n-        i0          An update was performed on sites ``i0, i0+1``.\n-        ----------- -------------------------------------------------------------------\n-        age         The number of physical sites involved in the simulation.\n-        ----------- -------------------------------------------------------------------\n-        E_total     The total energy before truncation.\n-        ----------- -------------------------------------------------------------------\n-        N_lanczos   Dimension of the Krylov space used in the lanczos diagonalization.\n-        ----------- -------------------------------------------------------------------\n-        time        Wallclock time evolved since :attr:`time0` (in seconds).\n-        =========== ===================================================================\n-\n-    sweep_stats : dict\n-        A dictionary with detailed statistics of the convergence.\n-        For each key in the following table, the dictionary contains a list where one value is\n-        added each time :meth:`DMRGEngine.sweep` is called (with ``optimize=True``).\n-\n-        ============= ===================================================================\n-        key           description\n-        ============= ===================================================================\n-        sweep         Number of sweeps performed so far.\n-        ------------- -------------------------------------------------------------------\n-        E             The energy *before* truncation (as calculated by Lanczos).\n-        ------------- -------------------------------------------------------------------\n-        Delta_E       The change in `E` (above) since the last iteration.\n-        ------------- -------------------------------------------------------------------\n-        S             Maximum entanglement entropy.\n-        ------------- -------------------------------------------------------------------\n-        Delta_S       The change in `S` (above) since the last iteration.\n-        ------------- -------------------------------------------------------------------\n-        time          Wallclock time evolved since :attr:`time0` (in seconds).\n-        ------------- -------------------------------------------------------------------\n-        max_trunc_err The maximum truncation error in the last sweep\n-        ------------- -------------------------------------------------------------------\n-        max_E_trunc   Maximum change or Energy due to truncation in the last sweep.\n-        ------------- -------------------------------------------------------------------\n-        max_chi       Maximum bond dimension used.\n-        ------------- -------------------------------------------------------------------\n-        norm_err      Error of canonical form ``np.linalg.norm(psi.norm_test())``.\n-        ============= ===================================================================\n     \"\"\"\n     EffectiveH = OneSiteH\n     DefaultMixer = mps_common.SubspaceExpansion\ndiff --git a/tenpy/algorithms/mpo_evolution.py b/tenpy/algorithms/mpo_evolution.py\nindex 744da80c6..36fcb63d7 100644\n--- a/tenpy/algorithms/mpo_evolution.py\n+++ b/tenpy/algorithms/mpo_evolution.py\n@@ -7,7 +7,7 @@\n logger = logging.getLogger(__name__)\n \n from .algorithm import TimeEvolutionAlgorithm, TimeDependentHAlgorithm\n-from .truncation import TruncationError\n+from ..linalg.truncation import TruncationError\n from ..tools.misc import consistency_check\n \n __all__ = ['ExpMPOEvolution', 'TimeDependentExpMPOEvolution']\n@@ -28,8 +28,6 @@ class ExpMPOEvolution(TimeEvolutionAlgorithm):\n     .. cfg:config :: ExpMPOEvolution\n         :include: ApplyMPO, TimeEvolutionAlgorithm\n \n-        start_trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n-            Initial truncation error for :attr:`trunc_err`\n         approximation : 'I' | 'II'\n             Specifies which approximation is applied. The default 'II' is more precise.\n             See :cite:`zaletel2015` and :meth:`~tenpy.networks.mpo.MPO.make_U`\n@@ -46,17 +44,6 @@ class ExpMPOEvolution(TimeEvolutionAlgorithm):\n \n     Attributes\n     ----------\n-    options : :class:`~tenpy.tools.params.Config`\n-        Optional parameters, see :meth:`run` for more details\n-    evolved_time : float\n-        Indicating how long `psi` has been evolved, ``psi = exp(-i * evolved_time * H) psi(t=0)``.\n-    trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n-        The error of the represented state which is introduced due to the truncation during\n-        the sequence of update steps\n-    psi : :class:`~tenpy.networks.mps.MPS`\n-        The MPS, time evolved in-place.\n-    model : :class:`~tenpy.models.model.MPOModel`\n-        The model defining the Hamiltonian.\n     _U : list of :class:`~tenpy.networks.mps.MPO`\n         Exponentiated `H_MPO`;\n     _U_param : dict\n@@ -66,7 +53,6 @@ class ExpMPOEvolution(TimeEvolutionAlgorithm):\n     def __init__(self, psi, model, options, **kwargs):\n         super().__init__(psi, model, options, **kwargs)\n         options = self.options\n-        self.trunc_err = options.get('start_trunc_err', TruncationError(), TruncationError)\n         self._U_MPO = None\n         self._U_param = {}\n \ndiff --git a/tenpy/algorithms/mps_common.py b/tenpy/algorithms/mps_common.py\nindex 169f498c8..7b697426a 100644\n--- a/tenpy/algorithms/mps_common.py\n+++ b/tenpy/algorithms/mps_common.py\n@@ -25,7 +25,7 @@\n from ..linalg.sparse import NpcLinearOperator, SumNpcLinearOperator, OrthogonalNpcLinearOperator\n from ..networks.mpo import MPOEnvironment\n from ..networks.mps import MPSEnvironment\n-from .truncation import truncate, svd_theta, decompose_theta_qr_based, TruncationError\n+from ..linalg.truncation import truncate, svd_theta, decompose_theta_qr_based, TruncationError\n from ..linalg import np_conserved as npc\n from ..tools.params import asConfig\n from ..tools.misc import find_subclass, consistency_check\n@@ -119,6 +119,8 @@ class Sweep(Algorithm):\n         Cutoff for singular values when taking inverses of them is required.\n     time0 : float\n         Time marker for the start of the run.\n+    eff_H : :class:`~tenpy.algorithms.mps_common.EffectiveH`\n+        Effective single-site or two-site Hamiltonian.\n     trunc_err_list : list\n         List of truncation errors from the last sweep.\n     chi_list : dict | ``None``\n@@ -129,7 +131,7 @@ class Sweep(Algorithm):\n     \"\"\"\n     DefaultMixer = None\n     use_mixer_by_default = False  # The default for the \"mixer\" config option\n-    \n+\n     def __init__(self, psi, model, options, *, orthogonal_to=None, **kwargs):\n         if not hasattr(self, \"EffectiveH\"):\n             raise NotImplementedError(\"Subclass needs to set EffectiveH\")\n@@ -217,7 +219,7 @@ def init_env(self, model=None, resume_data=None, orthogonal_to=None):\n         -------\n \n         .. cfg:configoptions :: Sweep\n-                \n+\n             start_env : int\n                 Number of sweeps to be performed without optimization to update the environment.\n \n@@ -302,6 +304,8 @@ def reset_stats(self, resume_data=None):\n                 the value `chi` is to be used for ``trunc_params['chi_max']``.\n                 For example ``chi_list={0: 50, 20: 100}`` uses ``chi_max=50`` for the first\n                 20 sweeps and ``chi_max=100`` afterwards.\n+                A value of `None` is initialized to the current value of\n+                ``trunc_params['chi_max']`` at algorithm initialization.\n         \"\"\"\n         self.sweeps = 0\n         if resume_data is not None and 'sweeps' in resume_data:\n@@ -309,6 +313,10 @@ def reset_stats(self, resume_data=None):\n         self.shelve = False\n         self.chi_list = self.options.get('chi_list', None)\n         if self.chi_list is not None:\n+            for k, v in self.chi_list.items():\n+                if v is None:\n+                    self.chi_list[k] = chi_max = self.trunc_params['chi_max']\n+                    logger.info(\"Setting chi_list[%d]=%d\", k, chi_max)\n             done = [k for k in self.chi_list.keys() if k < self.sweeps]\n             if len(done) > 0:\n                 chi_max = self.chi_list[max(done)]\n@@ -391,7 +399,7 @@ def sweep(self, optimize=True):\n                     self.mixer_deactivate()\n                 else:\n                     self.mixer = mixer\n-            \n+\n         return np.max(self.trunc_err_list)\n \n     def get_sweep_schedule(self):\n@@ -684,14 +692,14 @@ def mixer_cleanup(self):\n         #   new_B[i] = V[i] * B[i] * hc(V[i + 1])\n         # LP environments transform like A tensors on the vR(*) leg(s)\n         # RP environments transform like B tensors on the vL(*) leg(s)\n-        \n+\n         if self.psi.finite:\n             assert self.psi.get_SL(0).ndim == 1\n             assert self.psi.get_SR(self.psi.L - 1).ndim == 1\n             first = 1\n         else:\n             first = 0\n-        \n+\n         for i in range(first, self.psi.L):  # converting S to the left of site i\n             S = self.psi.get_SL(i)\n             if S.ndim == 1:\n@@ -724,7 +732,7 @@ def mixer_cleanup(self):\n             self.psi.set_B(i - 1, B_L, form=self.psi.form[i - 1])\n             self.psi.set_SL(i, S)\n             self.psi.set_B(i, B_R, form=self.psi.form[i])\n-            \n+\n             # Update environment LP and RP\n             assert self.env.bra is self.psi\n             update_env_ket_leg = (self.env.ket is self.psi)\n@@ -764,7 +772,7 @@ class IterativeSweeps(Sweep):\n             If the any truncation error :attr:`~tenpy.algorithms.truncation.TruncationError.eps`\n             on the final sweep exceeds this value, we raise.\n             Can be downgraded to a warning by setting this option to ``None``.\n-    \n+\n     \"\"\"\n \n     def run(self):\n@@ -807,7 +815,7 @@ def run_iteration(self):\n             iteration\n         \"\"\"\n         raise NotImplementedError(\"Subclasses should implement this.\")\n-    \n+\n     def status_update(self, iteration_start_time: float):\n         \"\"\"Emits a status message to the logging system after an iteration.\n \n@@ -830,7 +838,7 @@ def status_update(self, iteration_start_time: float):\n                 'sep': \"=\" * 80,\n             }\n         )\n-        \n+\n     def stopping_criterion(self, iteration_start_time: float) -> bool:\n         \"\"\"Determines if the main loop should be terminated.\n \n@@ -842,7 +850,7 @@ def stopping_criterion(self, iteration_start_time: float) -> bool:\n         Options\n         -------\n         .. cfg:configoptions :: IterativeSweeps\n-        \n+\n             min_sweeps : int\n                 Minimum number of sweeps to perform.\n             max_sweeps : int\n@@ -860,7 +868,7 @@ def stopping_criterion(self, iteration_start_time: float) -> bool:\n         min_sweeps = self.options.get('min_sweeps', 1, int)\n         max_sweeps = self.options.get('max_sweeps', 1000, int)\n         max_seconds = 3600 * self.options.get('max_hours', 24 * 365, 'real')\n-        \n+\n         if self.sweeps > max_sweeps:\n             if self.is_converged():\n                 logger.info(f'{self.__class__.__name__}: Converged.')\n@@ -886,14 +894,14 @@ def is_converged(self) -> bool:\n         \"\"\"Determines if the algorithm is converged.\n \n         Does not cover any other reasons to abort, such as reaching a time limit.\n-        Such checks are covered by :meth:`stopping_condition`.\n+        Such checks are covered by :meth:`stopping_criterion`.\n         \"\"\"\n         raise NotImplementedError(\"Subclasses should implement this.\")\n-    \n+\n     def post_run_cleanup(self):\n         \"\"\"Perform any final steps or clean up after the main loop has terminated.\"\"\"\n         self.mixer_cleanup()\n-        \n+\n \n class EffectiveH(NpcLinearOperator):\n     \"\"\"Prototype class for local effective Hamiltonians used in sweep algorithms.\n@@ -2297,7 +2305,7 @@ class VariationalApplyMPO(VariationalCompression):\n \n     The goal is to find a new MPS `phi` (with `N` tensors) which is optimally close\n     to ``U_MPO|psi>``, i.e. it is normalized and maximizes ``| <phi|U_MPO|psi> |^2``.\n-    The network for this (with `M` tensors for `psi`) is given by\n+    The network for this (with `M` tensors for `psi`) is given by::\n \n \n         |     .-------M[0]----M[1]----M[2]---- ...  ----.\n@@ -2463,13 +2471,13 @@ def update_new_psi(self, theta: npc.Array):\n             # for old_T_R `'A'` form fine as well, but i0+1 in `'Th'` form if ``use_eig_based_svd=True``\n         expand = self._expansion_rate(i0)\n         use_eig_based_svd = self.options.get('use_eig_based_svd', False, bool)\n-        \n+\n         T_Lc, S, T_Rc, form, err, renormalize = decompose_theta_qr_based(\n-            old_qtotal_L=old_T_L.qtotal, old_qtotal_R=old_T_R.qtotal, old_bond_leg=old_bond_leg, \n+            old_qtotal_L=old_T_L.qtotal, old_qtotal_R=old_T_R.qtotal, old_bond_leg=old_bond_leg,\n             theta=theta, move_right=self.move_right,\n             expand=expand, min_block_increase = self.options.get('cbe_min_block_increase', 1, int),\n             use_eig_based_svd=use_eig_based_svd,\n-            trunc_params=self.trunc_params, \n+            trunc_params=self.trunc_params,\n             compute_err=self.options.get('compute_err', True, bool),\n             return_both_T=True\n         )\n@@ -2480,11 +2488,11 @@ def update_new_psi(self, theta: npc.Array):\n         else:\n             assert form[1] == 'B'\n             VH = T_Rc\n-        \n+\n         T_L = T_Lc.split_legs(['(vL.p)'])\n         T_R = T_Rc.split_legs(['(p.vR)'])\n         U, VH = None, None\n-        \n+\n         self.renormalize.append(renormalize)\n \n         # compare to old best guess to check convergence of the sweeps\n@@ -2498,9 +2506,9 @@ def update_new_psi(self, theta: npc.Array):\n             ov = npc.inner(theta_new_trunc, theta_old, do_conj=True, axes='labels')\n             theta_diff = 1. - abs(ov)\n             self._theta_diff.append(theta_diff)\n-        \n+\n         # set the new tensors to the MPS\n         new_psi.set_B(i0, T_L, form=form[0])\n         new_psi.set_B(i0+1, T_R, form=form[1])\n         new_psi.set_SR(i0, S)\n-        return {'U': U, 'VH': VH, 'err': err}\n\\ No newline at end of file\n+        return {'U': U, 'VH': VH, 'err': err}\ndiff --git a/tenpy/algorithms/purification.py b/tenpy/algorithms/purification.py\nindex 442d7250d..fa5beb005 100644\n--- a/tenpy/algorithms/purification.py\n+++ b/tenpy/algorithms/purification.py\n@@ -9,7 +9,7 @@\n from ..linalg import np_conserved as npc\n from . import tebd\n from .mps_common import VariationalApplyMPO, TwoSiteH\n-from .truncation import svd_theta, TruncationError\n+from ..linalg.truncation import svd_theta, TruncationError\n from .disentangler import get_disentangler\n \n __all__ = ['PurificationTwoSiteU', 'PurificationApplyMPO', 'PurificationTEBD', 'PurificationTEBD2']\ndiff --git a/tenpy/algorithms/tdvp.py b/tenpy/algorithms/tdvp.py\nindex 0edca7f06..d92c2f506 100644\n--- a/tenpy/algorithms/tdvp.py\n+++ b/tenpy/algorithms/tdvp.py\n@@ -18,10 +18,11 @@\n Much of the code is very similar to DMRG, and also based on the\n :class:`~tenpy.algorithms.mps_common.Sweep` class.\n \n-.. warning ::\n-    The interface changed compared to version 0.9.0: Using :class:`TDVPEngine` will result\n-    in a error. Use :class:`SingleSiteTDVPEngine` or :class:`TwoSiteTDVPEngine` instead.\n-    The old code is still around as :class:`OldTDVPEngine`.\n+.. versionchanged :: 0.10.0\n+    The interface changed compared to version 0.9.0:\n+    Just :class:`TDVPEngine` will result in a error.\n+    Use :class:`SingleSiteTDVPEngine` or :class:`TwoSiteTDVPEngine` instead.\n+\n \n .. todo ::\n     extend code to infinite MPS\n@@ -32,12 +33,14 @@\n # Copyright (C) TeNPy Developers, GNU GPLv3\n \n from ..linalg.krylov_based import LanczosEvolution\n-from .truncation import svd_theta, TruncationError\n+from ..linalg.truncation import svd_theta, TruncationError\n from .mps_common import Sweep, ZeroSiteH, OneSiteH, TwoSiteH\n from .algorithm import TimeEvolutionAlgorithm, TimeDependentHAlgorithm\n from ..linalg import np_conserved as npc\n from ..tools.misc import consistency_check\n+from ..tools.params import asConfig\n import logging\n+import warnings\n \n logger = logging.getLogger(__name__)\n \n@@ -52,6 +55,10 @@ class TDVPEngine(TimeEvolutionAlgorithm, Sweep):\n     :class:`SingleSiteTDVPEngine` and :class:`TwoSiteTDVPEngine`.\n     Use the latter two classes for actual TDVP runs.\n \n+    .. versionchanged :: 1.1\n+        Previously had separate `lanczos_options`, which have been renamed to `lanczos_params`\n+        for consistency with the Sweep class.\n+\n     Parameters\n     ----------\n     psi, model, options, **kwargs:\n@@ -59,13 +66,9 @@ class TDVPEngine(TimeEvolutionAlgorithm, Sweep):\n \n     Options\n     -------\n-    .. cfg:config :: TDVP\n-        :include: TimeEvolutionAlgorithm\n+    .. cfg:config :: TDVPEngine\n+        :include: TimeEvolutionAlgorithm, Sweep\n \n-        trunc_params : dict\n-            Truncation parameters as described in :func:`~tenpy.algorithms.truncation.truncate`\n-        lanczos_options : dict\n-            Lanczos options as described in :cfg:config:`Lanczos`.\n         max_dt : float | None\n             Threshold for raising errors on too large time steps. Default ``1.0``.\n             See :meth:`~tenpy.tools.misc.consistency_check`.\n@@ -73,18 +76,6 @@ class TDVPEngine(TimeEvolutionAlgorithm, Sweep):\n             of TDVP, can not be a good approximation anymore. We raise in that case.\n             Can be downgraded to a warning by setting this option to ``None``.\n \n-    Attributes\n-    ----------\n-    options: dict\n-        Optional parameters.\n-    evolved_time : float | complex\n-        Indicating how long `psi` has been evolved, ``psi = exp(-i * evolved_time * H) psi(t=0)``.\n-    psi : :class:`~tenpy.networks.mps.MPS`\n-        The MPS, time evolved in-place.\n-    env : :class:`~tenpy.networks.mpo.MPOEnvironment`\n-        The environment, storing the `LP` and `RP` to avoid recalculations.\n-    lanczos_options : :class:`~tenpy.tools.params.Config`\n-        Options passed on to :class:`~tenpy.linalg.lanczos.LanczosEvolution`.\n     \"\"\"\n     EffectiveH = None\n \n@@ -93,17 +84,25 @@ def __init__(self, psi, model, options, **kwargs):\n             msg = (\"TDVP interface changed. \\n\"\n                    \"The new TDVPEngine has subclasses SingleSiteTDVPEngine\"\n                    \" and TwoSiteTDVPEngine that you can use.\\n\"\n-                   \"For now, the previous version is still available as OldTDVPEngine.\"\n                    )\n             raise NameError(msg)\n         if psi.bc != 'finite':\n             raise NotImplementedError(\"Only finite TDVP is implemented\")\n         assert psi.bc == model.lat.bc_MPS\n+        options = asConfig(options, self.__class__.__name__)\n+        options.deprecated_alias(\"lanczos_options\", \"lanczos_params\",\n+                                 \"See also https://github.com/tenpy/tenpy/issues/459\")\n         super().__init__(psi, model, options, **kwargs)\n-        self.lanczos_options = self.options.subconfig('lanczos_options')\n \n     # run() from TimeEvolutionAlgorithm\n \n+    @property\n+    def lanczos_options(self):\n+        \"\"\"Deprecated alias of :attr:`lanczos_params`.\"\"\"\n+        warnings.warn(\"Accessing deprecated alias TDVPEngine.lanczos_options instead of lanczos_params\",\n+                      FutureWarning, stacklevel=2)\n+        return self.lanczos_params\n+\n     def prepare_evolve(self, dt):\n         \"Do nothing.\"\n         pass\n@@ -138,32 +137,14 @@ class TwoSiteTDVPEngine(TDVPEngine):\n \n     Options\n     -------\n-    .. cfg:config :: TDVP\n-        :include: TimeEvolutionAlgorithm\n-\n-        trunc_params : dict\n-            Truncation parameters as described in :func:`~tenpy.algorithms.truncation.truncate`\n-        lanczos_options : dict\n-            Lanczos options as described in :cfg:config:`Lanczos`.\n+    .. cfg:config :: TwoSiteTDVPEngine\n+        :include: TDVPEngine\n \n-    Attributes\n-    ----------\n-    options: dict\n-        Optional parameters.\n-    evolved_time : float | complex\n-        Indicating how long `psi` has been evolved, ``psi = exp(-i * evolved_time * H) psi(t=0)``.\n-    psi : :class:`~tenpy.networks.mps.MPS`\n-        The MPS, time evolved in-place.\n-    env : :class:`~tenpy.networks.mpo.MPOEnvironment`\n-        The environment, storing the `LP` and `RP` to avoid recalculations.\n-    lanczos_options : :class:`~tenpy.tools.params.Config`\n-        Options passed on to :class:`~tenpy.linalg.lanczos.LanczosEvolution`.\n     \"\"\"\n     EffectiveH = TwoSiteH\n \n     def __init__(self, psi, model, options, **kwargs):\n         super().__init__(psi, model, options, **kwargs)\n-        self.trunc_err = TruncationError()\n \n     def get_sweep_schedule(self):\n         \"\"\"Slightly different sweep schedule than DMRG\"\"\"\n@@ -180,11 +161,11 @@ def update_local(self, theta, **kwargs):\n         i0 = self.i0\n         L = self.psi.L\n \n-        dt = self.dt\n+        dt = -0.5j * self.dt\n         if i0 == L - 2:\n             dt = 2. * dt  # instead of updating the last pair of sites twice, we double the time\n         # update two-site wavefunction\n-        theta, N = LanczosEvolution(self.eff_H, theta, self.lanczos_options).run(-0.5j * dt)\n+        theta, N = LanczosEvolution(self.eff_H, theta, self.lanczos_params).run(dt)\n         if self.combine:\n             theta.itranspose(['(vL.p0)', '(p1.vR)'])  # shouldn't do anything\n         else:\n@@ -211,7 +192,7 @@ def update_local(self, theta, **kwargs):\n         elif (self.move_right is False):\n             self.one_site_update(i0, 0.5j * self.dt)\n         # for the last update of the sweep, where move_right is None, there is no one_site_update\n-        \n+\n         return update_data\n \n     def update_env(self, **update_data):\n@@ -222,7 +203,7 @@ def one_site_update(self, i, dt):\n         H1 = OneSiteH(self.env, i, combine=False)\n         theta = self.psi.get_theta(i, n=1, cutoff=self.S_inv_cutoff)\n         theta = H1.combine_theta(theta)\n-        theta, _ = LanczosEvolution(H1, theta, self.lanczos_options).run(dt)\n+        theta, _ = LanczosEvolution(H1, theta, self.lanczos_params).run(dt)\n         self.psi.set_B(i, theta.replace_label('p0', 'p'), form='Th')\n \n \n@@ -236,26 +217,9 @@ class SingleSiteTDVPEngine(TDVPEngine):\n \n     Options\n     -------\n-    .. cfg:config :: TDVP\n-        :include: TimeEvolutionAlgorithm\n+    .. cfg:config :: SingleSiteTDVPEngine\n+        :include: TDVPEngine\n \n-        trunc_params : dict\n-            Truncation parameters as described in :func:`~tenpy.algorithms.truncation.truncate`\n-        lanczos_options : dict\n-            Lanczos options as described in :cfg:config:`Lanczos`.\n-\n-    Attributes\n-    ----------\n-    options: dict\n-        Optional parameters.\n-    evolved_time : float | complex\n-        Indicating how long `psi` has been evolved, ``psi = exp(-i * evolved_time * H) psi(t=0)``.\n-    psi : :class:`~tenpy.networks.mps.MPS`\n-        The MPS, time evolved in-place.\n-    env : :class:`~tenpy.networks.mpo.MPOEnvironment`\n-        The environment, storing the `LP` and `RP` to avoid recalculations.\n-    lanczos_options : :class:`~tenpy.tools.params.Config`\n-        Options passed on to :class:`~tenpy.linalg.lanczos.LanczosEvolution`.\n     \"\"\"\n     EffectiveH = OneSiteH\n \n@@ -274,12 +238,12 @@ def update_local(self, theta, **kwargs):\n         i0 = self.i0\n         L = self.psi.L\n \n-        dt = self.dt\n+        dt = -0.5j * self.dt\n         if i0 == L - 1:\n             dt = 2. * dt  # instead of updating the last site twice, we double the time\n \n         # update one-site wavefunction\n-        theta, N = LanczosEvolution(self.eff_H, theta, self.lanczos_options).run(-0.5j * dt)\n+        theta, N = LanczosEvolution(self.eff_H, theta, self.lanczos_params).run(dt)\n         if self.move_right:\n             self.right_moving_update(i0, theta)\n         else:\n@@ -339,7 +303,7 @@ def update_env(self, **update_data):\n     def zero_site_update(self, i, theta, dt):\n         \"\"\"Zero-site update on the left of site `i`.\"\"\"\n         H0 = ZeroSiteH(self.env, i)\n-        theta, _ = LanczosEvolution(H0, theta, self.lanczos_options).run(dt)\n+        theta, _ = LanczosEvolution(H0, theta, self.lanczos_params).run(dt)\n         return theta, H0\n \n     def post_update_local(self, **update_data):\ndiff --git a/tenpy/algorithms/tebd.py b/tenpy/algorithms/tebd.py\nindex cd2d20b82..46cb0aa00 100644\n--- a/tenpy/algorithms/tebd.py\n+++ b/tenpy/algorithms/tebd.py\n@@ -48,7 +48,7 @@\n \n from .algorithm import TimeEvolutionAlgorithm, TimeDependentHAlgorithm\n from ..linalg import np_conserved as npc\n-from .truncation import svd_theta, decompose_theta_qr_based, TruncationError\n+from ..linalg.truncation import svd_theta, decompose_theta_qr_based, TruncationError\n from ..linalg import random_matrix\n from ..tools.misc import consistency_check\n \n@@ -65,8 +65,6 @@ class TEBDEngine(TimeEvolutionAlgorithm):\n     .. cfg:config :: TEBDEngine\n         :include: TimeEvolutionAlgorithm\n \n-        start_trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n-            Initial truncation error for :attr:`trunc_err`.\n         order : int\n             Order of the algorithm. The total error for evolution up to a fixed time `t`\n             scales as ``O(t*dt^order)``.\n@@ -81,13 +79,6 @@ class TEBDEngine(TimeEvolutionAlgorithm):\n \n     Attributes\n     ----------\n-    trunc_err : :class:`~tenpy.algorithms.truncation.TruncationError`\n-        The error of the represented state which is introduced due to the truncation during\n-        the sequence of update steps.\n-    psi : :class:`~tenpy.networks.mps.MPS`\n-        The MPS, time evolved in-place.\n-    model : :class:`~tenpy.models.model.NearestNeighborModel`\n-        The model defining the Hamiltonian.\n     _U : list of list of :class:`~tenpy.linalg.np_conserved.Array`\n         Exponentiated `H_bond` (bond Hamiltonians), i.e. roughly ``exp(-i H_bond dt_i)``.\n         First list for different `dt_i` as necessary for the chosen `order`,\n@@ -707,7 +698,7 @@ def update_bond_imag(self, i, U_bond):\n             expand = expand, min_block_increase=self.options.get('cbe_min_block_increase', 1, int),\n             use_eig_based_svd=self.options.get('use_eig_based_svd', False, bool),\n             trunc_params=self.trunc_params,\n-            compute_err=self.options.get('compute_err', True, bool), \n+            compute_err=self.options.get('compute_err', True, bool),\n             return_both_T=True,\n         )\n         assert form == ['A','B']\ndiff --git a/tenpy/algorithms/truncation.py b/tenpy/algorithms/truncation.py\nindex 9124428be..063beffbf 100644\n--- a/tenpy/algorithms/truncation.py\n+++ b/tenpy/algorithms/truncation.py\n@@ -1,652 +1,14 @@\n-r\"\"\"Truncation of Schmidt values.\n+\"\"\"Dummy module for backwards compatibility.\n \n-Often, it is necessary to truncate the number of states on a virtual bond of an MPS,\n-keeping only the state with the largest Schmidt values.\n-The function :func:`truncate` picks exactly those from a given Schmidt spectrum\n-:math:`\\lambda_a`, depending on some parameters explained in the doc-string of the function.\n-\n-Further, we provide :class:`TruncationError` for a simple way to keep track of the\n-total truncation error.\n-\n-The SVD on a virtual bond of an MPS actually gives a Schmidt decomposition\n-:math:`|\\psi\\rangle = \\sum_{a} \\lambda_a |L_a\\rangle |R_a\\rangle`\n-where :math:`|L_a\\rangle` and :math:`|R_a\\rangle` form orthonormal bases of the parts\n-left and right of the virtual bond.\n-Let us assume that the state is properly normalized,\n-:math:`\\langle\\psi | \\psi\\rangle = \\sum_{a} \\lambda^2_a = 1`.\n-Assume that the singular values are ordered descending, and that we keep the first :math:`\\chi_c`\n-of the initially :math:`\\chi` Schmidt values.\n-\n-Then we decompose the untruncated state as\n-:math:`|\\psi\\rangle = \\sqrt{1-\\epsilon}|\\psi_{tr}\\rangle + \\sqrt{\\epsilon}|\\psi_{tr}^\\perp\\rangle`\n-where\n-:math:`|\\psi_{tr}\\rangle =\n-\\frac{1}{\\sqrt{1-\\epsilon}} \\sum_{a < \\chi_c} \\lambda_a|L_a\\rangle|R_a\\rangle`\n-is the truncated state kept (normalized to 1),\n-:math:`|\\psi_{tr}^\\perp\\rangle =\n-\\frac{1}{\\sqrt{\\epsilon}} \\sum_{a >= \\chi_c} \\lambda_a |L_a\\rangle|R_a\\rangle`\n-is the discarded part (orthogonal to the kept part) and the\n-*truncation error of a single truncation* is defined as\n-:math:`\\epsilon = 1 - |\\langle \\psi | \\psi_{tr}\\rangle |^2 = \\sum_{a >= \\chi_c} \\lambda_a^2`.\n-\n-.. warning ::\n-    For imaginary time evolution (e.g. with TEBD), you try to project out the ground state.\n-    Then, looking at the truncation error defined in this module does *not* give you any\n-    information how good the found state coincides with the actual ground state!\n-    (Instead, the returned truncation error depends on the overlap with the initial state,\n-    which is arbitrary > 0)\n-\n-.. warning ::\n-    This module takes only track of the errors coming from the truncation of Schmidt values.\n-    There might be other sources of error as well, for example TEBD has also an discretization\n-    error depending on the chosen time step.\n+The `tenpy.algorithms.truncation` module was moved to :mod:`tenpy.linalg.truncation`.\n+Here we just import all the names again for backwards compatibility,\n+to support loading pickle and HDF5 data files with `TruncationError` instances in them.\n \"\"\"\n # Copyright (C) TeNPy Developers, GNU GPLv3\n \n-import numpy as np\n-from ..linalg import np_conserved as npc\n-from ..tools.hdf5_io import Hdf5Exportable\n-import warnings\n-from ..tools.params import asConfig\n-\n-__all__ = ['TruncationError', 'truncate', 'svd_theta', 'decompose_theta_qr_based']\n-\n-\n-\n-class TruncationError(Hdf5Exportable):\n-    r\"\"\"Class representing a truncation error.\n-\n-    The default initialization represents \"no truncation\".\n-\n-    .. warning ::\n-        For imaginary time evolution, this is *not* the error you are interested in!\n-\n-    Parameters\n-    ----------\n-    eps, ov : float\n-        See below.\n-\n-\n-    Attributes\n-    ----------\n-    eps : float\n-        The total sum of all discarded Schmidt values squared.\n-        Note that if you keep singular values up to 1.e-14 (= a bit more than machine precision\n-        for 64bit floats), `eps` is on the order of 1.e-28 (due to the square)!\n-    ov : float\n-        A lower bound for the overlap :math:`|\\langle \\psi_{trunc} | \\psi_{correct} \\rangle|^2`\n-        (assuming normalization of both states).\n-        This is probably the quantity you are actually interested in.\n-        Takes into account the factor 2 explained in the section on Errors in the\n-        `TEBD Wikipedia article <https://en.wikipedia.org/wiki/Time-evolving_block_decimation>`.\n-    \"\"\"\n-    def __init__(self, eps=0., ov=1.):\n-        self.eps = eps\n-        self.ov = ov\n-\n-    def copy(self):\n-        \"\"\"Return a copy of self.\"\"\"\n-        return TruncationError(self.eps, self.ov)\n-\n-    @classmethod\n-    def from_norm(cls, norm_new, norm_old=1.):\n-        r\"\"\"Construct TruncationError from norm after and before the truncation.\n-\n-        Parameters\n-        ----------\n-        norm_new : float\n-            Norm of Schmidt values kept, :math:`\\sqrt{\\sum_{a kept} \\lambda_a^2}`\n-            (before re-normalization).\n-        norm_old : float\n-            Norm of all Schmidt values before truncation, :math:`\\sqrt{\\sum_{a} \\lambda_a^2}`.\n-        \"\"\"\n-        eps = 1. - norm_new**2 / norm_old**2  # = (norm_old**2 - norm_new**2)/norm_old**2\n-        return cls(eps, 1. - 2. * eps)\n-\n-    @classmethod\n-    def from_S(cls, S_discarded, norm_old=None):\n-        r\"\"\"Construct TruncationError from discarded singular values.\n-\n-        Parameters\n-        ----------\n-        S_discarded : 1D numpy array\n-            The singular values discarded.\n-        norm_old : float\n-            Norm of all Schmidt values before truncation, :math:`\\sqrt{\\sum_{a} \\lambda_a^2}`.\n-            Default (``None``) is 1.\n-        \"\"\"\n-        eps = np.sum(np.square(S_discarded))\n-        if norm_old:\n-            eps /= norm_old * norm_old\n-        return cls(eps, 1. - 2. * eps)\n-\n-    def __add__(self, other):\n-        res = TruncationError()\n-        res.eps = self.eps + other.eps  # whatever that actually means...\n-        res.ov = self.ov * other.ov\n-        return res\n-\n-    @property\n-    def ov_err(self):\n-        \"\"\"Error ``1.-ov`` of the overlap with the correct state.\"\"\"\n-        return 1. - self.ov\n-\n-    def __repr__(self):\n-        if self.eps != 0 or self.ov != 1.:\n-            return \"TruncationError(eps={eps:.4e}, ov={ov:.10f})\".format(eps=self.eps, ov=self.ov)\n-        else:\n-            return \"TruncationError()\"\n-\n-\n-def truncate(S, options):\n-    \"\"\"Given a Schmidt spectrum `S`, determine which values to keep.\n-\n-    Options\n-    -------\n-    .. cfg:config:: truncation\n-\n-        chi_max : int\n-            Keep at most `chi_max` Schmidt values.\n-        chi_min : int\n-            Keep at least `chi_min` Schmidt values.\n-        degeneracy_tol: float\n-            Don't cut between neighboring Schmidt values with\n-            ``|log(S[i]/S[j])| < degeneracy_tol``, or equivalently\n-            ``|S[i] - S[j]|/S[j] < exp(degeneracy_tol) - 1 ~= degeneracy_tol``\n-            for small `degeneracy_tol`.\n-            In other words, keep either both `i` and `j` or none, if the\n-            Schmidt values are degenerate with a relative error smaller\n-            than `degeneracy_tol`, which we expect to happen in the case\n-            of symmetries.\n-        svd_min : float\n-            Discard all small Schmidt values ``S[i] < svd_min``.\n-        trunc_cut : float\n-            Discard all small Schmidt values as long as\n-            ``sum_{i discarded} S[i]**2 <= trunc_cut**2``.\n-\n-    Parameters\n-    ----------\n-    S : 1D array\n-        Schmidt values (as returned by an SVD), not necessarily sorted.\n-        Should be normalized to ``np.sum(S*S) == 1.``.\n-    options: dict-like\n-        Config with constraints for the truncation, see :cfg:config:`truncation`.\n-        If a constraint can not be fulfilled (without violating a previous one), it is ignored.\n-        A value ``None`` indicates that the constraint should be ignored.\n-\n-    Returns\n-    -------\n-    mask : 1D bool array\n-        Index mask, True for indices which should be kept.\n-    norm_new : float\n-        The norm of the truncated Schmidt values, ``np.linalg.norm(S[mask])``.\n-        Useful for re-normalization.\n-    err : :class:`TruncationError`\n-        The error of the represented state which is introduced due to the truncation.\n-    \"\"\"\n-    options = asConfig(options, \"truncation\")\n-    # by default, only truncate values which are much closer to zero than machine precision.\n-    # This is only to avoid problems with taking the inverse of `S`.\n-    chi_max = options.get('chi_max', 100, int)\n-    chi_min = options.get('chi_min', None, int)\n-    deg_tol = options.get('degeneracy_tol', None, 'real')\n-    svd_min = options.get('svd_min', 1.e-14, 'real')\n-    trunc_cut = options.get('trunc_cut', 1.e-14, 'real')\n-\n-    if trunc_cut is not None and trunc_cut >= 1.:\n-        raise ValueError(\"trunc_cut >=1.\")\n-    if not np.any(S > 1.e-10):\n-        warnings.warn(\"no Schmidt value above 1.e-10\", stacklevel=2)\n-    if np.any(S < -1.e-10):\n-        warnings.warn(\"negative Schmidt values!\", stacklevel=2)\n-\n-    # use 1.e-100 as replacement for <=0 values for a well-defined logarithm.\n-    logS = np.log(np.choose(S <= 0., [S, 1.e-100 * np.ones(len(S))]))\n-    piv = np.argsort(logS)  # sort *ascending*.\n-    logS = logS[piv]\n-    # goal: find an index 'cut' such that we keep piv[cut:], i.e. cut between `cut-1` and `cut`.\n-    good = np.ones(len(piv), dtype=np.bool_)  # good[cut] = (is `cut` a good choice?)\n-    # we choose the smallest 'good' cut.\n-\n-    if chi_max is not None:\n-        # keep at most chi_max values\n-        good2 = np.zeros(len(piv), dtype=np.bool_)\n-        good2[-chi_max:] = True\n-        good = _combine_constraints(good, good2, \"chi_max\")\n-\n-    if chi_min is not None and chi_min > 1:\n-        # keep at most chi_max values\n-        good2 = np.ones(len(piv), dtype=np.bool_)\n-        good2[-chi_min + 1:] = False\n-        good = _combine_constraints(good, good2, \"chi_min\")\n-\n-    if deg_tol:\n-        # don't cut between values (cut-1, cut) with ``log(S[cut]/S[cut-1]) < deg_tol``\n-        # this is equivalent to\n-        # ``(S[cut] - S[cut-1])/S[cut-1] < exp(deg_tol) - 1 = deg_tol + O(deg_tol^2)``\n-        good2 = np.empty(len(piv), np.bool_)\n-        good2[0] = True\n-        good2[1:] = np.greater_equal(logS[1:] - logS[:-1], deg_tol)\n-        good = _combine_constraints(good, good2, \"degeneracy_tol\")\n-\n-    if svd_min is not None:\n-        # keep only values S[i] >= svd_min\n-        good2 = np.greater_equal(logS, np.log(svd_min))\n-        good = _combine_constraints(good, good2, \"svd_min\")\n-\n-    if trunc_cut is not None:\n-        good2 = (np.cumsum(S[piv]**2) > trunc_cut * trunc_cut)\n-        good = _combine_constraints(good, good2, \"trunc_cut\")\n-\n-    cut = np.nonzero(good)[0][0]  # smallest possible cut: keep as many S as allowed\n-    mask = np.zeros(len(S), dtype=np.bool_)\n-    np.put(mask, piv[cut:], True)\n-    norm_new = np.linalg.norm(S[mask])\n-    return mask, norm_new, TruncationError.from_S(S[np.logical_not(mask)]),\n-\n-\n-def svd_theta(theta, trunc_par, qtotal_LR=[None, None], inner_labels=['vR', 'vL']):\n-    \"\"\"Performs SVD of a matrix `theta` (= the wavefunction) and truncates it.\n-\n-    Perform a singular value decomposition (SVD) with :func:`~tenpy.linalg.np_conserved.svd`\n-    and truncates with :func:`truncate`.\n-    The result is an approximation\n-    ``theta ~= tensordot(U.scale_axis(S*renormalization, 1), VH, axes=1)``\n-\n-    Parameters\n-    ----------\n-    theta : :class:`~tenpy.linalg.np_conserved.Array`, shape ``(M, N)``\n-        The matrix, on which the singular value decomposition (SVD) is performed.\n-        Usually, `theta` represents the wavefunction, such that the SVD is a Schmidt decomposition.\n-    trunc_par : dict\n-        truncation parameters as described in :func:`truncate`.\n-    qtotalLR : (charges, charges)\n-        The total charges for the returned `U` and `VH`.\n-    inner_labels : (string, string)\n-        Labels for the `U` and `VH` on the newly-created bond.\n-\n-    Returns\n-    -------\n-    U : :class:`~tenpy.linalg.np_conserved.Array`\n-        Matrix with left singular vectors as columns.\n-        Shape ``(M, M)`` or ``(M, K)`` depending on `full_matrices`.\n-    S : 1D ndarray\n-        The singular values of the array.\n-        If no `cutoff` is given, it has length ``min(M, N)``.\n-        Normalized to ``np.linalg.norm(S)==1``.\n-    VH : :class:`~tenpy.linalg.np_conserved.Array`\n-        Matrix with right singular vectors as rows.\n-        Shape ``(N, N)`` or ``(K, N)`` depending on `full_matrices`.\n-    err : :class:`TruncationError`\n-        The truncation error introduced.\n-    renormalization : float\n-        Factor, by which S was renormalized.\n-    \"\"\"\n-    U, S, VH = npc.svd(theta,\n-                       full_matrices=False,\n-                       compute_uv=True,\n-                       qtotal_LR=qtotal_LR,\n-                       inner_labels=inner_labels)\n-    renormalization = np.linalg.norm(S)\n-    S = S / renormalization\n-    piv, new_norm, err = truncate(S, trunc_par)\n-    new_len_S = np.sum(piv, dtype=np.int_)\n-    if new_len_S * 100 < len(S) and (trunc_par['chi_max'] is None\n-                                     or new_len_S != trunc_par['chi_max']):\n-        msg = \"Catastrophic reduction in chi: {0:d} -> {1:d}\".format(len(S), new_len_S)\n-        # NANs are excluded in npc.svd\n-        UHU = npc.tensordot(U.conj(), U, axes=[[0], [0]])\n-        msg += \" |U^d U - 1| = {0:f}\".format(npc.norm(UHU - npc.eye_like(UHU)))\n-        VHV = npc.tensordot(VH, VH.conj(), axes=[[1], [1]])\n-        msg += \" |V V - 1| = {0:f}\".format(npc.norm(VHV - npc.eye_like(VHV)))\n-        warnings.warn(msg, stacklevel=2)\n-    S = S[piv] / new_norm\n-    renormalization *= new_norm\n-    U.iproject(piv, axes=1)  # U = U[:, piv]\n-    VH.iproject(piv, axes=0)  # VH = VH[piv, :]\n-    return U, S, VH, err, renormalization\n-\n-\n-def _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta: npc.Array, move_right: bool, expand: float, min_block_increase: int):\n-    \"\"\"Generate the initial guess `Y0` for the (left) right isometry for the QR based theta decomposition `decompose_theta_qr_based()`.\n-\n-    Parameters\n-    ----------\n-    old_qtotal_L : 1D array\n-        The total charge of the old left tensor.\n-        e.g. ``old_qtotal_L = T_L.qtotal``\n-    old_qtotal_R : 1D array\n-        The total charge of the old right tensor.\n-        e.g. ``old_qtotal_R = T_R.qtotal``\n-    old_bond_leg : :class:`~tenpy.linalg.charges.LegCharge`\n-        The leg between the old left tensor and the old right tensor.\n-        e.g. ``old_bond_leg = T_L.get_leg('vR')`` or ``old_bond_leg = T_R.get_leg('vL')``\n-    theta : Array with legs [(vL.p0), (p1.vR)]\n-    move_right : bool \n-    expand : float\n-    min_block_increase : int\n-\n-    Returns\n-    -------\n-    Y0 : Array with legs [vL, (p1.vR)] or [(vL.p0), vR]\n-        If ``move_right=True``, the legs of Y0 are [vL, (p1.vR)].\n-        If ``move_right=False``, the legs of Y0 are [(vL.p0), vR].\n-    \"\"\"\n-\n-    assert min_block_increase >= 0\n-    assert expand is not None and expand != 0\n-    \n-    if move_right:\n-        Y0 = theta.copy(deep=False)\n-        Y0.legs[1] = Y0.legs[1].to_LegCharge()\n-        Y0.ireplace_label('(p1.vR)', 'vR')\n-        if any(old_qtotal_R != 0):\n-            Y0.gauge_total_charge('vR', new_qtotal=old_qtotal_L)\n-        vR_old = old_bond_leg\n-        if not vR_old.is_blocked():\n-            vR_old = vR_old.sort()[1]\n-        vR_new = Y0.get_leg('vR')  # is blocked, since created from pipe\n-        v_old, v_new = vR_old, vR_new\n-        q_axis, norm_axis = 1, 0\n-    else:\n-        Y0 = theta.copy(deep=False)\n-        Y0.legs[0] = Y0.legs[0].to_LegCharge()\n-        Y0.ireplace_label('(vL.p0)', 'vL')\n-        if any(old_qtotal_L != 0):\n-            Y0.gauge_total_charge('vL', new_qtotal=old_qtotal_R)\n-        vL_old = old_bond_leg\n-        if not vL_old.is_blocked():\n-            vL_old = vL_old.sort()[1]\n-        vL_new = Y0.get_leg('vL')  # is blocked, since created from pipe\n-        v_old, v_new = vL_old, vL_new\n-        q_axis, norm_axis = 0, 1\n-\n-    # vL(R)_old is guaranteed to be a slice of vL(R)_new by charge rule in T_L(R)_old\n-    piv = np.zeros(v_new.ind_len, dtype=bool)  # indices to keep in v_new\n-    increase_per_block = max(min_block_increase, int(v_old.ind_len * expand // v_new.block_number))\n-    sizes_old = v_old.get_block_sizes()\n-    sizes_new = v_new.get_block_sizes()\n-\n-    # iterate over charge blocks in vL(R)_new and vL(R)_old at the same time\n-    j_old = 0\n-    q_old = v_old.charges[j_old, :]\n-    qdata_order = np.argsort(Y0._qdata[:, q_axis])\n-    qdata_idx = 0\n-    for j_new, q_new in enumerate(v_new.charges):\n-        if all(q_new == q_old):  # have charge block in both v_new and v_old\n-            s_new = sizes_old[j_old] + increase_per_block\n-            # move to next charge block in next loop iteration\n-            j_old += 1\n-            if j_old < len(v_old.charges):\n-                q_old = v_old.charges[j_old, :]\n-        else:  # charge block only in v_new\n-            s_new = increase_per_block\n-        s_new = min(s_new, sizes_new[j_new])  # don't go beyond block\n-\n-        if Y0._qdata[qdata_order[qdata_idx], q_axis] != j_new:\n-            # block does not exist\n-            # while we could set corresponding piv entries to True, it would not help, since\n-            # the corresponding \"entries\" of Y0 are zero anyway\n-            continue\n-\n-        # block has axis [(vL.p0),vR]. want to keep the s_new slices of the vR axis\n-        #  that have the largest norm\n-        norms = np.linalg.norm(Y0._data[qdata_order[qdata_idx]], axis=norm_axis)\n-        kept_slices = np.argsort(-norms)[:s_new]  # negative sign so we sort large to small\n-        start = v_new.slices[j_new]\n-        piv[start + kept_slices] = True\n-\n-        qdata_idx += 1\n-        if qdata_idx >= Y0._qdata.shape[0]:\n-            break\n-    \n-    if move_right:\n-        Y0.iproject(piv, 'vR')\n-    else:\n-        Y0.iproject(piv, 'vL')\n-\n-    return Y0\n-\n-\n-def _eig_based_svd(A, need_U: bool = True, need_Vd: bool = True, inner_labels=[None, None],\n-                   trunc_params=None):\n-    \"\"\"Computes the singular value decomposition of a matrix A via eigh\n-\n-    Singular values and vectors are obtained by diagonalizing the \"square\" A.hc @ A and/or A @ A.hc,\n-    i.e. with two eigh calls instead of an svd call.\n-\n-    Truncation if performed if and only if trunc_params are given.\n-    This performs better on GPU, but is not really useful on CPU.\n-    If isometries U or Vd are not needed, their computation can be omitted for performance.\n-\n-    Does not (yet) support computing both U and Vd\n-    \"\"\"\n-    warnings.warn('_eig_based_svd is nonsensical on CPU!!')\n-    assert A.rank == 2\n-\n-    if need_U and need_Vd:\n-        # TODO (JU) just doing separate eighs for U, S and for S, Vd is not sufficient\n-        #  the phases of U / Vd are arbitrary.\n-        #  Need to put in more work in that case...\n-        raise NotImplementedError\n-\n-    if need_U:\n-        Vd = None\n-        A_Ahc = npc.tensordot(A, A.conj(), [1, 1])\n-        L, U = npc.eigh(A_Ahc, sort='>')\n-        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n-        U = U.ireplace_label('eig', inner_labels[0])\n-    elif need_Vd:\n-        U = None\n-        Ahc_A = npc.tensordot(A.conj(), A, [0, 0])\n-        L, V = npc.eigh(Ahc_A, sort='>')\n-        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n-        Vd = V.iconj().itranspose().ireplace_label('eig*', inner_labels[1])\n-    else:\n-        U = None\n-        Vd = None\n-        # use the smaller of the two square matrices -- they have the same eigenvalues\n-        if A.shape[1] >= A.shape[0]:\n-            A2 = npc.tensordot(A, A.conj(), [1, 0])\n-        else:\n-            A2 = npc.tensordot(A.conj(), A, [1, 0])\n-        L = npc.eigvalsh(A2)\n-        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n-\n-    if trunc_params is not None:\n-        piv, renormalize, trunc_err = truncate(S, trunc_params)\n-        S = S[piv]\n-        S /= renormalize\n-        if need_U:\n-            U.iproject(piv, 1)\n-        if need_Vd:\n-            Vd.iproject(piv, 0)\n-    else:\n-        renormalize = np.linalg.norm(S)\n-        S /= renormalize\n-        trunc_err = TruncationError()\n-\n-    return U, S, Vd, trunc_err, renormalize\n-\n-\n-def decompose_theta_qr_based(old_qtotal_L, old_qtotal_R, old_bond_leg, theta: npc.Array, \n-                             move_right: bool, expand: float, min_block_increase: int, \n-                             use_eig_based_svd: bool, trunc_params: dict, compute_err: bool, \n-                             return_both_T: bool):\n-    r\"\"\"Performs a QR based decomposition of a matrix `theta` (= the wavefunction) and truncates it.\n-    The result is an approximation.\n-\n-    The decomposition for ``use_eig_based_svd=False`` is::\n-\n-        |   -- theta --   ~=   renormalization * -- T_Lc --- S --- T_Rc --\n-        |      |   |                                 |              |\n-\n-    Where `T_Lc` is in `'A'` form and `T_Rc` in `'B'` form.\n-\n-    The decomposition for ``use_eig_based_svd=True`` is::\n-\n-        |   -- theta --   ~=   renormalization * -- T_Lc --- T_Rc --\n-        |      |   |                                 |        |\n-\n-    Where `T_Lc` is in `'A'` (`'Th'`) form and `T_Rc` in `'Th'` (`'B'`) form, if ``move_right=True`` \n-    (``move_right=False``).\n-    \n-    Parameters\n-    ----------\n-    old_qtotal_L : 1D array\n-        The total charge of the old left tensor.\n-        e.g. ``old_qtotal_L = T_L.qtotal``\n-    old_qtotal_R : 1D array\n-        The total charge of the old right tensor.\n-        e.g. ``old_qtotal_R = T_R.qtotal``\n-    old_bond_leg : :class:`~tenpy.linalg.charges.LegCharge`\n-        The leg between the old left tensor and the old right tensor.\n-        e.g. ``old_bond_leg = T_L.get_leg('vR')`` or ``old_bond_leg = T_R.get_leg('vL')``\n-    theta : npc.Array\n-        Array with legs [(vL.p0), (p1.vR)]\n-    expand : float | None\n-        Expansion rate. The QR-based decomposition is carried out at an expanded bond dimension.\n-    min_block_increase : int\n-        Minimum bond dimension increase for each block.\n-    move_right : bool \n-        If `True`, the left tensor `T_Lc` is returned in `'A'` form and the right tensor `T_Rc` is set to `None`.\n-        If `False`, the right tensor `T_Rc` is returned in `'B'` form and the left tensor `T_Lc` is set to `None`.\n-    use_eig_based_svd : bool\n-        Whether the SVD of the bond matrix :math:`\\Xi` should be carried out numerically via\n-        the eigensystem. This is faster on GPUs, but less accurate.\n-        It makes no sense to do this on CPU.\n-    trunc_par : dict\n-        truncation parameters as described in :func:`truncate`.\n-    compute_err : bool\n-        Whether the truncation error should be computed exactly.\n-        Computing the truncation error is significantly more expensive.\n-        If `True`, the full error is computed and ``return_both_T=True``.\n-        Otherwise, the truncation error is set to NaN.\n-    return_both_T : bool\n-        Whether the other tensor (associated with ``not move_right``) should be returned as well.\n-        If `True` and ``move_right=True``, the right tensor `T_Rc` is returned in `'Th'` (`'B'`) form, \n-        if ``use_eig_based_svd=True`` (``use_eig_based_svd=False``).\n-        If `True` and ``move_right=False``, the left tensor `T_Lc` is returned in `'Th'` (`'A'`) form, \n-        if ``use_eig_based_svd=True`` (``use_eig_based_svd=False``).\n-\n-    Returns\n-    -------\n-    T_Lc : array with legs [(vL.p), vR] or None\n-    S : 1D numpy array\n-        The singular values of the array.\n-        Normalized to ``np.linalg.norm(S)==1``.\n-    T_Rc : array with legs [vL, (p.vR)] or None\n-    form : list\n-        List containing two entries providing the form of the two arrays `T_Lc` and `T_Rc` in string form.\n-        e.g. ``['A','Th']``\n-    trunc_err : TruncationError\n-    renormalization : float\n-        Factor, by which S was renormalized.\n-    \"\"\"\n-\n-    if compute_err:\n-        return_both_T = True\n-    \n-    if move_right:\n-        # Get initial guess for the left isometry\n-        Y0 = _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta, move_right, expand, min_block_increase) # Y0: [(vL.p0), vR]\n-\n-        # QR based updates\n-        theta_i1 = npc.tensordot(Y0.conj(), theta, ['(vL*.p0*)', '(vL.p0)']).ireplace_label('vR*', 'vL') # theta_i1: [vL,(p1.vR)]\n-        theta_i1.itranspose(['(p1.vR)', 'vL']) # theta_i1: [(p1.vR),vL]\n-        B_R, _ = npc.qr(theta_i1, inner_labels=['vL', 'vR'], inner_qconj=-1) # B_R: [(p1.vR),vL] \n-        B_R.itranspose(['vL', '(p1.vR)']) # B_R: [vL,(p1.vR)] \n-\n-        theta_i0 = npc.tensordot(theta, B_R.conj(), ['(p1.vR)', '(p1*.vR*)']).ireplace_label('vL*', 'vR') # theta_i0: [(vL.p0),vR]\n-        A_L, Xi = npc.qr(theta_i0, inner_labels=['vR', 'vL']) # A_L: [(vL.p0), vR]\n-        \n-    else:\n-        # Get initial guess for the right isometry\n-        Y0 = _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta, move_right, expand, min_block_increase) # Y0: [vL, (p1.vR)]\n-\n-        # QR based updates\n-        theta_i0 = npc.tensordot(theta, Y0.conj(), ['(p1.vR)', '(p1*.vR*)']).ireplace_label('vL*', 'vR') # theta_i0: [(vL.p0),vR]\n-        A_L, _ = npc.qr(theta_i0, inner_labels=['vR', 'vL']) # A_L: [(vL.p0), vR]\n-\n-        theta_i1 = npc.tensordot(A_L.conj(), theta, ['(vL*.p0*)', '(vL.p0)']).ireplace_label('vR*', 'vL') # theta_i1: [vL,(p1.vR)]\n-        theta_i1.itranspose(['(p1.vR)', 'vL']) # theta_i1: [(p1.vR),vL]\n-        B_R, Xi = npc.qr(theta_i1, inner_labels=['vL', 'vR'], inner_qconj=-1)\n-        B_R.itranspose(['vL', '(p1.vR)'])\n-        Xi.itranspose(['vL', 'vR'])\n-\n-    # SVD of bond matrix Xi\n-    if use_eig_based_svd:\n-        U, S, Vd, _, renormalization = _eig_based_svd(\n-            Xi, need_U=move_right, need_Vd=(not move_right), inner_labels=['vR', 'vL'], trunc_params=trunc_params\n-        )\n-    else:\n-        U, S, Vd, _, renormalization = svd_theta(Xi, trunc_params)\n-\n-    # Assign return matrices\n-    T_Lc, T_Rc = None, None\n-    form = ['A','B']\n-    if move_right:\n-        T_Lc = npc.tensordot(A_L, U, ['vR', 'vL'])\n-        if return_both_T:\n-            if use_eig_based_svd:\n-                T_Rc = npc.tensordot(Xi, B_R, ['vR', 'vL'])\n-                T_Rc = npc.tensordot(U.iconj(), T_Rc, ['vL*', 'vL']).ireplace_label('vR*', 'vL')\n-                T_Rc /= npc.norm(T_Rc)\n-                form[1] = 'Th'\n-            else:\n-                T_Rc = npc.tensordot(Vd, B_R, ['vR', 'vL'])\n-    else:\n-        T_Rc = npc.tensordot(Vd, B_R, ['vR', 'vL'])\n-        if return_both_T:\n-            if use_eig_based_svd:\n-                T_Lc = npc.tensordot(A_L, Xi, ['vR', 'vL'])\n-                T_Lc = npc.tensordot(T_Lc, Vd.iconj(), ['vR', 'vR*']).ireplace_label('vL*', 'vR')\n-                T_Lc /= npc.norm(T_Lc)\n-                form[0] = 'Th'\n-            else:\n-                T_Lc = npc.tensordot(A_L, U, ['vR', 'vL'])\n-    \n-    # Compute error\n-    if compute_err:\n-        if use_eig_based_svd:\n-            theta_approx = npc.tensordot(T_Lc, T_Rc, ['vR', 'vL'])\n-        else:\n-            theta_approx = npc.tensordot(T_Lc.scale_axis(S, axis='vR'), T_Rc, ['vR', 'vL'])\n-        N_theta = npc.norm(theta)\n-        eps = npc.norm(theta / N_theta - theta_approx * renormalization / N_theta) ** 2\n-        trunc_err = TruncationError(eps, 1. - 2. * eps)\n-    else:\n-        trunc_err = TruncationError(np.nan, np.nan)\n-\n-    # Replace labels\n-    if move_right:\n-        T_Lc.ireplace_label('(vL.p0)', '(vL.p)')\n-        if return_both_T:\n-            T_Rc.ireplace_label('(p1.vR)', '(p.vR)')\n-    else:\n-        T_Rc.ireplace_label('(p1.vR)', '(p.vR)')\n-        if return_both_T:\n-            T_Lc.ireplace_label('(vL.p0)', '(vL.p)')\n-        \n-    return T_Lc, S, T_Rc, form, trunc_err, renormalization\n-\n-\n-def _combine_constraints(good1, good2, warn):\n-    \"\"\"return logical_and(good1, good2) if there remains at least one `True` entry.\n-\n-    Otherwise print a warning and return just `good1`.\n-    \"\"\"\n-    res = np.logical_and(good1, good2)\n-    if np.any(res):\n-        return res\n-    warnings.warn(\"truncation: can't satisfy constraint for \" + warn, stacklevel=3)\n-    return good1\n+# just provide namespace from ..linalg.truncation\n \n+from ..linalg import truncation\n+from ..linalg.truncation import TruncationError, truncate, svd_theta, decompose_theta_qr_based  # noqa: F401\n \n-# truncation parameter for truncating svd values at machine precision\n-# excluding 0. and negative S values only\n-_machine_prec_trunc_par = asConfig({'svd_min': np.finfo(np.float64).eps,\n-                                    'trunc_cut': None,\n-                                    'chi_max': None},\n-                                   'machine_prec_trunc_params')\n-_machine_prec_trunc_par.unused.clear()\n+__all__ = truncation.__all__\ndiff --git a/tenpy/algorithms/vumps.py b/tenpy/algorithms/vumps.py\nindex 323601e5b..df560108e 100644\n--- a/tenpy/algorithms/vumps.py\n+++ b/tenpy/algorithms/vumps.py\n@@ -36,6 +36,7 @@\n import numpy as np\n import time\n import logging\n+import warnings\n \n logger = logging.getLogger(__name__)\n \n@@ -44,12 +45,13 @@\n from ..networks.mps import MPS\n from ..networks.uniform_mps import UniformMPS\n from ..linalg.sparse import SumNpcLinearOperator\n-from ..algorithms.mps_common import DensityMatrixMixer, SubspaceExpansion\n+from .mps_common import DensityMatrixMixer, SubspaceExpansion\n from ..linalg.krylov_based import LanczosGroundState\n from ..tools.math import entropy\n from ..tools.process import memory_usage\n+from ..tools.params import asConfig\n from .mps_common import IterativeSweeps, ZeroSiteH, OneSiteH, TwoSiteH\n-from .truncation import svd_theta\n+from ..linalg.truncation import svd_theta\n from .plane_wave_excitation import append_right_env, append_left_env, construct_orthogonal\n \n __all__ = ['VUMPSEngine', 'SingleSiteVUMPSEngine', 'TwoSiteVUMPSEngine']\n@@ -63,6 +65,10 @@ class VUMPSEngine(IterativeSweeps):\n     :class:`TwoSiteVUMPSEngine`.\n     Use the latter two classes for actual VUMPS runs.\n \n+    .. versionchanged :: 1.1\n+        Previously had separate `lanczos_options`, which have been renamed to `lanczos_params`\n+        for consistency with the Sweep class.\n+\n     Options\n     -------\n     .. cfg:config :: VUMPSEngine\n@@ -70,22 +76,6 @@ class VUMPSEngine(IterativeSweeps):\n \n     Attributes\n     ----------\n-    EffectiveH : class type\n-        Class for the effective Hamiltonian, i.e., a subclass of\n-        :class:`~tenpy.algorithms.mps_common.EffectiveH`. Has a `length` class attribute which\n-        specifies the number of sites updated at once (e.g., whether we do single-site vs. two-site\n-        VUMPS).\n-    chi_list : dict | ``None``\n-        See :cfg:option:`DMRGEngine.chi_list`\n-    eff_H : :class:`~tenpy.algorithms.mps_common.EffectiveH`\n-        Effective single-site or two-site Hamiltonian.\n-    shelve : bool\n-        If a simulation runs out of time (`time.time() - start_time > max_seconds`), the run will\n-        terminate with `shelve = True`.\n-    sweeps : int\n-        The number of sweeps already performed. (Useful for re-start).\n-    time0 : float\n-        Time marker for the start of the run.\n     update_stats : dict\n         A dictionary with detailed statistics of the convergence at local update-level.\n         For each key in the following table, the dictionary contains a list where one value is\n@@ -157,10 +147,12 @@ class VUMPSEngine(IterativeSweeps):\n     EffectiveH = None\n \n     def __init__(self, psi, model, options, **kwargs):\n-        #options = asConfig(options, self.__class__.__name__)\n         if not isinstance(psi, UniformMPS):\n             assert isinstance(psi, MPS)\n             psi = UniformMPS.from_MPS(psi)  # psi is an MPS, so convert it to a uMPS\n+        options = asConfig(options, self.__class__.__name__)\n+        options.deprecated_alias(\"lanczos_options\", \"lanczos_params\",\n+                                 \"See also https://github.com/tenpy/tenpy/issues/459\")\n         super().__init__(psi, model, options, **kwargs)\n         self.guess_init_env_data = self.env.get_initialization_data()\n         self.env.clear()\n@@ -175,10 +167,17 @@ def __init__(self, psi, model, options, **kwargs):\n         if self.chi_list is not None:\n             default_min_sweeps = max(max(self.chi_list.keys()), default_min_sweeps)\n         self.options.setdefault('min_sweeps', default_min_sweeps)\n-        mixer_options = self.options.subconfig('mixer_params')\n-        mixer_options.setdefault('amplitude', 1.e-5)\n-        mixer_options.setdefault('decay', 2)\n-        mixer_options.setdefault('disable_after', 5)\n+        mixer_params = self.options.subconfig('mixer_params')\n+        mixer_params.setdefault('amplitude', 1.e-5)\n+        mixer_params.setdefault('decay', 2)\n+        mixer_params.setdefault('disable_after', 5)\n+\n+    @property\n+    def lanczos_options(self):\n+        \"\"\"Deprecated alias of :attr:`lanczos_params`.\"\"\"\n+        warnings.warn(\"Accessing deprecated alias TDVPEngine.lanczos_options instead of lanczos_params\",\n+                      FutureWarning, stacklevel=2)\n+        return self.lanczos_params\n \n     @property\n     def S_inv_cutoff(self):\n@@ -192,7 +191,7 @@ def run_iteration(self):\n         Options\n         -------\n         .. cfg:configoptions :: VUMPSEngine\n-        \n+\n             diagonal_gauge_frequency : int\n                 Number of sweeps how often we restore the UniformMPS to the diagonal gauge\n             cutoff : float\n@@ -298,7 +297,7 @@ def is_converged(self):\n         Options\n         -------\n         .. cfg:configoptions :: VUMPSEngine\n-        \n+\n             max_E_err : float\n                 Convergence if the change of the energy in each step\n                 satisfies ``|Delta E / max(E, 1)| < max_E_err``. Note that\n@@ -330,13 +329,13 @@ def post_run_cleanup(self):\n         Options\n         -------\n         .. cfg:configoptions :: VUMPSEngine\n-        \n+\n             check_overlap : bool\n                 Since AL C = C AR is not identically true, the MPS defined by AL and AR are not exactly the same.\n                 We can compute the overlap of the two to check.\n             norm_tol : float\n                 Check if final state is in canonical form.\n-        \n+\n         \"\"\"\n         super().post_run_cleanup()\n         check_overlap = self.options.get('check_overlap', True, bool)\n@@ -400,20 +399,7 @@ def environment_sweeps(self, N_sweeps):\n         pass\n \n     def reset_stats(self, resume_data=None):\n-        \"\"\"Reset the statistics, useful if you want to start a new sweep run.\n-\n-        .. cfg:configoptions :: VUMPSEngine\n-\n-            chi_list : dict | None\n-                A dictionary to gradually increase the `chi_max` parameter of\n-                `trunc_params`. The key defines starting from which sweep\n-                `chi_max` is set to the value, e.g. ``{0: 50, 20: 100}`` uses\n-                ``chi_max=50`` for the first 20 sweeps and ``chi_max=100``\n-                afterwards. Overwrites `trunc_params['chi_list']``.\n-                By default (``None``) this feature is disabled.\n-            sweep_0 : int\n-                The number of sweeps already performed. (Useful for re-start).\n-        \"\"\"\n+        \"\"\"Reset the statistics, useful if you want to start a new sweep run.\"\"\"\n \n         super().reset_stats(resume_data)\n         self.update_stats = {\n@@ -625,13 +611,13 @@ def update_local(self, theta, **kwargs):\n         i0 = self.i0\n         H0_1, H0_2, H1 = self.eff_H0_1, self.eff_H0_2, self.eff_H\n         AC, C1, C2 = theta\n-        lanczos_options = self.options.subconfig('lanczos_options')\n+        lanczos_params = self.options.subconfig('lanczos_params')\n \n-        E0_1, theta0_1, N0_1 = LanczosGroundState(H0_1, C1, lanczos_options).run()\n+        E0_1, theta0_1, N0_1 = LanczosGroundState(H0_1, C1, lanczos_params).run()\n \n         if self.psi.L > 1:\n-            E0_2, theta0_2, N0_2 = LanczosGroundState(H0_2, C2, lanczos_options).run()\n-        E1, theta1, N1 = LanczosGroundState(H1, AC, lanczos_options).run()\n+            E0_2, theta0_2, N0_2 = LanczosGroundState(H0_2, C2, lanczos_params).run()\n+        E1, theta1, N1 = LanczosGroundState(H1, AC, lanczos_params).run()\n \n         if self.psi.L == 1:\n             E0_2, theta0_2, N0_2 = E0_1, theta0_1, N0_1\n@@ -675,7 +661,7 @@ def polar_max(self, AC, C1, C2):\n             Center matrix left of site ``i0``\n         C2: :class:`~tenpy.linalg.np_conserved.Array`\n             Center matrix right of site ``i0``\n-        \n+\n         Returns\n         -------\n         AL : :class:`~tenpy.linalg.np_conserved.Array`\n@@ -762,10 +748,10 @@ def update_local(self, theta, **kwargs):\n         H0_1, H0_2, H2 = self.eff_H0_1, self.eff_H0_2, self.eff_H\n         AC, C1, C2 = theta\n \n-        lanczos_options = self.options.subconfig('lanczos_options')\n-        E0_1, theta0_1, N0_1 = LanczosGroundState(H0_1, C1, lanczos_options).run()\n-        E0_2, theta0_2, N0_2 = LanczosGroundState(H0_2, C2, lanczos_options).run()\n-        E2, theta2, N2 = LanczosGroundState(H2, AC, lanczos_options).run()\n+        lanczos_params = self.options.subconfig('lanczos_params')\n+        E0_1, theta0_1, N0_1 = LanczosGroundState(H0_1, C1, lanczos_params).run()\n+        E0_2, theta0_2, N0_2 = LanczosGroundState(H0_2, C2, lanczos_params).run()\n+        E2, theta2, N2 = LanczosGroundState(H2, AC, lanczos_params).run()\n \n         U, S, VH, err, S_approx = self.mixed_svd(\n             theta2.combine_legs([['vL', 'p0'], ['p1', 'vR']], qconj=[+1, -1]))\n@@ -823,7 +809,7 @@ def polar_max(self, AC1, AC2, C1, C3):\n             Center matrix left of site ``i0``\n         C3: :class:`~tenpy.linalg.np_conserved.Array`\n             Center matrix right of site ``i0+1``\n-        \n+\n         Returns\n         -------\n         AL2 : :class:`~tenpy.linalg.np_conserved.Array`\ndiff --git a/tenpy/linalg/__init__.py b/tenpy/linalg/__init__.py\nindex 54e374dd8..91a2ec4f6 100644\n--- a/tenpy/linalg/__init__.py\n+++ b/tenpy/linalg/__init__.py\n@@ -19,23 +19,27 @@\n     random_matrix\n     sparse\n     krylov_based\n+    truncation\n \n \"\"\"\n # Copyright (C) TeNPy Developers, GNU GPLv3\n \n-from . import charges, np_conserved, krylov_based, random_matrix, sparse, svd_robust\n+from . import charges, np_conserved, krylov_based, random_matrix, sparse, svd_robust, truncation\n from .charges import *\n from .np_conserved import *\n from .krylov_based import *\n from .random_matrix import *\n from .sparse import *\n+from .truncation import *\n \n __all__ = ['charges', 'np_conserved', 'krylov_based', 'random_matrix', 'sparse', 'svd_robust',\n+           'truncation',\n            *charges.__all__,\n            *[n for n in np_conserved.__all__ if n not in ['ChargeInfo', 'LegCharge', 'LegPipe']],\n            *krylov_based.__all__,\n            *random_matrix.__all__,\n            *sparse.__all__,\n+           *truncation.__all__,\n            ]\n \n from ..tools import optimization\ndiff --git a/tenpy/linalg/truncation.py b/tenpy/linalg/truncation.py\nnew file mode 100644\nindex 000000000..9124428be\n--- /dev/null\n+++ b/tenpy/linalg/truncation.py\n@@ -0,0 +1,652 @@\n+r\"\"\"Truncation of Schmidt values.\n+\n+Often, it is necessary to truncate the number of states on a virtual bond of an MPS,\n+keeping only the state with the largest Schmidt values.\n+The function :func:`truncate` picks exactly those from a given Schmidt spectrum\n+:math:`\\lambda_a`, depending on some parameters explained in the doc-string of the function.\n+\n+Further, we provide :class:`TruncationError` for a simple way to keep track of the\n+total truncation error.\n+\n+The SVD on a virtual bond of an MPS actually gives a Schmidt decomposition\n+:math:`|\\psi\\rangle = \\sum_{a} \\lambda_a |L_a\\rangle |R_a\\rangle`\n+where :math:`|L_a\\rangle` and :math:`|R_a\\rangle` form orthonormal bases of the parts\n+left and right of the virtual bond.\n+Let us assume that the state is properly normalized,\n+:math:`\\langle\\psi | \\psi\\rangle = \\sum_{a} \\lambda^2_a = 1`.\n+Assume that the singular values are ordered descending, and that we keep the first :math:`\\chi_c`\n+of the initially :math:`\\chi` Schmidt values.\n+\n+Then we decompose the untruncated state as\n+:math:`|\\psi\\rangle = \\sqrt{1-\\epsilon}|\\psi_{tr}\\rangle + \\sqrt{\\epsilon}|\\psi_{tr}^\\perp\\rangle`\n+where\n+:math:`|\\psi_{tr}\\rangle =\n+\\frac{1}{\\sqrt{1-\\epsilon}} \\sum_{a < \\chi_c} \\lambda_a|L_a\\rangle|R_a\\rangle`\n+is the truncated state kept (normalized to 1),\n+:math:`|\\psi_{tr}^\\perp\\rangle =\n+\\frac{1}{\\sqrt{\\epsilon}} \\sum_{a >= \\chi_c} \\lambda_a |L_a\\rangle|R_a\\rangle`\n+is the discarded part (orthogonal to the kept part) and the\n+*truncation error of a single truncation* is defined as\n+:math:`\\epsilon = 1 - |\\langle \\psi | \\psi_{tr}\\rangle |^2 = \\sum_{a >= \\chi_c} \\lambda_a^2`.\n+\n+.. warning ::\n+    For imaginary time evolution (e.g. with TEBD), you try to project out the ground state.\n+    Then, looking at the truncation error defined in this module does *not* give you any\n+    information how good the found state coincides with the actual ground state!\n+    (Instead, the returned truncation error depends on the overlap with the initial state,\n+    which is arbitrary > 0)\n+\n+.. warning ::\n+    This module takes only track of the errors coming from the truncation of Schmidt values.\n+    There might be other sources of error as well, for example TEBD has also an discretization\n+    error depending on the chosen time step.\n+\"\"\"\n+# Copyright (C) TeNPy Developers, GNU GPLv3\n+\n+import numpy as np\n+from ..linalg import np_conserved as npc\n+from ..tools.hdf5_io import Hdf5Exportable\n+import warnings\n+from ..tools.params import asConfig\n+\n+__all__ = ['TruncationError', 'truncate', 'svd_theta', 'decompose_theta_qr_based']\n+\n+\n+\n+class TruncationError(Hdf5Exportable):\n+    r\"\"\"Class representing a truncation error.\n+\n+    The default initialization represents \"no truncation\".\n+\n+    .. warning ::\n+        For imaginary time evolution, this is *not* the error you are interested in!\n+\n+    Parameters\n+    ----------\n+    eps, ov : float\n+        See below.\n+\n+\n+    Attributes\n+    ----------\n+    eps : float\n+        The total sum of all discarded Schmidt values squared.\n+        Note that if you keep singular values up to 1.e-14 (= a bit more than machine precision\n+        for 64bit floats), `eps` is on the order of 1.e-28 (due to the square)!\n+    ov : float\n+        A lower bound for the overlap :math:`|\\langle \\psi_{trunc} | \\psi_{correct} \\rangle|^2`\n+        (assuming normalization of both states).\n+        This is probably the quantity you are actually interested in.\n+        Takes into account the factor 2 explained in the section on Errors in the\n+        `TEBD Wikipedia article <https://en.wikipedia.org/wiki/Time-evolving_block_decimation>`.\n+    \"\"\"\n+    def __init__(self, eps=0., ov=1.):\n+        self.eps = eps\n+        self.ov = ov\n+\n+    def copy(self):\n+        \"\"\"Return a copy of self.\"\"\"\n+        return TruncationError(self.eps, self.ov)\n+\n+    @classmethod\n+    def from_norm(cls, norm_new, norm_old=1.):\n+        r\"\"\"Construct TruncationError from norm after and before the truncation.\n+\n+        Parameters\n+        ----------\n+        norm_new : float\n+            Norm of Schmidt values kept, :math:`\\sqrt{\\sum_{a kept} \\lambda_a^2}`\n+            (before re-normalization).\n+        norm_old : float\n+            Norm of all Schmidt values before truncation, :math:`\\sqrt{\\sum_{a} \\lambda_a^2}`.\n+        \"\"\"\n+        eps = 1. - norm_new**2 / norm_old**2  # = (norm_old**2 - norm_new**2)/norm_old**2\n+        return cls(eps, 1. - 2. * eps)\n+\n+    @classmethod\n+    def from_S(cls, S_discarded, norm_old=None):\n+        r\"\"\"Construct TruncationError from discarded singular values.\n+\n+        Parameters\n+        ----------\n+        S_discarded : 1D numpy array\n+            The singular values discarded.\n+        norm_old : float\n+            Norm of all Schmidt values before truncation, :math:`\\sqrt{\\sum_{a} \\lambda_a^2}`.\n+            Default (``None``) is 1.\n+        \"\"\"\n+        eps = np.sum(np.square(S_discarded))\n+        if norm_old:\n+            eps /= norm_old * norm_old\n+        return cls(eps, 1. - 2. * eps)\n+\n+    def __add__(self, other):\n+        res = TruncationError()\n+        res.eps = self.eps + other.eps  # whatever that actually means...\n+        res.ov = self.ov * other.ov\n+        return res\n+\n+    @property\n+    def ov_err(self):\n+        \"\"\"Error ``1.-ov`` of the overlap with the correct state.\"\"\"\n+        return 1. - self.ov\n+\n+    def __repr__(self):\n+        if self.eps != 0 or self.ov != 1.:\n+            return \"TruncationError(eps={eps:.4e}, ov={ov:.10f})\".format(eps=self.eps, ov=self.ov)\n+        else:\n+            return \"TruncationError()\"\n+\n+\n+def truncate(S, options):\n+    \"\"\"Given a Schmidt spectrum `S`, determine which values to keep.\n+\n+    Options\n+    -------\n+    .. cfg:config:: truncation\n+\n+        chi_max : int\n+            Keep at most `chi_max` Schmidt values.\n+        chi_min : int\n+            Keep at least `chi_min` Schmidt values.\n+        degeneracy_tol: float\n+            Don't cut between neighboring Schmidt values with\n+            ``|log(S[i]/S[j])| < degeneracy_tol``, or equivalently\n+            ``|S[i] - S[j]|/S[j] < exp(degeneracy_tol) - 1 ~= degeneracy_tol``\n+            for small `degeneracy_tol`.\n+            In other words, keep either both `i` and `j` or none, if the\n+            Schmidt values are degenerate with a relative error smaller\n+            than `degeneracy_tol`, which we expect to happen in the case\n+            of symmetries.\n+        svd_min : float\n+            Discard all small Schmidt values ``S[i] < svd_min``.\n+        trunc_cut : float\n+            Discard all small Schmidt values as long as\n+            ``sum_{i discarded} S[i]**2 <= trunc_cut**2``.\n+\n+    Parameters\n+    ----------\n+    S : 1D array\n+        Schmidt values (as returned by an SVD), not necessarily sorted.\n+        Should be normalized to ``np.sum(S*S) == 1.``.\n+    options: dict-like\n+        Config with constraints for the truncation, see :cfg:config:`truncation`.\n+        If a constraint can not be fulfilled (without violating a previous one), it is ignored.\n+        A value ``None`` indicates that the constraint should be ignored.\n+\n+    Returns\n+    -------\n+    mask : 1D bool array\n+        Index mask, True for indices which should be kept.\n+    norm_new : float\n+        The norm of the truncated Schmidt values, ``np.linalg.norm(S[mask])``.\n+        Useful for re-normalization.\n+    err : :class:`TruncationError`\n+        The error of the represented state which is introduced due to the truncation.\n+    \"\"\"\n+    options = asConfig(options, \"truncation\")\n+    # by default, only truncate values which are much closer to zero than machine precision.\n+    # This is only to avoid problems with taking the inverse of `S`.\n+    chi_max = options.get('chi_max', 100, int)\n+    chi_min = options.get('chi_min', None, int)\n+    deg_tol = options.get('degeneracy_tol', None, 'real')\n+    svd_min = options.get('svd_min', 1.e-14, 'real')\n+    trunc_cut = options.get('trunc_cut', 1.e-14, 'real')\n+\n+    if trunc_cut is not None and trunc_cut >= 1.:\n+        raise ValueError(\"trunc_cut >=1.\")\n+    if not np.any(S > 1.e-10):\n+        warnings.warn(\"no Schmidt value above 1.e-10\", stacklevel=2)\n+    if np.any(S < -1.e-10):\n+        warnings.warn(\"negative Schmidt values!\", stacklevel=2)\n+\n+    # use 1.e-100 as replacement for <=0 values for a well-defined logarithm.\n+    logS = np.log(np.choose(S <= 0., [S, 1.e-100 * np.ones(len(S))]))\n+    piv = np.argsort(logS)  # sort *ascending*.\n+    logS = logS[piv]\n+    # goal: find an index 'cut' such that we keep piv[cut:], i.e. cut between `cut-1` and `cut`.\n+    good = np.ones(len(piv), dtype=np.bool_)  # good[cut] = (is `cut` a good choice?)\n+    # we choose the smallest 'good' cut.\n+\n+    if chi_max is not None:\n+        # keep at most chi_max values\n+        good2 = np.zeros(len(piv), dtype=np.bool_)\n+        good2[-chi_max:] = True\n+        good = _combine_constraints(good, good2, \"chi_max\")\n+\n+    if chi_min is not None and chi_min > 1:\n+        # keep at most chi_max values\n+        good2 = np.ones(len(piv), dtype=np.bool_)\n+        good2[-chi_min + 1:] = False\n+        good = _combine_constraints(good, good2, \"chi_min\")\n+\n+    if deg_tol:\n+        # don't cut between values (cut-1, cut) with ``log(S[cut]/S[cut-1]) < deg_tol``\n+        # this is equivalent to\n+        # ``(S[cut] - S[cut-1])/S[cut-1] < exp(deg_tol) - 1 = deg_tol + O(deg_tol^2)``\n+        good2 = np.empty(len(piv), np.bool_)\n+        good2[0] = True\n+        good2[1:] = np.greater_equal(logS[1:] - logS[:-1], deg_tol)\n+        good = _combine_constraints(good, good2, \"degeneracy_tol\")\n+\n+    if svd_min is not None:\n+        # keep only values S[i] >= svd_min\n+        good2 = np.greater_equal(logS, np.log(svd_min))\n+        good = _combine_constraints(good, good2, \"svd_min\")\n+\n+    if trunc_cut is not None:\n+        good2 = (np.cumsum(S[piv]**2) > trunc_cut * trunc_cut)\n+        good = _combine_constraints(good, good2, \"trunc_cut\")\n+\n+    cut = np.nonzero(good)[0][0]  # smallest possible cut: keep as many S as allowed\n+    mask = np.zeros(len(S), dtype=np.bool_)\n+    np.put(mask, piv[cut:], True)\n+    norm_new = np.linalg.norm(S[mask])\n+    return mask, norm_new, TruncationError.from_S(S[np.logical_not(mask)]),\n+\n+\n+def svd_theta(theta, trunc_par, qtotal_LR=[None, None], inner_labels=['vR', 'vL']):\n+    \"\"\"Performs SVD of a matrix `theta` (= the wavefunction) and truncates it.\n+\n+    Perform a singular value decomposition (SVD) with :func:`~tenpy.linalg.np_conserved.svd`\n+    and truncates with :func:`truncate`.\n+    The result is an approximation\n+    ``theta ~= tensordot(U.scale_axis(S*renormalization, 1), VH, axes=1)``\n+\n+    Parameters\n+    ----------\n+    theta : :class:`~tenpy.linalg.np_conserved.Array`, shape ``(M, N)``\n+        The matrix, on which the singular value decomposition (SVD) is performed.\n+        Usually, `theta` represents the wavefunction, such that the SVD is a Schmidt decomposition.\n+    trunc_par : dict\n+        truncation parameters as described in :func:`truncate`.\n+    qtotalLR : (charges, charges)\n+        The total charges for the returned `U` and `VH`.\n+    inner_labels : (string, string)\n+        Labels for the `U` and `VH` on the newly-created bond.\n+\n+    Returns\n+    -------\n+    U : :class:`~tenpy.linalg.np_conserved.Array`\n+        Matrix with left singular vectors as columns.\n+        Shape ``(M, M)`` or ``(M, K)`` depending on `full_matrices`.\n+    S : 1D ndarray\n+        The singular values of the array.\n+        If no `cutoff` is given, it has length ``min(M, N)``.\n+        Normalized to ``np.linalg.norm(S)==1``.\n+    VH : :class:`~tenpy.linalg.np_conserved.Array`\n+        Matrix with right singular vectors as rows.\n+        Shape ``(N, N)`` or ``(K, N)`` depending on `full_matrices`.\n+    err : :class:`TruncationError`\n+        The truncation error introduced.\n+    renormalization : float\n+        Factor, by which S was renormalized.\n+    \"\"\"\n+    U, S, VH = npc.svd(theta,\n+                       full_matrices=False,\n+                       compute_uv=True,\n+                       qtotal_LR=qtotal_LR,\n+                       inner_labels=inner_labels)\n+    renormalization = np.linalg.norm(S)\n+    S = S / renormalization\n+    piv, new_norm, err = truncate(S, trunc_par)\n+    new_len_S = np.sum(piv, dtype=np.int_)\n+    if new_len_S * 100 < len(S) and (trunc_par['chi_max'] is None\n+                                     or new_len_S != trunc_par['chi_max']):\n+        msg = \"Catastrophic reduction in chi: {0:d} -> {1:d}\".format(len(S), new_len_S)\n+        # NANs are excluded in npc.svd\n+        UHU = npc.tensordot(U.conj(), U, axes=[[0], [0]])\n+        msg += \" |U^d U - 1| = {0:f}\".format(npc.norm(UHU - npc.eye_like(UHU)))\n+        VHV = npc.tensordot(VH, VH.conj(), axes=[[1], [1]])\n+        msg += \" |V V - 1| = {0:f}\".format(npc.norm(VHV - npc.eye_like(VHV)))\n+        warnings.warn(msg, stacklevel=2)\n+    S = S[piv] / new_norm\n+    renormalization *= new_norm\n+    U.iproject(piv, axes=1)  # U = U[:, piv]\n+    VH.iproject(piv, axes=0)  # VH = VH[piv, :]\n+    return U, S, VH, err, renormalization\n+\n+\n+def _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta: npc.Array, move_right: bool, expand: float, min_block_increase: int):\n+    \"\"\"Generate the initial guess `Y0` for the (left) right isometry for the QR based theta decomposition `decompose_theta_qr_based()`.\n+\n+    Parameters\n+    ----------\n+    old_qtotal_L : 1D array\n+        The total charge of the old left tensor.\n+        e.g. ``old_qtotal_L = T_L.qtotal``\n+    old_qtotal_R : 1D array\n+        The total charge of the old right tensor.\n+        e.g. ``old_qtotal_R = T_R.qtotal``\n+    old_bond_leg : :class:`~tenpy.linalg.charges.LegCharge`\n+        The leg between the old left tensor and the old right tensor.\n+        e.g. ``old_bond_leg = T_L.get_leg('vR')`` or ``old_bond_leg = T_R.get_leg('vL')``\n+    theta : Array with legs [(vL.p0), (p1.vR)]\n+    move_right : bool \n+    expand : float\n+    min_block_increase : int\n+\n+    Returns\n+    -------\n+    Y0 : Array with legs [vL, (p1.vR)] or [(vL.p0), vR]\n+        If ``move_right=True``, the legs of Y0 are [vL, (p1.vR)].\n+        If ``move_right=False``, the legs of Y0 are [(vL.p0), vR].\n+    \"\"\"\n+\n+    assert min_block_increase >= 0\n+    assert expand is not None and expand != 0\n+    \n+    if move_right:\n+        Y0 = theta.copy(deep=False)\n+        Y0.legs[1] = Y0.legs[1].to_LegCharge()\n+        Y0.ireplace_label('(p1.vR)', 'vR')\n+        if any(old_qtotal_R != 0):\n+            Y0.gauge_total_charge('vR', new_qtotal=old_qtotal_L)\n+        vR_old = old_bond_leg\n+        if not vR_old.is_blocked():\n+            vR_old = vR_old.sort()[1]\n+        vR_new = Y0.get_leg('vR')  # is blocked, since created from pipe\n+        v_old, v_new = vR_old, vR_new\n+        q_axis, norm_axis = 1, 0\n+    else:\n+        Y0 = theta.copy(deep=False)\n+        Y0.legs[0] = Y0.legs[0].to_LegCharge()\n+        Y0.ireplace_label('(vL.p0)', 'vL')\n+        if any(old_qtotal_L != 0):\n+            Y0.gauge_total_charge('vL', new_qtotal=old_qtotal_R)\n+        vL_old = old_bond_leg\n+        if not vL_old.is_blocked():\n+            vL_old = vL_old.sort()[1]\n+        vL_new = Y0.get_leg('vL')  # is blocked, since created from pipe\n+        v_old, v_new = vL_old, vL_new\n+        q_axis, norm_axis = 0, 1\n+\n+    # vL(R)_old is guaranteed to be a slice of vL(R)_new by charge rule in T_L(R)_old\n+    piv = np.zeros(v_new.ind_len, dtype=bool)  # indices to keep in v_new\n+    increase_per_block = max(min_block_increase, int(v_old.ind_len * expand // v_new.block_number))\n+    sizes_old = v_old.get_block_sizes()\n+    sizes_new = v_new.get_block_sizes()\n+\n+    # iterate over charge blocks in vL(R)_new and vL(R)_old at the same time\n+    j_old = 0\n+    q_old = v_old.charges[j_old, :]\n+    qdata_order = np.argsort(Y0._qdata[:, q_axis])\n+    qdata_idx = 0\n+    for j_new, q_new in enumerate(v_new.charges):\n+        if all(q_new == q_old):  # have charge block in both v_new and v_old\n+            s_new = sizes_old[j_old] + increase_per_block\n+            # move to next charge block in next loop iteration\n+            j_old += 1\n+            if j_old < len(v_old.charges):\n+                q_old = v_old.charges[j_old, :]\n+        else:  # charge block only in v_new\n+            s_new = increase_per_block\n+        s_new = min(s_new, sizes_new[j_new])  # don't go beyond block\n+\n+        if Y0._qdata[qdata_order[qdata_idx], q_axis] != j_new:\n+            # block does not exist\n+            # while we could set corresponding piv entries to True, it would not help, since\n+            # the corresponding \"entries\" of Y0 are zero anyway\n+            continue\n+\n+        # block has axis [(vL.p0),vR]. want to keep the s_new slices of the vR axis\n+        #  that have the largest norm\n+        norms = np.linalg.norm(Y0._data[qdata_order[qdata_idx]], axis=norm_axis)\n+        kept_slices = np.argsort(-norms)[:s_new]  # negative sign so we sort large to small\n+        start = v_new.slices[j_new]\n+        piv[start + kept_slices] = True\n+\n+        qdata_idx += 1\n+        if qdata_idx >= Y0._qdata.shape[0]:\n+            break\n+    \n+    if move_right:\n+        Y0.iproject(piv, 'vR')\n+    else:\n+        Y0.iproject(piv, 'vL')\n+\n+    return Y0\n+\n+\n+def _eig_based_svd(A, need_U: bool = True, need_Vd: bool = True, inner_labels=[None, None],\n+                   trunc_params=None):\n+    \"\"\"Computes the singular value decomposition of a matrix A via eigh\n+\n+    Singular values and vectors are obtained by diagonalizing the \"square\" A.hc @ A and/or A @ A.hc,\n+    i.e. with two eigh calls instead of an svd call.\n+\n+    Truncation if performed if and only if trunc_params are given.\n+    This performs better on GPU, but is not really useful on CPU.\n+    If isometries U or Vd are not needed, their computation can be omitted for performance.\n+\n+    Does not (yet) support computing both U and Vd\n+    \"\"\"\n+    warnings.warn('_eig_based_svd is nonsensical on CPU!!')\n+    assert A.rank == 2\n+\n+    if need_U and need_Vd:\n+        # TODO (JU) just doing separate eighs for U, S and for S, Vd is not sufficient\n+        #  the phases of U / Vd are arbitrary.\n+        #  Need to put in more work in that case...\n+        raise NotImplementedError\n+\n+    if need_U:\n+        Vd = None\n+        A_Ahc = npc.tensordot(A, A.conj(), [1, 1])\n+        L, U = npc.eigh(A_Ahc, sort='>')\n+        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n+        U = U.ireplace_label('eig', inner_labels[0])\n+    elif need_Vd:\n+        U = None\n+        Ahc_A = npc.tensordot(A.conj(), A, [0, 0])\n+        L, V = npc.eigh(Ahc_A, sort='>')\n+        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n+        Vd = V.iconj().itranspose().ireplace_label('eig*', inner_labels[1])\n+    else:\n+        U = None\n+        Vd = None\n+        # use the smaller of the two square matrices -- they have the same eigenvalues\n+        if A.shape[1] >= A.shape[0]:\n+            A2 = npc.tensordot(A, A.conj(), [1, 0])\n+        else:\n+            A2 = npc.tensordot(A.conj(), A, [1, 0])\n+        L = npc.eigvalsh(A2)\n+        S = np.sqrt(np.abs(L))  # abs to avoid `nan` due to accidentally negative values close to zero\n+\n+    if trunc_params is not None:\n+        piv, renormalize, trunc_err = truncate(S, trunc_params)\n+        S = S[piv]\n+        S /= renormalize\n+        if need_U:\n+            U.iproject(piv, 1)\n+        if need_Vd:\n+            Vd.iproject(piv, 0)\n+    else:\n+        renormalize = np.linalg.norm(S)\n+        S /= renormalize\n+        trunc_err = TruncationError()\n+\n+    return U, S, Vd, trunc_err, renormalize\n+\n+\n+def decompose_theta_qr_based(old_qtotal_L, old_qtotal_R, old_bond_leg, theta: npc.Array, \n+                             move_right: bool, expand: float, min_block_increase: int, \n+                             use_eig_based_svd: bool, trunc_params: dict, compute_err: bool, \n+                             return_both_T: bool):\n+    r\"\"\"Performs a QR based decomposition of a matrix `theta` (= the wavefunction) and truncates it.\n+    The result is an approximation.\n+\n+    The decomposition for ``use_eig_based_svd=False`` is::\n+\n+        |   -- theta --   ~=   renormalization * -- T_Lc --- S --- T_Rc --\n+        |      |   |                                 |              |\n+\n+    Where `T_Lc` is in `'A'` form and `T_Rc` in `'B'` form.\n+\n+    The decomposition for ``use_eig_based_svd=True`` is::\n+\n+        |   -- theta --   ~=   renormalization * -- T_Lc --- T_Rc --\n+        |      |   |                                 |        |\n+\n+    Where `T_Lc` is in `'A'` (`'Th'`) form and `T_Rc` in `'Th'` (`'B'`) form, if ``move_right=True`` \n+    (``move_right=False``).\n+    \n+    Parameters\n+    ----------\n+    old_qtotal_L : 1D array\n+        The total charge of the old left tensor.\n+        e.g. ``old_qtotal_L = T_L.qtotal``\n+    old_qtotal_R : 1D array\n+        The total charge of the old right tensor.\n+        e.g. ``old_qtotal_R = T_R.qtotal``\n+    old_bond_leg : :class:`~tenpy.linalg.charges.LegCharge`\n+        The leg between the old left tensor and the old right tensor.\n+        e.g. ``old_bond_leg = T_L.get_leg('vR')`` or ``old_bond_leg = T_R.get_leg('vL')``\n+    theta : npc.Array\n+        Array with legs [(vL.p0), (p1.vR)]\n+    expand : float | None\n+        Expansion rate. The QR-based decomposition is carried out at an expanded bond dimension.\n+    min_block_increase : int\n+        Minimum bond dimension increase for each block.\n+    move_right : bool \n+        If `True`, the left tensor `T_Lc` is returned in `'A'` form and the right tensor `T_Rc` is set to `None`.\n+        If `False`, the right tensor `T_Rc` is returned in `'B'` form and the left tensor `T_Lc` is set to `None`.\n+    use_eig_based_svd : bool\n+        Whether the SVD of the bond matrix :math:`\\Xi` should be carried out numerically via\n+        the eigensystem. This is faster on GPUs, but less accurate.\n+        It makes no sense to do this on CPU.\n+    trunc_par : dict\n+        truncation parameters as described in :func:`truncate`.\n+    compute_err : bool\n+        Whether the truncation error should be computed exactly.\n+        Computing the truncation error is significantly more expensive.\n+        If `True`, the full error is computed and ``return_both_T=True``.\n+        Otherwise, the truncation error is set to NaN.\n+    return_both_T : bool\n+        Whether the other tensor (associated with ``not move_right``) should be returned as well.\n+        If `True` and ``move_right=True``, the right tensor `T_Rc` is returned in `'Th'` (`'B'`) form, \n+        if ``use_eig_based_svd=True`` (``use_eig_based_svd=False``).\n+        If `True` and ``move_right=False``, the left tensor `T_Lc` is returned in `'Th'` (`'A'`) form, \n+        if ``use_eig_based_svd=True`` (``use_eig_based_svd=False``).\n+\n+    Returns\n+    -------\n+    T_Lc : array with legs [(vL.p), vR] or None\n+    S : 1D numpy array\n+        The singular values of the array.\n+        Normalized to ``np.linalg.norm(S)==1``.\n+    T_Rc : array with legs [vL, (p.vR)] or None\n+    form : list\n+        List containing two entries providing the form of the two arrays `T_Lc` and `T_Rc` in string form.\n+        e.g. ``['A','Th']``\n+    trunc_err : TruncationError\n+    renormalization : float\n+        Factor, by which S was renormalized.\n+    \"\"\"\n+\n+    if compute_err:\n+        return_both_T = True\n+    \n+    if move_right:\n+        # Get initial guess for the left isometry\n+        Y0 = _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta, move_right, expand, min_block_increase) # Y0: [(vL.p0), vR]\n+\n+        # QR based updates\n+        theta_i1 = npc.tensordot(Y0.conj(), theta, ['(vL*.p0*)', '(vL.p0)']).ireplace_label('vR*', 'vL') # theta_i1: [vL,(p1.vR)]\n+        theta_i1.itranspose(['(p1.vR)', 'vL']) # theta_i1: [(p1.vR),vL]\n+        B_R, _ = npc.qr(theta_i1, inner_labels=['vL', 'vR'], inner_qconj=-1) # B_R: [(p1.vR),vL] \n+        B_R.itranspose(['vL', '(p1.vR)']) # B_R: [vL,(p1.vR)] \n+\n+        theta_i0 = npc.tensordot(theta, B_R.conj(), ['(p1.vR)', '(p1*.vR*)']).ireplace_label('vL*', 'vR') # theta_i0: [(vL.p0),vR]\n+        A_L, Xi = npc.qr(theta_i0, inner_labels=['vR', 'vL']) # A_L: [(vL.p0), vR]\n+        \n+    else:\n+        # Get initial guess for the right isometry\n+        Y0 = _qr_theta_Y0(old_qtotal_L, old_qtotal_R, old_bond_leg, theta, move_right, expand, min_block_increase) # Y0: [vL, (p1.vR)]\n+\n+        # QR based updates\n+        theta_i0 = npc.tensordot(theta, Y0.conj(), ['(p1.vR)', '(p1*.vR*)']).ireplace_label('vL*', 'vR') # theta_i0: [(vL.p0),vR]\n+        A_L, _ = npc.qr(theta_i0, inner_labels=['vR', 'vL']) # A_L: [(vL.p0), vR]\n+\n+        theta_i1 = npc.tensordot(A_L.conj(), theta, ['(vL*.p0*)', '(vL.p0)']).ireplace_label('vR*', 'vL') # theta_i1: [vL,(p1.vR)]\n+        theta_i1.itranspose(['(p1.vR)', 'vL']) # theta_i1: [(p1.vR),vL]\n+        B_R, Xi = npc.qr(theta_i1, inner_labels=['vL', 'vR'], inner_qconj=-1)\n+        B_R.itranspose(['vL', '(p1.vR)'])\n+        Xi.itranspose(['vL', 'vR'])\n+\n+    # SVD of bond matrix Xi\n+    if use_eig_based_svd:\n+        U, S, Vd, _, renormalization = _eig_based_svd(\n+            Xi, need_U=move_right, need_Vd=(not move_right), inner_labels=['vR', 'vL'], trunc_params=trunc_params\n+        )\n+    else:\n+        U, S, Vd, _, renormalization = svd_theta(Xi, trunc_params)\n+\n+    # Assign return matrices\n+    T_Lc, T_Rc = None, None\n+    form = ['A','B']\n+    if move_right:\n+        T_Lc = npc.tensordot(A_L, U, ['vR', 'vL'])\n+        if return_both_T:\n+            if use_eig_based_svd:\n+                T_Rc = npc.tensordot(Xi, B_R, ['vR', 'vL'])\n+                T_Rc = npc.tensordot(U.iconj(), T_Rc, ['vL*', 'vL']).ireplace_label('vR*', 'vL')\n+                T_Rc /= npc.norm(T_Rc)\n+                form[1] = 'Th'\n+            else:\n+                T_Rc = npc.tensordot(Vd, B_R, ['vR', 'vL'])\n+    else:\n+        T_Rc = npc.tensordot(Vd, B_R, ['vR', 'vL'])\n+        if return_both_T:\n+            if use_eig_based_svd:\n+                T_Lc = npc.tensordot(A_L, Xi, ['vR', 'vL'])\n+                T_Lc = npc.tensordot(T_Lc, Vd.iconj(), ['vR', 'vR*']).ireplace_label('vL*', 'vR')\n+                T_Lc /= npc.norm(T_Lc)\n+                form[0] = 'Th'\n+            else:\n+                T_Lc = npc.tensordot(A_L, U, ['vR', 'vL'])\n+    \n+    # Compute error\n+    if compute_err:\n+        if use_eig_based_svd:\n+            theta_approx = npc.tensordot(T_Lc, T_Rc, ['vR', 'vL'])\n+        else:\n+            theta_approx = npc.tensordot(T_Lc.scale_axis(S, axis='vR'), T_Rc, ['vR', 'vL'])\n+        N_theta = npc.norm(theta)\n+        eps = npc.norm(theta / N_theta - theta_approx * renormalization / N_theta) ** 2\n+        trunc_err = TruncationError(eps, 1. - 2. * eps)\n+    else:\n+        trunc_err = TruncationError(np.nan, np.nan)\n+\n+    # Replace labels\n+    if move_right:\n+        T_Lc.ireplace_label('(vL.p0)', '(vL.p)')\n+        if return_both_T:\n+            T_Rc.ireplace_label('(p1.vR)', '(p.vR)')\n+    else:\n+        T_Rc.ireplace_label('(p1.vR)', '(p.vR)')\n+        if return_both_T:\n+            T_Lc.ireplace_label('(vL.p0)', '(vL.p)')\n+        \n+    return T_Lc, S, T_Rc, form, trunc_err, renormalization\n+\n+\n+def _combine_constraints(good1, good2, warn):\n+    \"\"\"return logical_and(good1, good2) if there remains at least one `True` entry.\n+\n+    Otherwise print a warning and return just `good1`.\n+    \"\"\"\n+    res = np.logical_and(good1, good2)\n+    if np.any(res):\n+        return res\n+    warnings.warn(\"truncation: can't satisfy constraint for \" + warn, stacklevel=3)\n+    return good1\n+\n+\n+# truncation parameter for truncating svd values at machine precision\n+# excluding 0. and negative S values only\n+_machine_prec_trunc_par = asConfig({'svd_min': np.finfo(np.float64).eps,\n+                                    'trunc_cut': None,\n+                                    'chi_max': None},\n+                                   'machine_prec_trunc_params')\n+_machine_prec_trunc_par.unused.clear()\ndiff --git a/tenpy/models/__init__.py b/tenpy/models/__init__.py\nindex 20ce807c5..5fefe6497 100644\n--- a/tenpy/models/__init__.py\n+++ b/tenpy/models/__init__.py\n@@ -57,7 +57,7 @@\n \n __all__ = [\n     'lattice', 'model', 'tf_ising', 'xxz_chain', 'spins', 'spins_nnn', 'fermions_spinless',\n-    'hubbard', 'tj_model', 'hofstadter', 'haldane', 'toric_code', 'aklt', 'mixed_xk',\n+    'hubbard', 'tj_model', 'hofstadter', 'haldane', 'toric_code', 'aklt', 'mixed_xk', 'clock',\n     *lattice.__all__,\n     *model.__all__,\n     *tf_ising.__all__,\ndiff --git a/tenpy/models/clock.py b/tenpy/models/clock.py\nindex 5aadc63d8..a3600c9e1 100644\n--- a/tenpy/models/clock.py\n+++ b/tenpy/models/clock.py\n@@ -47,6 +47,7 @@ class ClockModel(CouplingMPOModel):\n             The number of states per site.\n         J, g : float | array\n             Couplings as defined for the Hamiltonian above.\n+            Defaults to ``J=g=1``.\n \n     \"\"\"\n \ndiff --git a/tenpy/models/fermions_spinless.py b/tenpy/models/fermions_spinless.py\nindex 539c43f1e..89dea3e14 100644\n--- a/tenpy/models/fermions_spinless.py\n+++ b/tenpy/models/fermions_spinless.py\n@@ -46,6 +46,7 @@ class FermionModel(CouplingMPOModel):\n             For ``'best'``, we check the parameters what can be preserved.\n         J, V, mu : float | array\n             Hopping, interaction and chemical potential as defined for the Hamiltonian above.\n+            Defaults to ``J=V=1`` and ``mu=0``.\n         phi_ext : float\n             For 2D lattices and periodic y boundary conditions only.\n             External magnetic flux 'threaded' through the cylinder.\ndiff --git a/tenpy/models/hubbard.py b/tenpy/models/hubbard.py\nindex 6daa48be1..d64c08dcb 100644\n--- a/tenpy/models/hubbard.py\n+++ b/tenpy/models/hubbard.py\n@@ -44,6 +44,7 @@ class BoseHubbardModel(CouplingMPOModel):\n             What should be conserved. See :class:`~tenpy.networks.Site.BosonSite`.\n         t, U, V, mu: float | array\n             Couplings as defined in the Hamiltonian above. Note the signs!\n+            Defaults to `t=1.` without interaction ``V=U=0`` and ``mu=0``.\n         phi_ext : float\n             For 2D lattices and periodic y boundary conditions only.\n             External magnetic flux 'threaded' through the cylinder. Hopping amplitudes for bonds\n@@ -158,6 +159,7 @@ class FermiHubbardModel(CouplingMPOModel):\n             see :class:`~tenpy.networks.site.SpinHalfFermionSite` for details.\n         t, U, mu : float | array\n             Couplings as defined for the Hamiltonian above. Note the signs!\n+            Defaults to ``t=1`` without interaction ``U=0`` and ``mu=0``.\n         phi_ext : float\n             For 2D lattices and periodic y boundary conditions only.\n             External magnetic flux 'threaded' through the cylinder. Hopping amplitudes for bonds\ndiff --git a/tenpy/models/spins.py b/tenpy/models/spins.py\nindex ad9117acf..6869772ff 100644\n--- a/tenpy/models/spins.py\n+++ b/tenpy/models/spins.py\n@@ -46,7 +46,7 @@ class SpinModel(CouplingMPOModel):\n             Whether to sort by charges of physical legs. `True` by default.\n         Jx, Jy, Jz, hx, hy, hz, muJ, D, E  : float | array\n             Coupling as defined for the Hamiltonian above.\n-\n+            Defaults to Heisenberg ``Jx=Jy=Jz=1.`` with other couplings 0.\n     \"\"\"\n     def init_sites(self, model_params):\n         S = model_params.get('S', 0.5, 'real')\ndiff --git a/tenpy/models/spins_nnn.py b/tenpy/models/spins_nnn.py\nindex c2d30b870..ef53f1e72 100644\n--- a/tenpy/models/spins_nnn.py\n+++ b/tenpy/models/spins_nnn.py\n@@ -60,6 +60,7 @@ class SpinChainNNN(CouplingMPOModel, NearestNeighborModel):\n             What should be conserved. See :class:`~tenpy.networks.Site.SpinSite`.\n         Jx, Jy, Jz, Jxp, Jyp, Jzp, hx, hy, hz : float | array\n             Coupling as defined for the Hamiltonian above.\n+            Defaults to all ``Jx=Jy=Jz=Jxp=Jyp=Jzp=1`` and zero fields ``h*=0``.\n         bc_MPS : {'finite' | 'infinite'}\n             MPS boundary conditions. Coupling boundary conditions are chosen appropriately.\n \ndiff --git a/tenpy/models/tf_ising.py b/tenpy/models/tf_ising.py\nindex cdff1a476..b7680f8ad 100644\n--- a/tenpy/models/tf_ising.py\n+++ b/tenpy/models/tf_ising.py\n@@ -47,6 +47,7 @@ class TFIModel(CouplingMPOModel):\n             Whether to sort by charges of physical legs. `True` by default.\n         J, g : float | array\n             Coupling as defined for the Hamiltonian above.\n+            Defaults to ``J=g=1``\n \n     \"\"\"\n     def init_sites(self, model_params):\ndiff --git a/tenpy/models/tj_model.py b/tenpy/models/tj_model.py\nindex 8a6b4bb28..aa0e5e2cf 100644\n--- a/tenpy/models/tj_model.py\n+++ b/tenpy/models/tj_model.py\n@@ -46,6 +46,7 @@ class tJModel(CouplingMPOModel):\n             see :class:`~tenpy.networks.site.SpinHalfHoleSite` for details.\n         t, J: float | array\n             Couplings as defined for the Hamiltonian above. Note the signs!\n+            Defaults to ``t=J=1``\n     \"\"\"\n \n     def init_sites(self, model_params):\ndiff --git a/tenpy/models/xxz_chain.py b/tenpy/models/xxz_chain.py\nindex ee0390ab3..d68deedb8 100644\n--- a/tenpy/models/xxz_chain.py\n+++ b/tenpy/models/xxz_chain.py\n@@ -41,6 +41,7 @@ class XXZChain(CouplingModel, NearestNeighborModel, MPOModel):\n             Length of the chain.\n         Jxx, Jz, hz : float | array\n             Coupling as defined for the Hamiltonian above.\n+            Defaults to ``Jxx=Jz=1`` without field ``hz=0``.\n         bc_MPS : {'finite' | 'infinite'}\n             MPS boundary conditions. Coupling boundary conditions are chosen appropriately.\n         sort_charge : bool\ndiff --git a/tenpy/networks/mpo.py b/tenpy/networks/mpo.py\nindex 024b94f25..20e518b7c 100644\n--- a/tenpy/networks/mpo.py\n+++ b/tenpy/networks/mpo.py\n@@ -46,6 +46,7 @@\n \n from ..linalg import np_conserved as npc\n from ..linalg.sparse import NpcLinearOperator, FlatLinearOperator\n+from ..linalg.truncation import TruncationError, svd_theta\n from .site import group_sites\n from ..tools.string import vert_join\n from .mps import MPS as _MPS  # only for MPS._valid_bc\n@@ -54,7 +55,6 @@\n from ..tools.misc import to_iterable, add_with_None_0\n from ..tools.math import lcm\n from ..tools.params import asConfig\n-from ..algorithms.truncation import TruncationError, svd_theta\n \n __all__ = [\n     'MPO', 'make_W_II', 'MPOGraph', 'MPOEnvironment', 'MPOTransferMatrix', 'grid_insert_ops'\n@@ -335,7 +335,7 @@ def from_wavepacket(cls, sites, coeff, op, eps=1.e-15):\n             import numpy as np\n \n         .. doctest :: from_wavepacket\n-        \n+\n             >>> L, k0, x0, sigma, = 50, np.pi/8., 10., 5.\n             >>> x = np.arange(L)\n             >>> coeff = np.exp(-1.j * k0 * x) * np.exp(- 0.5 * (x - x0)**2 / sigma**2)\n@@ -348,7 +348,7 @@ def from_wavepacket(cls, sites, coeff, op, eps=1.e-15):\n         Indeed, we can apply this to a (vacuum) MPS and get the correct state:\n \n         .. doctest :: from_wavepacket\n-        \n+\n             >>> psi = MPS.from_product_state([site] * L, ['empty'] * L)\n             >>> wp.apply(psi, dict(compression_method='SVD'))\n             TruncationError()\n@@ -1408,7 +1408,7 @@ def __add__(self, other):\n         \"\"\"\n         if self.explicit_plus_hc != other.explicit_plus_hc:\n             raise ValueError('Can not add MPOs with different explicit_plus_hc flags')\n-        \n+\n         L = self.L\n         assert self.bc == other.bc\n         assert other.L == L\ndiff --git a/tenpy/networks/mps.py b/tenpy/networks/mps.py\nindex 4eeaa6f58..6552416a6 100644\n--- a/tenpy/networks/mps.py\n+++ b/tenpy/networks/mps.py\n@@ -158,14 +158,13 @@\n from ..linalg import np_conserved as npc\n from ..linalg import sparse\n from ..linalg.krylov_based import Arnoldi\n+from ..linalg.truncation import TruncationError, svd_theta, _machine_prec_trunc_par\n from .site import group_sites\n from ..tools.misc import argsort, to_iterable, to_array, get_recursive, inverse_permutation\n from ..tools.math import lcm, entropy\n from ..tools.params import asConfig\n from ..tools.cache import DictCache\n from ..tools import hdf5_io\n-from ..algorithms.truncation import TruncationError, svd_theta, _machine_prec_trunc_par\n-from ..algorithms.tebd import RandomUnitaryEvolution\n \n __all__ = ['BaseMPSExpectationValue', 'MPS', 'BaseEnvironment', 'MPSEnvironment', 'TransferMatrix',\n            'InitialStateBuilder', 'build_initial_state']\n@@ -1802,12 +1801,14 @@ def from_random_unitary_evolution(cls,\n         chargeL : charges\n             Leg charges at bond 0, which are purely conventional.\n         \"\"\"\n+        from ..algorithms.tebd import RandomUnitaryEvolution  # local import: avoid circular import\n+\n         if bc == 'segment':\n             msg = \"MPS.from_random_unitary_evolution not implemented for segment BC.\"\n             raise NotImplementedError(msg)\n         psi = MPS.from_product_state(sites, p_state, bc, dtype, permute, form, chargeL)\n-        tebd_options = dict(N_steps = 10, trunc_params={'chi_max': chi})\n-        eng = RandomUnitaryEvolution(psi, tebd_options)\n+        tebd_params = dict(N_steps = 10, trunc_params={'chi_max': chi})\n+        eng = RandomUnitaryEvolution(psi, tebd_params)\n         _max_iter = 1000\n         for _ in range(_max_iter):\n             if psi.finite and (max(psi.chi) >= chi):\n@@ -4765,7 +4766,7 @@ def perturb(self, randomize_params=None, close_1=True, canonicalize=None):\n         canonicalize : bool\n             Wether to call `psi.canonical_from in the end. Defaults to ``not close_1``.\n         \"\"\"\n-        from ..algorithms.tebd import RandomUnitaryEvolution\n+        from ..algorithms.tebd import RandomUnitaryEvolution  # local import: avoid circular import\n         if randomize_params is None:\n             randomize_params = {}\n         if close_1:\ndiff --git a/tenpy/simulations/post_processing.py b/tenpy/simulations/post_processing.py\nindex bd329fbc7..a11c32f0e 100644\n--- a/tenpy/simulations/post_processing.py\n+++ b/tenpy/simulations/post_processing.py\n@@ -31,7 +31,7 @@\n     h5py_version = (0, 0)\n \n __all__ = [\n-    'DataLoader', 'pp_spectral_function', 'pp_plot_correlations_on_lattice'\n+    'DataLoader', 'DataFiles', 'pp_spectral_function', 'pp_plot_correlations_on_lattice'\n ]\n \n \n@@ -68,7 +68,7 @@ def __init__(self, filename=None, simulation=None, data=None):\n \n         if filename is not None:\n             self.filename = Path(filename)\n-            self.logger.info(f\"Loading data from {self.filename.name}\")\n+            self.logger.info(f\"Loading data from {self.filename!s}\")\n             if self.filename.suffix == '.h5' or self.filename.suffix == '.hdf5':\n                 # create a h5group (which is open)\n                 self.logger.info(\n@@ -80,7 +80,7 @@ def __init__(self, filename=None, simulation=None, data=None):\n             else:\n                 self.logger.info(f\"Not using hdf5 data-format.\\nLoading data can be slow\")\n                 # all data is loaded as other filenames\n-                self._all_data = hdf5_io.load(self.filename.name)\n+                self._all_data = hdf5_io.load(self.filename)\n \n             self.sim_params = self._load('simulation_parameters')\n \n@@ -111,6 +111,13 @@ def close(self):\n             self._Hdf5Loader.h5group.close()\n             self.logger.info(f\"Closed {self.filename}\")\n \n+    def __repr__(self):\n+        if self.filename is not None:\n+            return f\"DataLoader(filename={self.filename!r})\"\n+        if hasattr(self, 'sim'):\n+            return f\"DataLoader(simulation={self.sim!r})\"\n+        return \"Dataloader(data=...)\"\n+\n     @property\n     def measurements(self):\n         if self._measurements is None:\n@@ -169,8 +176,8 @@ def _load(self, path, prefix='', convert_to_numpy=False):\n                 raise ValueError(\"Can't find any results.\")\n             if isinstance(value, Config):\n                 value = value.as_dict()\n-            if convert_to_numpy is True:\n-                value = self.convert_list_to_ndarray(value)\n+            if convert_to_numpy:\n+                value = self.convert_list_to_ndarray(value, key=key)\n             return value\n         except KeyError:\n             warnings.warn(f\"{key} does not exist!\")\n@@ -181,24 +188,29 @@ def get_data_m(self, key, prefix='measurements/', convert_to_numpy=True):\n     def get_data(self, key, prefix='', convert_to_numpy=False):\n         return self._load(key, prefix=prefix, convert_to_numpy=convert_to_numpy)\n \n-    @staticmethod\n-    def convert_list_to_ndarray(value):\n-        try:\n-            if isinstance(value, list):\n-                value = np.array(value)\n-                if value.dtype == np.dtype(object):\n-                    raise Exception(\"Can't convert results to numpy array\")\n-        except Exception as e:\n-            logging.exception(f\"{e}, proceeding without converting\")\n+    def convert_list_to_ndarray(self, value, key):\n+        if isinstance(value, list):\n+            converted_value = np.array(value)\n+            if converted_value.dtype == np.dtype(object):\n+                self.logger.info(\"Can't convert %s to numpy array, proceed without conversion\",\n+                                 key)\n+            else:\n+                value = converted_value\n         return value\n \n     @property\n     def model(self):\n         if not hasattr(self, '_model'):\n-            self._model = self.get_model()\n+            self._model = self._get_model()\n         return self._model\n \n     def get_model(self):\n+        \"\"\"Deprecated in favor of the simpler property access via :attr:`DataLoader.model`.\"\"\"\n+        warnings.warn(\"Use ``DataLoader.model`` instead of ``DataLoader.get_model()``\",\n+                      FutureWarning, 2)\n+        return self.model\n+\n+    def _get_model(self):\n         model_class_name = self.sim_params['model_class']\n         model_params = self.sim_params['model_params']\n         model_class = find_subclass(Model, model_class_name)\n@@ -227,6 +239,125 @@ def get_all_keys_as_dict(self):\n             raise ValueError(\"Can't find any results.\")\n \n \n+class DataFiles:\n+    \"\"\"Hold multiple DataLoader instances open, indexed by the filename.\n+\n+    Acts like a dictionary mapping filenames to :class:`DataLoader`.\n+    Item access implicitly opens files that are not yet loaded.\n+\n+    Parameters\n+    ----------\n+    files : list of str\n+        Filenames of output files to be opened.\n+\n+    Examples\n+    --------\n+    .. doctest ::\n+        :skipif: True\n+\n+        >>> data_files = DataFiles(['results/output_1.h5',\n+        ...                         'results_other/output_3.h5'])\n+        >>> data_files['results/output_1.h5']\n+        DataLoader(filename='results/output_1.h5')\n+        >>> data_files['results/output_2.h5']\n+        loading results/output_2.h5 ... successful\n+    \"\"\"\n+    def __init__(self, files=None, folder=None):\n+        self._open_files = {} # filename -> DataLoader\n+        self._resolve_filenames = {}\n+        self._keys = []\n+        if files:\n+            for file in files:\n+                _ = self[file]\n+        if folder:\n+            self.load_from_folder(folder)\n+\n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, exc_type, exc_value, traceback):\n+        self.close()\n+\n+    def close(self):\n+        \"\"\"Close all files held open by self.\"\"\"\n+        for dl in self._open_files.values():\n+            dl.close()\n+\n+    def __getitem__(self, filename):\n+        normalized = self._normalize_filename(filename)\n+        data = self._open_files.get(normalized, None)\n+        if data is None:\n+            filename = str(filename)\n+            try:\n+                data = DataLoader(filename)\n+            except OSError as e:\n+                print(f\"Erorr: failed to open {filename}\")\n+                raise e from None\n+            self._keys.append(filename)\n+            self._open_files[normalized] = data\n+        return data\n+\n+    def __setitem__(self, filename, data_loader):\n+        if filename is None:\n+            filename = data_loader.filename\n+        normalized = self._normalize_filename(filename)\n+        self._open_files[normalized] = data_loader\n+        return data_loader  # TODO: do we need to return this?\n+\n+    def _normalize_filename(self, filename):\n+        filename = str(filename)\n+        resolved = self._resolve_filenames.get(filename, None)\n+        if resolved is None:\n+            resolved = str(Path(filename).resolve())\n+            self._resolve_filenames[filename] = resolved\n+        return resolved\n+\n+    def keys(self):\n+        \"\"\"Return paths of the files opened.\"\"\"\n+        return self._keys\n+\n+    def values(self):\n+        \"\"\"Return iterator over the :class:`DataLoader` instances.\"\"\"\n+        return self._open_files.values()\n+\n+    def items(self):\n+        return zip(self._keys, self.values())\n+\n+    def __delitem__(self, filename):\n+        normalized = self._normalize_filename(filename)\n+        self._open_files[normalized].close()\n+        del self._open_files[normalized]\n+        for key in self._keys:\n+            if self._resolve_filenames[key] == normalized:\n+                self._keys.remove(key)\n+                break\n+        for key, val in list(self._resolve_filenames.items()):\n+            if val == normalized:\n+                del self._resolve_filenames[key]\n+\n+    def __repr__(self):\n+        if self._open_files:\n+            return \"<DataFiles() with files\\n    \" + '\\n    '.join(self.keys()) + \">\"\n+\n+    def load_from_folder(self, folder, glob=\"*.h5\"):\n+        \"\"\"Load all data files from a given folder.\"\"\"\n+        files = Path(folder).glob(glob)\n+        for file in files:\n+            print(f\"loading {file!s}\", end=' ')\n+            try:\n+                _ = self[file]\n+            except OSError as e:\n+                print(\"... FAILED! Ignoring.\")\n+            else:\n+                print(\"... successful\")\n+        # done\n+\n+    # TODO: tests for this\n+\n+    # TODO: semi-automatically analyze sim_params and find differences?\n+    # TODO get pandas.DataFrame from changing keys\n+\n+\n def pp_spectral_function(DL: DataLoader,\n                          *,\n                          correlation_key,\ndiff --git a/tenpy/simulations/simulation.py b/tenpy/simulations/simulation.py\nindex ce4edbfd1..9d4e9aa6d 100644\n--- a/tenpy/simulations/simulation.py\n+++ b/tenpy/simulations/simulation.py\n@@ -14,6 +14,7 @@\n from pathlib import Path\n import time\n import importlib\n+import signal\n import warnings\n import traceback\n import numpy as np\n@@ -22,6 +23,7 @@\n \n from ..models.model import Model\n from ..algorithms.algorithm import Algorithm\n+from ..linalg.truncation import TruncationError\n from ..networks.mps import InitialStateBuilder\n from ..models.model import NearestNeighborModel\n from ..tools import hdf5_io\n@@ -101,7 +103,7 @@ class Simulation:\n             We safeguard measurements with a try-except block to avoid loosing results after an expensive\n             simulation. This is the maximum number of errors happening during measurements\n             before we abort the whole simulation.\n-            Setting this to None disables raising the error due to failed measurements \n+            Setting this to None disables raising the error due to failed measurements\n             (also at the end of the simulation).\n \n     Attributes\n@@ -168,8 +170,11 @@ class Simulation:\n         Only set if `grouped` > 1. In that case, :attr:`model` is the modified/grouped model,\n         and `model_ungrouped` is the original ungrouped model.\n     final_processing : bool\n-        Flag that indicates that we're in the final processing and want to avoid raising errors \n+        Flag that indicates that we're in the final processing and want to avoid raising errors\n         before saving results.\n+    received_signal_sigint : bool\n+        Flag to indicate that the user pressed ctrl-c and want's the process to terminate.\n+        See :meth:`handle_ctrl_c_sigint` for details.\n     \"\"\"\n     #: name of the default algorithm `engine` class\n     default_algorithm = 'TwoSiteDMRGEngine'\n@@ -197,6 +202,7 @@ def __init__(self, options, *, setup_logging=True, resume_data=None):\n         if cwd is not None:\n             if not os.path.exists(cwd):\n                 os.mkdir(cwd)\n+            self._orig_dir = os.getcwd()  # save current dir to return to it in __exit__()\n             os.chdir(cwd)\n         self.fix_output_filenames()\n         if setup_logging:\n@@ -239,10 +245,12 @@ def __init__(self, options, *, setup_logging=True, resume_data=None):\n         self.grouped = 1\n         self.final_processing = False\n         self.max_errors_before_abort = self.options.get('max_errors_before_abort', 10, int)\n+        self.received_signal_sigint = False\n \n     def __enter__(self):\n         self.init_cache()\n         self.cache = self.cache.__enter__()  # start cache context\n+        self._orig_sigint_handler = signal.signal(signal.SIGINT, self.handle_abort_signal)\n         return self\n \n     def __exit__(self, exc_type, exc_value, traceback):\n@@ -251,6 +259,39 @@ def __exit__(self, exc_type, exc_value, traceback):\n             self.logger.exception(\"simulation abort with the following exception\",\n                                   exc_info=(exc_type, exc_value, traceback))\n         self.options.warn_unused(True)\n+        signal.signal(signal.SIGINT, self._orig_sigint_handler)\n+        orig_dir = getattr(self, '_orig_dir', None)\n+        if orig_dir is not None:\n+            os.chdir(orig_dir)\n+\n+    def handle_abort_signal(self, signum, frame):\n+        \"\"\"Handle a SIGINT signal, usually caused by a CTRL-C press.\n+\n+        When the user presses Ctrl-C the first time, we just print a message to stderr that we\n+        received the signal and set the flag :attr:`received_signal_sigint`.\n+        This allows the simulation to \"exit gracefully\": it will continue until the next\n+        algorithm checkpoint, where :meth:`save_at_checkpoint` checks for this flag,\n+        and if set, saves the results obtained so far and only then raises KeyboardInterrupt.\n+\n+        When Ctrl-C is presssed a second time, we immediately raise a KeyboardInterrupt.\n+\n+        This feature is especially handy to gracefully interrupt long-running simulations.\n+        When running in an HPC cluster linux environment, you can usually still send the SIGINT\n+        signal, e.g. with SLURM you can call ``scancel --signal=INT 1234`` for the job ide `1234`.\n+        \"\"\"\n+        if signum != signal.SIGINT:\n+            raise ValueError(f\"unexpected signal to handle: {signum=}\")\n+        if self.received_signal_sigint:\n+            raise KeyboardInterrupt(\"Got second SIGINT signal; abort the simulation immediately\")\n+        self.received_signal_sigint = True\n+        msg = (\"Got SIGINT signal (likely from Ctrl-C in the terminal) the first time. \\n\"\n+               \"TeNPy simulation will continue until the next checkpoint, then save and abort.\")\n+        self.logger.error(msg)\n+        print(msg, \"\\nTo exit immediately, press Ctrl-C again.\",\n+              file=sys.stderr,\n+              flush=True)\n+        # the received_signal_sigint flag should be handled in the next save_at_checkpoint call\n+        # which is always added to the algorithm checkpoints.\n \n     def estimate_RAM(self):\n         \"\"\"Estimates the RAM usage for the simulation, without running it.\n@@ -543,7 +584,9 @@ def init_algorithm(self, **kwargs):\n         kwargs.setdefault('cache', self.cache)\n         params = self.options.subconfig('algorithm_params')\n         self.engine = AlgorithmClass(self.psi, self.model, params, **kwargs)\n-        self.engine.checkpoint.connect(self.save_at_checkpoint)\n+        self.engine.checkpoint.connect(self.save_at_checkpoint, priority=-100)\n+        # with low prio to make sure we save after another set of potential measurements\n+        # enabled by the `measure_at_algorithm_checkpoints` option\n         con_checkpoint = list(self.options.get('connect_algorithm_checkpoint', []))\n         for entry in con_checkpoint:\n             self.engine.checkpoint.connect_by_name(*entry)\n@@ -715,8 +758,8 @@ def perform_measurements(self):\n                                                    psi=psi,\n                                                    model=model,\n                                                    simulation=self)\n-            # we safe-guard the measurements with try-except \n-            # to avoid that mistakes in the measurement cause us to loose all our data, \n+            # we safe-guard the measurements with try-except\n+            # to avoid that mistakes in the measurement cause us to loose all our data,\n             # e.g. if we were running DMRG for days, and just have a stupid typo in a measurement function\n         except Exception:\n             err_traceback = traceback.format_exc()\n@@ -1063,16 +1106,30 @@ def prepare_results_for_save(self):\n         if len(self.errors_during_run) > 0:\n             results['errors_during_run'] = self.errors_during_run\n         results['simulation_parameters'] = self.options.as_dict()\n-        if 'measurements' in results:\n-            # try to convert measurements into numpy arrays to store more compactly\n-            results['measurements'] = measurements = results['measurements'].copy()\n-            for k, v in measurements.items():\n-                try:\n-                    v = np.array(v)\n-                except:\n-                    continue\n-                if v.dtype != np.dtype(object):\n-                    measurements[k] = v\n+        for key in ['measurements', 'sweep_stats', 'update_stats']:\n+            if key in results:\n+                # try to convert lists into numpy arrays to store more compactly\n+                data = results[key].copy()\n+                for k, v in results[key].items():\n+                    if isinstance(v, list):\n+                        if len(v) > 0 and isinstance(v[0], TruncationError):\n+                            # special handling for TruncationError: convert to _eps and _ov lists\n+                            try:\n+                                v_err = [err.eps for err in v]\n+                                v_ov = [err.ov for err in v]\n+                                del data[k]\n+                                data[k + \"_eps\"] = np.array(v_err)\n+                                data[k + \"_ov\"] = np.array(v_ov)\n+                            except:\n+                                pass\n+                            continue\n+                        try:\n+                            v = np.array(v)\n+                        except:\n+                            continue\n+                        if v.dtype != np.dtype(object):\n+                            data[k] = v\n+                results[key] = data\n         if self.options.get('save_resume_data', self.options['save_psi'], bool):\n             results['resume_data'] = self.get_resume_data()\n         return results\n@@ -1111,8 +1168,12 @@ def save_at_checkpoint(self, alg_engine):\n         \"\"\"\n         save_every = self.options.get('save_every_x_seconds', None, 'real')\n         now = time.time()\n-        if save_every is not None and now - self._last_save > save_every:\n+        if save_every is not None and now - self._last_save > save_every or \\\n+                self.received_signal_sigint:\n             self.save_results()\n+            if self.received_signal_sigint:\n+                raise KeyboardInterrupt(\"Got SIGINT interrupt signal during TeNPy simulation, \"\n+                    \"but continued until the next checkpoint and saved checkpoint results\")\n             time_to_save = time.time() - now\n             if time_to_save > 0.1 * save_every > 0.:\n                 save_every = 20 * time_to_save\n@@ -1654,4 +1715,4 @@ def output_filename_from_dict(options,\n         vals = [get_recursive(options, r_key, separator) for r_key in recursive_key]\n         part = format_str.format(*vals)\n         formatted_parts.append(part)\n-    return joint.join(formatted_parts) + suffix\n\\ No newline at end of file\n+    return joint.join(formatted_parts) + suffix\n", "instance_id": "tenpy__tenpy-460", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in identifying two distinct tasks: addressing a bug related to duplicate names (`lanczos_params` and `lanczos_options`) in TDVP and VUMPS implementations, and adding a new paper to the list of publications using TeNPy. The bug description provides context about the issue and suggests a solution involving deprecation aliases for backward compatibility. The second task of adding a paper is straightforward with a clear reference to the paper and where it should be included. However, there are minor ambiguities: the bug fix lacks detailed steps on how to implement the deprecated alias or property access in the codebase, and there are no specific instructions on potential edge cases or user impact. Additionally, the problem statement does not explicitly connect to the provided code changes, which seem unrelated to the bug fix and focus instead on documentation updates. Overall, the statement is valid and mostly clear but misses some critical implementation details and alignment with the code changes.", "difficulty_explanation": "The difficulty of this problem is very low, falling in the 0.0-0.2 range, as it primarily involves basic code modifications and documentation updates. The bug fix for `lanczos_params` and `lanczos_options` requires simple changes, such as adding a deprecated alias and a property accessor in the TDVP configuration, which are straightforward tasks for someone familiar with the codebase. This involves minimal logic changes, likely confined to a single file or module, with no significant impact on the system's architecture. The second task of adding a paper to the documentation is a trivial update to a bibliography file, requiring no deep understanding of the codebase. The provided code changes, while extensive, are mostly unrelated to the stated bug and involve routine updates to documentation and references, which are low-effort tasks. There are no complex technical concepts, edge cases, or performance considerations involved, making this an easy problem for a developer with basic familiarity with the repository structure and Python. The score of 0.15 reflects the simplicity of the tasks with a slight increase over 0.0 due to the need for minimal codebase navigation to locate the relevant configuration sections.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.15}
{"problem_statement": "Bug: The Kitchn's branding prefers the definite article (the)\n**Pre-filing checks**\r\n\r\n- [x] I have searched for open issues that report the same problem\r\n- [x] I have checked that the bug affects the latest version of the library\r\n\r\n**The URL of the recipe(s) that are not being scraped correctly**\r\n\r\n- https://www.thekitchn.com/manicotti-22949270\r\n\r\n...\r\n\r\n**The results you expect to see**\r\n\r\nThe `site_name()` value should be `The Kitchn`.\r\n\r\n**The results (including any Python error messages) that you are seeing**\r\n\r\nThe `site_name()` value is `Kitchn`.\n", "patch": "diff --git a/recipe_scrapers/thekitchn.py b/recipe_scrapers/thekitchn.py\nindex 2c949f2ef..0841446ed 100644\n--- a/recipe_scrapers/thekitchn.py\n+++ b/recipe_scrapers/thekitchn.py\n@@ -1,7 +1,11 @@\n from ._abstract import AbstractScraper\n+from ._exceptions import StaticValueException\n \n \n class TheKitchn(AbstractScraper):\n     @classmethod\n     def host(cls):\n         return \"thekitchn.com\"\n+\n+    def site_name(self):\n+        raise StaticValueException(return_value=\"The Kitchn\")\n", "instance_id": "hhursev__recipe-scrapers-1316", "clarity": 2, "difficulty": 0.1, "clarity_explanation": "The problem statement is mostly clear in describing the issue: the `site_name()` method should return \"The Kitchn\" instead of \"Kitchn\" to align with the branding preference. The goal is straightforward, and the expected output is explicitly stated. Additionally, the URL of the affected recipe is provided, which helps in understanding the context. However, there are minor ambiguities or missing details. For instance, the problem statement does not specify whether this change should apply universally across all recipes from the website or if there are exceptions. It also lacks mention of potential edge cases or constraints, such as whether the branding could change in the future or if there are other parts of the codebase that rely on the current value. Despite these minor gaps, the statement is valid and provides enough information to address the issue, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem is very low, as it involves a simple and isolated code change. Analyzing the factors:\n\n1. **Scope and Depth of Code Changes:** The modification is confined to a single file (`thekitchn.py`) and involves adding a single method override for `site_name()` with a static return value. The change is minimal, consisting of just a few lines of code, and does not impact other parts of the codebase or the system's architecture.\n2. **Number of Technical Concepts:** The solution requires basic knowledge of Python class methods and exception handling (via `StaticValueException`). These are fundamental concepts that do not pose significant complexity. No advanced algorithms, design patterns, or domain-specific knowledge are needed.\n3. **Edge Cases and Error Handling:** The problem statement does not mention any specific edge cases, and the code change does not introduce or require complex error handling beyond raising a static exception with a predefined value. The implementation is straightforward with no apparent risks or side effects.\n4. **Overall Complexity:** The task is essentially a cosmetic fix to update a static string value, requiring minimal understanding of the surrounding codebase beyond the specific class being modified.\n\nGiven these points, the problem falls into the \"Very Easy\" category, as it is a basic code modification akin to changing a constant. Therefore, I assign a difficulty score of 0.1, reflecting the simplicity and minimal effort required to implement the solution.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.1}
{"problem_statement": "[Bug]: MetaData.reflect() raises exception with sqlalchemy v2.0.36\n### What happened?\n\nThis [commit](https://gerrit.sqlalchemy.org/c/sqlalchemy/sqlalchemy/+/5519/3/lib/sqlalchemy/dialects/postgresql/base.py) in sqlalchemy v2.0.36 causes a regression when creating a table in DuckDB. A SQLAlchemy developer [says](https://github.com/sqlalchemy/sqlalchemy/discussions/12011#discussioncomment-10992396) that this package will need to override the new statement.\r\n\r\n```python\r\nfrom sqlalchemy import MetaData, create_engine, text\r\n\r\nengine = create_engine(\"duckdb:///:memory:\")\r\nmetadata = MetaData()\r\nwith engine.connect() as conn:\r\n    conn.execute(text(\"CREATE TABLE tbl(col1 INTEGER)\"))\r\n    conn.commit()\r\nmetadata.reflect(engine)\r\n```\r\n\r\n```\r\n/private/tmp/env/lib/python3.11/site-packages/duckdb_engine/__init__.py:174: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1967, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 941, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/duckdb_engine/__init__.py\", line 140, in execute\r\n    self.__c.execute(statement, parameters)\r\nduckdb.duckdb.CatalogException: Catalog Error: Type with name REGCLASS does not exist!\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/dthom/repos/chronify/scripts/repro_alchemy.py\", line 8, in <module>\r\n    metadata.reflect(engine)\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/sql/schema.py\", line 5828, in reflect\r\n    _reflect_info = insp._get_reflection_info(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/reflection.py\", line 2024, in _get_reflection_info\r\n    table_comment=run(self.get_multi_table_comment, optional=True),\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/reflection.py\", line 2001, in run\r\n    res = meth(filter_names=_fn, **kw)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/reflection.py\", line 1377, in get_multi_table_comment\r\n    self.dialect.get_multi_table_comment(\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/base.py\", line 4709, in get_multi_table_comment\r\n    result = connection.execute(query, params)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1418, in execute\r\n    return meth(\r\n           ^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/sql/elements.py\", line 515, in _execute_on_connection\r\n    return connection._execute_clauseelement(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1640, in _execute_clauseelement\r\n    ret = self._execute_context(\r\n          ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1846, in _execute_context\r\n    return self._exec_single_context(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1986, in _exec_single_context\r\n    self._handle_dbapi_exception(\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 2355, in _handle_dbapi_exception\r\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/base.py\", line 1967, in _exec_single_context\r\n    self.dialect.do_execute(\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/sqlalchemy/engine/default.py\", line 941, in do_execute\r\n    cursor.execute(statement, parameters)\r\n  File \"/private/tmp/env/lib/python3.11/site-packages/duckdb_engine/__init__.py\", line 140, in execute\r\n    self.__c.execute(statement, parameters)\r\nsqlalchemy.exc.ProgrammingError: (duckdb.duckdb.CatalogException) Catalog Error: Type with name REGCLASS does not exist!\r\n[SQL: SELECT pg_catalog.pg_class.relname, pg_catalog.pg_description.description \r\nFROM pg_catalog.pg_class LEFT OUTER JOIN pg_catalog.pg_description ON pg_catalog.pg_class.oid = pg_catalog.pg_description.objoid AND pg_catalog.pg_description.objsubid = $1 AND pg_catalog.pg_description.classoid = CAST($2 AS REGCLASS) JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \r\nWHERE pg_catalog.pg_class.relkind = ANY (ARRAY[$3, $4, $5]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $6 AND pg_catalog.pg_class.relname IN ($7)]\r\n[parameters: (0, 'pg_catalog.pg_class', 'r', 'p', 'f', 'pg_catalog', 'tbl')]\r\n(Background on this error at: https://sqlalche.me/e/20/f405)\r\n```\r\n\n\n### DuckDB Engine Version\n\n0.13.2\n\n### DuckDB Version\n\n1.1.2\n\n### SQLAlchemy Version\n\n2.0.36\n\n### Relevant log output\n\n_No response_\n\n### Code of Conduct\n\n- [X] I agree to follow this project's Code of Conduct\n", "patch": "diff --git a/duckdb_engine/__init__.py b/duckdb_engine/__init__.py\nindex f300ed78..24377577 100644\n--- a/duckdb_engine/__init__.py\n+++ b/duckdb_engine/__init__.py\n@@ -1,5 +1,6 @@\n import re\n import warnings\n+from functools import lru_cache\n from typing import (\n     TYPE_CHECKING,\n     Any,\n@@ -15,7 +16,7 @@\n \n import duckdb\n import sqlalchemy\n-from sqlalchemy import pool, text, util\n+from sqlalchemy import pool, select, sql, text, util\n from sqlalchemy import types as sqltypes\n from sqlalchemy.dialects.postgresql import UUID\n from sqlalchemy.dialects.postgresql.base import (\n@@ -31,6 +32,7 @@\n from sqlalchemy.engine.url import URL\n from sqlalchemy.exc import NoSuchTableError\n from sqlalchemy.ext.compiler import compiles\n+from sqlalchemy.sql import bindparam\n from sqlalchemy.sql.selectable import Select\n \n from ._supports import has_comment_support\n@@ -599,6 +601,51 @@ def get_multi_columns(\n \n         return columns.items()\n \n+    # fix for https://github.com/Mause/duckdb_engine/issues/1128\n+    # (Overrides sqlalchemy method)\n+    @lru_cache()\n+    def _comment_query(  # type: ignore[no-untyped-def]\n+        self, schema: str, has_filter_names: bool, scope: Any, kind: Any\n+    ):\n+        if sqlalchemy.__version__ >= \"2.0.36\":\n+            from sqlalchemy.dialects.postgresql import (  # type: ignore[attr-defined]\n+                pg_catalog,\n+            )\n+\n+            if (\n+                hasattr(super(), \"_kind_to_relkinds\")\n+                and hasattr(super(), \"_pg_class_filter_scope_schema\")\n+                and hasattr(super(), \"_pg_class_relkind_condition\")\n+            ):\n+                relkinds = getattr(super(), \"_kind_to_relkinds\")(kind)\n+                query = (\n+                    select(\n+                        pg_catalog.pg_class.c.relname,\n+                        pg_catalog.pg_description.c.description,\n+                    )\n+                    .select_from(pg_catalog.pg_class)\n+                    .outerjoin(\n+                        pg_catalog.pg_description,\n+                        sql.and_(\n+                            pg_catalog.pg_class.c.oid\n+                            == pg_catalog.pg_description.c.objoid,\n+                            pg_catalog.pg_description.c.objsubid == 0,\n+                        ),\n+                    )\n+                    .where(getattr(super(), \"_pg_class_relkind_condition\")(relkinds))\n+                )\n+                query = self._pg_class_filter_scope_schema(query, schema, scope)\n+                if has_filter_names:\n+                    query = query.where(\n+                        pg_catalog.pg_class.c.relname.in_(bindparam(\"filter_names\"))\n+                    )\n+                return query\n+        else:\n+            if hasattr(super(), \"_comment_query\"):\n+                return getattr(super(), \"_comment_query\")(\n+                    schema, has_filter_names, scope, kind\n+                )\n+\n \n if sqlalchemy.__version__ >= \"2.0.14\":\n     from sqlalchemy import TryCast  # type: ignore[attr-defined]\n", "instance_id": "Mause__duckdb_engine-1147", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in describing the issue: a regression in SQLAlchemy v2.0.36 causes an exception when using `MetaData.reflect()` with DuckDB due to a specific commit in SQLAlchemy. It provides a reproducible code snippet, relevant version information, and a detailed error traceback, which helps in understanding the context and the root cause (a `CatalogException` due to an unsupported `REGCLASS` type in DuckDB). Additionally, it references a discussion with a SQLAlchemy developer suggesting the need to override a new statement. However, the statement lacks explicit mention of specific edge cases or constraints that might need to be handled in the solution. It also does not fully clarify the expected behavior or output after the fix (e.g., what should `reflect()` return for DuckDB tables). These minor ambiguities prevent it from being comprehensive, hence a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category (0.6-0.8) due to several factors. First, the scope of code changes is relatively focused but impactful, as it involves overriding a method in the `duckdb_engine` to handle a specific SQLAlchemy behavior introduced in version 2.0.36. The changes are confined to a single file (`duckdb_engine/__init__.py`) and involve adding a new method (`_comment_query`) with conditional logic based on SQLAlchemy version, but they require understanding the interaction between SQLAlchemy's PostgreSQL dialect and DuckDB's limitations (e.g., lack of `REGCLASS` support). Second, the technical concepts involved are moderately complex, including familiarity with SQLAlchemy's internal reflection mechanisms, PostgreSQL catalog queries, and DuckDB's catalog system limitations. It also requires knowledge of SQLAlchemy's API for constructing queries (`select`, `bindparam`, etc.) and version-specific behavior. Third, while the problem statement does not explicitly mention edge cases, the code change must ensure compatibility with different SQLAlchemy versions (using version checks) and handle potential schema or table name filtering scenarios, which adds some complexity to error handling and testing. Finally, the solution impacts a critical functionality (table reflection), which is a core part of database interaction, necessitating careful implementation to avoid introducing new regressions. Overall, this problem requires a deep understanding of the libraries involved and careful modification of behavior, justifying a difficulty score of 0.65.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.65}
{"problem_statement": "GroupBy[Series].count() should have return type Series[int]\n**Describe the bug**\r\n\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\n\r\n```python\r\ns = pd.Series([\"a\", \"b\", \"a\"], index=[1, 2, 2])\r\ns.groupby(level=0).count()\r\n```\r\n\r\nType checker: pyright (in VS Code)\r\n\r\nThe expected type is `Series[int]`, but instead pyright shows it as `Series[str]`\r\n\r\n**Please complete the following information:**\r\n - OS: Ubuntu\r\n - OS Version: 22.04.4 LTS\r\n - python version: 3.10.12\r\n - version of type checker: pyright 1.1.369\r\n - version of installed `pandas-stubs`: 2.2.2.240603\n", "patch": "diff --git a/pandas-stubs/core/groupby/groupby.pyi b/pandas-stubs/core/groupby/groupby.pyi\nindex cac03085..75be9578 100644\n--- a/pandas-stubs/core/groupby/groupby.pyi\n+++ b/pandas-stubs/core/groupby/groupby.pyi\n@@ -176,7 +176,10 @@ class GroupBy(BaseGroupBy[NDFrameT]):\n     @overload\n     def all(self: GroupBy[DataFrame], skipna: bool = ...) -> DataFrame: ...\n     @final\n-    def count(self) -> NDFrameT: ...\n+    @overload\n+    def count(self: GroupBy[Series]) -> Series[int]: ...\n+    @overload\n+    def count(self: GroupBy[DataFrame]) -> DataFrame: ...\n     @final\n     def mean(\n         self,\ndiff --git a/pyproject.toml b/pyproject.toml\nindex 71c22ca5..c5f8f9eb 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -40,7 +40,7 @@ mypy = \"1.10.1\"\n pandas = \"2.2.2\"\n pyarrow = \">=10.0.1\"\n pytest = \">=7.1.2\"\n-pyright = \">=1.1.369\"\n+pyright = \">= 1.1.374\"\n poethepoet = \">=0.16.5\"\n loguru = \">=0.6.0\"\n typing-extensions = \">=4.4.0\"\n", "instance_id": "pandas-dev__pandas-stubs-966", "clarity": 2, "difficulty": 0.15, "clarity_explanation": "The problem statement is mostly clear in describing the bug: the return type of `GroupBy[Series].count()` is incorrectly inferred by the type checker (pyright) as `Series[str]` instead of the expected `Series[int]`. It provides a reproducible code snippet and relevant environment details (OS, Python version, type checker version, and library version). However, it lacks explicit mention of edge cases or specific constraints that might affect the solution. Additionally, the description under \"Describe the bug\" is placeholder text and not filled out, which slightly reduces clarity. Overall, the goal is understandable, but minor details are missing, warranting a score of 2 (Mostly Clear).", "difficulty_explanation": "The difficulty of this problem is very low, as it involves a straightforward type annotation fix in a type stub file (`pandas-stubs/core/groupby/groupby.pyi`). The code change is minimal, confined to a single file, and involves adding overloads to the `count()` method to specify the correct return type for `Series` as `Series[int]`. It does not require deep understanding of the codebase architecture or complex logic, just familiarity with Python type hints and overloads using the `@overload` decorator from the `typing` module. The change in `pyproject.toml` to update the `pyright` version is trivial and unrelated to the core fix. No significant edge cases or error handling are involved, and there is no impact on the system's runtime behavior since this is purely a type annotation fix for static type checking. Therefore, I assign a difficulty score of 0.15, placing it in the \"Very Easy\" range (0.0-0.2), as it requires only basic modifications to type definitions.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.15}
{"problem_statement": "Wrong typing for the `values` argument of the `pandas.DataFrame.pivot_table` method\n**Describe the bug**\r\nThe `values` argument of the `pandas.DataFrame.pivot_table` method has type of `str | None`:\r\nhttps://github.com/pandas-dev/pandas-stubs/blob/7dd7b6a037819729da84a94bcda4d2f731e43bf6/pandas-stubs/core/frame.pyi#L1126-L1137\r\n\r\nBut the Pandas documentation says that `values` may have not only a string value, but also a list-like value:\r\n[Docs of `pandas.DataFrame.pivot_table`](https://pandas.pydata.org/pandas-docs/version/2.0/reference/api/pandas.DataFrame.pivot_table.html#pandas-dataframe-pivot-table)\r\n\r\n**To Reproduce**\r\n1. A minimal runnable `pandas` example that is not properly checked by the stubs:\r\n```python\r\nfrom pandas import DataFrame\r\n\r\ndata_frame = DataFrame({\r\n    'a': [1, 2],\r\n    'b': [1, 2],\r\n    'c': [1, 2],\r\n    'd': [1, 2],\r\n})\r\ndata_frame.pivot_table(\r\n    values=['a', 'b'],\r\n    index=['c', 'd'],\r\n)\r\n```\r\n\r\n3. I am using `mypy`.\r\n4. The error message received from `mypy`:\r\n```\r\nerror: Argument \"values\" to \"pivot_table\" of \"DataFrame\" has incompatible type \"list[str]\"; expected \"str | None\"  [arg-type]\r\nFound 1 error in 1 file (checked 80 source files)\r\n```\r\n\r\n\r\n**Please complete the following information:**\r\n - OS: Ubuntu\r\n - OS version: 23.10\r\n - `python` version: 3.10.11\r\n - `mypy` version: 1.8.0\r\n - `pandas-stubs` version: 2.2.0.240218\r\n\nWrong typing for the `values` argument of the `pandas.DataFrame.pivot_table` method\n**Describe the bug**\r\nThe `values` argument of the `pandas.DataFrame.pivot_table` method has type of `str | None`:\r\nhttps://github.com/pandas-dev/pandas-stubs/blob/7dd7b6a037819729da84a94bcda4d2f731e43bf6/pandas-stubs/core/frame.pyi#L1126-L1137\r\n\r\nBut the Pandas documentation says that `values` may have not only a string value, but also a list-like value:\r\n[Docs of `pandas.DataFrame.pivot_table`](https://pandas.pydata.org/pandas-docs/version/2.0/reference/api/pandas.DataFrame.pivot_table.html#pandas-dataframe-pivot-table)\r\n\r\n**To Reproduce**\r\n1. A minimal runnable `pandas` example that is not properly checked by the stubs:\r\n```python\r\nfrom pandas import DataFrame\r\n\r\ndata_frame = DataFrame({\r\n    'a': [1, 2],\r\n    'b': [1, 2],\r\n    'c': [1, 2],\r\n    'd': [1, 2],\r\n})\r\ndata_frame.pivot_table(\r\n    values=['a', 'b'],\r\n    index=['c', 'd'],\r\n)\r\n```\r\n\r\n3. I am using `mypy`.\r\n4. The error message received from `mypy`:\r\n```\r\nerror: Argument \"values\" to \"pivot_table\" of \"DataFrame\" has incompatible type \"list[str]\"; expected \"str | None\"  [arg-type]\r\nFound 1 error in 1 file (checked 80 source files)\r\n```\r\n\r\n\r\n**Please complete the following information:**\r\n - OS: Ubuntu\r\n - OS version: 23.10\r\n - `python` version: 3.10.11\r\n - `mypy` version: 1.8.0\r\n - `pandas-stubs` version: 2.2.0.240218\r\n\n", "patch": "diff --git a/pandas-stubs/core/frame.pyi b/pandas-stubs/core/frame.pyi\nindex fe3fef2f..7ce2f5d6 100644\n--- a/pandas-stubs/core/frame.pyi\n+++ b/pandas-stubs/core/frame.pyi\n@@ -1125,7 +1125,7 @@ class DataFrame(NDFrame, OpsMixin):\n     ) -> DataFrame: ...\n     def pivot_table(\n         self,\n-        values: _str | None = ...,\n+        values: _str | None | Sequence[_str] = ...,\n         index: _str | Grouper | Sequence | None = ...,\n         columns: _str | Grouper | Sequence | None = ...,\n         aggfunc=...,\n", "instance_id": "pandas-dev__pandas-stubs-893", "clarity": 3, "difficulty": 0.15, "clarity_explanation": "The problem statement is comprehensive and well-structured. It clearly describes the bug related to the typing of the `values` argument in the `pandas.DataFrame.pivot_table` method. The goal is explicitly stated: the current type annotation in the pandas-stubs repository does not match the actual functionality described in the Pandas documentation, which allows list-like values in addition to strings or None. The input and output expectations are implicitly clear through the provided reproduction code and the error message from `mypy`. The statement includes a minimal reproducible example, links to relevant documentation, and specific version information for the environment, which aids in understanding the context. There are no significant ambiguities, and the problem is supported by concrete evidence (e.g., the `mypy` error and documentation reference). All critical details are provided, making this a very clear and actionable issue report.", "difficulty_explanation": "The difficulty of this problem is very low, falling into the \"very easy\" category. The issue is a straightforward type annotation fix in the pandas-stubs repository, requiring a single-line change in the `frame.pyi` file to update the type of the `values` parameter from `_str | None` to `_str | None | Sequence[_str]`. The scope of the code change is minimal, confined to a single file and a single argument in a method signature, with no impact on the broader codebase or system architecture. The technical concepts involved are basic: understanding Python type hints and the use of the `Sequence` type from the typing module, which are fundamental for anyone familiar with Python type annotations. No complex algorithms, design patterns, or domain-specific knowledge beyond basic Pandas usage are required. There are no edge cases or error handling considerations mentioned or needed for this fix, as it is purely a static typing adjustment for a stub file, not runtime logic. Overall, this is a simple and isolated modification that can be resolved quickly by someone with basic familiarity with Python type annotations and stub files.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 3, "human_difficulty": 0.15}
{"problem_statement": "Unify setting values across transcriptions\n### Proposed feature.\n\nCurrently each of the different transcriptions require distinct methods of setting state values. \r\nFor Gauss-Lobatto and Radau-ps, we use `set_val('phase.states:{}', val)`. \r\nFor explicit shooting, this causes an error since `'states.{}'` does not exist. We must instead do `set_val('phase.initial_states:{}', val)`.\r\nFor Birkhoff, we need to set `'states:{}'`, `'initial_states:{}'`, and `'final_states:{}'`.\r\n\r\nThis makes it cumbersome to move between transcriptions. Additionally, in the birkhoff transcription, if the initial and final state values are not set they default to 1. In that case, if `fix_initial` or `fix_final` is used, the collocation constraint will drive the initial and/or final value to 1, likely leading to invalid trajectories. This can be confusing, so to simplify the process we should have a single method to set the initial guess for the states.\r\n\r\nThe proposed change is to use `phase.set_state_val()` with the signature `set_state_val(self, name, vals=None, time_vals=None, units=None, interpolation_kind='linear')`\r\n\r\nThis method will automatically set the appropriate values required for the transcription.\r\n\r\nTo keep the API consistent, we should also introduce the methods `set_control_val`, `set_polynomial_control_val`, `set_parameter_val`, and `set_time_val` to `Phase`. With the signatures\r\n\r\n`set_time_val(self, initial=None, duration=None, units=None)`\r\n`set_control_val(self, name, vals=None, time_vals=None, units=None, interpolation_kind='linear')`\r\n`set_polynomial_control_val(self, name, vals=None, time_vals=None, units=None, interpolation_kind='linear')`\r\n`set_parameter_val(self, name, val=None, units=None)`\n\n### Example\n\n_No response_\n", "patch": "diff --git a/docs/dymos_book/api/phase_api.ipynb b/docs/dymos_book/api/phase_api.ipynb\nindex 01ca8d272..ab5d38a5d 100644\n--- a/docs/dymos_book/api/phase_api.ipynb\n+++ b/docs/dymos_book/api/phase_api.ipynb\n@@ -170,6 +170,14 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_time_val\\n\",\n+    \"\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Phase.set_time_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n+    \"\\n\",\n     \"## add_state\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Phase.add_state\\n\",\n@@ -182,6 +190,12 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_state_val\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Phase.set_state_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n     \"## add_control\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Phase.add_control\\n\",\n@@ -194,6 +208,12 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_control_val\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Phase.set_control_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n     \"## add_polynomial_control\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Phase.add_polynomial_control\\n\",\n@@ -206,6 +226,12 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_polynomial_control_val\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Phase.set_polynomial_control_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n     \"## add_parameter\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Phase.add_parameter\\n\",\n@@ -218,6 +244,12 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_parameter_val\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Phase.set_parameter_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n     \"## add_timeseries\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Phase.add_timeseries\\n\",\n@@ -266,6 +298,13 @@\n     \"        :noindex:\\n\",\n     \"```\"\n    ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": []\n   }\n  ],\n  \"metadata\": {\n@@ -293,7 +332,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/api/trajectory_api.ipynb b/docs/dymos_book/api/trajectory_api.ipynb\nindex e31190dca..fdaff59b9 100644\n--- a/docs/dymos_book/api/trajectory_api.ipynb\n+++ b/docs/dymos_book/api/trajectory_api.ipynb\n@@ -66,6 +66,12 @@\n     \"        :noindex:\\n\",\n     \"```\\n\",\n     \"\\n\",\n+    \"## set_parameter_val\\n\",\n+    \"```{eval-rst}\\n\",\n+    \"    .. automethod:: dymos.Trajectory.set_parameter_val\\n\",\n+    \"        :noindex:\\n\",\n+    \"```\\n\",\n+    \"\\n\",\n     \"## add_phase\\n\",\n     \"```{eval-rst}\\n\",\n     \"    .. automethod:: dymos.Trajectory.add_phase\\n\",\n@@ -111,7 +117,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/balanced_field/balanced_field.ipynb b/docs/dymos_book/examples/balanced_field/balanced_field.ipynb\nindex 48fd00ad4..8372bd8f9 100644\n--- a/docs/dymos_book/examples/balanced_field/balanced_field.ipynb\n+++ b/docs/dymos_book/examples/balanced_field/balanced_field.ipynb\n@@ -423,19 +423,19 @@\n    ]\n   },\n   {\n-    \"cell_type\": \"code\",\n-    \"execution_count\": null,\n-    \"metadata\": {\n-     \"tags\": [\n-      \"active-ipynb\",\n-      \"remove-input\",\n-      \"remove-output\"\n-     ]\n-    },\n-    \"outputs\": [],\n-    \"source\": [\n-     \"%matplotlib inline\"\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {\n+    \"tags\": [\n+     \"active-ipynb\",\n+     \"remove-input\",\n+     \"remove-output\"\n     ]\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"%matplotlib inline\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -661,7 +661,6 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": null,\n    \"metadata\": {\n-    \"scrolled\": true,\n     \"tags\": [\n      \"output_scroll\"\n     ]\n@@ -670,37 +669,32 @@\n    \"source\": [\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.br_to_v1.t_initial', 0)\\n\",\n-    \"p.set_val('traj.br_to_v1.t_duration', 35)\\n\",\n-    \"p.set_val('traj.br_to_v1.states:r', br_to_v1.interp('r', [0, 2500.0]))\\n\",\n-    \"p.set_val('traj.br_to_v1.states:v', br_to_v1.interp('v', [0, 100.0]))\\n\",\n-    \"p.set_val('traj.br_to_v1.parameters:alpha', 0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.v1_to_vr.t_initial', 35)\\n\",\n-    \"p.set_val('traj.v1_to_vr.t_duration', 35)\\n\",\n-    \"p.set_val('traj.v1_to_vr.states:r', v1_to_vr.interp('r', [2500, 300.0]))\\n\",\n-    \"p.set_val('traj.v1_to_vr.states:v', v1_to_vr.interp('v', [100, 110.0]))\\n\",\n-    \"p.set_val('traj.v1_to_vr.parameters:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.rto.t_initial', 35)\\n\",\n-    \"p.set_val('traj.rto.t_duration', 35)\\n\",\n-    \"p.set_val('traj.rto.states:r', rto.interp('r', [2500, 5000.0]))\\n\",\n-    \"p.set_val('traj.rto.states:v', rto.interp('v', [110, 0]))\\n\",\n-    \"p.set_val('traj.rto.parameters:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.rotate.t_initial', 70)\\n\",\n-    \"p.set_val('traj.rotate.t_duration', 5)\\n\",\n-    \"p.set_val('traj.rotate.states:r', rotate.interp('r', [1750, 1800.0]))\\n\",\n-    \"p.set_val('traj.rotate.states:v', rotate.interp('v', [80, 85.0]))\\n\",\n-    \"p.set_val('traj.rotate.polynomial_controls:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.climb.t_initial', 75)\\n\",\n-    \"p.set_val('traj.climb.t_duration', 15)\\n\",\n-    \"p.set_val('traj.climb.states:r', climb.interp('r', [5000, 5500.0]), units='ft')\\n\",\n-    \"p.set_val('traj.climb.states:v', climb.interp('v', [160, 170.0]), units='kn')\\n\",\n-    \"p.set_val('traj.climb.states:h', climb.interp('h', [0, 35.0]), units='ft')\\n\",\n-    \"p.set_val('traj.climb.states:gam', climb.interp('gam', [0, 5.0]), units='deg')\\n\",\n-    \"p.set_val('traj.climb.controls:alpha', 5.0, units='deg')\\n\",\n+    \"br_to_v1.set_time_val(initial=0.0, duration=35.0)\\n\",\n+    \"br_to_v1.set_state_val('r', [0, 2500.0])\\n\",\n+    \"br_to_v1.set_state_val('v', [0.0001, 100.0])\\n\",\n+    \"br_to_v1.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"v1_to_vr.set_time_val(initial=35.0, duration=35.0)\\n\",\n+    \"v1_to_vr.set_state_val('r', [2500, 300.0])\\n\",\n+    \"v1_to_vr.set_state_val('v', [100, 110.0])\\n\",\n+    \"v1_to_vr.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"rto.set_time_val(initial=35.0, duration=1.0)\\n\",\n+    \"rto.set_state_val('r', [2500, 5000.0])\\n\",\n+    \"rto.set_state_val('v', [110, 0.0001])\\n\",\n+    \"rto.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"rotate.set_time_val(initial=35.0, duration=5.0)\\n\",\n+    \"rotate.set_state_val('r', [1750, 1800.0])\\n\",\n+    \"rotate.set_state_val('v', [80, 85.0])\\n\",\n+    \"rotate.set_polynomial_control_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"climb.set_time_val(initial=30.0, duration=20.0)\\n\",\n+    \"climb.set_state_val('r', [5000, 5500.0], units='ft')\\n\",\n+    \"climb.set_state_val('v', [160, 170.0], units='kn')\\n\",\n+    \"climb.set_state_val('h', [0.0, 35.0], units='ft')\\n\",\n+    \"climb.set_state_val('gam', [0.0, 5.0], units='deg')\\n\",\n+    \"climb.set_control_val('alpha', 5.0, units='deg')\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, run_driver=True, simulate=True)\"\n    ]\n@@ -818,7 +812,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/balanced_field/balanced_field_funccomp.ipynb b/docs/dymos_book/examples/balanced_field/balanced_field_funccomp.ipynb\nindex 3502f21eb..696233bc7 100644\n--- a/docs/dymos_book/examples/balanced_field/balanced_field_funccomp.ipynb\n+++ b/docs/dymos_book/examples/balanced_field/balanced_field_funccomp.ipynb\n@@ -419,37 +419,32 @@\n     \"#\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.br_to_v1.t_initial', 0)\\n\",\n-    \"p.set_val('traj.br_to_v1.t_duration', 35)\\n\",\n-    \"p.set_val('traj.br_to_v1.states:r', br_to_v1.interp('r', [0, 2500.0]))\\n\",\n-    \"p.set_val('traj.br_to_v1.states:v', br_to_v1.interp('v', [0, 100.0]))\\n\",\n-    \"p.set_val('traj.br_to_v1.parameters:alpha', 0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.v1_to_vr.t_initial', 35)\\n\",\n-    \"p.set_val('traj.v1_to_vr.t_duration', 35)\\n\",\n-    \"p.set_val('traj.v1_to_vr.states:r', v1_to_vr.interp('r', [2500, 300.0]))\\n\",\n-    \"p.set_val('traj.v1_to_vr.states:v', v1_to_vr.interp('v', [100, 110.0]))\\n\",\n-    \"p.set_val('traj.v1_to_vr.parameters:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.rto.t_initial', 35)\\n\",\n-    \"p.set_val('traj.rto.t_duration', 35)\\n\",\n-    \"p.set_val('traj.rto.states:r', rto.interp('r', [2500, 5000.0]))\\n\",\n-    \"p.set_val('traj.rto.states:v', rto.interp('v', [110, 0]))\\n\",\n-    \"p.set_val('traj.rto.parameters:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.rotate.t_initial', 70)\\n\",\n-    \"p.set_val('traj.rotate.t_duration', 5)\\n\",\n-    \"p.set_val('traj.rotate.states:r', rotate.interp('r', [1750, 1800.0]))\\n\",\n-    \"p.set_val('traj.rotate.states:v', rotate.interp('v', [80, 85.0]))\\n\",\n-    \"p.set_val('traj.rotate.polynomial_controls:alpha', 0.0, units='deg')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.climb.t_initial', 75)\\n\",\n-    \"p.set_val('traj.climb.t_duration', 15)\\n\",\n-    \"p.set_val('traj.climb.states:r', climb.interp('r', [5000, 5500.0]), units='ft')\\n\",\n-    \"p.set_val('traj.climb.states:v', climb.interp('v', [160, 170.0]), units='kn')\\n\",\n-    \"p.set_val('traj.climb.states:h', climb.interp('h', [0, 35.0]), units='ft')\\n\",\n-    \"p.set_val('traj.climb.states:gam', climb.interp('gam', [0, 5.0]), units='deg')\\n\",\n-    \"p.set_val('traj.climb.controls:alpha', 5.0, units='deg')\\n\",\n+    \"br_to_v1.set_time_val(initial=0.0, duration=35.0)\\n\",\n+    \"br_to_v1.set_state_val('r', [0, 2500.0])\\n\",\n+    \"br_to_v1.set_state_val('v', [0.0001, 100.0])\\n\",\n+    \"br_to_v1.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"v1_to_vr.set_time_val(initial=35.0, duration=35.0)\\n\",\n+    \"v1_to_vr.set_state_val('r', [2500, 300.0])\\n\",\n+    \"v1_to_vr.set_state_val('v', [100, 110.0])\\n\",\n+    \"v1_to_vr.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"rto.set_time_val(initial=35.0, duration=1.0)\\n\",\n+    \"rto.set_state_val('r', [2500, 5000.0])\\n\",\n+    \"rto.set_state_val('v', [110, 0.0001])\\n\",\n+    \"rto.set_parameter_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"rotate.set_time_val(initial=35.0, duration=5.0)\\n\",\n+    \"rotate.set_state_val('r', [1750, 1800.0])\\n\",\n+    \"rotate.set_state_val('v', [80, 85.0])\\n\",\n+    \"rotate.set_polynomial_control_val('alpha', 0.0, units='deg')\\n\",\n+    \"\\n\",\n+    \"climb.set_time_val(initial=30.0, duration=20.0)\\n\",\n+    \"climb.set_state_val('r', [5000, 5500.0], units='ft')\\n\",\n+    \"climb.set_state_val('v', [160, 170.0], units='kn')\\n\",\n+    \"climb.set_state_val('h', [0.0, 35.0], units='ft')\\n\",\n+    \"climb.set_state_val('gam', [0.0, 5.0], units='deg')\\n\",\n+    \"climb.set_control_val('alpha', 5.0, units='deg')\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, run_driver=True, simulate=True)\\n\",\n     \"\\n\",\n@@ -555,7 +550,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/brachistochrone/brachistochrone.ipynb b/docs/dymos_book/examples/brachistochrone/brachistochrone.ipynb\nindex 5a2b9b87f..a26591b11 100644\n--- a/docs/dymos_book/examples/brachistochrone/brachistochrone.ipynb\n+++ b/docs/dymos_book/examples/brachistochrone/brachistochrone.ipynb\n@@ -476,13 +476,11 @@\n     \"#\\n\",\n     \"# Set the initial values\\n\",\n     \"#\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 2.0\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', ys=[0, 10]))\\n\",\n-    \"p.set_val('traj.phase0.states:y', phase.interp('y', ys=[10, 5]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', ys=[0, 9.9]))\\n\",\n-    \"p.set_val('traj.phase0.controls:theta', phase.interp('theta', ys=[5, 100.5]))\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=2.0)\\n\",\n+    \"phase.set_state_val('x', [0, 10])\\n\",\n+    \"phase.set_state_val('y', [10, 5])\\n\",\n+    \"phase.set_state_val('v', [0, 9.9])\\n\",\n+    \"phase.set_control_val('theta', [5, 100.5])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\n@@ -623,15 +621,11 @@\n     \"#\\n\",\n     \"# Set the initial values\\n\",\n     \"#\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 2.0\\n\",\n-    \"\\n\",\n-    \"# Only the initial values of the states are design variables,\\n\",\n-    \"# so the phase interp method is not used on states.\\n\",\n-    \"p.set_val('traj.phase0.initial_states:x', 0.0)\\n\",\n-    \"p.set_val('traj.phase0.initial_states:y', 10.0)\\n\",\n-    \"p.set_val('traj.phase0.initial_states:v', 0.0)\\n\",\n-    \"p.set_val('traj.phase0.controls:theta', phase.interp('theta', ys=[5, 100.5]))\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=2.0)\\n\",\n+    \"phase.set_state_val('x', [0, 10])\\n\",\n+    \"phase.set_state_val('y', [10, 5])\\n\",\n+    \"phase.set_state_val('v', [0, 9.9])\\n\",\n+    \"phase.set_control_val('theta', [5, 100.5])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\ndiff --git a/docs/dymos_book/examples/brachistochrone/brachistochrone_tandem_phases.ipynb b/docs/dymos_book/examples/brachistochrone/brachistochrone_tandem_phases.ipynb\nindex 2699fbb85..0ad7aecde 100644\n--- a/docs/dymos_book/examples/brachistochrone/brachistochrone_tandem_phases.ipynb\n+++ b/docs/dymos_book/examples/brachistochrone/brachistochrone_tandem_phases.ipynb\n@@ -258,13 +258,11 @@\n     \"p.model.linear_solver = om.DirectSolver()\\n\",\n     \"p.setup()\\n\",\n     \"\\n\",\n-    \"p['phase0.t_initial'] = 0.0\\n\",\n-    \"p['phase0.t_duration'] = 2.0\\n\",\n-    \"\\n\",\n-    \"p.set_val('phase0.states:x', phase0.interp('x', ys=[0, 10]))\\n\",\n-    \"p.set_val('phase0.states:y', phase0.interp('y', ys=[10, 5]))\\n\",\n-    \"p.set_val('phase0.states:v', phase0.interp('v', ys=[0, 9.9]))\\n\",\n-    \"p.set_val('phase0.controls:theta', phase0.interp('theta', ys=[5, 100]))\\n\",\n+    \"phase0.set_time_val(initial=0.0, duration=2.0)\\n\",\n+    \"phase0.set_state_val('x', [0, 10])\\n\",\n+    \"phase0.set_state_val('y', [10, 5])\\n\",\n+    \"phase0.set_state_val('v', [0, 9.9])\\n\",\n+    \"phase0.set_control_val('theta', [5, 100.5])\\n\",\n     \"\\n\",\n     \"p['phase0.parameters:g'] = 9.80665\\n\",\n     \"\\n\",\n@@ -372,7 +370,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_controls.ipynb b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_controls.ipynb\nindex e60502dcd..df7c1e2db 100644\n--- a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_controls.ipynb\n+++ b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_controls.ipynb\n@@ -179,13 +179,13 @@\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n     \"# Now that the OpenMDAO problem is setup, we can set the values of the states and controls.\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', [0, 10]), units='m')\\n\",\n+    \"phase.set_state_val('x', [0, 10])\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:y', phase.interp('y', [10, 5]), units='m')\\n\",\n+    \"phase.set_state_val('y', [10, 5])\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', [0, 5]), units='m/s')\\n\",\n+    \"phase.set_state_val('v', [0, 5])\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.controls:theta', phase.interp('theta', [90, 90]), units='deg')\\n\",\n+    \"phase.set_control_val('theta', [90, 90.5], units='deg')\\n\",\n     \"\\n\",\n     \"# Run the driver to solve the problem\\n\",\n     \"p.run_driver()\\n\",\n@@ -259,7 +259,7 @@\n    }\n   },\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3\",\n+   \"display_name\": \"Python 3 (ipykernel)\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -273,7 +273,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.8.3\"\n+   \"version\": \"3.11.0\"\n   },\n   \"orphan\": true\n  },\ndiff --git a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_init_duration_states.ipynb b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_init_duration_states.ipynb\nindex 161060fbf..62fc96589 100644\n--- a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_init_duration_states.ipynb\n+++ b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_init_duration_states.ipynb\n@@ -164,18 +164,17 @@\n     \"# p.set_val('x0', 0.0, units='m')\\n\",\n     \"# Here we're intentially setting the intiial x value to something other than zero, just\\n\",\n     \"# to demonstrate that the optimizer brings it back in line with the value of x0 set above.\\n\",\n-    \"p.set_val('traj.phase0.states:x',\\n\",\n-    \"          phase.interp('x', [0, 10]),\\n\",\n-    \"          units='m')\\n\",\n-    \"p.set_val('traj.phase0.states:y',\\n\",\n-    \"          phase.interp('y', [10, 5]),\\n\",\n-    \"          units='m')\\n\",\n-    \"p.set_val('traj.phase0.states:v',\\n\",\n-    \"          phase.interp('v', [0, 5]),\\n\",\n-    \"          units='m/s')\\n\",\n-    \"p.set_val('traj.phase0.controls:theta',\\n\",\n-    \"          phase.interp('theta', [90, 90]),\\n\",\n-    \"          units='deg')\\n\",\n+    \"phase.set_state_val('x', [0, 10],\\n\",\n+    \"                    units='m')\\n\",\n+    \"\\n\",\n+    \"phase.set_state_val('y', [10, 5],\\n\",\n+    \"                    units='m')\\n\",\n+    \"\\n\",\n+    \"phase.set_state_val('v', [0, 9.9],\\n\",\n+    \"                    units='m/s')\\n\",\n+    \"\\n\",\n+    \"phase.set_control_val('theta', [5, 100.5],\\n\",\n+    \"                      units='deg')\\n\",\n     \"\\n\",\n     \"# Run the driver to solve the problem\\n\",\n     \"dm.run_problem(p, simulate=True)\\n\"\n@@ -260,7 +259,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_states.ipynb b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_states.ipynb\nindex 9a8d1948a..576a86dbe 100644\n--- a/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_states.ipynb\n+++ b/docs/dymos_book/examples/brachistochrone/brachistochrone_upstream_states.ipynb\n@@ -190,21 +190,18 @@\n     \"\\n\",\n     \"# Here we're intentially setting the intiial x value to something other than zero, just\\n\",\n     \"# to demonstrate that the optimizer brings it back in line with the value of x0 set above.\\n\",\n-    \"p.set_val('traj.phase0.states:x',\\n\",\n-    \"          phase.interp('x', [1, 10]),\\n\",\n-    \"          units='m')\\n\",\n+    \"phase.set_state_val('x', [1, 10],\\n\",\n+    \"                   units='m')\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:y',\\n\",\n-    \"          phase.interp('y', [10, 5]),\\n\",\n-    \"          units='m')\\n\",\n+    \"phase.set_state_val('y', [10, 5],\\n\",\n+    \"                   units='m')\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:v',\\n\",\n-    \"          phase.interp('v', [0, 5]),\\n\",\n-    \"          units='m/s')\\n\",\n+    \"phase.set_state_val('v', [0, 5],\\n\",\n+    \"                   units='m/s')\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.controls:theta',\\n\",\n-    \"          phase.interp('theta', [90, 90]),\\n\",\n-    \"          units='deg')\\n\",\n+    \"phase.set_control_val('theta',\\n\",\n+    \"                      [90, 90],\\n\",\n+    \"                     units='deg')\\n\",\n     \"\\n\",\n     \"# Run the driver to solve the problem\\n\",\n     \"dm.run_problem(p, make_plots=True)\\n\",\n@@ -275,7 +272,7 @@\n    }\n   },\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3\",\n+   \"display_name\": \"Python 3 (ipykernel)\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -289,7 +286,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.8.3\"\n+   \"version\": \"3.11.0\"\n   },\n   \"orphan\": true\n  },\ndiff --git a/docs/dymos_book/examples/bryson_denham/bryson_denham.ipynb b/docs/dymos_book/examples/bryson_denham/bryson_denham.ipynb\nindex 3f0a159de..02fe19939 100644\n--- a/docs/dymos_book/examples/bryson_denham/bryson_denham.ipynb\n+++ b/docs/dymos_book/examples/bryson_denham/bryson_denham.ipynb\n@@ -220,19 +220,20 @@\n    ]\n   },\n   {\n-    \"cell_type\": \"code\",\n-    \"execution_count\": null,\n-    \"metadata\": {\n-     \"tags\": [\n-      \"active-ipynb\",\n-      \"remove-input\",\n-      \"remove-output\"\n-     ]\n-    },\n-    \"outputs\": [],\n-    \"source\": [\n-     \"%matplotlib inline\"\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"0f14deb3\",\n+   \"metadata\": {\n+    \"tags\": [\n+     \"active-ipynb\",\n+     \"remove-input\",\n+     \"remove-output\"\n     ]\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"%matplotlib inline\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -423,13 +424,13 @@\n     \"#\\n\",\n     \"# Set the initial values\\n\",\n     \"#\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 1.0\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', ys=[0, 0]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', ys=[1, -1]))\\n\",\n-    \"p.set_val('traj.phase0.states:J', phase.interp('J', ys=[0, 1]))\\n\",\n-    \"p.set_val('traj.phase0.controls:u', np.sin(phase.interp('u', ys=[0, 0])))\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=1.0)\\n\",\n+    \"\\n\",\n+    \"phase.set_state_val('x', [0, 0])\\n\",\n+    \"phase.set_state_val('v', [1, -1])\\n\",\n+    \"phase.set_state_val('J', [0, 1])\\n\",\n+    \"phase.set_control_val('u', [0, 0])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\n@@ -718,7 +719,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/cannonball_implicit_duration/cannonball_implicit_duration.ipynb b/docs/dymos_book/examples/cannonball_implicit_duration/cannonball_implicit_duration.ipynb\nindex 16a8f5dc0..58683c036 100644\n--- a/docs/dymos_book/examples/cannonball_implicit_duration/cannonball_implicit_duration.ipynb\n+++ b/docs/dymos_book/examples/cannonball_implicit_duration/cannonball_implicit_duration.ipynb\n@@ -370,13 +370,12 @@\n     \"\\n\",\n     \"guess = initial_guess(t_dur=30.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase.t_initial', 0.0)\\n\",\n-    \"p.set_val('traj.phase.t_duration', 30.0)\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=30.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase.states:r', phase.interp('r', ys=guess['r'], xs=guess['t']))\\n\",\n-    \"p.set_val('traj.phase.states:h', phase.interp('h', ys=guess['h'], xs=guess['t']))\\n\",\n-    \"p.set_val('traj.phase.states:v', phase.interp('v', ys=guess['v'], xs=guess['t']))\\n\",\n-    \"p.set_val('traj.phase.states:gam', phase.interp('gam', ys=guess['gam'], xs=guess['t']), units='rad')\\n\",\n+    \"phase.set_state_val('r', vals=guess['r'], time_vals=guess['t'])\\n\",\n+    \"phase.set_state_val('h', vals=guess['h'], time_vals=guess['t'])\\n\",\n+    \"phase.set_state_val('v', vals=guess['v'], time_vals=guess['t'])\\n\",\n+    \"phase.set_state_val('gam', vals=guess['gam'], time_vals=guess['t'], units='rad')\\n\",\n     \"\\n\",\n     \"#####################################################\\n\",\n     \"# Run the optimization and final explicit simulation\\n\",\n@@ -448,7 +447,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/cart_pole/cart_pole.ipynb b/docs/dymos_book/examples/cart_pole/cart_pole.ipynb\nindex 17d91e0f3..0862cbfb0 100644\n--- a/docs/dymos_book/examples/cart_pole/cart_pole.ipynb\n+++ b/docs/dymos_book/examples/cart_pole/cart_pole.ipynb\n@@ -296,14 +296,14 @@\n    \"source\": [\n     \"# --- set initial guess ---\\n\",\n     \"# The initial condition of cart-pole (i.e., state values at time 0) is set here because we set `fix_initial=True` when declaring the states.\\n\",\n-    \"p.set_val('traj.phase.t_initial', 0.0)  # set initial time to 0.\\n\",\n-    \"p.set_val(\\\"traj.phase.states:x\\\", phase.interp(xs=[0, 1, 2], ys=[0, 1, 1], nodes=\\\"state_input\\\"), units=\\\"m\\\")\\n\",\n-    \"p.set_val(\\\"traj.phase.states:x_dot\\\", phase.interp(xs=[0, 1, 2], ys=[0, 0.1, 0], nodes=\\\"state_input\\\"), units=\\\"m/s\\\")\\n\",\n-    \"p.set_val(\\\"traj.phase.states:theta\\\", phase.interp(xs=[0, 1, 2], ys=[0, np.pi/2, np.pi], nodes=\\\"state_input\\\"), units=\\\"rad\\\")\\n\",\n-    \"p.set_val(\\\"traj.phase.states:theta_dot\\\", phase.interp(xs=[0, 1, 2], ys=[0, 1, 0], nodes=\\\"state_input\\\"), units=\\\"rad/s\\\")\\n\",\n-    \"p.set_val(\\\"traj.phase.states:energy\\\", phase.interp(xs=[0, 1, 2], ys=[0, 30, 60], nodes=\\\"state_input\\\"))\\n\",\n-    \"p.set_val(\\\"traj.phase.controls:f\\\", phase.interp(xs=[0, 1, 2], ys=[3, -1, 0], nodes=\\\"control_input\\\"), units=\\\"N\\\")\\n\",\n-    \"    \\n\",\n+    \"phase.set_time_val(initial=0.0)  # set initial time to 0.\\n\",\n+    \"phase.set_state_val('x', vals=[0, 1, 1], time_vals=[0, 1, 2], units='m')\\n\",\n+    \"phase.set_state_val('x_dot', vals=[0, 0.1, 0], time_vals=[0, 1, 2], units='m/s')\\n\",\n+    \"phase.set_state_val('theta', vals=[0, np.pi/2, np.pi], time_vals=[0, 1, 2], units='rad')\\n\",\n+    \"phase.set_state_val('theta_dot', vals=[0, 1, 0], time_vals=[0, 1, 2], units='rad/s')\\n\",\n+    \"phase.set_state_val('energy', vals=[0, 30, 60], time_vals=[0, 1, 2])\\n\",\n+    \"phase.set_control_val('f', vals=[3, -1, 0], time_vals=[0, 1, 2], units='N')\\n\",\n+    \"\\n\",\n     \"# --- run optimization ---\\n\",\n     \"dm.run_problem(p, run_driver=True, simulate=True, simulate_kwargs={'method' : 'Radau', 'times_per_seg' : 10})\\n\",\n     \"# NOTE: with Simulate=True, dymos will call scipy.integrate.solve_ivp and simulate the trajectory using the optimized control inputs.\"\n@@ -396,7 +396,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.5\"\n+   \"version\": \"3.11.0\"\n   },\n   \"vscode\": {\n    \"interpreter\": {\ndiff --git a/docs/dymos_book/examples/commercial_aircraft/commercial_aircraft.ipynb b/docs/dymos_book/examples/commercial_aircraft/commercial_aircraft.ipynb\nindex 650a0f3ac..0b39db6b1 100644\n--- a/docs/dymos_book/examples/commercial_aircraft/commercial_aircraft.ipynb\n+++ b/docs/dymos_book/examples/commercial_aircraft/commercial_aircraft.ipynb\n@@ -636,13 +636,11 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 3600.0\\n\",\n-    \"p['traj.phase0.states:range'] = phase.interp('range', ys=(0, 724.0))\\n\",\n-    \"p['traj.phase0.states:mass_fuel'] = phase.interp('mass_fuel', ys=(30000, 1e-3))\\n\",\n-    \"p['traj.phase0.states:alt'][:] = 10.0\\n\",\n-    \"\\n\",\n-    \"p['traj.phase0.controls:mach'][:] = 0.8\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=3600)\\n\",\n+    \"phase.set_state_val('range', (0, 724.0))\\n\",\n+    \"phase.set_state_val('mass_fuel', (30000, 1e-3))\\n\",\n+    \"phase.set_state_val('alt', 10.0)\\n\",\n+    \"phase.set_control_val('mach', 0.8)\\n\",\n     \"\\n\",\n     \"p['assumptions.S'] = 427.8\\n\",\n     \"p['assumptions.mass_empty'] = 0.15E6\\n\",\n@@ -736,7 +734,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/double_integrator/double_integrator.ipynb b/docs/dymos_book/examples/double_integrator/double_integrator.ipynb\nindex 41b70e78a..dcae666f2 100644\n--- a/docs/dymos_book/examples/double_integrator/double_integrator.ipynb\n+++ b/docs/dymos_book/examples/double_integrator/double_integrator.ipynb\n@@ -204,12 +204,11 @@\n     \"#\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 1.0\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=1.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', ys=[0, 0.25]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', ys=[0, 0]))\\n\",\n-    \"p.set_val('traj.phase0.controls:u', phase.interp('u', ys=[1, -1]))\\n\",\n+    \"phase.set_state_val('x', [0, 0.25])\\n\",\n+    \"phase.set_state_val('v', [0, 0])\\n\",\n+    \"phase.set_control_val('u', [1, -1])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve the problem.\\n\",\n@@ -287,7 +286,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/finite_burn_orbit_raise/finite_burn_orbit_raise.ipynb b/docs/dymos_book/examples/finite_burn_orbit_raise/finite_burn_orbit_raise.ipynb\nindex debe4a1c1..4f52d3eeb 100644\n--- a/docs/dymos_book/examples/finite_burn_orbit_raise/finite_burn_orbit_raise.ipynb\n+++ b/docs/dymos_book/examples/finite_burn_orbit_raise/finite_burn_orbit_raise.ipynb\n@@ -260,36 +260,30 @@\n     \"burn2 = p.model.traj.phases.burn2\\n\",\n     \"coast = p.model.traj.phases.coast\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.burn1.t_initial', val=0.0)\\n\",\n-    \"p.set_val('traj.burn1.t_duration', val=2.25)\\n\",\n-    \"p.set_val('traj.burn1.states:r', val=burn1.interp('r', [1, 1.5]))\\n\",\n-    \"p.set_val('traj.burn1.states:theta', val=burn1.interp('theta', [0, 1.7]))\\n\",\n-    \"p.set_val('traj.burn1.states:vr', val=burn1.interp('vr', [0, 0]))\\n\",\n-    \"p.set_val('traj.burn1.states:vt', val=burn1.interp('vt', [1, 1]))\\n\",\n-    \"p.set_val('traj.burn1.states:accel', val=burn1.interp('accel', [0.1, 0]))\\n\",\n-    \"p.set_val('traj.burn1.states:deltav', val=burn1.interp('deltav', [0, 0.1]))\\n\",\n-    \"p.set_val('traj.burn1.controls:u1', val=burn1.interp('u1', [-3.5, 13.0]))\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.coast.t_initial', val=2.25)\\n\",\n-    \"p.set_val('traj.coast.t_duration', val=3.0)\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.coast.states:r', val=coast.interp('r', [1.3, 1.5]))\\n\",\n-    \"p.set_val('traj.coast.states:theta', val=coast.interp('theta', [2.1767, 1.7]))\\n\",\n-    \"p.set_val('traj.coast.states:vr', val=coast.interp('vr', [0.3285, 0]))\\n\",\n-    \"p.set_val('traj.coast.states:vt', val=coast.interp('vt', [0.97, 1]))\\n\",\n-    \"p.set_val('traj.coast.states:accel', val=coast.interp('accel', [0, 0]))\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.burn2.t_initial', val=5.25)\\n\",\n-    \"p.set_val('traj.burn2.t_duration', val=1.75)\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.burn2.states:r', val=burn2.interp('r', [1, 3.]))\\n\",\n-    \"p.set_val('traj.burn2.states:theta', val=burn2.interp('theta', [0, 4.0]))\\n\",\n-    \"p.set_val('traj.burn2.states:vr', val=burn2.interp('vr', [0, 0]))\\n\",\n-    \"p.set_val('traj.burn2.states:vt', val=burn2.interp('vt', [1, np.sqrt(1 / 3.)]))\\n\",\n-    \"p.set_val('traj.burn2.states:deltav', val=burn2.interp('deltav', [0.1, 0.2]))\\n\",\n-    \"p.set_val('traj.burn2.states:accel', val=burn2.interp('accel', [0.1, 0]))\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.burn2.controls:u1', val=burn2.interp('u1', [0, 0]))\\n\",\n+    \"burn1.set_time_val(initial=0.0, duration=2.25)\\n\",\n+    \"burn1.set_state_val('r', [1, 1.5])\\n\",\n+    \"burn1.set_state_val('theta', [0, 1.7])\\n\",\n+    \"burn1.set_state_val('vr', [0, 0])\\n\",\n+    \"burn1.set_state_val('vt', [1, 1])\\n\",\n+    \"burn1.set_state_val('accel', [0.1, 0.0])\\n\",\n+    \"burn1.set_state_val('deltav', [0, 0.1])\\n\",\n+    \"burn1.set_control_val('u1', [-3.5, 13.0])\\n\",\n+    \"\\n\",\n+    \"coast.set_time_val(initial=2.25, duration=3.0)\\n\",\n+    \"coast.set_state_val('r', [1.3, 1.5])\\n\",\n+    \"coast.set_state_val('theta', [2.1767, 1.7])\\n\",\n+    \"coast.set_state_val('vr', [0.3285, 0])\\n\",\n+    \"coast.set_state_val('vt', [0.97, 1])\\n\",\n+    \"coast.set_state_val('accel', [0, 0])\\n\",\n+    \"\\n\",\n+    \"burn2.set_time_val(initial=5.25, duration=1.75)\\n\",\n+    \"burn2.set_state_val('r', [1, 3])\\n\",\n+    \"burn2.set_state_val('theta', [0, 4])\\n\",\n+    \"burn2.set_state_val('vr', [0, 0])\\n\",\n+    \"burn2.set_state_val('vt', [1, np.sqrt(1 / 3)])\\n\",\n+    \"burn2.set_state_val('accel', [0.1, 0.0])\\n\",\n+    \"burn2.set_state_val('deltav', [0.1, 0.2])\\n\",\n+    \"burn2.set_control_val('u1', [0, 0])\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, simulate=True)\"\n    ]\n@@ -436,7 +430,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/hull/hull_problem.ipynb b/docs/dymos_book/examples/hull/hull_problem.ipynb\nindex ea84eff39..9dec62449 100644\n--- a/docs/dymos_book/examples/hull/hull_problem.ipynb\n+++ b/docs/dymos_book/examples/hull/hull_problem.ipynb\n@@ -213,19 +213,20 @@\n    ]\n   },\n   {\n-    \"cell_type\": \"code\",\n-    \"execution_count\": null,\n-    \"metadata\": {\n-     \"tags\": [\n-      \"active-ipynb\",\n-      \"remove-input\",\n-      \"remove-output\"\n-     ]\n-    },\n-    \"outputs\": [],\n-    \"source\": [\n-     \"%matplotlib inline\"\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"fc8f4299\",\n+   \"metadata\": {\n+    \"tags\": [\n+     \"active-ipynb\",\n+     \"remove-input\",\n+     \"remove-output\"\n     ]\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"%matplotlib inline\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -411,11 +412,11 @@\n     \"#\\n\",\n     \"# Set the initial values\\n\",\n     \"#\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', [1.5, 1]))\\n\",\n-    \"p.set_val('traj.phase0.states:xL', phase.interp('xL', [0, 1]))\\n\",\n-    \"p.set_val('traj.phase0.t_initial', 0)\\n\",\n-    \"p.set_val('traj.phase0.t_duration', 10)\\n\",\n-    \"p.set_val('traj.phase0.controls:u', phase.interp('u', [-7, -0.14]))\\n\",\n+    \"phase.set_state_val('x', [1.5, 1])\\n\",\n+    \"phase.set_state_val('xL', [0, 1])\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=10.0)\\n\",\n+    \"phase.set_control_val('u', [-7, -0.14])\\n\",\n+    \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\n     \"#\\n\",\ndiff --git a/docs/dymos_book/examples/hypersensitive/hypersensitive.ipynb b/docs/dymos_book/examples/hypersensitive/hypersensitive.ipynb\nindex 91d3e8870..8029582d5 100644\n--- a/docs/dymos_book/examples/hypersensitive/hypersensitive.ipynb\n+++ b/docs/dymos_book/examples/hypersensitive/hypersensitive.ipynb\n@@ -246,11 +246,10 @@\n     \"\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', [1.5, 1]))\\n\",\n-    \"p.set_val('traj.phase0.states:xL', phase.interp('xL', [0, 1]))\\n\",\n-    \"p.set_val('traj.phase0.t_initial', 0)\\n\",\n-    \"p.set_val('traj.phase0.t_duration', tf)\\n\",\n-    \"p.set_val('traj.phase0.controls:u', phase.interp('u', [-0.6, 2.4]))\\n\",\n+    \"phase.set_time_val(initial=0, duration=tf)\\n\",\n+    \"phase.set_state_val('x', [1.5, 1])\\n\",\n+    \"phase.set_state_val('xL', [0, 1])\\n\",\n+    \"phase.set_control_val('u', [-0.6, 2.4])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve the problem.\\n\",\ndiff --git a/docs/dymos_book/examples/length_constrained_brachistochrone/length_constrained_brachistochrone.ipynb b/docs/dymos_book/examples/length_constrained_brachistochrone/length_constrained_brachistochrone.ipynb\nindex d767f963e..05a05236c 100644\n--- a/docs/dymos_book/examples/length_constrained_brachistochrone/length_constrained_brachistochrone.ipynb\n+++ b/docs/dymos_book/examples/length_constrained_brachistochrone/length_constrained_brachistochrone.ipynb\n@@ -219,14 +219,12 @@\n     \"\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.t_initial', 0.0)\\n\",\n-    \"p.set_val('traj.phase0.t_duration', 2.0)\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', [0, 10]))\\n\",\n-    \"p.set_val('traj.phase0.states:y', phase.interp('y', [10, 5]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', [0, 9.9]))\\n\",\n-    \"p.set_val('traj.phase0.controls:theta', phase.interp('theta', [5, 100]))\\n\",\n-    \"p.set_val('traj.phase0.parameters:g', 9.80665)\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=2.0)\\n\",\n+    \"phase.set_state_val('x', [0, 10])\\n\",\n+    \"phase.set_state_val('y', [10, 5])\\n\",\n+    \"phase.set_state_val('v', [0, 9.9])\\n\",\n+    \"phase.set_control_val('theta', [5, 100])\\n\",\n+    \"phase.set_parameter_val('g', 9.80665)\\n\",\n     \"\\n\",\n     \"p.run_driver()\\n\",\n     \"\\n\",\n@@ -274,7 +272,7 @@\n    }\n   },\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3\",\n+   \"display_name\": \"Python 3 (ipykernel)\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -288,7 +286,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.8.3\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/min_time_climb/min_time_climb.ipynb b/docs/dymos_book/examples/min_time_climb/min_time_climb.ipynb\nindex 24e23ad18..5a68d9abf 100644\n--- a/docs/dymos_book/examples/min_time_climb/min_time_climb.ipynb\n+++ b/docs/dymos_book/examples/min_time_climb/min_time_climb.ipynb\n@@ -274,15 +274,13 @@\n     \"#\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 500\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.phase0.states:r', phase.interp('r', [0.0, 50000.0]))\\n\",\n-    \"p.set_val('traj.phase0.states:h', phase.interp('h', [100.0, 20000.0]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', [135.964, 283.159]))\\n\",\n-    \"p.set_val('traj.phase0.states:gam', phase.interp('gam', [0.0, 0.0]))\\n\",\n-    \"p.set_val('traj.phase0.states:m', phase.interp('m', [19030.468, 10000.]))\\n\",\n-    \"p.set_val('traj.phase0.controls:alpha', phase.interp('alpha', [0.0, 0.0]))\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=350)\\n\",\n+    \"phase.set_state_val('r', [0.0, 50000.0])\\n\",\n+    \"phase.set_state_val('h', [100.0, 20000.0])\\n\",\n+    \"phase.set_state_val('v', [135.964, 283.159])\\n\",\n+    \"phase.set_state_val('gam', [0.0, 0.0])\\n\",\n+    \"phase.set_state_val('m', [19030.468, 10000.])\\n\",\n+    \"phase.set_control_val('alpha', [0.0, 0.0])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\n@@ -363,7 +361,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/mountain_car/mountain_car.ipynb b/docs/dymos_book/examples/mountain_car/mountain_car.ipynb\nindex 21801be1e..1c35916c5 100644\n--- a/docs/dymos_book/examples/mountain_car/mountain_car.ipynb\n+++ b/docs/dymos_book/examples/mountain_car/mountain_car.ipynb\n@@ -478,12 +478,11 @@\n     \"#\\n\",\n     \"# Set the initial values\\n\",\n     \"#\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 500.0\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=500.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', ys=[-0.5, 0.5]))\\n\",\n-    \"p.set_val('traj.phase0.states:v', phase.interp('v', ys=[0, 0.07]))\\n\",\n-    \"p.set_val('traj.phase0.controls:u', np.sin(phase.interp('u', ys=[0, 1.0])))\\n\",\n+    \"phase.set_state_val('x', [-0.5, 0.5])\\n\",\n+    \"phase.set_state_val('v', [0, 0.07])\\n\",\n+    \"phase.set_control_val('u', [0, np.sin(1.0)])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve for the optimal trajectory\\n\",\n@@ -722,7 +721,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/multi_phase_cannonball/multi_phase_cannonball.ipynb b/docs/dymos_book/examples/multi_phase_cannonball/multi_phase_cannonball.ipynb\nindex f37970bce..ec7d16c28 100644\n--- a/docs/dymos_book/examples/multi_phase_cannonball/multi_phase_cannonball.ipynb\n+++ b/docs/dymos_book/examples/multi_phase_cannonball/multi_phase_cannonball.ipynb\n@@ -412,23 +412,22 @@\n     \"p.set_val('radius', 0.05, units='m')\\n\",\n     \"p.set_val('dens', 7.87, units='g/cm**3')\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.parameters:CD', 0.5)\\n\",\n+    \"traj.set_parameter_val('CD', 0.5)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.ascent.t_initial', 0.0)\\n\",\n-    \"p.set_val('traj.ascent.t_duration', 10.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.ascent.states:r', ascent.interp('r', [0, 100]))\\n\",\n-    \"p.set_val('traj.ascent.states:h', ascent.interp('h', [0, 100]))\\n\",\n-    \"p.set_val('traj.ascent.states:v', ascent.interp('v', [200, 150]))\\n\",\n-    \"p.set_val('traj.ascent.states:gam', ascent.interp('gam', [25, 0]), units='deg')\\n\",\n+    \"ascent.set_time_val(initial=0.0, duration=10.0)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.descent.t_initial', 10.0)\\n\",\n-    \"p.set_val('traj.descent.t_duration', 10.0)\\n\",\n+    \"ascent.set_state_val('r', [0, 100])\\n\",\n+    \"ascent.set_state_val('h', [0, 100])\\n\",\n+    \"ascent.set_state_val('v', [200, 150])\\n\",\n+    \"ascent.set_state_val('gam', [25, 0], units='deg')\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.descent.states:r', descent.interp('r', [100, 200]))\\n\",\n-    \"p.set_val('traj.descent.states:h', descent.interp('h', [100, 0]))\\n\",\n-    \"p.set_val('traj.descent.states:v', descent.interp('v', [150, 200]))\\n\",\n-    \"p.set_val('traj.descent.states:gam', descent.interp('gam', [0, -45]), units='deg')\\n\",\n+    \"descent.set_time_val(initial=10.0, duration=10.0)\\n\",\n+    \"\\n\",\n+    \"descent.set_state_val('r', [100, 200])\\n\",\n+    \"descent.set_state_val('h', [100, 0])\\n\",\n+    \"descent.set_state_val('v', [150, 200])\\n\",\n+    \"descent.set_state_val('gam', [0, -45], units='deg')\\n\",\n     \"\\n\",\n     \"#####################################################\\n\",\n     \"# Run the optimization and final explicit simulation\\n\",\n@@ -561,7 +560,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.4\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/multibranch_trajectory/multibranch_trajectory.ipynb b/docs/dymos_book/examples/multibranch_trajectory/multibranch_trajectory.ipynb\nindex b99fa0fe6..659c44719 100644\n--- a/docs/dymos_book/examples/multibranch_trajectory/multibranch_trajectory.ipynb\n+++ b/docs/dymos_book/examples/multibranch_trajectory/multibranch_trajectory.ipynb\n@@ -431,17 +431,10 @@\n     \"\\n\",\n     \"prob.setup()\\n\",\n     \"\\n\",\n-    \"prob['traj.phase0.t_initial'] = 0\\n\",\n-    \"prob['traj.phase0.t_duration'] = 1.0*3600\\n\",\n-    \"\\n\",\n-    \"prob['traj.phase1.t_initial'] = 1.0*3600\\n\",\n-    \"prob['traj.phase1.t_duration'] = 1.0*3600\\n\",\n-    \"\\n\",\n-    \"prob['traj.phase1_bfail.t_initial'] = 1.0*3600\\n\",\n-    \"prob['traj.phase1_bfail.t_duration'] = 1.0*3600\\n\",\n-    \"\\n\",\n-    \"prob['traj.phase1_mfail.t_initial'] = 1.0*3600\\n\",\n-    \"prob['traj.phase1_mfail.t_duration'] = 1.0*3600\\n\",\n+    \"phase0.set_time_val(initial=0.0, duration=3600)\\n\",\n+    \"phase1.set_time_val(initial=3600.0, duration=3600.0)\\n\",\n+    \"phase1_bfail.set_time_val(initial=3600.0, duration=3600.0)\\n\",\n+    \"phase1_mfail.set_time_val(initial=3600.0, duration=3600.0)\\n\",\n     \"\\n\",\n     \"prob.set_solver_print(level=0)\\n\",\n     \"dm.run_problem(prob)\\n\",\n@@ -544,7 +537,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.6\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/racecar/racecar.ipynb b/docs/dymos_book/examples/racecar/racecar.ipynb\nindex e7d0a31df..b0fa201ca 100644\n--- a/docs/dymos_book/examples/racecar/racecar.ipynb\n+++ b/docs/dymos_book/examples/racecar/racecar.ipynb\n@@ -379,21 +379,21 @@\n     \"\\n\",\n     \"# States\\n\",\n     \"# Nonzero velocity to avoid division by zero errors\\n\",\n-    \"p.set_val('traj.phase0.states:V', phase.interp('V', [20, 20]), units='m/s')\\n\",\n+    \"phase.set_state_val('V', 20.0, units='m/s')\\n\",\n     \"# All other states start at 0\\n\",\n-    \"p.set_val('traj.phase0.states:lambda', phase.interp('lambda', [0.0, 0.0]), units='rad')\\n\",\n-    \"p.set_val('traj.phase0.states:omega', phase.interp('omega', [0.0, 0.0]), units='rad/s')\\n\",\n-    \"p.set_val('traj.phase0.states:alpha', phase.interp('alpha', [0.0, 0.0]), units='rad')\\n\",\n-    \"p.set_val('traj.phase0.states:ax', phase.interp('ax', [0.0, 0.0]), units='m/s**2')\\n\",\n-    \"p.set_val('traj.phase0.states:ay', phase.interp('ay', [0.0, 0.0]), units='m/s**2')\\n\",\n-    \"p.set_val('traj.phase0.states:n', phase.interp('n', [0.0, 0.0]), units='m')\\n\",\n+    \"phase.set_state_val('lambda', 0.0, units='rad')\\n\",\n+    \"phase.set_state_val('omega', 0.0, units='rad/s')\\n\",\n+    \"phase.set_state_val('alpha', 0.0, units='rad')\\n\",\n+    \"phase.set_state_val('ax', 0.0, units='m/s**2')\\n\",\n+    \"phase.set_state_val('ay', 0.0, units='m/s**2')\\n\",\n+    \"phase.set_state_val('n', 0.0, units='m')\\n\",\n     \"# initial guess for what the final time should be\\n\",\n-    \"p.set_val('traj.phase0.states:t', phase.interp('t', [0.0, 100.0]), units='s')\\n\",\n+    \"phase.set_state_val('t', [0.0, 100.0], units='s')\\n\",\n     \"\\n\",\n     \"# Controls\\n\",\n     \"# a small amount of thrust can speed up convergence\\n\",\n-    \"p.set_val('traj.phase0.controls:delta', phase.interp('delta', [0.0, 0.0]), units='rad')\\n\",\n-    \"p.set_val('traj.phase0.controls:thrust', phase.interp('thrust', [0.1, 0.1]), units=None)\\n\",\n+    \"phase.set_control_val('delta', 0.0, units='rad')\\n\",\n+    \"phase.set_control_val('thrust', 0.1, units=None)\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, run_driver=True)\\n\",\n     \"print('Optimization finished')\\n\",\n@@ -629,7 +629,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.6\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/reentry/reentry.ipynb b/docs/dymos_book/examples/reentry/reentry.ipynb\nindex 4ff901bf8..574e54d92 100644\n--- a/docs/dymos_book/examples/reentry/reentry.ipynb\n+++ b/docs/dymos_book/examples/reentry/reentry.ipynb\n@@ -667,26 +667,17 @@\n     \"\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.t_initial', 0, units='s')\\n\",\n-    \"p.set_val('traj.phase0.t_duration', 2000, units='s')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.phase0.states:h',\\n\",\n-    \"          phase0.interp('h', [260000, 80000]), units='ft')\\n\",\n-    \"p.set_val('traj.phase0.states:gamma',\\n\",\n-    \"          phase0.interp('gamma', [-1, -5]), units='deg')\\n\",\n-    \"p.set_val('traj.phase0.states:phi',\\n\",\n-    \"          phase0.interp('phi', [0, 75]), units='deg')\\n\",\n-    \"p.set_val('traj.phase0.states:psi',\\n\",\n-    \"          phase0.interp('psi', [90, 10]), units='deg')\\n\",\n-    \"p.set_val('traj.phase0.states:theta',\\n\",\n-    \"          phase0.interp('theta', [0, 25]), units='deg')\\n\",\n-    \"p.set_val('traj.phase0.states:v',\\n\",\n-    \"          phase0.interp('v', [25600, 2500]), units='ft/s')\\n\",\n-    \"\\n\",\n-    \"p.set_val('traj.phase0.controls:alpha',\\n\",\n-    \"          phase0.interp('alpha', ys=[17.4, 17.4]), units='deg')\\n\",\n-    \"p.set_val('traj.phase0.controls:beta',\\n\",\n-    \"          phase0.interp('beta', ys=[-75, 0]), units='deg')\\n\",\n+    \"phase0.set_time_val(initial=0, duration=2000, units='s')\\n\",\n+    \"\\n\",\n+    \"phase0.set_state_val('h', [260000, 80000], units='ft')\\n\",\n+    \"phase0.set_state_val('gamma', [-1, -5], units='deg')\\n\",\n+    \"phase0.set_state_val('phi', [0, 75], units='deg')\\n\",\n+    \"phase0.set_state_val('psi', [90, 10], units='deg')\\n\",\n+    \"phase0.set_state_val('theta', [0, 25], units='deg')\\n\",\n+    \"phase0.set_state_val('v', [25600, 2500], units='ft/s')\\n\",\n+    \"\\n\",\n+    \"phase0.set_control_val('alpha', 17.4, units='deg')\\n\",\n+    \"phase0.set_control_val('beta', [-75, 0], units='deg')\\n\",\n     \"\\n\",\n     \"# Run the driver\\n\",\n     \"dm.run_problem(p, simulate=True)\"\ndiff --git a/docs/dymos_book/examples/robertson_problem/robertson_problem.ipynb b/docs/dymos_book/examples/robertson_problem/robertson_problem.ipynb\nindex d416a0cf9..73a7e287c 100644\n--- a/docs/dymos_book/examples/robertson_problem/robertson_problem.ipynb\n+++ b/docs/dymos_book/examples/robertson_problem/robertson_problem.ipynb\n@@ -240,7 +240,6 @@\n    ]\n   },\n   {\n-   \"attachments\": {},\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n@@ -297,12 +296,11 @@\n     \"    #\\n\",\n     \"    # Set the initial values\\n\",\n     \"    #\\n\",\n-    \"    p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"    p['traj.phase0.t_duration'] = t_final\\n\",\n     \"\\n\",\n-    \"    p.set_val('traj.phase0.initial_states:x0', 1.0)\\n\",\n-    \"    p.set_val('traj.phase0.initial_states:y0', 0.0)\\n\",\n-    \"    p.set_val('traj.phase0.initial_states:z0', 0.0)\\n\",\n+    \"    phase.set_time_val(initial=0.0, duration=t_final)\\n\",\n+    \"    phase.set_state_val('x0', [1.0, 0.7])\\n\",\n+    \"    phase.set_state_val('y0', [0.0, 1e-5])\\n\",\n+    \"    phase.set_state_val('z0', [0.0, 0.3])\\n\",\n     \"\\n\",\n     \"    return p\\n\"\n    ]\ndiff --git a/docs/dymos_book/examples/ssto_earth/ssto_earth.ipynb b/docs/dymos_book/examples/ssto_earth/ssto_earth.ipynb\nindex 9de6ed22a..3c7f98003 100644\n--- a/docs/dymos_book/examples/ssto_earth/ssto_earth.ipynb\n+++ b/docs/dymos_book/examples/ssto_earth/ssto_earth.ipynb\n@@ -323,14 +323,13 @@\n     \"#\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p.set_val('traj.phase0.t_initial', 0.0)\\n\",\n-    \"p.set_val('traj.phase0.t_duration', 150.0)\\n\",\n-    \"p.set_val('traj.phase0.states:x', phase.interp('x', [0, 1.15E5]))\\n\",\n-    \"p.set_val('traj.phase0.states:y', phase.interp('y', [0, 1.85E5]))\\n\",\n-    \"p.set_val('traj.phase0.states:vy', phase.interp('vy', [1.0E-6, 0]))\\n\",\n-    \"p.set_val('traj.phase0.states:m', phase.interp('m', [117000, 1163]))\\n\",\n-    \"p.set_val('traj.phase0.controls:theta', phase.interp('theta', [1.5, -0.76]))\\n\",\n-    \"p.set_val('traj.phase0.parameters:thrust', 2.1, units='MN')\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=150.0)\\n\",\n+    \"phase.set_state_val('x', [0, 1.15E5])\\n\",\n+    \"phase.set_state_val('y', [0, 1.85E5])\\n\",\n+    \"phase.set_state_val('vy', [1.0E-6, 0])\\n\",\n+    \"phase.set_state_val('m', [117000, 1163])\\n\",\n+    \"phase.set_control_val('theta', [1.5, -0.76])\\n\",\n+    \"phase.set_parameter_val('thrust', 2.1, units='MN')\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve the Problem\\n\",\n@@ -448,7 +447,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.5\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/ssto_moon_linear_tangent/ssto_moon_linear_tangent.ipynb b/docs/dymos_book/examples/ssto_moon_linear_tangent/ssto_moon_linear_tangent.ipynb\nindex b960506a7..3b6713ee6 100644\n--- a/docs/dymos_book/examples/ssto_moon_linear_tangent/ssto_moon_linear_tangent.ipynb\n+++ b/docs/dymos_book/examples/ssto_moon_linear_tangent/ssto_moon_linear_tangent.ipynb\n@@ -348,15 +348,14 @@\n     \"\\n\",\n     \"p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 500.0\\n\",\n-    \"p['traj.phase0.states:x'] = phase.interp('x', [0, 350000.0])\\n\",\n-    \"p['traj.phase0.states:y'] = phase.interp('y', [0, 185000.0])\\n\",\n-    \"p['traj.phase0.states:vx'] = phase.interp('vx', [0, 1627.0])\\n\",\n-    \"p['traj.phase0.states:vy'] = phase.interp('vy', [1.0E-6, 0])\\n\",\n-    \"p['traj.phase0.states:m'] = phase.interp('m', [50000, 50000])\\n\",\n-    \"p['traj.phase0.parameters:a_ctrl'] = -0.01\\n\",\n-    \"p['traj.phase0.parameters:b_ctrl'] = 3.0\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=500.0)\\n\",\n+    \"phase.set_state_val('x', [0, 350000.0])\\n\",\n+    \"phase.set_state_val('y', [0, 185000.0])\\n\",\n+    \"phase.set_state_val('vx', [0, 1627.0])\\n\",\n+    \"phase.set_state_val('vy', [1.0E-6, 0.0])\\n\",\n+    \"phase.set_state_val('m', 50000)\\n\",\n+    \"phase.set_parameter_val('a_ctrl', -0.01)\\n\",\n+    \"phase.set_parameter_val('b_ctrl', 3.0)\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, simulate=True)\"\n    ]\n@@ -497,7 +496,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.6\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/ssto_moon_polynomial_controls/ssto_moon_polynomial_controls.ipynb b/docs/dymos_book/examples/ssto_moon_polynomial_controls/ssto_moon_polynomial_controls.ipynb\nindex 974bb938a..3bda1da63 100644\n--- a/docs/dymos_book/examples/ssto_moon_polynomial_controls/ssto_moon_polynomial_controls.ipynb\n+++ b/docs/dymos_book/examples/ssto_moon_polynomial_controls/ssto_moon_polynomial_controls.ipynb\n@@ -333,14 +333,13 @@\n     \"#\\n\",\n     \"# Assign initial guesses for the independent variables in the problem.\\n\",\n     \"#\\n\",\n-    \"p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"p['traj.phase0.t_duration'] = 500.0\\n\",\n-    \"p['traj.phase0.states:x'] = phase.interp('x', [0, 350000.0])\\n\",\n-    \"p['traj.phase0.states:y'] = phase.interp('y', [0, 185000.0])\\n\",\n-    \"p['traj.phase0.states:vx'] = phase.interp('vx', [0, 1627.0])\\n\",\n-    \"p['traj.phase0.states:vy'] = phase.interp('vy', [1.0E-6, 0])\\n\",\n-    \"p['traj.phase0.states:m'] = phase.interp('m', [50000, 50000])\\n\",\n-    \"p['traj.phase0.polynomial_controls:tan_theta'] = [[0.5 * np.pi], [0.0]]\\n\",\n+    \"phase.set_time_val(initial=0.0, duration=500.0)\\n\",\n+    \"phase.set_state_val('x', [0, 350000.0])\\n\",\n+    \"phase.set_state_val('y', [0, 185000.0])\\n\",\n+    \"phase.set_state_val('vx', [0, 1627.0])\\n\",\n+    \"phase.set_state_val('vy', [1.0E-6, 0.0])\\n\",\n+    \"phase.set_state_val('m', 50000)\\n\",\n+    \"phase.set_polynomial_control_val('tan_theta', [[0.5 * np.pi], [0.0]])\\n\",\n     \"\\n\",\n     \"#\\n\",\n     \"# Solve the problem.\\n\",\n@@ -460,7 +459,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/vanderpol/vanderpol.ipynb b/docs/dymos_book/examples/vanderpol/vanderpol.ipynb\nindex fe66eb2b5..953271139 100644\n--- a/docs/dymos_book/examples/vanderpol/vanderpol.ipynb\n+++ b/docs/dymos_book/examples/vanderpol/vanderpol.ipynb\n@@ -332,14 +332,13 @@\n     \"    # setup the problem\\n\",\n     \"    p.setup(check=True)\\n\",\n     \"\\n\",\n-    \"    p['traj.phase0.t_initial'] = 0.0\\n\",\n-    \"    p['traj.phase0.t_duration'] = t_final\\n\",\n+    \"    phase.set_time_val(0.0, t_final)\\n\",\n     \"\\n\",\n     \"    # add a linearly interpolated initial guess for the state and control curves\\n\",\n-    \"    p['traj.phase0.states:x0'] = phase.interp('x0', [0, 0])\\n\",\n-    \"    p['traj.phase0.states:x1'] = phase.interp('x1', [1, 0])\\n\",\n-    \"    p['traj.phase0.states:J'] = phase.interp('J', [0, 1])\\n\",\n-    \"    p['traj.phase0.controls:u'] = phase.interp('u', [0, 0])\\n\",\n+    \"    phase.set_state_val('x0', [1, 0])\\n\",\n+    \"    phase.set_state_val('x0', [1, 0])\\n\",\n+    \"    phase.set_state_val('x0', [0, 1])\\n\",\n+    \"    phase.set_control_val('u', -0.75)\\n\",\n     \"\\n\",\n     \"    return p\"\n    ]\n@@ -559,7 +558,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.7\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/docs/dymos_book/examples/water_rocket/water_rocket.ipynb b/docs/dymos_book/examples/water_rocket/water_rocket.ipynb\nindex 4ccafcbd2..8cb2bfcb0 100644\n--- a/docs/dymos_book/examples/water_rocket/water_rocket.ipynb\n+++ b/docs/dymos_book/examples/water_rocket/water_rocket.ipynb\n@@ -98,7 +98,6 @@\n    ]\n   },\n   {\n-   \"attachments\": {},\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n@@ -162,19 +161,19 @@\n    ]\n   },\n   {\n-    \"cell_type\": \"code\",\n-    \"execution_count\": null,\n-    \"metadata\": {\n-     \"tags\": [\n-      \"active-ipynb\",\n-      \"remove-input\",\n-      \"remove-output\"\n-     ]\n-    },\n-    \"outputs\": [],\n-    \"source\": [\n-     \"%matplotlib inline\"\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {\n+    \"tags\": [\n+     \"active-ipynb\",\n+     \"remove-input\",\n+     \"remove-output\"\n     ]\n+   },\n+   \"outputs\": [],\n+   \"source\": [\n+    \"%matplotlib inline\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -619,7 +618,7 @@\n     \"p.model.linear_solver = om.DirectSolver()\\n\",\n     \"\\n\",\n     \"p.setup()\\n\",\n-    \"set_sane_initial_guesses(p, phases)\\n\",\n+    \"set_sane_initial_guesses(phases)\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, run_driver=True, simulate=True)\\n\",\n     \"\\n\",\n@@ -736,7 +735,7 @@\n     \"p.model.linear_solver = om.DirectSolver()\\n\",\n     \"\\n\",\n     \"p.setup()\\n\",\n-    \"set_sane_initial_guesses(p, phases)\\n\",\n+    \"set_sane_initial_guesses(phases)\\n\",\n     \"\\n\",\n     \"dm.run_problem(p, run_driver=True, simulate=True)\\n\",\n     \"\\n\",\n@@ -831,6 +830,13 @@\n     \":filter: docname in docnames\\n\",\n     \"```\"\n    ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": []\n   }\n  ],\n  \"metadata\": {\n@@ -858,7 +864,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.6\"\n+   \"version\": \"3.11.0\"\n   }\n  },\n  \"nbformat\": 4,\ndiff --git a/dymos/examples/finite_burn_orbit_raise/finite_burn_orbit_raise_problem.py b/dymos/examples/finite_burn_orbit_raise/finite_burn_orbit_raise_problem.py\nindex 3d02cb01b..d6d9e9a92 100644\n--- a/dymos/examples/finite_burn_orbit_raise/finite_burn_orbit_raise_problem.py\n+++ b/dymos/examples/finite_burn_orbit_raise/finite_burn_orbit_raise_problem.py\n@@ -242,58 +242,51 @@ def two_burn_orbit_raise_problem(transcription='gauss-lobatto', optimizer='SLSQP\n     p.setup(check=True)\n \n     # Set Initial Guesses\n-    p.set_val('traj.parameters:c', val=1.5, units='DU/TU')\n+    traj.set_parameter_val('c', val=1.5, units='DU/TU')\n \n     burn1 = p.model.traj.phases.burn1\n     burn2 = p.model.traj.phases.burn2\n     coast = p.model.traj.phases.coast\n \n     if burn1 in p.model.traj.phases._subsystems_myproc:\n-        p.set_val('traj.burn1.t_initial', val=0.0)\n-        p.set_val('traj.burn1.t_duration', val=2.25)\n-        p.set_val('traj.burn1.states:r', val=burn1.interp('r', [1, 1.5]))\n-        p.set_val('traj.burn1.states:theta', val=burn1.interp('theta', [0, 1.7]))\n-        p.set_val('traj.burn1.states:vr', val=burn1.interp('vr', [0, 0]))\n-        p.set_val('traj.burn1.states:vt', val=burn1.interp('vt', [1, 1]))\n-        p.set_val('traj.burn1.states:accel', val=burn1.interp('accel', [0.1, 0]))\n-        p.set_val('traj.burn1.states:deltav', val=burn1.interp('deltav', [0, 0.1]))\n-        p.set_val('traj.burn1.controls:u1', val=burn1.interp('u1', [-3.5, 13.0]))\n+        burn1.set_time_val(initial=0.0, duration=2.25)\n+        burn1.set_state_val('r', [1, 1.5])\n+        burn1.set_state_val('theta', [0, 1.7])\n+        burn1.set_state_val('vr', [0, 0])\n+        burn1.set_state_val('vt', [1, 1])\n+        burn1.set_state_val('accel', [0.1, 0.0])\n+        burn1.set_state_val('deltav', [0, 0.1])\n+        burn1.set_control_val('u1', [0.0, 0.0])\n \n     if coast in p.model.traj.phases._subsystems_myproc:\n-        p.set_val('traj.coast.t_initial', val=2.25)\n-        p.set_val('traj.coast.t_duration', val=3.0)\n-\n-        p.set_val('traj.coast.states:r', val=coast.interp('r', [1.3, 1.5]))\n-        p.set_val('traj.coast.states:theta', val=coast.interp('theta', [2.1767, 1.7]))\n-        p.set_val('traj.coast.states:vr', val=coast.interp('vr', [0.3285, 0]))\n-        p.set_val('traj.coast.states:vt', val=coast.interp('vt', [0.97, 1]))\n-        p.set_val('traj.coast.states:accel', val=coast.interp('accel', [0, 0]))\n-        p.set_val('traj.burn1.controls:u1', val=burn1.interp('u1', [0, 0]))\n+        coast.set_time_val(initial=2.25, duration=3.0)\n+        coast.set_state_val('r', [1.3, 1.5])\n+        coast.set_state_val('theta', [2.1767, 1.7])\n+        coast.set_state_val('vr', [0.3285, 0])\n+        coast.set_state_val('vt', [0.97, 1])\n+        coast.set_state_val('accel', [0, 0])\n+        coast.set_parameter_val('u1', 0)\n \n     if burn2 in p.model.traj.phases._subsystems_myproc:\n         if connected:\n-            p.set_val('traj.burn2.t_initial', val=7.0)\n-            p.set_val('traj.burn2.t_duration', val=-1.75)\n-\n-            p.set_val('traj.burn2.states:r', val=burn2.interp('r', [r_target, 1]))\n-            p.set_val('traj.burn2.states:theta', val=burn2.interp('theta', [4.0, 0.0]))\n-            p.set_val('traj.burn2.states:vr', val=burn2.interp('vr', [0, 0]))\n-            p.set_val('traj.burn2.states:vt', val=burn2.interp('vt', [np.sqrt(1 / r_target), 1]))\n-            p.set_val('traj.burn2.states:deltav', val=burn2.interp('deltav', [0.2, 0.1]))\n-            p.set_val('traj.burn2.states:accel', val=burn2.interp('accel', [0., 0.1]))\n-            p.set_val('traj.burn2.controls:u1', val=burn2.interp('u1', [0, 0]))\n+            burn2.set_time_val(initial=7.0, duration=-1.75)\n+            burn2.set_state_val('r', [r_target, 1])\n+            burn2.set_state_val('theta', [4, 0])\n+            burn2.set_state_val('vr', [0, 0])\n+            burn2.set_state_val('vt', [np.sqrt(1 / r_target), 1])\n+            burn2.set_state_val('accel', [0.0, 0.1])\n+            burn2.set_state_val('deltav', [0.2, 0.1])\n+            burn2.set_control_val('u1', [0, 0])\n \n         else:\n-            p.set_val('traj.burn2.t_initial', val=5.25)\n-            p.set_val('traj.burn2.t_duration', val=1.75)\n-\n-            p.set_val('traj.burn2.states:r', val=burn2.interp('r', [1, r_target]))\n-            p.set_val('traj.burn2.states:theta', val=burn2.interp('theta', [0, 4.0]))\n-            p.set_val('traj.burn2.states:vr', val=burn2.interp('vr', [0, 0]))\n-            p.set_val('traj.burn2.states:vt', val=burn2.interp('vt', [1, np.sqrt(1 / r_target)]))\n-            p.set_val('traj.burn2.states:deltav', val=burn2.interp('deltav', [0.1, 0.2]))\n-            p.set_val('traj.burn2.states:accel', val=burn2.interp('accel', [0.1, 0]))\n-            p.set_val('traj.burn2.controls:u1', val=burn2.interp('u1', [0, 0]))\n+            burn2.set_time_val(initial=5.25, duration=1.75)\n+            burn2.set_state_val('r', [1, r_target])\n+            burn2.set_state_val('theta', [0, 4])\n+            burn2.set_state_val('vr', [0, 0])\n+            burn2.set_state_val('vt', [1, np.sqrt(1 / r_target)])\n+            burn2.set_state_val('accel', [0.1, 0.0])\n+            burn2.set_state_val('deltav', [0.1, 0.2])\n+            burn2.set_control_val('u1', [0, 0])\n \n     if run_driver or simulate:\n         dm.run_problem(p, run_driver=run_driver, simulate=simulate, restart=restart, make_plots=True,\ndiff --git a/dymos/examples/robertson_problem/doc/robertson_ode.py b/dymos/examples/robertson_problem/robertson_ode.py\nsimilarity index 100%\nrename from dymos/examples/robertson_problem/doc/robertson_ode.py\nrename to dymos/examples/robertson_problem/robertson_ode.py\ndiff --git a/dymos/examples/robot_arm/robot_arm_ode.py b/dymos/examples/robot_arm/robot_arm_ode.py\nindex e3e183a17..a08c52233 100644\n--- a/dymos/examples/robot_arm/robot_arm_ode.py\n+++ b/dymos/examples/robot_arm/robot_arm_ode.py\n@@ -48,7 +48,6 @@ def setup(self):\n         self.declare_partials(of='x4_dot', wrt='x2', rows=r, cols=c)\n         self.declare_partials(of='x4_dot', wrt='x4', rows=r, cols=c, val=1.0)\n         self.declare_partials(of='x4_dot', wrt='u1', rows=r, cols=c)\n-        self.declare_partials(of='x4_dot', wrt='u2', rows=r, cols=c, val=0.0)\n \n         self.declare_partials(of='x5_dot', wrt='x0', rows=r, cols=c)\n         self.declare_partials(of='x5_dot', wrt='x5', rows=r, cols=c, val=1.0)\ndiff --git a/dymos/examples/vanderpol/vanderpol_dymos.py b/dymos/examples/vanderpol/vanderpol_dymos.py\nindex 26612dbfd..858527739 100644\n--- a/dymos/examples/vanderpol/vanderpol_dymos.py\n+++ b/dymos/examples/vanderpol/vanderpol_dymos.py\n@@ -78,14 +78,13 @@ def vanderpol(transcription='gauss-lobatto', num_segments=40, transcription_orde\n     # setup the problem\n     p.setup(check=True, force_alloc_complex=True)\n \n-    p['traj.phase0.t_initial'] = 0.0\n-    p['traj.phase0.t_duration'] = t_final\n+    phase.set_time_val(0.0, t_final)\n \n     # add a linearly interpolated initial guess for the state and control curves\n-    p['traj.phase0.states:x0'] = phase.interp('x0', [1, 0])\n-    p['traj.phase0.states:x1'] = phase.interp('x1', [1, 0])\n-    p['traj.phase0.states:J'] = phase.interp('J', [0, 1])\n-    p['traj.phase0.controls:u'] = phase.interp('u', [-0.75, -0.75])\n+    phase.set_state_val('x0', [1, 0])\n+    phase.set_state_val('x0', [1, 0])\n+    phase.set_state_val('x0', [0, 1])\n+    phase.set_control_val('u', -0.75)\n \n     return p\n \ndiff --git a/dymos/examples/water_rocket/phases.py b/dymos/examples/water_rocket/phases.py\nindex ffd0fc6b9..43cd63ef6 100644\n--- a/dymos/examples/water_rocket/phases.py\n+++ b/dymos/examples/water_rocket/phases.py\n@@ -162,51 +162,31 @@ def new_water_rocket_trajectory(objective):\n                   'descent': descent}\n \n \n-def set_sane_initial_guesses(problem, phases):\n-    p = problem\n-    # Set Initial Guesses\n-    p.set_val('traj.propelled_ascent.t_initial', 0.0)\n-    p.set_val('traj.propelled_ascent.t_duration', 0.3)\n+def set_sane_initial_guesses(phases):\n+    propelled_ascent = phases['propelled_ascent']\n+    ballistic_ascent = phases['ballistic_ascent']\n+    descent = phases['descent']\n \n-    p.set_val('traj.propelled_ascent.states:r',\n-              phases['propelled_ascent'].interp('r', [0, 3]))\n-    p.set_val('traj.propelled_ascent.states:h',\n-              phases['propelled_ascent'].interp('h', [0, 10]))\n+    # Set Initial Guesses\n+    propelled_ascent.set_time_val(initial=0.0, duration=0.3)\n+    propelled_ascent.set_state_val('r', [0, 3])\n+    propelled_ascent.set_state_val('h', [0, 10])\n     # Set initial value for velocity as non-zero to avoid undefined EOM\n-    p.set_val('traj.propelled_ascent.states:v',\n-              phases['propelled_ascent'].interp('v', [0.1, 100]))\n-    p.set_val('traj.propelled_ascent.states:gam',\n-              phases['propelled_ascent'].interp('gam', [80, 80]),\n-              units='deg')\n-    p.set_val('traj.propelled_ascent.states:V_w',\n-              phases['propelled_ascent'].interp('V_w', [9, 0]),\n-              units='L')\n-    p.set_val('traj.propelled_ascent.states:p',\n-              phases['propelled_ascent'].interp('p', [6.5, 3.5]),\n-              units='bar')\n-\n-    p.set_val('traj.ballistic_ascent.t_initial', 0.3)\n-    p.set_val('traj.ballistic_ascent.t_duration', 5)\n-\n-    p.set_val('traj.ballistic_ascent.states:r',\n-              phases['ballistic_ascent'].interp('r', [0, 10]))\n-    p.set_val('traj.ballistic_ascent.states:h',\n-              phases['ballistic_ascent'].interp('h', [10, 100]))\n-    p.set_val('traj.ballistic_ascent.states:v',\n-              phases['ballistic_ascent'].interp('v', [60, 20]))\n-    p.set_val('traj.ballistic_ascent.states:gam',\n-              phases['ballistic_ascent'].interp('gam', [80, 0]),\n-              units='deg')\n-\n-    p.set_val('traj.descent.t_initial', 10.0)\n-    p.set_val('traj.descent.t_duration', 10.0)\n-\n-    p.set_val('traj.descent.states:r',\n-              phases['descent'].interp('r', [10, 20]))\n-    p.set_val('traj.descent.states:h',\n-              phases['descent'].interp('h', [10, 0]))\n-    p.set_val('traj.descent.states:v',\n-              phases['descent'].interp('v', [20, 60]))\n-    p.set_val('traj.descent.states:gam',\n-              phases['descent'].interp('gam', [0, -45]),\n-              units='deg')\n+    propelled_ascent.set_state_val('v', [0.1, 100])\n+    propelled_ascent.set_state_val('gam', [80, 80], units='deg')\n+    propelled_ascent.set_state_val('V_w', [9, 0], units='L')\n+    propelled_ascent.set_state_val('p', [6.5, 3.5], units='bar')\n+\n+    ballistic_ascent.set_time_val(initial=0.3, duration=5)\n+\n+    ballistic_ascent.set_state_val('r', [0, 10])\n+    ballistic_ascent.set_state_val('h', [10, 100])\n+    ballistic_ascent.set_state_val('v', [60, 20])\n+    ballistic_ascent.set_state_val('gam', [80, 0], units='deg')\n+\n+    descent.set_time_val(initial=10, duration=10)\n+\n+    descent.set_state_val('r', [10, 20])\n+    descent.set_state_val('h', [10, 0])\n+    descent.set_state_val('v', [20, 60])\n+    descent.set_state_val('gam', [0, -45], units='deg')\ndiff --git a/dymos/phase/phase.py b/dymos/phase/phase.py\nindex 8684f6211..e9a7b9259 100644\n--- a/dymos/phase/phase.py\n+++ b/dymos/phase/phase.py\n@@ -24,7 +24,7 @@\n \n from ..transcriptions.transcription_base import TranscriptionBase\n from ..transcriptions.grid_data import GaussLobattoGrid, RadauGrid, UniformGrid, BirkhoffGrid\n-from ..transcriptions import ExplicitShooting, GaussLobatto, Radau\n+from ..transcriptions import ExplicitShooting, GaussLobatto, Radau, Birkhoff\n from ..utils.indexing import get_constraint_flat_idxs\n from ..utils.introspection import configure_time_introspection, _configure_constraint_introspection, \\\n     configure_controls_introspection, configure_parameters_introspection, \\\n@@ -1854,6 +1854,145 @@ def set_time_options(self, units=_unspecified, fix_initial=_unspecified,\n         if name is not _unspecified:\n             self.time_options['name'] = name\n \n+    def set_time_val(self, initial=None, duration=None, units=None):\n+        \"\"\"\n+        Set the values for initial time and the duration of the phase.\n+\n+        Parameters\n+        ----------\n+        initial : float or None\n+            Value for the initial time.\n+        duration : float or None\n+            Value for the phase duration.\n+        units : str or None\n+            Units of the time. If none are specified, the default units are used.\n+        \"\"\"\n+        if units is None:\n+            units = self.time_options['units']\n+        if initial is not None:\n+            self.set_val('t_initial', initial, units=units)\n+        if duration is not None:\n+            self.set_val('t_duration', duration, units=units)\n+\n+    def set_state_val(self, name, vals=None, time_vals=None,\n+                      units=None, interpolation_kind='linear'):\n+        \"\"\"\n+        Set the necessary input values for state as appropriate for the specified transcription.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            Name of the variable. This should be a state variable.\n+        vals : ndarray or Sequence or float or None\n+            Array of state values.\n+        time_vals :  ndarray or Sequence or None\n+            Array of integration variable values.\n+        units : str, optional\n+            The units of the state values specified.\n+            If None, use the units associated with the target.\n+            If provided, must be compatible with the target units.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+        \"\"\"\n+        transcription = self.options['transcription']\n+        input_data_to_set = transcription._phase_set_state_val(self, name,\n+                                                               vals, time_vals,\n+                                                               interpolation_kind)\n+        if units is None:\n+            units = self.state_options[name]['units']\n+        for var, value in input_data_to_set.items():\n+            self.set_val(var, value, units=units)\n+\n+    def set_control_val(self, name, vals=None, time_vals=None,\n+                        units=None, interpolation_kind='linear'):\n+        \"\"\"\n+        Set the control values as appropriate.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            Name of the variable. This should be a control variable.\n+        vals : ndarray or Sequence or None\n+            Array of state values.\n+        time_vals :  ndarray or Sequence or None\n+            Array of integration variable values.\n+        units : str, optional\n+            The units of the state values specified.\n+            If None, use the units associated with the target.\n+            If provided, must be compatible with the target units.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+        \"\"\"\n+        if np.isscalar(vals):\n+            val = vals\n+        else:\n+            val = self.interp(name, ys=vals, xs=time_vals, nodes='control_input', kind=interpolation_kind)\n+        if units is None:\n+            units = self.control_options[name]['units']\n+        self.set_val(f'controls:{name}', val=val, units=units)\n+\n+    def set_polynomial_control_val(self, name, vals=None, time_vals=None,\n+                                   units=None, interpolation_kind='linear'):\n+        \"\"\"\n+        Set the polynomial control values as appropriate.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            Name of the variable. This should be a polynomial control variable.\n+        vals : ndarray or Sequence or None\n+            Array of state values.\n+        time_vals :  ndarray or Sequence or None\n+            Array of integration variable values.\n+        units : str, optional\n+            The units of the state values specified.\n+            If None, use the units associated with the target.\n+            If provided, must be compatible with the target units.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+        \"\"\"\n+        if np.isscalar(vals):\n+            val = vals\n+        else:\n+            val = self.interp(name, ys=vals, xs=time_vals, kind=interpolation_kind)\n+        if units is None:\n+            units = self.polynomial_control_options[name]['units']\n+        self.set_val(f'polynomial_controls:{name}', val=val, units=units)\n+\n+    def set_parameter_val(self, name, val=None, units=None):\n+        \"\"\"\n+        Set the parameter values.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            Name of the variable. This should be a parameter variable.\n+        val : ndarray or Sequence or None\n+            Array of state values.\n+        units : str, optional\n+            The units of the state values specified.\n+            If None, use the units associated with the target.\n+            If provided, must be compatible with the target units.\n+        \"\"\"\n+        if units is None:\n+            units = self.parameter_options[name]['units']\n+        self.set_val(f'parameters:{name}', val=val, units=units)\n+\n     def set_duration_balance(self, name, val=0.0, index=None, units=None, mult_val=None, normalize=False):\n         \"\"\"\n         Adds a condition for the duration of the phase. This is satisfied using a nonlinear solver.\n@@ -2395,7 +2534,7 @@ def get_simulation_phase(self, times_per_seg=_unspecified, method=_unspecified,\n                 isinstance(self_tx.grid_data, RadauGrid) or isinstance(self_tx.grid_data, BirkhoffGrid):\n             grid = self_tx.grid_data\n         else:\n-            raise RuntimeError(f'Unexpected grid class for {phase_tx.grid_data}. Only phases with GaussLobatto '\n+            raise RuntimeError(f'Unexpected grid class for {self_tx.grid_data}. Only phases with GaussLobatto '\n                                f'or Radau grids can be simulated.')\n \n         if _times_per_seg is None:\ndiff --git a/dymos/trajectory/trajectory.py b/dymos/trajectory/trajectory.py\nindex 0f4c12db1..de75e851c 100644\n--- a/dymos/trajectory/trajectory.py\n+++ b/dymos/trajectory/trajectory.py\n@@ -288,6 +288,25 @@ def add_parameter(self, name, units=_unspecified, val=_unspecified, desc=_unspec\n                                    upper=upper, scaler=scaler, adder=adder, ref0=ref0, ref=ref, shape=shape,\n                                    dynamic=dynamic, static_target=static_target)\n \n+    def set_parameter_val(self, name, val=None, units=None):\n+        \"\"\"\n+        Set the parameter values.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            Name of the variable. This should be a parameter variable.\n+        val : ndarray or Sequence or None\n+            Array of state values.\n+        units : str, optional\n+            The units of the state values specified.\n+            If None, use the units associated with the target.\n+            If provided, must be compatible with the target units.\n+        \"\"\"\n+        if units is None:\n+            units = self.parameter_options[name]['units']\n+        self.set_val(f'parameters:{name}', val=val, units=units)\n+\n     def _setup_parameters(self):\n         \"\"\"\n         Adds an IndepVarComp if necessary and issues appropriate connections based\ndiff --git a/dymos/transcriptions/explicit_shooting/explicit_shooting.py b/dymos/transcriptions/explicit_shooting/explicit_shooting.py\nindex 8bcf7b77c..c5d366773 100644\n--- a/dymos/transcriptions/explicit_shooting/explicit_shooting.py\n+++ b/dymos/transcriptions/explicit_shooting/explicit_shooting.py\n@@ -977,3 +977,40 @@ def _get_timeseries_var_source(self, var, output_name, phase):\n         meta['shape'] = src_shape\n \n         return meta\n+\n+    def _phase_set_state_val(self, phase, name, vals, time_vals=None, interpolation_kind=None):\n+        \"\"\"\n+        Method to interpolate the provided input and return the variables that need to be set\n+        along with their appropriate value.\n+\n+        Parameters\n+        ----------\n+        phase : dymos.Phase\n+            The phase to which this transcription applies.\n+        name : str\n+            The name of the phase variable to be set.\n+        vals : ndarray or Sequence or float\n+            Array of control/state/parameter values.\n+        time_vals : ndarray or Sequence or None\n+            Array of integration variable values.\n+        interpolation_kind : str or None\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+\n+        Returns\n+        -------\n+        input_data : dict\n+            Dict containing the values that need to be set in the phase\n+\n+        \"\"\"\n+        if np.isscalar(vals):\n+            val = vals\n+        else:\n+            val = vals[0]\n+        input_data = {f'initial_states:{name}': val}\n+\n+        return input_data\ndiff --git a/dymos/transcriptions/pseudospectral/birkhoff.py b/dymos/transcriptions/pseudospectral/birkhoff.py\nindex 3cfbdc693..6e1ffbbed 100644\n--- a/dymos/transcriptions/pseudospectral/birkhoff.py\n+++ b/dymos/transcriptions/pseudospectral/birkhoff.py\n@@ -882,3 +882,47 @@ def _requires_continuity_constraints(self, phase):\n         any_rate_continuity = any_rate_continuity and num_seg > 1\n \n         return any_state_continuity, any_control_continuity, any_rate_continuity\n+\n+    def _phase_set_state_val(self, phase, name, vals, time_vals, interpolation_kind):\n+        \"\"\"\n+        Method to interpolate the provided input and return the variables that need to be set\n+        along with their appropriate value.\n+\n+        Parameters\n+        ----------\n+        phase : dymos.Phase\n+            The phase to which this transcription applies.\n+        name : str\n+            The name of the phase variable to be set.\n+        vals : ndarray or Sequence or float\n+            Array of control/state/parameter values.\n+        time_vals : ndarray or Sequence or None\n+            Array of integration variable values.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+\n+        Returns\n+        -------\n+        input_data : dict\n+            Dict containing the values that need to be set in the phase\n+\n+        \"\"\"\n+        input_data = {}\n+        if np.isscalar(vals):\n+            input_data[f'states:{name}'] = vals\n+            input_data[f'initial_states:{name}'] = vals\n+            input_data[f'final_states:{name}'] = vals\n+        else:\n+            interp_vals = phase.interp(name, vals, time_vals,\n+                                       nodes='state_input',\n+                                       kind=interpolation_kind)\n+            input_data[f'states:{name}'] = interp_vals\n+            input_data[f'initial_states:{name}'] = vals[0]\n+            input_data[f'final_states:{name}'] = vals[-1]\n+\n+        return input_data\ndiff --git a/dymos/transcriptions/pseudospectral/pseudospectral_base.py b/dymos/transcriptions/pseudospectral/pseudospectral_base.py\nindex 411440065..5c1e9a05b 100644\n--- a/dymos/transcriptions/pseudospectral/pseudospectral_base.py\n+++ b/dymos/transcriptions/pseudospectral/pseudospectral_base.py\n@@ -672,3 +672,44 @@ def _get_num_timeseries_nodes(self):\n             The number of nodes in the default timeseries for this transcription.\n         \"\"\"\n         return self.grid_data.num_nodes\n+\n+    def _phase_set_state_val(self, phase, name, vals, time_vals, interpolation_kind):\n+        \"\"\"\n+        Method to interpolate the provided input and return the variables that need to be set\n+        along with their appropriate value.\n+\n+        Parameters\n+        ----------\n+        phase : dymos.Phase\n+            The phase to which this transcription applies.\n+        name : str\n+            The name of the phase variable to be set.\n+        vals : ndarray or Sequence or float\n+            Array of control/state/parameter values.\n+        time_vals : ndarray or Sequence or None\n+            Array of integration variable values.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+\n+        Returns\n+        -------\n+        input_data : dict\n+            Dict containing the values that need to be set in the phase\n+\n+        \"\"\"\n+\n+        input_data = {}\n+        if np.isscalar(vals):\n+            interp_vals = vals\n+        else:\n+            interp_vals = phase.interp(name, vals, time_vals,\n+                                       nodes='state_input',\n+                                       kind=interpolation_kind)\n+        input_data[f'states:{name}'] = interp_vals\n+\n+        return input_data\ndiff --git a/dymos/transcriptions/transcription_base.py b/dymos/transcriptions/transcription_base.py\nindex adb8f5f87..0f13ff99b 100644\n--- a/dymos/transcriptions/transcription_base.py\n+++ b/dymos/transcriptions/transcription_base.py\n@@ -776,6 +776,38 @@ def _requires_continuity_constraints(self, phase):\n         raise NotImplementedError(f'The transcription {self.__class__} does not provide an '\n                                   f'implementation of _requires_continuity_constraints')\n \n+    def _phase_set_state_val(self, phase, name, vals, times, interpolation_kind):\n+        \"\"\"\n+        Method to interpolate the provided input and return the variables that need to be set\n+        along with their appropriate value.\n+\n+        Parameters\n+        ----------\n+        phase : dymos.Phase\n+            The phase to which this transcription applies.\n+        name : str\n+            The name of the phase variable to be set.\n+        vals : ndarray or Sequence or float\n+            Array of control/state/parameter values.\n+        times : ndarray or Sequence or None\n+            Array of integration variable values.\n+        interpolation_kind : str\n+            Specifies the kind of interpolation, as per the scipy.interpolate package.\n+            One of ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'\n+            where 'zero', 'slinear', 'quadratic' and 'cubic' refer to a spline\n+            interpolation of zeroth, first, second or third order) or as an\n+            integer specifying the order of the spline interpolator to use.\n+            Default is 'linear'.\n+\n+        Returns\n+        -------\n+        input_data : dict\n+            Dict containing the values that need to be set in the phase\n+\n+        \"\"\"\n+        raise NotImplementedError(f'Transcription {self.__class__.__name__} does not implement method '\n+                                  '_phase_set_val.')\n+\n     def _get_num_timeseries_nodes(self):\n         \"\"\"\n         Returns the number of nodes in the default timeseries for this transcription.\ndiff --git a/dymos/utils/introspection.py b/dymos/utils/introspection.py\nindex 775fa29bc..2dc4dca4f 100644\n--- a/dymos/utils/introspection.py\n+++ b/dymos/utils/introspection.py\n@@ -569,7 +569,7 @@ def configure_states_introspection(state_options, time_options, control_options,\n                     options['shape'] = shape[1:]\n \n             if any(['dymos.static_target' in meta['tags'] for meta in targets.values()]):\n-                raise ValueError(f\"State '{name}' cannot be connected to its targets because one \"\n+                raise ValueError(f\"State '{state_name}' cannot be connected to its targets because one \"\n                                  f\"or more targets are tagged with 'dymos.static_target'.\")\n \n         # 3. Attempt rate-source introspection\n", "instance_id": "OpenMDAO__dymos-1072", "clarity": 2, "difficulty": 0.65, "clarity_explanation": "The problem statement is mostly clear in describing the goal of unifying the method for setting state values across different transcriptions in a trajectory optimization library (Dymos). It identifies the current inconsistencies in setting state values for different transcription methods (Gauss-Lobatto, Radau-PS, Explicit Shooting, and Birkhoff) and proposes a unified API with methods like `set_state_val`, `set_control_val`, etc., to simplify the process. The input and output expectations for the proposed methods are outlined with method signatures, which provide a good starting point. However, there are minor ambiguities and missing details: the problem statement lacks specific examples of usage (despite a placeholder for an example section), does not explicitly address potential edge cases or constraints for the new methods, and does not clarify how the unification handles underlying differences in transcription implementations. Additionally, the impact on existing users or backward compatibility is not discussed. These gaps prevent it from being fully comprehensive, but the intent and scope are sufficiently clear for a developer familiar with the domain.", "difficulty_explanation": "The difficulty of this problem falls into the \"Hard\" category due to several factors. First, the scope of code changes is significant, as evidenced by the extensive diff across multiple files, including documentation updates, example modifications, and core library changes in the `Phase` and `Trajectory` classes. This indicates that the solution impacts a broad part of the codebase, requiring modifications in multiple modules (e.g., `phase.py`, `trajectory.py`, various transcription implementations, and numerous example files). Second, it requires a deep understanding of the Dymos library's architecture, particularly how different transcription methods (Gauss-Lobatto, Radau, Explicit Shooting, Birkhoff) handle state and control values internally, as the solution must abstract these differences into a unified API. This involves understanding complex concepts like interpolation methods, transcription-specific grid data, and the interaction between states, controls, and parameters. Third, the implementation introduces new methods (`set_state_val`, `set_control_val`, etc.) that must handle various input scenarios and delegate appropriately to transcription-specific logic, which adds complexity in terms of ensuring correctness and maintaining performance. While edge case handling is not explicitly detailed in the problem statement, the code changes suggest considerations for scalar vs. array inputs and interpolation, which implies some error handling logic is needed. However, this is not at the \"Very Hard\" level (0.8-1.0) because it does not appear to require advanced domain-specific knowledge beyond trajectory optimization or system-level redesign; it is more of a significant refactoring and abstraction task within an existing framework. A score of 0.65 reflects the need for deep codebase familiarity, complex multi-file changes, and careful handling of transcription differences, but not the highest level of technical challenge.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.65}
{"problem_statement": "ECR gates returned by the Qiskit transpiler service aren't parsed as gates of type ECR\nAfter some offline discussion, we have discovered that the gates returned by the service in QASM as `'ecr'` gates are not properly parsed by the client so their type is `Gate` instead of `ECRGate`. This is related to using OpenQASM2 and OpenQASM3 instead of a proper way of serializing such as using QPY https://docs.quantum.ibm.com/api/qiskit/qpy\r\n\r\nNot using the proper type for ECRGate(s) has side-effects when executing the circuits via primitives.\n", "patch": "diff --git a/qiskit_ibm_transpiler/wrappers/__init__.py b/qiskit_ibm_transpiler/wrappers/__init__.py\nindex 8e88539..46b1cc3 100644\n--- a/qiskit_ibm_transpiler/wrappers/__init__.py\n+++ b/qiskit_ibm_transpiler/wrappers/__init__.py\n@@ -34,4 +34,4 @@\n from .ai_routing import AIRoutingAPI\n from .ai_synthesis import AICliffordAPI, AILinearFunctionAPI, AIPermutationAPI\n from .base import BackendTaskError, QiskitTranspilerService\n-from .transpile import TranspileAPI, _get_circuit_from_result\n+from .transpile import TranspileAPI, _get_circuit_from_result, _get_circuit_from_qasm\ndiff --git a/qiskit_ibm_transpiler/wrappers/transpile.py b/qiskit_ibm_transpiler/wrappers/transpile.py\nindex 17b8eaf..b52cd8b 100644\n--- a/qiskit_ibm_transpiler/wrappers/transpile.py\n+++ b/qiskit_ibm_transpiler/wrappers/transpile.py\n@@ -15,7 +15,8 @@\n \n import numpy as np\n from qiskit import QuantumCircuit, QuantumRegister, qasm2, qasm3\n-from qiskit.circuit import QuantumCircuit, QuantumRegister, Qubit\n+from qiskit.circuit import QuantumCircuit, QuantumRegister, Qubit, library\n+from qiskit.transpiler.basepasses import TransformationPass\n from qiskit.qasm2 import QASM2ExportError, QASM2ParseError\n from qiskit.transpiler import TranspileLayout\n from qiskit.transpiler.layout import Layout\n@@ -193,11 +194,25 @@ def _create_transpile_layout(initial, final, circuit, orig_circuit):\n     )\n \n \n-def _get_circuit_from_qasm(qasm_string):\n+class FixECR(TransformationPass):\n+    def run(self, dag):\n+        for node in dag.named_nodes(\"ecr\"):\n+            dag.substitute_node(node, library.ECRGate())\n+        return dag\n+\n+\n+def _get_circuit_from_qasm(qasm_string: str):\n     try:\n         return qasm2.loads(\n             qasm_string,\n-            custom_instructions=qasm2.LEGACY_CUSTOM_INSTRUCTIONS,\n+            custom_instructions=_get_circuit_from_qasm.QISKIT_INSTRUCTIONS,\n         )\n     except QASM2ParseError:\n-        return qasm3.loads(qasm_string)\n+        return _get_circuit_from_qasm.fix_ecr(qasm3.loads(qasm_string))\n+\n+\n+_get_circuit_from_qasm.QISKIT_INSTRUCTIONS = list(qasm2.LEGACY_CUSTOM_INSTRUCTIONS)\n+_get_circuit_from_qasm.QISKIT_INSTRUCTIONS.append(\n+    qasm2.CustomInstruction(\"ecr\", 0, 2, library.ECRGate)\n+)\n+_get_circuit_from_qasm.fix_ecr = FixECR()\n", "instance_id": "Qiskit__qiskit-ibm-transpiler-63", "clarity": 2, "difficulty": 0.45, "clarity_explanation": "The problem statement is mostly clear in identifying the core issue: ECR gates returned by the Qiskit transpiler service are not parsed correctly as `ECRGate` type, resulting in them being treated as generic `Gate` objects, which causes side effects when executing circuits via primitives. It also provides context by mentioning the use of OpenQASM2 and OpenQASM3 versus a more robust serialization method like QPY. However, there are minor ambiguities and missing details. For instance, the statement does not specify the exact side effects caused by the incorrect gate type, nor does it provide examples of input/output or constraints for the fix. Additionally, it lacks clarity on whether this issue affects specific versions of Qiskit or particular use cases. While the intent is understandable, these missing details prevent it from being comprehensive.", "difficulty_explanation": "The difficulty of this problem falls in the medium range due to several factors. First, the scope of code changes is relatively contained, primarily affecting two files (`__init__.py` and `transpile.py`) within the Qiskit IBM transpiler wrappers. The changes involve modifying the parsing logic for QASM strings to correctly handle ECR gates by introducing a custom transformation pass (`FixECR`) and updating the custom instruction set for QASM parsing. This requires a moderate understanding of Qiskit\u2019s internal APIs, specifically the `qasm2` and `qasm3` parsing mechanisms, the `TransformationPass` class, and the gate library (`library.ECRGate`). The technical concepts involved include familiarity with quantum computing gate representations, Qiskit\u2019s circuit and transpiler architecture, and custom instruction handling in QASM parsing, which are moderately complex for someone not deeply familiar with the Qiskit framework. The changes do not significantly impact the broader system architecture but do require careful handling to ensure compatibility with existing code. Edge cases are not explicitly mentioned in the problem statement, but the code changes suggest a need to handle different QASM parsing scenarios (e.g., falling back to QASM3 if QASM2 fails), which adds a slight layer of complexity. Overall, this problem requires understanding multiple concepts and making targeted but non-trivial modifications, justifying a score of 0.45 in the medium difficulty range.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.45}
{"problem_statement": "[feature request] accept sizes in Mi, Gi\n### What change would you like to see?\n\nAny configuration accepting MB and GB should accept Mi and Gi too.\n\n### How would implementing this improve `pydistcheck`?\n\nPyPI expresses file limits in these terms. Accepting them in `pydistcheck` would make it a bit easier to use this tool as a way to prevent going over those limits.\n\n### Notes\n\nSee the k8s docs for some guidance on spelling these units.\n", "patch": "diff --git a/src/pydistcheck/cli.py b/src/pydistcheck/cli.py\nindex 263c6a8..0c33e10 100644\n--- a/src/pydistcheck/cli.py\n+++ b/src/pydistcheck/cli.py\n@@ -126,12 +126,15 @@ class ExitCodes:\n     show_default=True,\n     type=str,\n     help=(\n-        \"maximum allowed compressed size, a string like '1.5M' indicating\"\n+        \"maximum allowed compressed size, a string like '1.5MB' indicating\"\n         \" '1.5 megabytes'. Supported units:\\n\"\n         \"  - B = bytes\\n\"\n-        \"  - K = kilobytes\\n\"\n-        \"  - M = megabytes\\n\"\n-        \"  - G = gigabytes\"\n+        \"  - KB = kilobytes\\n\"\n+        \"  - K, Ki = kibibytes\\n\"\n+        \"  - MB = megabytes\\n\"\n+        \"  - M, Mi = mebibytes\\n\"\n+        \"  - GB = gigabytes\\n\"\n+        \"  - G, Gi = gibibytes\"\n     ),\n )\n @click.option(\n@@ -140,12 +143,15 @@ class ExitCodes:\n     show_default=True,\n     type=str,\n     help=(\n-        \"maximum allowed uncompressed size, a string like '1.5M' indicating\"\n+        \"maximum allowed uncompressed size, a string like '1.5MB' indicating\"\n         \" '1.5 megabytes'. Supported units:\\n\"\n         \"  - B = bytes\\n\"\n-        \"  - K = kilobytes\\n\"\n-        \"  - M = megabytes\\n\"\n-        \"  - G = gigabytes\"\n+        \"  - KB = kilobytes\\n\"\n+        \"  - K, Ki = kibibytes\\n\"\n+        \"  - MB = megabytes\\n\"\n+        \"  - M, Mi = mebibytes\\n\"\n+        \"  - GB = gigabytes\\n\"\n+        \"  - G, Gi = gibibytes\"\n     ),\n )\n @click.option(\ndiff --git a/src/pydistcheck/utils.py b/src/pydistcheck/utils.py\nindex f630859..b04843c 100644\n--- a/src/pydistcheck/utils.py\n+++ b/src/pydistcheck/utils.py\n@@ -5,7 +5,23 @@\n \n from typing import Tuple\n \n-_UNIT_TO_NUM_BYTES = {\"B\": 1, \"K\": 1024, \"M\": 1024**2, \"G\": 1024**3}\n+# references:\n+#\n+#   * https://physics.nist.gov/cuu/Units/binary.html\n+#   * https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory\n+#\n+_UNIT_TO_NUM_BYTES = {\n+    \"b\": 1,\n+    \"k\": 1024,\n+    \"kb\": 1000,\n+    \"ki\": 1024,\n+    \"m\": 1024**2,\n+    \"mb\": 1000000,\n+    \"mi\": 1024**2,\n+    \"g\": 1024**3,\n+    \"gb\": 1000000000,\n+    \"gi\": 1024**3,\n+}\n \n \n def _recommend_size_str(num_bytes: int) -> Tuple[float, str]:\n@@ -35,7 +51,7 @@ def from_string(cls, size_str: str) -> \"_FileSize\":\n \n     @property\n     def total_size_bytes(self) -> int:\n-        return int(self._num * _UNIT_TO_NUM_BYTES[self._unit_str])\n+        return int(self._num * _UNIT_TO_NUM_BYTES[self._unit_str.lower()])\n \n     def __eq__(self, other: object) -> bool:\n         return (\n", "instance_id": "jameslamb__pydistcheck-277", "clarity": 2, "difficulty": 0.25, "clarity_explanation": "The problem statement is mostly clear in its intent: it requests the addition of support for \"Mi\" and \"Gi\" units alongside existing \"MB\" and \"GB\" units in the `pydistcheck` tool to align with PyPI's file size limits and Kubernetes documentation. The goal is straightforward, and the context (improving usability with PyPI limits) is provided. However, there are minor ambiguities and missing details. For instance, the problem statement does not explicitly define whether \"Mi\" and \"Gi\" should follow the binary (base-1024) or decimal (base-1000) interpretation, though the code changes imply binary. Additionally, there are no examples of input/output or specific edge cases mentioned (e.g., case sensitivity, invalid unit handling). While the reference to Kubernetes docs is helpful, it would have been better to explicitly clarify the expected behavior in the statement itself. Thus, it falls under \"Mostly Clear\" with minor details missing.", "difficulty_explanation": "The difficulty of this problem is relatively low, falling into the \"Easy\" range (0.2-0.4). Here's the breakdown based on the evaluation factors:\n\n1. **Scope and Depth of Code Changes:** The changes are localized to two files (`cli.py` and `utils.py`) and involve straightforward modifications. In `cli.py`, the help text for command-line options is updated to reflect the new units. In `utils.py`, the mapping of units to byte values in `_UNIT_TO_NUM_BYTES` is expanded to include the new units (\"Mi\", \"Gi\", etc.), and a minor adjustment is made to handle case insensitivity with `.lower()`. The changes do not impact the broader architecture of the system and are limited to a small amount of code.\n\n2. **Number of Technical Concepts:** The problem requires basic knowledge of Python string manipulation, dictionary usage, and command-line argument handling (via the `click` library). The concept of binary (kibibyte, mebibyte) vs. decimal (kilobyte, megabyte) units is introduced, but it is not complex for a developer with moderate experience. No advanced algorithms, design patterns, or domain-specific knowledge are needed beyond understanding file size units.\n\n3. **Edge Cases and Error Handling:** The problem statement does not explicitly mention edge cases, but the code changes introduce case insensitivity (via `.lower()`), which addresses potential user input variations. However, no additional error handling (e.g., for invalid units or malformed input) is added or required based on the diff. The edge cases are minimal and not complex.\n\n4. **Overall Complexity:** The task involves understanding a small part of the codebase (size parsing logic) and making simple updates to dictionaries and help text. It does not require deep knowledge of the overall system or intricate logic.\n\nGiven these factors, a difficulty score of 0.25 reflects an \"Easy\" problem that requires minimal effort and basic Python knowledge to implement. It is slightly above the \"Very Easy\" range due to the need to understand the distinction between binary and decimal units and ensure consistency in the implementation.", "clarity_label": 1, "difficulty_label": 1, "human_clarity": 2, "human_difficulty": 0.25}
